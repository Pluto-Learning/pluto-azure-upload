[
    {
        "id": "0",
        "title": "Title for Chunk 0",
        "content": "Confirming Pages\n127\n Chapter \n Chapter \n Parallel and Distributed \nComputing, Clusters, \nand Grids  \nIn this chapter: \n \n7.1 Introduction 127\n \n7.2 Key Concepts 128\n \n7.3 Parallel and Distributed Processing 128\n \n7.4 Distributed System Architectures  132\n \n7.5 How Operating System Concepts Differ in SMPs, Clusters, and Grids 138\n \n7.6 Examples 142\n \n7.7 Summary 147\n7.1 INTRODUCTION \n So far we have been discussing the designs of Operating Systems that run on a single \nmachine. But many systems are now designed for processing in situations where \nmany processors are used together. In this chapter we discuss computing on more \nthan one CPU and how we can manage such systems. There are several common \nconfigurations for multiple CPU systems, and many unusual ones. \n We start by introducing a few key concepts encountered in distributed process-\ning. Then, after covering these concepts, in Section 7.3 we introduce some theory \nabout computation and programming in parallel environments. Next, Section 7.4 \ncovers the common architectures found in distributed systems. OSs designed to \nrun in such environments have special concerns that do not arise in uniprocessing \nsituations, so in Section 7.5 we cover these OS issues. These topics include such \nquestions as what needs to be managed, how does resource management differ from \nuniprocessor systems, and what interfaces are presented to programmers and users. \nIn Section 7.6 we discuss some real systems that fit into this chapter and we close \nwith a summary in Section 7.7. \n 7  7 \nelm49810_ch07_127-148.indd   127\nelm49810_ch07_127-148.indd   127\n12/11/08   5:25:15 PM\n12/11/08   5:25:15 PM\n",
        "category": "Category"
    },
    {
        "id": "1",
        "title": "Title for Chunk 1",
        "content": "Rev. Confirming Pages\n128 \nPart 2 Building Operating Systems Incrementally: A Breadth-Oriented Spiral Approach\n 7.2 KEY CONCEPTS \n Moore\u2019s law recognized that computers will become more capable year after year. It \npredicts that CPUs double in transistor count every 18 to 24 months. Usually there has \nbeen a corresponding increase in CPU speed. Memory and disk capacities double at an \neven faster rate as well. Moore\u2019s law has been a fairly accurate rule-of-thumb for more \nthan three decades. In the last few years CPU speed has increased by exploiting paral-\nlelism inside the CPU chip; such techniques as pipelining, multiple execution units in \nthe CPU, and multicore integrated circuits have featured in the relentless pursuit of \nCPU speed. At the same time, they have all appeared transparent to the programmer. 1 \n Unfortunately, there is a rapidly approaching limit\u2014the speed of light, at 3 \u00b7 10 8 \nmeters per second. This means that at a clock speed of 3 Gigahertz (GHz) a signal \ncan travel only 10 centimeters in a vacuum between clock cycles, and significantly \nless distance in the silicon material that makes up an integrated circuit. Since CPUs \nare typically more than a centimeter across, this limits how much a CPU can do in \none clock cycle. Yet CPUs have been getting faster clocks and faster processing \nevery year. This forces computer architects to make CPUs do work in parallel (on \nthe chip) yet hide those implementation details from programmers and users (who \ndon\u2019t want to redesign and rewrite programs for each new CPU chip). We would \nlike to exploit parallelism in our computing problems on a higher level (parallel \ncomputing or clusters) as well, but this requires some modifications to the programs \nand enhancements to the OSs and the middleware. We describe those issues and \nhow one may take advantage of these hardware facilities through OSs and other \n(middleware) software.  \n 7.3 PARALLEL AND DISTRIBUTED PROCESSING \n It is common to use the term \u201cparallel\u201d to refer to work being done in multiple places \nsimultaneously. We have used the term parallel for that meaning, so far. There are several \npossible ways that we can configure multiple processors to provide parallelism. In this \nsection we briefly describe the differences. Later we discuss each one in greater detail. \n More precisely, we now describe parallel processing (or parallel computing) \nto refer to multiple processors sharing one big pool of memory and other resources \n(disks and printers, for example). This type of computer architecture is usually called \n multiprocessing  (MP). Today, most MP systems run under an OS that uses sym-\nmetric multiprocessing (SMP), as was discussed in Chapter 6 on Linux. While MP \ncomputers may have any number of CPUs sharing common memory, there are gen-\neral guidelines to most MPs:\n \ufffd CPUs share one common pool of memory, and any CPU may read or write any \nmemory location (even if it is being used by another CPU). \n \ufffd All CPUs are of the same type and speed. \n1 In this case \u201ctransparent\u201d only means that a program that will run correctly without them will still run \ncorrectly with them. It does not mean that a skillful programmer might not want to take advantage of \nthese features when extra performance is needed and the extra work is warranted. \nelm49810_ch07_127-148.indd   128\nelm49810_ch07_127-148.indd   128\n12/22/08   1:05:03 PM\n12/22/08   1:05:03 PM\n",
        "category": "Category"
    },
    {
        "id": "2",
        "title": "Title for Chunk 2",
        "content": "Rev. Confirming Pages\n \nChapter 7 Parallel and Distributed Computing, Clusters, and Grids \n129\n \ufffd All other computer resources (disks, networking, and printers) are shared among \nall the CPUs. \n \ufffd There is usually only one copy of the OS running, and it knows about all of the \nCPUs and shared resources. (It is much less common to have multiple OSs run-\nning or to have the OS running on only one CPU.) \n \ufffd Programs must be specially written or modified to take advantage of running on \nmultiple CPUs. \n \ufffd MPs may have two, four, or more (usually a power of two), but currently two- \nor four-processor (CPU) MPs offer the best performance per dollar, even better \nthan single-processor CPUs; and more than eight-processor MPs are expensive. \nMany rack-mounted systems are two- or four-processor MPs. For hardware rea-\nsons these rarely run over 64 CPUs in a single system. 2 \nOn the other hand, distributed computer systems:\n \ufffd don\u2019t share memory; \n \ufffd often have their own resources (such as disk drives); \n \ufffd communicate with each other through a network; \n \ufffd may not use the same hardware; and \n \ufffd run a separate copy of the OS on each machine. \nWhile sending a message (or sharing data) between computers in a distributed sys-\ntem may only take a few microseconds, it is usually at least a hundred times slower \nthan sharing memory on an MP system. There are several different classes of distrib-\nuted systems as well, and each class has unique performance characteristics. \n Clusters are a special class of distributed system. A cluster is comprised of indi-\nvidual computing nodes. These nodes may be single processors or MP systems. They \nare managed and protected from each other by special software and are connected \nover a dedicated LAN that is separate from other LANs connecting the cluster to \nother resources. Usually the cluster shares a single connection outside the cluster, \ncommonly to the Internet. Normally each cluster node has identical software and \nhardware to all other nodes in the cluster. It is possible, though less common, to build \nclusters from nonidentical nodes.  Clusters are usually administered by a single group \nof people (or person) and all login user names and passwords are identical for each \nnode in the cluster. This means that a user can run jobs on one or more nodes with a \nsingle user name and password. Nodes in clusters typically share storage resources \nutilizing  SAN ( storage area network ) and  NAS ( network attached storage) sys-\ntems. These are essentially marketing terms for a pool of disks operating as a single \nnetworked resource using protocols such as  NFS ( network file system ). Clusters \ntypically have multinode job schedulers running through designated \u201chead nodes,\u201d \nwhich allow jobs, queues, and workflows to be managed. One such scheduler,  PBS, \nor  portable batch system, is discussed later in Section 7.6.6. \n Grids (grid computer systems) are comprised of multiple workstations or clusters \nwith different administrators. As a result, they do not share resources directly, do not \n2 Some hardware configurations exist with a few thousand CPUs sharing memory. However the \narchitecture is not a completely shared memory. These systems are referred to as Non-Uniform Memory \nAccess (NUMA) systems, and not the sort we are discussing here. \nelm49810_ch07_127-148.indd   129\nelm49810_ch07_127-148.indd   129\n12/22/08   1:05:03 PM\n12/22/08   1:05:03 PM\n",
        "category": "Category"
    },
    {
        "id": "3",
        "title": "Title for Chunk 3",
        "content": "Confirming Pages\n130 \nPart 2 Building Operating Systems Incrementally: A Breadth-Oriented Spiral Approach\nshare common logins, and may have totally different hardware and software configu-\nrations. But the administrators of the individual clusters have agreed to allow some \njobs belonging to users of other clusters or computer systems to run on their clusters. \n Other common shared, distributed configurations include  peer-to-peer ( P2P ) \nsystems,  clusters of workstations ( COWS ), and volunteer computing systems (such \nas the BOINC system used for SETI@Home, physics, and biology processing, \namong many other projects). While such configurations are often more difficult for \na developer to utilize, they may offer potentially hundreds of thousands of nodes, \nspread throughout the world. \n In the following sections we discuss the utilization and potentials of these con-\nfigurations for processing large computational work, sharing data and processing, \ngathering results, and monitoring progress of work being done. \n 7.3.1 Just to start, a little bit of theory \n Work to be done may be described in  workflows. These workflows specify the pro-\ncessing steps that need to be done, the inputs and outputs of these steps, and the \ndependencies between the elements. Often a directed acyclic graph (dag) describes \nthis process, as is shown in  Figure 7.1 . The nodes A, B, C, and D are shown as \nboxes and represent units of processing work to be done. The edges are shown as \narrows and represent the dependencies between the processing nodes. We have omit-\nted describing inputs or outputs of the processing. \n This workflow graph shows the flow of this job: first step A must process some \ndata. After step A has completed, either step B or step C may run. Since there are no \ndependencies of steps B and C on each other, they may run at the same time. After \nboth steps B and C have completed, then step D may run. For example, step A reads \nsome data then passes a part of the data to step B and a part to step C. Then steps B \nand C each process their part and pass their results to step D, which processes their \nresults. Let\u2019s say that step A takes 10 minutes to run, step B takes 60 minutes, step C \ntakes 60 minutes, and step D takes 20 minutes. If these were done on a single com-\nputer they would take: 10  \ufffd 60  \ufffd 60  \ufffd 20 minutes  \ufffd 150 minutes. On two comput-\ners (ignoring overhead such as communication) this flow should take 10  \ufffd 60  \ufffd 20 \nminutes (steps A  \ufffd B  \ufffd D side) on one processing node, and 60 minutes on the \nother node (step C). The total work done in either case is 150 minutes but the two-\ncomputer solution reduces the \u201cwall-clock\u201d time (observed time) to 90 minutes, an \nhour faster. Notice that running step D on the second computer would not help to \nD\nC\nB\nA\nFIGURE 7.1 \nA workflow graph.\nelm49810_ch07_127-148.indd   130\nelm49810_ch07_127-148.indd   130\n12/11/08   5:25:16 PM\n12/11/08   5:25:16 PM\n",
        "category": "Category"
    },
    {
        "id": "4",
        "title": "Title for Chunk 4",
        "content": "Rev. Confirming Pages\n \nChapter 7 Parallel and Distributed Computing, Clusters, and Grids \n131\ncomplete this work faster since we still have to wait on steps B and C. Nor would \nhaving three or four nodes improve performance because of our flow dependencies. \nSuppose we had special computers that can run steps B and C faster. How much ben-\nefit do we gain? If we could speed up the runtime of B and C by a factor of two, each \ntaking only 30 minutes, we would complete the flow in 10  \ufffd 30  \ufffd 20  \ufffd 60 minutes. \nThis is often called Amdahl\u2019s law: the speed up of a portion of the work makes only \nthat part faster, not the entire flow. Thus, even a 10 times faster processing in B and \nC only speeds up:\n(10 + 60 + 20) minutes (old)\n(10 + 6 + 20) minutes (new)   = 2.5 times\nNot bad (2.5 times faster), but not 10 times faster (the speed increase of B and C). \nAmdahl\u2019s law will make it very difficult for a practical system to approach the ideal \nof parallel computing: linear speedup. Linear speedup would mean that work done \non a 10-node system happens 10 times faster than on a one-node system, and on a \n50-node system it would be 50-times faster. Sometimes there can be a superlinear \nspeedup! On 10 nodes, processing is more than 10 times faster! This is very unusual, \nand is normally due to caching effects in memory. When 10 processors are running, \nthen we also have 10 times as much cache memory involved and this can drastically \nspeed up the processing. \n Workflows are usually composed of two structures, as seen in  Figure 7.2 . \n Pipeline flows indicate dependencies, but sweep flows may be done simultane-\nously in parallel. Most workflows are combinations of these patterns. One valuable \ninsight is the condition where some part of a pipeline may actually allow partial \nprocessing, where a stage in the pipeline (a processing node) may process data one \nrecord at a time and then pass those results to the next stage, which may begin pro-\ncessing of that record immediately, while the previous stage of the pipeline processes \nthe next record, in parallel. \n In workflows there are several items that would be interesting to measure:\n \ufffd Work time\u2014total time spent on all nodes to process the work. \n \ufffd Wall time (or clock time)\u2014elapsed time, start to finish. \nA Pipeline Flow\nA Sweep Flow\nFIGURE 7.2 \nPipeline flows \nand sweep flows.\nelm49810_ch07_127-148.indd   131\nelm49810_ch07_127-148.indd   131\n12/22/08   1:05:04 PM\n12/22/08   1:05:04 PM\n",
        "category": "Category"
    },
    {
        "id": "5",
        "title": "Title for Chunk 5",
        "content": "Rev. Confirming Pages\n132 \nPart 2 Building Operating Systems Incrementally: A Breadth-Oriented Spiral Approach\n \ufffd Utilization (resource utilization)\u2014percentage of time each node (or the average \nof all nodes) is busy. \n \ufffd Throughput\u2014number of jobs or workflow processes run per hour (or day). \n 7.4 DISTRIBUTED SYSTEM ARCHITECTURES \n 7.4.1 Overview of execution environments \n There are significant differences between the various distributed system architec-\ntures and single processor, multitasking systems. While each of the architectures \nallows us to run jobs in parallel, the effort that we must expend to utilize any one \nparticular architecture, as compared to the others, varies quite a bit. So this section \ndiscusses each of these possible architectures in a bit more detail so that we can bet-\nter understand some of the problems that can occur. \n As we have seen in previous discussions, as we take advantage of more advanced \nfeatures, we need to be a bit cautious about side effects and interactions between \ndifferent features. For example, recall that the ability to run several processes con-\ncurrently allows more efficient use of computer resources. But it also introduces \nthe difficulties of interprocess communication that arise because we build so much \nseparation and protection between processes. Then we need locking and unlocking \nto avoid conflicts that arise when sharing resources, and then we need to worry about \nthe deadlocks that can arise from the use of locks. \n 7.4.2 Symmetric multiprocessing systems \n SMP systems share memory, and applications that process large amounts of data and \npass data between stages or share tables can benefit substantially from being run on \nsuch architecture. There are parallel versions of many common programs (software \ntools). As you might recall, in SMP systems there is a single copy of the OS running \nand it may run on any CPU available. It must manage process scheduling for each \nCPU, memory allocation (there is only one shared physical memory space), and \nother resources (disks, terminals, and so forth). So, how does one utilize an SMP \nsystem to do work in parallel? Such a system is seen in  Figure 7.3 . \n There are two main techniques that are used to take advantage of the power of an \nSMP system: multiprocessing and multithreading. (The distinction between these two \ntechniques is discussed in Chapter 8.) If this seems familiar, these are the same facili-\nties offered by most modern OSs such as with Linux and the Mac OS, as we discussed \npreviously. The key concept to the use of an SMP system is that it is very similar to a \ntraditional uniprocessor computer but with more main memory and more CPUs. \n From a programmer\u2019s view, harnessing the power of multiple CPUs may be \ndone by simply dividing the system into many separate programs, which run as sepa-\nrate processes. Usually this means running at least as many processes as there are \nCPUs in the system. Usually we run more processes than there are CPUs in order to \nallow some to run when others are blocked and waiting. A program or a workflow \n(a group of programs/processes) that has been written to create many processes that \nelm49810_ch07_127-148.indd   132\nelm49810_ch07_127-148.indd   132\n12/22/08   1:05:04 PM\n12/22/08   1:05:04 PM\n",
        "category": "Category"
    },
    {
        "id": "6",
        "title": "Title for Chunk 6",
        "content": "Confirming Pages\n \nChapter 7 Parallel and Distributed Computing, Clusters, and Grids \n133\nrun simultaneously will run on a single processor computer. But they will also run \njust as well on an SMP system without any change, only faster. (In some unusual \ncases\u2014such as a situation where almost all of the processes are blocked waiting for \ninput\u2014there won\u2019t be any speedup benefit.) While this method of parallelism is a \ncommon one, there are difficulties in having multiple processes share data such as \nthe race conditions previously mentioned. Interprocess communication and synchro-\nnization work well, but incur overhead that may be avoidable by other methods. If \nwork can be partitioned into sets that don\u2019t require much interprocess communica-\ntion and synchronization (such as do several types of sweep workflows, described \npreviously), multiple process models work very well. \n So then what does the OS need to do to manage multiprocessing or multithreading \non an SMP as opposed to what it had to do on a uniprocessor? It turns out that there is \nnot a great deal of difference. Since memory is shared in one big pool, memory man-\nagement is the same as on uniprocessor computers. CPU scheduling is more complex \nthan with uniprocessor systems because the additional CPUs must be handled sepa-\nrately. Time-slicing scheduling is commonly used in SMP systems, just as in uniproces-\nsor systems, so that part of the design is not much different. But the scheduler does have \nto consider where to schedule processes since work may be sent to different CPUs. This \nis not much more difficult than scheduling one CPU. However, one recent advancement \nin CPU architecture may complicate the scheduling. Recall that most CPUs have cache \nmemory on the chip that contain copies of portions of main memory, but whose access \nis much faster. If the scheduler randomly assigns processes and threads to processors, \nthe benefits of caching will be impaired. The system will still work correctly, but it will \nrun much more slowly than if the data were in the cache for the correct CPU. Sophis-\nticated SMP schedulers try to keep a process (or multiple threads from one process) \nrunning on the same CPU once they have started. This is called  CPU preference or \n processor affinity. This technique also allows a programmer or administrator to pro-\nvide a suggestion to the scheduler to run a process or thread on a specific CPU. \n The other problem that SMP OSs face is that there may be multiple copies of \nthe OS running at the same time. These copies may try to update the same data at the \nsame time. Therefore, SMP OSs must make use of locking mechanisms to prevent \nCPU 1\nCPU 3\nCPU 4\nCPU 2\nMemory\nFIGURE 7.3 \nA multiprocessing \nsystem.\nelm49810_ch07_127-148.indd   133\nelm49810_ch07_127-148.indd   133\n12/11/08   5:25:19 PM\n12/11/08   5:25:19 PM\n",
        "category": "Category"
    },
    {
        "id": "7",
        "title": "Title for Chunk 7",
        "content": "Confirming Pages\n134 \nPart 2 Building Operating Systems Incrementally: A Breadth-Oriented Spiral Approach\ndifferent executing copies from interfering with one another. This issue is discussed \nmore fully in Chapter 9. \n 7.4.3 Clusters \n Cluster systems are more loosely coupled than SMP systems. They usually have \nessentially identical system software on each node as well as several options for \nsharing and communicating between processes. An example is seen in  Figure 7.4 , \nwhere there are two groups of two systems with close coupling between the odd-\nnumbered systems and even-numbered systems and additional coupling between the \ntwo groups. In addition, each system has local memory and local storage. Clusters \nare normally administered by a single authority such as a corporation or university. \nThey rely on  middleware, software that facilitates interfaces between systems but is \nnot part of the OS\u2014it is in the \u201cmiddle\u201d between the OS and applications. Middle-\nware attempts to provide abstractions that facilitate distributed processing in ways \nthat are independent of the underlying OSs involved. They are said to be  platform \nagnostic. This allows us to connect existing systems together, among other things, \nand let the middleware sort out the differences. But middleware can be used in clus-\nters that are homogeneous as well. \n Commonly found middleware packages include  MPI/PVM,  CORBA,  DCOM, \n .net remoting,  and Java/ RMI ( remote method invocation ). MPI/PVM ( message \npassing interface, parallel virtual machines ) offers a language-independent \nmanner for a process to send or receive messages, data, and parameters to or from \nother processes on other nodes in the cluster, even if the processes are written \nin different programming languages. CORBA ( Common Object Request Bro-\nker Architecture ) is similar but allows one object to invoke methods on another \nCPU 3\nCPU 1\nCPU 2\nCPU 4\nMemory\nMemory\nMemory\nMemory\nFIGURE 7.4 \nA clustered \nmultiprocessing \nsystem.\nelm49810_ch07_127-148.indd   134\nelm49810_ch07_127-148.indd   134\n12/11/08   5:25:19 PM\n12/11/08   5:25:19 PM\n",
        "category": "Category"
    },
    {
        "id": "8",
        "title": "Title for Chunk 8",
        "content": "Confirming Pages\n \nChapter 7 Parallel and Distributed Computing, Clusters, and Grids \n135\nobject that resides on a different computer. RMI is similar to CORBA but is spe-\ncific to the Java language. DCOM (Distributed Component Object Model) is a \nmethod for invoking methods on remote objects that was created by Microsoft. It \nis considered to be a binary mechanism rather than a language-oriented mecha-\nnism like CORBA or RMI. This means that it finds its target interface via what \namounts to a branch table on the remote object. Due to the widespread presence of \nthe Microsoft OSs, DCOM has been implemented on most other OSs as well. It is \nan older mechanism that is not favored for new development but is still supported \nbecause it is in such widespread use. Newer development is directed to the .net \nremoting methods. \n These middleware packages allow processes that do not directly share memory \nto pass information between themselves\u2014ideal for a cluster. But these middleware \nmechanisms are actually better suited to general distributed computing than they \nare to cluster computing. When programs are designed to exploit the parallelism \nin computing clusters, they can make use of other specific cluster interfaces for \nthe OS. These are discussed later, for example, the use of PBS cluster scheduling \ncommands. \n 7.4.4 Computing grids \n Grids are even more loosely coupled than clusters. They are loose aggregates of indi-\nvidual nodes or clusters administered by different institutions. The primary advan-\ntage of grid computing is that each node can be an inexpensive computer, and by \ncombining them into a grid they can produce computing power similar to a multi-\nprocessor supercomputer at lower cost due to the economy of producing commodity \nhardware compared to the higher cost of building a small number of single-purpose \nsupercomputers. The greatest disadvantage is that the nodes do not have high-speed, \nlow latency interconnections. So this arrangement is best for applications in which \nmany parallel computations take place independently. \n Nodes in a grid don\u2019t usually share user logins and passwords and the nodes \ntypically have different configurations. They normally run the same OS, however. \nNeither multithreading nor MPI, RMI, or similar middleware mechanisms will be \neffective in distributing work, sharing data, or monitoring work progress in grid \nsystems because the systems are so loosely connected. A consortium of industry, \nacademic, and other interested parties have contributed to a freely available  Globus \nToolkit that is widely used to administer computing grids. This package is a set of \nutilities, interfaces, and protocols that allow cluster administrators to share some of \ntheir resources as a part of a grid. \n Since the nodes are administered separately, security is a large concern with \na grid system. For security reasons, rather than creating temporary user logins for \njobs, \u201ctickets\u201d are issued by  ticket granting agencies. Many different administrative \nauthorities will be concerned with the administration of a given grid. Any source that \nthe various administrators can agree to trust can be a ticket granting agency. Transfer-\nring data and programs among nodes in a grid, reserving local space, and retrieving \nresults are done by Globus commands and interfaces. Coordinating between sites \n(clusters) is somewhat more difficult than on a single cluster, and very little software \nelm49810_ch07_127-148.indd   135\nelm49810_ch07_127-148.indd   135\n12/11/08   5:25:20 PM\n12/11/08   5:25:20 PM\n",
        "category": "Category"
    },
    {
        "id": "9",
        "title": "Title for Chunk 9",
        "content": "Confirming Pages\n136 \nPart 2 Building Operating Systems Incrementally: A Breadth-Oriented Spiral Approach\nhas been made grid-enabled. There are many other systems designed to facilitate grid \ncomputing besides Globus.  \n 7.4.5 Volunteer computing \n Individual people worldwide control millions of computers that sit idle for a large per-\ncentage of the time. Even when working at their assigned tasks most personal comput-\ners have many unused CPU cycles caused by the need to wait for I/O task completion. \nFor many years, utilizing this otherwise wasted computation time on these computers \nhas been a desire of several large projects. Many individual systems have been devel-\noped to take advantage of this otherwise wasted computer processing capacity. These \nsystems needed to handle several problems, including allowing individuals to register \ntheir computers in the system, getting jobs to those computers, allowing those jobs to \nbe suspended when other, more important work needs to be done on the computer, \nreturning results to the originator, and keeping track of the \u201ccredit\u201d each user or group \nof users has amassed. Eventually the Condor Project at the University of Wiscon-\nsin and BOINC at Berkeley developed common infrastructures to allow many dif-\nferent projects to be run in such a mode without the need for each project to develop \nthe infrastructure from scratch. While both offer the possibility of aggregating many \notherwise unused computer resources, they have important differences. \n Most volunteer computing projects are based on parameter sweep flows in which \nlarge amounts of data are broken up into small sets and sent to volunteers\u2019 comput-\ners. These computers all run the same science program to analyze their particular set \nof data, then send the results back. The amount of work to be done in one sweep is \nusually a few hours and the data initially sent to the volunteer and results sent back \nto the server is usually not too large (several hundred kilobytes to several megabytes) \nso that volunteers are not overly burdened. Also, if a job is abnormally terminated for \nsome reason, not too much work is lost. \n BOINC \n If the computing work of a project can be partitioned into reasonable-size chunks and \nthe potential of using millions of volunteer computers will facilitate the project, then \nthe BOINC infrastructure will be attractive. BOINC provides the common infrastruc-\nture and allows a project to submit its computing application to be run by millions of \nuser computers, which have CPU cycles that are not currently being used. \n Following on the success of early volunteer computing systems, BOINC (Berkeley \nOpen Infrastructure for Network Computing) created an infrastructure for any software \nsystem to be distributed to millions of volunteer computers. BOINC is composed of \na server system that sends out work and receives results. It may be configured to use \nany volunteer computer or to prefer computers where the software has already been \ninstalled and is running Linux or Windows. The BOINC client part is sent to volun-\nteer client computers and it then downloads the actual science applications. When \nusers register with BOINC they can select which science projects they want to par-\nticipate in and what portion of the spare cycles should go to each project. The BOINC \nclient software then takes care of the rest of the problems. It schedules when the \nscience applications will run. This might be any time when the computer is idle for \nelm49810_ch07_127-148.indd   136\nelm49810_ch07_127-148.indd   136\n12/11/08   5:25:20 PM\n12/11/08   5:25:20 PM\n",
        "category": "Category"
    },
    {
        "id": "10",
        "title": "Title for Chunk 10",
        "content": "Confirming Pages\n \nChapter 7 Parallel and Distributed Computing, Clusters, and Grids \n137\na certain time or it might run all the time in the background using idle CPU cycles. \nThe BOINC client will keep the version of the science applications current, check-\ning with the server, and handle communication with the server, sending results back. \nMost BOINC science applications have a screen saver graphic display that shows the \nwork being done in graphs, charts, and animated graphics. Currently BOINC supports \nseveral particle physics experiments, climate prediction, protein structure, epidemiol-\nogy and medical disease projects, cancer research, and SETI@home. In early 2008 \nBOINC had over 2.5 million active computers worldwide, providing a bit more than \n800 TFLOPS. Of course these numbers will continue to increase.  \n Condor \n The Condor system is a different approach that allows an administrator to create a \nlocal cluster of idle workstations to do distributed processing without the limitations \nor constraints of a cluster and without going to the trouble of setting up a cluster in \nhardware and software or organizing a grid. It provides an infrastructure similar to \nBOINC but each project administers its own single project and a private set of nodes. \nThese nodes are probably owned by a single institution. \n Condor is an ongoing project at the University of Wisconsin that allows users of \ncomputers to register them as being available and to describe a computer\u2019s capabili-\nties: what type of processor(s) it has (Pentium, PowerPC, Athlon, etc.), how much \nmemory and disk space, what software libraries are installed, and other character-\nistics. Someone who wants to run a program or a group of programs (a workflow) \ndescribes the requirements of those programs in a similar manner. These descrip-\ntions are called ClassAds (like classified advertisements) and are used by Condor to \nmatchmake (i.e., to find the best matches between providers and requestors). Condor \nallows computers to describe preferences about when they should do this work. For \nexample, a system might be allowed to do the work in the background, or when no \none has pressed a keyboard key for a few minutes. After many years of development, \nCondor has become very popular and widespread and is a very stable system that \nrequires only a simple procedure to install on computers wishing to provide service. \n Common problems \n Volunteer computing systems must cope with several problems of the computers \nused:\n They are heterogeneous, so the software must adapt readily. \n They join and leave the system unpredictably. \n Their availability is irregular. \n The systems should not interfere with normal system use. \nIn addition, volunteer computing systems must deal with a few problems concern-\ning reliable results, stemming from the fact that volunteers are often anonymous and \ntherefore unaccountable:\n Some volunteer computers may malfunction and return incorrect results. \n Volunteer computers may have their speed set too fast in order to gain extra \ncredit and therefore more often malfunction. \nelm49810_ch07_127-148.indd   137\nelm49810_ch07_127-148.indd   137\n12/11/08   5:25:20 PM\n12/11/08   5:25:20 PM\n",
        "category": "Category"
    },
    {
        "id": "11",
        "title": "Title for Chunk 11",
        "content": "Confirming Pages\n138 \nPart 2 Building Operating Systems Incrementally: A Breadth-Oriented Spiral Approach\n Volunteers may intentionally return incorrect results. \n Volunteers may claim excessive credit for results. \nOne common approach to all of these problems is to have each batch of data pro-\ncessed on at least two computers. The results and the credit are accepted only if they \nagree fairly closely. Another technique used is checksumming or performing a CRC \n(cyclic redundancy check) on the results. These are mathematical functions com-\nputed over the result data that detect transmission errors or tampering. \n 7.5 HOW OPERATING SYSTEM CONCEPTS DIFFER IN SMPS, \nCLUSTERS, AND GRIDS \n In this section, we discuss several of the OS concepts that we have described in \nprevious chapters and how they differ from the uniprocessor systems discussed \nthere. In some cases, the concepts and implementations in parallel systems are \nalmost identical to single CPU systems; in a few cases, the differences are note-\nworthy and important.  \n 7.5.1 Process synchronization and communication \n Recall that processes often share work with other processes. Sharing work usu-\nally also implies sharing data. This distribution of work and partitioning or shar-\ning data requires coordination between processes. Even in simple cases where \nthere is not very much interaction between these executable elements, one needs \nto exercise caution in those small parts of the program code where data (even a \nsingle number) may be shared between processes running on different systems. \nThe problem we are trying to avoid is caused by two processes that are trying \nto change a single data item at the same time. This is called a  race condition. \nTraditionally, interprocess communication is done using shared memory or mes-\nsage queues. Synchronizing concurrent access to data is done using semaphores \nor similar locking mechanisms in those  critical sections of the processes involved \nwhere they actually manipulate the data. These mechanisms are based on shared \nmemory and special CPU instructions. They will be elaborated on in Chapter 9. \nOn some distributed architectures these mechanisms are not available and other \nmechanisms must be used. Perhaps a simple example best illustrates the question \nof how systems can accomplish synchronization and communication in distrib-\nuted architectures.  \n 7.5.2 An example \n Suppose we have a very long list of information about many people. For example, \nit might include telephone numbers, names, email addresses, and some value such \nas the family income for the last year. We would like to sort this list into ascending \norder by phone number and calculate the average income at the same time. This is \nelm49810_ch07_127-148.indd   138\nelm49810_ch07_127-148.indd   138\n12/11/08   5:25:21 PM\n12/11/08   5:25:21 PM\n",
        "category": "Category"
    },
    {
        "id": "12",
        "title": "Title for Chunk 12",
        "content": "Confirming Pages\n \nChapter 7 Parallel and Distributed Computing, Clusters, and Grids \n139\nan ideal problem for the architectures discussed in this chapter. (In fact, this problem \nmay be too ideal since it can be structured as a highly parallel application and thus \nyields a speedup factor that may be atypical for distributed computing.) \n The obvious method to solve this problem is to partition the list into smaller, \nseparate lists. If we had eight processors to divide the work among we could have \neach processor sort and calculate the average on one eighth of the data, and then we \ncould merge the result. This is a sweep flow, as was described earlier. The merge step \nat the end is a pipeline, as is the partitioning of the data at the beginning of the work \nflow. While each processor is sorting and averaging its own part of the list there is \nno interaction between processes. But at the time of merging the resulting lists and \ncalculating the average there will be data sharing. \n It would be more efficient if we could start processing (merging) results before \nall the results have been calculated. But this might create a race condition where \nsome of the processors started trying to merge the results before all the processors \nhad produced their first output. Furthermore, even if all eight processors were the \nsame type and speed it would be very unusual that they completed their work at the \nsame time. We could try to balance this by giving more work\u2014more numbers in \ntheir list\u2014to faster processors. If a processor was twice as fast as the others we could \ngive it twice as many numbers to work with. But, this doesn\u2019t work since it takes \nmore than twice as long to sort this longer list, because sorting is not a linear time \nfunction. Predicting the running time of parallel processes is important, but usually \ndifficult\u2014and not very precise.  \n 7.5.3 But it gets difficult \n Now our simple example is getting complex\u2014merging the results of sorted lists, as \nthey become available, and calculating the average (a few adds, maybe scaled with \nmultiplications, and a divide) shared data\u2014and before we can use the result of a \nsweep process we need to know if it has finished. On a single CPU computer this is \nnot difficult. We can communicate using shared memory and signal completion by \nsetting flags in the data to indicate completion. \n 7.5.4 The SMP case \n How would this be done on a SMP system? Fortunately, it can be done exactly the \nsame way as on a single CPU computer. SMPs share memory among all the CPUs, \nso most of the common techniques used to communicate among processes work the \nsame way as in a uniprocessor system. We discuss the issues involved in SMP OSs \nfurther in Chapter 9. \n 7.5.5 The cluster case \n How are sharing and locking done on a cluster of computers? This architecture \nis somewhat more difficult than with a single CPU or an SMP system. Sharing \nmemory is not possible (it may be simulated, but that is quite slow). Messages must \nbe sent between processor nodes via a local area network. Work is partitioned and \nelm49810_ch07_127-148.indd   139\nelm49810_ch07_127-148.indd   139\n12/11/08   5:25:21 PM\n12/11/08   5:25:21 PM\n",
        "category": "Category"
    },
    {
        "id": "13",
        "title": "Title for Chunk 13",
        "content": "Confirming Pages\n140 \nPart 2 Building Operating Systems Incrementally: A Breadth-Oriented Spiral Approach\ndistributed. Since data is not shared in memory between processors, it must be sent \nto each processor node separately. If the data is originating in a file, there may be \nfile sharing across nodes, minimizing the impact of this distribution. \n It is common to try to partition the processing of problems for a cluster so \nthat there is almost no interaction between processes until the end of each process \nbecause communication between systems in a cluster is much slower than in an SMP \nsystem. For this reason, usually the rewriting and restructuring of a work flow for \na cluster requires more programming and design than for an SMP system or single \nCPU and it does not end up doing as much work in parallel. But, the tradeoff is that \nthe per-processing node cost in a cluster is much lower. \n 7.5.6 The grid case \n How are locking and sharing done on a system with a grid architecture? This is the \nmost difficult case. Sharing memory is not physically possible between clusters in \na grid and is very difficult to simulate. Messages must be sent between nodes or \nbetween clusters via a network that may be protected by firewalls. The nodes may be \nvery far apart and thus have very high communication latency. The work is therefore \npartitioned and distributed. Since data is not shared in memory between processors \nit must be sent to each cluster through a network, primarily the Internet, which is \noften slow, but perhaps over the Internet2, which is usually a bit better performing. \nResults must similarly travel back over the same network. Even if the data is stored \nin a file, the files being shared must still be copied to another cluster, where they may \nbe shared between nodes in that cluster. \n Why is this effort worthwhile? Why do we use grids for computation? We \nuse them because grids also share, but instead of only sharing memory, they share \nwhole clusters of computers between users. Rather than being limited to using  only \nthe perhaps few hundred or so nodes available in a local cluster, a researcher may \nbe able to use 50 clusters of computers, ranging from 10 to 400 nodes in each \ncluster. This high-level sharing may allow the use of many thousands of nodes \nfor a short time. Since one is using someone else\u2019s cluster, then one may not be \nable to use it for  too long, maybe only a few thousand hours. But one should also \nshare one\u2019s own local cluster, so things should balance out in the long run. Users \nof grids therefore form  virtual organizations. These organizations agree to pool \nand share resources such as their clusters. Such organizations are very dynamic. A \nvirtual organization may form to computationally analyze one problem. It might be \none task, such as a bioinformatics work flow that takes 100,000 compute hours in \ntotal, but is done by two dozen (24) clusters creating a small grid, and done over \nthe weekend. Then the virtual organization disbands until the next big problem. \nThis problem might take more than 10 years if done on a single computer similar to \nnodes on the cluster, or half a year on a typical local cluster such as that described \nlater in this chapter. \n For very large data sets, for example, the output of the LHC (Large Hadron Col-\nlider, a large-particle accelerator at CERN, in Europe) physics experiment, the analysis \nwork will take many millions of compute hours, so the virtual organizations will be \naround for quite a while. These organizations depend on Moore\u2019s law, that computers \nelm49810_ch07_127-148.indd   140\nelm49810_ch07_127-148.indd   140\n12/11/08   5:25:21 PM\n12/11/08   5:25:21 PM\n",
        "category": "Category"
    },
    {
        "id": "14",
        "title": "Title for Chunk 14",
        "content": "Confirming Pages\n \nChapter 7 Parallel and Distributed Computing, Clusters, and Grids \n141\nand capacities will increase, year-by-year, so that in later years, processing will speed \nup, and possibly the researchers will discover new principles of science that would oth-\nerwise never be found.  \n 7.5.7 File-sharing techniques \n Large-scale computation users typically need lots of files. Files contain raw data \nvalues, parameters, intermediate and final results, and other information. It is not \nunusual that some of these files are very large, perhaps many gigabytes each. Clusters \nwith many terabytes of storage (in a few cases, a hundred terabytes) are common, and \nthe previously mentioned LHC will need petabytes of storage. \n File sharing for SMPs is relatively easy since the processes also share the file \nsystem. Of course, the processes that share files may need to coordinate using locks or \nsimilar mechanisms. In most SMPs there is a primary file system (or a few) managed \nby the OS. Since the OS handles file operations it can coordinate among multiple \nprocesses that are creating, reading, writing, and performing other file operations. \n In clusters, there are multiple instances of identical OSs running on the differ-\nent processors and they manage the sharing of files. This may be done by creating \nspecial file-sharing nodes, which allow files that they control to be manipulated by \nany (or many) nodes in the cluster. These nodes support an interface that provides \nessentially the same functions as those provided by a local OS in a single node or \nSMP system. Since it is possible to have race conditions on files in a cluster, file \nsharing nodes usually also provide locking commands to lock all or part of a file to \nallow error-free data sharing. \n Grids do not share parts of files, nor do they allow locking between clusters. \nThey do allow entire files to be copied, and some grid tools may simulate cluster-like \nfile sharing. Ensuring that all nodes in multiple clusters have a consistent, identical \nview of every shared file is very challenging and is an active area of grid research. \nEven more difficult is the management of files that are almost the same between \nclusters, but have been changed a little, and yet still have the same name. \n 7.5.8 Using remote services \n Applications often need to access remote services. These may include remote sub-\nroutines or function, methods on objects, or separate processes. The topic of remote \nservices has been a very popular topic in parallel and distributed computing for many \ndecades. This refers to how remote services are started and invoked remotely, how \nparameters are passed, and how results are returned. \n On SMP systems services outside a particular process are most typically invoked \nthrough remote procedure calls (RPCs) or remote method invocations (RMIs). This is \nthe same mechanism as discussed previously for interprocess management. Systems \nrunning on clusters employ middleware that enhances RPC calls or RMI invocations \nto be similar to the same calls in SMP or multiprocessing uniprocessor systems. Grid \nsystems present challenges due to the difficulty of sharing (particularly of sharing \ndata) and the issues of security. Naturally, most cluster administrators are very wary \nof allowing direct contact with a node in the cluster they are allowing remote access \nto. Grid systems have potentially long network delays, so usually grid services are \nelm49810_ch07_127-148.indd   141\nelm49810_ch07_127-148.indd   141\n12/11/08   5:25:22 PM\n12/11/08   5:25:22 PM\n",
        "category": "Category"
    },
    {
        "id": "15",
        "title": "Title for Chunk 15",
        "content": "Confirming Pages\n142 \nPart 2 Building Operating Systems Incrementally: A Breadth-Oriented Spiral Approach\nprovided by batch-like, noninteractive servers. New grid service models, for example, \nthe new Globus model discussed in Section 7.4.4, do provide Web services as a model \nand provide security through certificates. \n With a long history and many opinions and implementations of remote servers \nand services, this area will be contentious and important for many years to come. \n 7.5.9 Handling failures \n Lastly, we come to the somewhat unpleasant question of what happens  when some-\nthing goes wrong? \n As more components, more computers, and more software are aggregated into \na larger system, the chances that something will go wrong increases, maybe just \nsomething minor. This is why SMP systems, clusters, and grids must all recognize \nand deal with the eventuality of failure. \n What can fail? The first thing that comes to mind is a hardware failure\u2014a disk goes \nbad, maybe a chip fries, and a computer stops working. This will result in a node fail-\ning or not responding and losing the work it was doing. Network failures are probably \nmore likely than node failures. A cable might come loose or a switch or router might \nfail. A network or server might suffer a denial of service (DOS) attack. (We discuss \nsuch attacks in Chapter 16.) Even more commonly a network or router will get very \noverloaded and drop traffic. In general, network failures will mimic node failures. \n But software may also cause failures. For example, the wrong version of a pro-\ngram or the wrong version of a runtime library may be loaded on a system. This is a \nvery common problem. Unfortunately, software bugs may cause failures that are not \ndetected until long after the failure actually occurred. \n Software must be written to account for failures. For example, middleware can \nuse timeouts to check that a remote procedure call or other server request is responded \nto within a reasonable amount of time. And if the service does not respond within the \ntime limit another call is made, perhaps to a different server. If the original request \nresponse shows up later, then the result is simply thrown away. \n Monitoring systems can watch network traffic, trying to detect failures. They \ncan also watch individual node or cluster performance for failures due to hardware \nor misconfigured software. There are tradeoffs to be made here. For example, too \nlittle monitoring will cause failures to be unnoticed and unmanaged for a long time \nbut too much monitoring creates a substantial overhead in computing resources and \nnetwork bandwidth. \n 7.6 EXAMPLES \n 7.6.1 Scientific computing on clusters and grids \n In the last few years several significant, computationally intensive natural science \nprojects have used large computational clusters and grids. In this section, we discuss \na few such projects. The continually declining price of commodity computers, disk \nstorage systems, high-speed networking equipment, and network bandwidth and \nelm49810_ch07_127-148.indd   142\nelm49810_ch07_127-148.indd   142\n12/11/08   5:25:22 PM\n12/11/08   5:25:22 PM\n",
        "category": "Category"
    },
    {
        "id": "16",
        "title": "Title for Chunk 16",
        "content": "Confirming Pages\n \nChapter 7 Parallel and Distributed Computing, Clusters, and Grids \n143\nsoftware to control the distribution of work and data have very recently reached the \npoint where such systems are affordable by most research communities. As a result, \nmany new projects have only achieved results in the last year and others have not yet \nreached such milestones. The following projects are not the largest or perhaps the \nmost significant; rather, they are a representative sample of different approaches and \ntechnologies employed to accomplish intense computational work. \n 7.6.2 The human genome DNA assembly \n In the early 1990s, J. Craig Venter suggested using a whole genome shotgun assem-\nbly approach for large genomes. (It is not possible with current technology to simply \nread each nucleotide, one at a time, in very long pieces of DNA.) A genome assem-\nbly starts with ripping a DNA strand into many short pieces. These pieces are then \n\u201cread\u201d by sequencing machines in strings of up to 900 bases at a time. The four \nbases are adenine, guanine, cytosine, and thymine, normally shown as A, G, C, and \nT. A genome assembly algorithm works by taking all the pieces and aligning them to \none another, and detecting all places where two of the short strings overlap. An exam-\nple is shown in  Figure 7.5 , where several overlaps of short segments of the original \nstring can be seen. This method has become very popular, due, in large part, to the \navailability of computer clusters to assemble the large number of overlapping frag-\nments. While smaller genomes had already been sequenced by Venter using shotgun \nassembly, assembling the human genome needed much greater computing resources \nand very sophisticated software. This approach scans a slightly more than 3 billion \nbase pair human genome that has been broken into more than 50 million overlap-\nping pieces. Since the chemical process for breaking up and reading sequences is not \nperfect, the algorithmic looks for near matches to align ends.  \n The processing done in this work on the human genome assembly initially took \nabout 20,000 CPU hours. But it was done on a cluster of 40 four-processor SMP sys-\ntems in a few days. This system, which at the time cost $40 million, would now cost, \nfor an equivalent amount of processing power, a few hundred thousand dollars. \n The major alternative approach, used by the public Human Genome Project, was \nto assemble ever-longer sequences, growing pieces into longer, known sequences. This \nhierarchical approach also requires significant computational resources. A custom writ-\nten program, GigAssembler, was developed that ran on a 100-node Linux cluster. In \nboth approaches, the computational needs were large enough to require using compu-\ntational clusters. These were cases where there really was no other reasonable choice.  \nOriginal string\n1st sample\u2013A\nXXXACGATCGTCGAGTCATCGTXXXXXXXXXXX\n1st sample\u2013B\nXXXXXXXXXXXXXXXXXXXXXXTAGCGTAXXXX\n2nd sample\u2013A\nXXXACGATGXXXXXXXXXXXXXXXXXXXXXXXX\n2nd sample\u2013B\nXXXXXXXXXCTCGAGTCATCGTTAGCGTAXXXX\nXXXACGATCGTCGAGTCATCGTTAGCGTAXXXX\nFIGURE 7.5 \nGenome assembly.\nelm49810_ch07_127-148.indd   143\nelm49810_ch07_127-148.indd   143\n12/11/08   5:25:22 PM\n12/11/08   5:25:22 PM\n",
        "category": "Category"
    },
    {
        "id": "17",
        "title": "Title for Chunk 17",
        "content": "Confirming Pages\n144 \nPart 2 Building Operating Systems Incrementally: A Breadth-Oriented Spiral Approach\n 7.6.3 IBM Computational Biology Center and cluster computing \n IBM has been active in parallel and distributed computing for many years, and has \ntaken a leadership role in developing very large-scale computer clusters and soft-\nware infrastructure and biological applications to use those systems. Blue Gene/L \nis a 131,000-processor cluster, with multiple network pathways to each node. This \nsystem, which was co-designed by Lawrence Livermore Labs, is used for science \nresearch. About half of the 500 largest computational clusters in the world are IBM \ncomputers. The Blue Gene series of computers, all very large clusters, use relatively \nmodest-speed CPUs and employ a modified version of Linux as the OS. \n The Computational Biology Center has several large projects of interest, includ-\ning bioinformatics, medical informatics, and functional genomics research. One of \nthese projects, a biomolecular simulator called Blue Matter, simulates modest-size \nsystems (10,000\u2013100,000 atoms) for long time scales (hundreds of nanoseconds to \na few microseconds). Using 4,096 processors on Blue Gene/L, a 43,000 atom mem-\nbrane protein system ran for a simulated time of one microsecond in a wall clock \ntime of slightly less than two months. \n 7.6.4 Volunteer computing clusters \n The goal of using processor cycles that would otherwise be wasted has appealed to \nmany people for years. SETI@home, a project that searched for extraterrestrial intel-\nligence, utilized years of data collected from radio telescopes that had been stored in \nrepositories but for which no computing resources had been available to analyze this \ndata. SETI@home has been remarkably successful from a computing view. More \nthan 5 million participants have contributed over 2 million years of aggregate com-\nputing time over the years. In early 2008 it was estimated that at any given time all of \nthe computers in the SETI@home system together provide 370 TFLOPS (370 \u00b7 10 12 \nfloating point operations per second). As a comparison, Blue Gene/L can reach the \npeak performance of 478.2 TFLOPS, with about one-sixth the number of processors \nas SETI. But note that the SETI computers are connected over home networks and \nphone lines, composed of a mixture of older and newer machines, and sometimes \ndo other real work for their users. While no conclusive signs of extraterrestrial intel-\nligence have been found, there have been several interesting findings that may war-\nrant further investigation. One concern voiced in a recent astronomy publication is \nthat the digital signals collected at radio telescopes and sent over the Internet might \nexpose the earth\u2019s Internet to extraterrestrial viruses. While this would confirm extra-\nterrestrial intelligence, no extraterrestrial viruses have yet been detected on earth. \nSETI@home is considered to be the largest grid/cluster computation in history. \n Folding@home is an effort to simulate protein folding and misfolding; it was \ncreated by the Pande Group at Stanford. It has simulated folding in the 5- to 10-\nmicrosecond range, which is a time scale thousands of times longer than was previ-\nously thought possible. It is the second largest volunteer project (after SETI@home). \nOn September 16, 2007, the Folding@home project officially attained a perfor-\nmance level higher than one petaflops. It has been used lately for analyzing protein \nmisfolding, which is thought to be applicable to diseases such as bovine spongiform \nencephalopathy (BSE), or mad cow disease. \nelm49810_ch07_127-148.indd   144\nelm49810_ch07_127-148.indd   144\n12/11/08   5:25:23 PM\n12/11/08   5:25:23 PM\n",
        "category": "Category"
    },
    {
        "id": "18",
        "title": "Title for Chunk 18",
        "content": "Confirming Pages\n \nChapter 7 Parallel and Distributed Computing, Clusters, and Grids \n145\n 7.6.5 A typical computer cluster \n Here we describe a typical computer cluster with 98 two-processor computers. It \nhappens to exist, but it is intended merely as a typical example of such a cluster and \nsome samples of commands one might use in such an environment. Each node has \na local disk and two processors inside the computer, and each computer\u2019s two pro-\ncessors share two gigabytes of memory. The 98 computers communicate with each \nother and with the Internet via a one-gigabit per second switched Ethernet LAN. \nThere are also several NAS disk arrays using  redundant array of independent \ndisks ( RAID ) technology. (This technology is explained in Chapter 14). Together \nthey comprise 100 terabytes of storage. The cluster also has five \u201chead\u201d nodes con-\nnected to firewalls that allow an external user to connect to the cluster or to several \ndedicated database servers. It also has a few Web servers outside of the firewall for \ngeneral status and information about the system. \n Each computer node is running a separate but identical copy of Linux as the \nOS, and each node has common software installed such as OS utilities, high-level \nlanguage compilers, libraries, and several science applications. Individual computa-\ntional nodes and storage are isolated from the Internet. Access is granted through the \naforementioned head nodes. The head nodes run clustering software that allows a user \nto log in to the head node and run multiple parallel jobs by using PBS (portable batch \nsystem\u2014now called TORQUE, but almost always still referred to as PBS). Head \nnodes also do monitoring and some other accounting work, but are designed to be \nused primarily as portals for running an actual workflow on multiple compute nodes.  \n 7.6.6 Utilizing a Globus cluster \n The Linux OS on the cluster has good support of the two-processor nodes and for \nmanaging scheduling on the two CPUs. These OSs don\u2019t know that they are part of a \ncluster. Rather than modifying the OS, the cluster work management is done by mid-\ndleware, running on top of the OS. The middleware scheduler called PBS is freeware, \nas is the Linux OS underneath it. While PBS is a sophisticated system with many \ninterfaces, a user can make effective use of it while knowing only a few commands. \n First, one has to tell PBS what kind of CPU resources are needed. One can \nspecify individual parameters on separate lines, like this:\n #PBS -M dave@mymailer.uta.edu  \n #PBS -l   nodes\ufffd10:ppn\ufffd2 \n #PBS -l   cput\ufffd02:00:00  \n #PBS -l   mem\ufffd213mb  \n #PBS -l   walltime\ufffd00:20:00  \nOr combine the last four lines, like this:\n #PBS -l  \n nodes\ufffd10:ppn\ufffd2,cput\ufffd2:00:00,mem\ufffd213mb,walltime\ufffd00:20:00  \nThis PBS command requests 10 nodes, two processors per node, and 213 MB of \nmemory. It requests a total of two hours of CPU time to run in 20 minutes of wall \nelm49810_ch07_127-148.indd   145\nelm49810_ch07_127-148.indd   145\n12/11/08   5:25:23 PM\n12/11/08   5:25:23 PM\n",
        "category": "Category"
    },
    {
        "id": "19",
        "title": "Title for Chunk 19",
        "content": "Rev. Confirming Pages\n146 \nPart 2 Building Operating Systems Incrementally: A Breadth-Oriented Spiral Approach\nclock time to run all of the workflow that users will submit. The M parameter tells \nthe system who the user is. \n In order to see the results of a program\u2019s execution a user will need to tell the \nsystem where the normal output and error output streams should go. Here they are \nredirected to files, so they can be retrieved later:\n #PBS -o outputfile  \n #PBS -e errorfile  \nSince the job may take some time to finish (weeks or even months, in some cases, \neven on large grids), a user can ask for an email to be sent when the job begins to run, \nand another when it terminates or aborts.\n #PBS -m bae  \nAnd finally, the OS needs to know where the program is that is to be run:\n cd /temp/my_working_dir  \n echo \"I am running on host 'hostname'\"  \n execute my_program  \n rm ./junk  \n exit  \nSpecifically a user asks the OS to run some programs, probably with different files \nas input data, clean up any leftover temporary files, and exit. Note that frequently the \nuser will put all of these commands into a shell script file and then run it. \n A user submitting jobs using PBS needs to keep in mind that it is a batch-oriented \nsystem. Most modern OSs are primarily interactive\u2014when an icon is clicked to tell the \nOS to run a job, it tries to start it immediately. In a batch system the job may not be able \nto run immediately because the resources asked for are not available at the time. So the \njobs may be placed in a queue for later execution. There are a number of commands \nthat a user can use to manage the jobs and queues available. Here are a few of them:  \n #qalter  \n Alter a batch job  \n #qdel  \n  Delete a batch job  \n #qhold  \n Hold a batch job  \n #qmove  \n  Move a batch job to another queue  \n #qrls  \n  Release held jobs  \n #qrerun  \n  Rerun a batch job  \n #qselect  \n  Select a specific subset of jobs  \n #qstat  \n  Show status of batch jobs  \nFor those users who are not comfortable with command-line interfaces there is also \na GUI version of PBS called XPBS. \n 7.6.7 Portals and Web interfaces \n After an application is working on a cluster, it might be desirable to make it avail-\nable to others, either within a group or to a wider community. Or a user might simply \nwant an easy-to-use interface to an application. In the past, creating a windowing \nelm49810_ch07_127-148.indd   146\nelm49810_ch07_127-148.indd   146\n12/22/08   1:05:08 PM\n12/22/08   1:05:08 PM\n",
        "category": "Category"
    },
    {
        "id": "20",
        "title": "Title for Chunk 20",
        "content": "Confirming Pages\n \nChapter 7 Parallel and Distributed Computing, Clusters, and Grids \n147\ninterface was an option, and many applications still do this. But it is now possible to \nmake a grid workflow or application Web-enabled. \n Portals are server computers that allow users to access data, applications, infor-\nmation, and to share results. A local portal allows anyone to login, look at ongoing \nresearch, match interests to faculty researchers, and apply for an account. Account \nholders may access local applications, get datasets, chat with whoever is online, and \nshare data and opinions. \n  7.7 SUMMARY \n Prior to this chapter we discussed the designs of OSs \nthat run on a single machine. Modern systems often \nare designed for applications where many proces-\nsors are used together. In this chapter we discussed \ncomputing on more than one CPU and some of the \ndifficulties that arise in constructing and using such \nsystems. We covered several common designs for \nmultiple CPU systems, and a few unusual designs \nas well. After an introduction and definitions of a \nfew key concepts, we discussed a bit of the theory of \nparallel computing and the issues of computational \nmodels and programming. Then we discussed some \ncommon architectures for distributed systems. OSs \ndesigned to run in such environments have special \nconsiderations that do not arise in uniprocessing sit-\nuations, so we covered some extra issues OSs face in \ndistributed systems. These topics included such ques-\ntions as what facets need to be managed, how does \nmultiprocessor system resource management differ \nfrom uniprocessor systems, and what interfaces are \npresented to programmers and users. Finally, we dis-\ncussed some real applications that are implemented \nas distributed systems, including a look at a typical \ncluster installation in a grid. \n In the next part of the book we begin looking at \nindividual topics in Operating Systems in more depth. \n BIBLIOGRAPHY \n Dubois, M., and F. A. Briggs, \u201cSynchronization, \nCoherence, and Event Ordering in Multiprocessors,\u201d \n Computer, Vol. 21, No. 2, February 1988, pp. 9\u201321. \n Geer, D., \u201cFor Programmers, Multicore Chips Mean \nMultiple Challenges,\u201d Computer, Volume 40, Issue \n9, September 2007, pp 17\u201319.  \n WEB RESOURCES \n http://www.globus.org (Home page for the Globus \nAlliance)\n http://www.globustoolkit.org (Open source software \ntoolkit used for building grids)\nhttp://boinc.berkeley.edu/  (BOINC home page - SETI \nproject, among others)\n REVIEW QUESTIONS \n \n7.1 Moore\u2019s law says that computers are getting faster \nand faster all the time. Why do we then go to the \ntrouble of building cluster systems and other exotic \ndesigns that require a programmer to work hard to \nexploit any possible parallelism in a design?  \n \n7.2 True or false? SMP systems and clusters (almost) \nalways use the same CPU in every node but grid \nsystems can use different CPUs in each node. \nelm49810_ch07_127-148.indd   147\nelm49810_ch07_127-148.indd   147\n12/11/08   5:25:24 PM\n12/11/08   5:25:24 PM\n",
        "category": "Category"
    },
    {
        "id": "21",
        "title": "Title for Chunk 21",
        "content": "Confirming Pages\n148 \nPart 2 Building Operating Systems Incrementally: A Breadth-Oriented Spiral Approach\n \n7.3 Which is true about the nodes in a cluster system?\n a. They share a single memory. \n b. They have no local peripherals. \n c. They communicate over a separate dedicated \nLAN. \n d. A dedicated node runs the OS. \n e. None of the above is true about the nodes in a \ncluster system.  \n \n7.4 True or false? A pipeline flow is an example of a \nworkflow where there is parallelism that can be \nexploited. \n \n7.5 What does Amdahl\u2019s law say about the speedup of \na workflow? \n \n7.6 What common technique used in uniprocessor \nsystems allows a programmer to exploit parallel-\nism on SMP systems?\n a. memory mapped files \n b. multithreading \n c. critical sections \n d. semaphores \n e. none of the above  \n \n7.7 What common hardware technique requires an \nSMP scheduler to make some special provisions \nfor scheduling processes? \n \n7.8 What is the term used to describe the mechanisms \nthat are commonly used to exploit parallelism in dis-\ntributed applications running on cluster systems?  \n \n7.9 Which of these techniques used in SMP systems \nor in clusters are also used to distribute processing \nin grid systems?\n a. multithreading \n b. RMI \n c. virtual systems \n d. CORBA \n e. none of the above \n 7.10 In uniprocessor systems we have to use criti-\ncal sections to protect shared memory when it is \nbeing accessed by multiple processes. Why do we \nnot usually need to use such mechanisms on clus-\nters and grids? \n 7.11 What mechanism is suggested to mitigate most \nfailures in distributed systems? \n 7.12 How does work get distributed on a multiprocess-\ning computer system? \n 7.13 How does work get distributed on a cluster com-\nputing system? \n 7.14 How does work get distributed on a volunteer \ncomputing system? \n 7.15 How does work get distributed in a Globus \nsystem? \nelm49810_ch07_127-148.indd   148\nelm49810_ch07_127-148.indd   148\n12/11/08   5:25:24 PM\n12/11/08   5:25:24 PM\n",
        "category": "Category"
    },
    {
        "id": "22",
        "title": "Title for Chunk 22",
        "content": "Confirming Pages\n149\nPart\nPart 3\nCPU and Memory Management\nIn this part:\nChapter 8:   Process Management: Concepts, Threads,\nand Scheduling 151\nChapter 9:   More Process Management: Interprocess Communication, \nSynchronization, and Deadlocks 181\nChapter 10: Basic Memory Management 209\nChapter 11: Advanced Memory Management 225\n P\narts 3\u20135 of this book are similar to the bulk of most OS textbooks. They pro-\nvide in-depth treatment of individual aspects of OSs. In particular, Part 3 treats \nsome of the more fundamental topics that all modern OSs have to deal with: \nprocess and thread management and memory management. Together these constitute \ntwo of the major portions of an OS.\nThere are four chapters in this part of the text. The first two deal with processes \nand threads and how they communicate and otherwise interact. Chapter 8 defines a \nprocess and discusses the algorithms and data structures that have evolved to manage \nand schedule processes. It also defines the concept of threads and how they are used \nand implemented.\nWhen high performance systems are developed that place great demands on an \nOS, it is usually necessary to break them into separate parts and allow them to run \nseparately. Chapter 9 discusses the reasons why we often end up with systems com-\nprised of multiple process or threads. Multiple processes will need to communicate \nto coordinate their work. So this chapter discusses mechanisms for such communi-\ncation. It then points out some of the pitfalls involved in such communication and \nintroduces the notions of synchronization and the deadlocks that may result.\nThe last two chapters in this part of the book deal with issues of memory man-\nagement. Chapter 10 deals with memory management in simple systems. In part \nthis is historical, but today it is clear that miniaturization of computer hardware will \nmean that we will continue to find computers in environments where resources are \nscarce, and these simple techniques will continue to be applicable in the foreseeable \nfuture.\nelm49810_ch08_149-180.indd   149\nelm49810_ch08_149-180.indd   149\n12/18/08   11:25:13 AM\n12/18/08   11:25:13 AM\n",
        "category": "Category"
    },
    {
        "id": "23",
        "title": "Title for Chunk 23",
        "content": "Confirming Pages\n150\nChapter 11 deals with how memory is managed in larger systems. The two \nmain techniques that have evolved are paging and segmentation. This chapter first \nexplains how these work and then goes on to explain the notion of effective memory \naccess time and the effect that paged or segmented memory would have. It then \nintroduces the idea of a translation lookaside buffer and how it mitigates this prob-\nlem. It next explains the notion of virtual memory and discusses some algorithms for \nthe management of virtual memory.\nelm49810_ch08_149-180.indd   150\nelm49810_ch08_149-180.indd   150\n12/18/08   11:25:14 AM\n12/18/08   11:25:14 AM\n",
        "category": "Category"
    },
    {
        "id": "24",
        "title": "Title for Chunk 24",
        "content": "Confirming Pages\n89\n Chapter\nChapter 5 5 \n A Single-User Multitasking/ \nMultithreading Operating \nSystem \nIn this chapter: \n \n5.1 Introduction 89\n \n5.2 The Origin of the Macintosh Computer 90\n \n5.3 The Macintosh OS\u2014System 1 91\n \n5.4 System 2 96\n \n5.5 System 3 98\n \n5.6 System 4 98\n \n5.7 System 5 100\n \n5.8 System 6 101\n \n5.9 System 7 101\n 5.10 System 8 105\n 5.11 System 9 107\n 5.12 Mac OS X  109\n 5.13 Summary  111\n5.1 INTRODUCTION \n The Mac OS represents an interesting level in our spiral evolution of OSs because it \nhas gone through a series of evolutions itself. It was initially intended to be an OS \nfor an affordable personal computer that had a GUI. At the time this was revolution-\nary. There had been other systems that used a GUI, but they were considerably more \nexpensive. But other than the GUI, in most ways the first release of the Mac OS was \nless sophisticated than the Palm OS that was discussed in Chapter 4. However, as \ntime went by, pressure from other systems caused an evolution in the Mac hardware \nand the Mac OS, and at the end of its line it was roughly as powerful as the multiuser \nelm49810_ch05_089-112.indd   89\nelm49810_ch05_089-112.indd   89\n12/10/08   5:56:10 PM\n12/10/08   5:56:10 PM\n",
        "category": "Category"
    },
    {
        "id": "25",
        "title": "Title for Chunk 25",
        "content": "Confirming Pages\n90 \nPart 2 Building Operating Systems Incrementally: A Breadth-Oriented Spiral Approach\nLinux OS that we will discuss in the next chapter. The difference was that Linux \nwas designed from the outset to support multiple concurrent users, and this made \nsome significant differences in its structure and design. So we discuss the Mac OS \nas an intermediate step between the Palm OS, which was intended for a very sparse \nenvironment with only a single user, multitasking but no user multithreading, limited \nscreen space, and no secondary storage, and Linux, an OS intended for a multiuser, \nmultitasking, multithreading environment with large secondary and tertiary storage \nand a GUI that supported large screens with overlapping windows. \n Because the Mac OS went through several profound changes during its history \nwe use a different approach in this chapter than we did in the other spiral chapters. \n We start this chapter in Section 5.1 with an overview of the Mac OS and some \nbackground about the underpinnings of the original kernel. After this short introduc-\ntion we follow the releases of the Mac OS in Sections 5.3 through 5.12 and describe \nthe additional features in each release. This is because the Mac OS began with such \nhumble origins, being little better than CP/M in most features, and ultimately evolving \ninto a full-featured, modern OS capable of supporting multiple users and multiple pro-\ncesses as completely as the Linux system discussed in the next chapter. Following the \nevolution of the Mac OS is in itself a bit of a mini-spiral approach. We stop short of the \nMac OS X release in favor of describing an alternate system in the next chapter, Linux. \nWe will say only enough about it to position it with regard to the other major PC OSs \non the market today. We conclude this chapter in Section 5.13 with a summary.  \n 5.2 THE ORIGIN OF THE MACINTOSH COMPUTER \n In 1973 a revolutionary computer system called the ALTO was designed at the \nXerox Palo Alto Research Center\u2014aka Xerox PARC. This computer was never \nsold, but over 200 were given to universities and other research institutions. They \ncost about $32,000 1 each to build, and included revolutionary technology such as \na forerunner of the GUI interface we know today, a type of Ethernet and a mouse, \namong other things. A later system, the Xerox Star, contained many of the same \nfeatures. It retailed for $16,600.  2 This was still too costly for a computer intended to \nbe used by only one person and the system was not a commercial success. However, \nthese systems were seen by some other visionary pioneers of the personal computer \nbusiness, and they began a drive to produce affordable systems that incorporated \nthese ideas. Among those pioneers was Steven Jobs, whose Apple Computer sys-\ntems had been among the first commercially successful personal computers. \n Apple first developed the Apple Lisa, which retailed for $10,000.  3 Like the \nXerox Star, it was also a commercial failure. But Apple persevered, and eventually \nintroduced the Macintosh personal computer in 1984,  4 which retailed for $2,500, in the \n1 $157,000 in 2007 dollars.\n2 $42,000 in 2007 dollars.\n3 Almost $21,000 in 2007 dollars. \n4 Over $5,000 in 2007 dollars. \nelm49810_ch05_089-112.indd   90\nelm49810_ch05_089-112.indd   90\n12/10/08   5:56:13 PM\n12/10/08   5:56:13 PM\n",
        "category": "Category"
    },
    {
        "id": "26",
        "title": "Title for Chunk 26",
        "content": "Confirming Pages\n \nChapter 5 A Single-User Multitasking/Multithreading Operating System \n91\nsame range as an IBM PC. The Mac seemed more affordable than the Lisa to  average \npeople, and the GUI interface made it a very usable system, so it was an immediate \nsuccess. The Macintosh hardware used the Motorola 68000 family of CPUs.  \n 5.3 THE MACINTOSH OS\u2014SYSTEM 1 \n The initial release of the Mac OS was known as System 1. System 1 had several \ncharacteristics that were typical of OSs of the time. It also had a few unique features \nbecause of its GUI. \n 5.3.1 The GUI \n System 1 had a desktop, windows, icons, a mouse, menus, and scrollbars. See \n Figure 5.1 . The desktop had a trash can icon that could be used to delete items \nby dragging and dropping them on the icon. These are all metaphors and features \nwe take for granted today, but they were fairly revolutionary for the time. Unlike \nthe Palm OS, the OS design assumed that the screen was large enough to hold \nmore than one window or to show the desktop with a window that did not take up \nthe entire screen. The screens were only black and white and only had a resolu-\ntion of 520  \ufffd 342 pixels, so the graphics were very limited. Nonetheless, it was \na GUI and many users found it friendlier than a command-line interface, espe-\ncially novice users. Compare this with the command-line prompt in CP/M, which \nmerely said:  \nA>\n And awaited input from the user with no hint of what to do. \nFIGURE 5.1 \nThe Mac OS GUI.\nSource: All of the MAC \nOS screen shots in this \nchapter were made with \nthe Mini vMac emulator. \nIt is available at http://\nminivmac.sourceforge\n.net/.\nelm49810_ch05_089-112.indd   91\nelm49810_ch05_089-112.indd   91\n12/10/08   5:56:13 PM\n12/10/08   5:56:13 PM\n",
        "category": "Category"
    },
    {
        "id": "27",
        "title": "Title for Chunk 27",
        "content": "Confirming Pages\n92 \nPart 2 Building Operating Systems Incrementally: A Breadth-Oriented Spiral Approach\n The GUI is probably the most significant thing about the Mac OS, not because it \nwas so original or so well done, but because of what it  did not have to support. In the \nrest of the world the OSs typically evolved from legacy systems that originally had \ncommand-line interfaces (as with DEC, UNIX, IBM, etc.). The applications were \nstandalone programs invoked through entry of one-line commands on an interface \ncalled a command line. These interfaces simulated the way a typewriter attached to \na computer worked. So they were designed around keyboard use and had little or no \nmouse support. Each application team was free to use whatever key they wished for \nany given function. So to invoke a spelling check, a word processor might use the \nF7 key while a spreadsheet program might use the F12 key. Even worse, there was \nno dominant package in most application areas, so the WordPerfect word processing \nprogram might use one key to print and a competitor program like WordStar might \nuse a different key for the same function. For each individual application there were \nkeyboard templates available that showed what every function key did, when used \nalone or when used with any combination of Shift, CTRL, and ALT keys! \n With the Mac there were no legacy applications. From the outset there was a \nkey sequence assigned to the Print function and a new application had no reason to \ndeviate from that assignment. As a result, Apple was able to truthfully advertise the \nease of learning to use software on a Mac. For example, suppose a user had mastered \na word processing application on a MAC. If that user understood how a spreadsheet \ntool worked, then that user would be able to easily use a spreadsheet program on the \nMAC because all the standard functions would be invoked just as they were on the \nword processing program. Even today this problem persists in Windows and Linux \napplications. The point is that one should not underestimate the impact of a require-\nment for backward compatibility\u2014something the Mac did not have. \n 5.3.2 Single Tasking \n In order to deliver an affordable product, the early Macintosh had to run with very \nlimited memory since it was still quite expensive. As a result, Apple\u2019s developers \ndecided to forego the multitasking Apple had used with the Lisa. Even though an \napplication window probably did not take up the entire screen, the Mac OS did not \ninitially allow more than one program to run at the same time, even for background \nprinting. To allow some parallel functionality, the OS included Desk Accessories, \nwhich included functions such as a Calculator, Alarm Clock, system Control Panel, \nand Notepad, but these were carefully limited so that they would not use too much \nRAM. They were implemented as \u201cdevice drivers\u201d rather than separate programs, \nand could open a single window.  Figure 5.2  shows how primitive these were by \ntoday\u2019s standards.  Figure 5.3  shows the  Control Panel, which allowed the user to \nchange many system settings. The system had an application called  finder that was \nused to find files in the system. The finder window was the command processor that \nin most OSs was a command-line console. So it was also the mechanism for running \nother programs. The finder window is visible in  Figure 5.1 . The System 1 version of \nfinder was referred to as a single application finder. Since only one application pro-\ngram was running at a time (not counting the Desk Accessories), there was no need \nfor protecting one program from reading or changing another program in memory, \nelm49810_ch05_089-112.indd   92\nelm49810_ch05_089-112.indd   92\n12/10/08   5:56:14 PM\n12/10/08   5:56:14 PM\n",
        "category": "Category"
    },
    {
        "id": "28",
        "title": "Title for Chunk 28",
        "content": "Confirming Pages\n \nChapter 5 A Single-User Multitasking/Multithreading Operating System \n93\nFIGURE 5.2 \nThe Calculator \ndesktop accessory.\nFIGURE 5.3 \nThe Control Panel.\nso the OS had no such scheme. System 1 also did not even protect the OS from the \napplications. This was also true of most other OSs available at the time. \n 5.3.3 Secondary storage \n As with the CP/M system discussed in Chapter 3, programs were kept on a single \nfloppy disk drive and loaded into RAM only when they were to be executed. The \ndisk system that was available on the early Macs was only 400 Kbytes. This is a \nsmall enough space that it was fairly easy to find files, so all files were kept in a \nsingle directory. Still, the developers of the OS realized that the idea of grouping like \nfiles together was useful, so the system showed  folders on the disk. As with CP/M, \nhowever, these folders were only a simulation. Each file directory entry could be \nmarked with a folder name, and the system would allow the user to look inside the \nfolder, essentially listing all the files marked with that folder name. As a result, it was \nalso not possible to nest folders within folders. \nelm49810_ch05_089-112.indd   93\nelm49810_ch05_089-112.indd   93\n12/10/08   5:56:14 PM\n12/10/08   5:56:14 PM\n",
        "category": "Category"
    },
    {
        "id": "29",
        "title": "Title for Chunk 29",
        "content": "Confirming Pages\n94 \nPart 2 Building Operating Systems Incrementally: A Breadth-Oriented Spiral Approach\n 5.3.4 Memory management \n The Mac OS has a single address space, as seen in  Figure 5.4 .  5 This architecture \nis said to be \u201cflat,\u201d which means that at any time any instruction can directly ref-\nerence all of memory. Other designs of the era used a more complex scheme that \nallowed large amounts of RAM but limited the addressing such that a program could \nonly address segments of 64 KB with any instruction. The 68000 CPU has 24-bit \naddresses, allowing for 16 MB of RAM. There is no memory protection, so any \nprogram can modify anything in memory, including the OS itself. In addition, the \napplication code runs in supervisor mode so there is no instruction protection to \nlimit what the application can do. The size of the address space is determined when \nthe OS boots. The lowest part of RAM is occupied by a  system partition. This area \ncontains some system global values, which applications should not access directly. \nRather, they should use the OS APIs to read and manipulate any system data. But \nwith no memory protection or instruction protection, there is nothing to prevent an \napplication from taking a shortcut and accessing such information directly. In the \nearly days of personal computers, application writers would often take such short-\ncuts and tried to justify their actions in the name of performance. \n An  application partition is allocated from the top of memory downward. The \nlayout of an application partition is seen in  Figure 5.5 . At the top is a fixed size data-\nblock called the  A5world, which contains the application\u2019s static data and some \nmetadata about the application. The name arose because the Mac OS loaded the A5 \nregister of the CPU with a pointer to this area so that the application would know \nwhere it was located in memory and could access its global data by addressing rela-\ntive to the A5 register. Below this is the stack, with the \u201ctop\u201d of the stack growing \ndownward. The heap grows from the bottom of the application partition upward and \n5 The initial releases of the Mac OS did not support multiple processes. That came later. \nApplication\npartition\nSystem\npartition\nHigh Memory\nA5world\nStack\nHeap\nSystem Heap\nSystem Global Variables\nUnallocated\nFIGURE 5.4 \nSystem 1 memory \nlayout.\nelm49810_ch05_089-112.indd   94\nelm49810_ch05_089-112.indd   94\n12/10/08   5:56:15 PM\n12/10/08   5:56:15 PM\n",
        "category": "Category"
    },
    {
        "id": "30",
        "title": "Title for Chunk 30",
        "content": "Confirming Pages\n \nChapter 5 A Single-User Multitasking/Multithreading Operating System \n95\nHeap\nA5world\nCurrentA5\nApplLimit\nApplZone\nStack\nHigh Memory\nCurStackBase\nFIGURE 5.5 \nApplication memory \npartition.\nincludes code segments. So one problem that the OS has to manage is to make sure \nthat these two areas do not run into one another. \n An upper limit on the size of the heap is set for an application when it starts. \nGrowth of the heap is controlled by the memory allocation routines, so they always \ncheck to make sure that a requested allocation will not exceed the limit. But the stack is \nautomatically maintained by the hardware. As subroutines and functions are called and \nreturn, data are pushed onto and popped off of the stack. Since many applications call \nmultiple levels of subroutines, sometimes recursively, this stack tends to grow as the \nprogram runs. But there is no hardware protection against the stack\u2019s extending below \nthe limit. Instead, a  stack sniffer subsystem runs during the interval of the monitor \nvertical retrace (about 60 times a second) that checks the stack level against the limit. \n A big problem for the designers of the Macintosh was how to make optimum \nuse of the 128 KB of RAM. In some ways this was a large amount of memory. \nOther personal computers of the same era had 16 or 64 KB of RAM. But the Mac \nwas intended to have a GUI, and such interfaces take a good deal of RAM. As was \nmentioned above, the developers decided to limit the Mac to run only one program at \na time. Their main concern appears to have been memory fragmentation\u2014repeated \nallocation and deallocation of memory leads to many small, isolated areas of mem-\nory, which cannot be used because they are too small, even though the total free \nmemory may be enough to satisfy a particular request. In order to avoid fragmenta-\ntion of heap memory the Mac OS supports relocatable memory blocks. These are \naccessed indirectly via a pointer into a nonrelocatable  master pointer block. The \nPalm OS discussed in the last chapter uses a similar mechanism. The relocatable \nblocks are compacted from time to time in a garbage collection process. Relocatable \nblocks can also be marked purgeable, which means the system may free them dur-\ning compaction if the free memory space falls below a predetermined limit. Pointers \nwere initially only 24 bits long, but were stored in a 32-bit field for anticipated future \ngrowth in the processors. So the top 8 bits (of the 32) were often used for flags mark-\ning blocks as relocatable, temporary, purgeable, and so on. \n The OS implemented two areas with this scheme: the  system heap used \nby the OS, and the  application heap. As long as only one program was run, the \nelm49810_ch05_089-112.indd   95\nelm49810_ch05_089-112.indd   95\n12/10/08   5:56:17 PM\n12/10/08   5:56:17 PM\n",
        "category": "Category"
    },
    {
        "id": "31",
        "title": "Title for Chunk 31",
        "content": "Confirming Pages\n96 \nPart 2 Building Operating Systems Incrementally: A Breadth-Oriented Spiral Approach\n system worked well. Since the application heap was erased when the program quit, \n fragmentation was minimized. Unfortunately, as was mentioned above, the OS pro-\nvided no memory protection, and crashes caused by application program errors \nmanipulating the system heap were not uncommon. \n 5.3.5 ROM \n Most personal computers used only a small amount of ROM to contain code for \nPower-On Self-Test ( POST ) and some Basic Input/Output System ( BIOS ) routines, \ntypically about 8 KB. The Mac OS ROM was significantly bigger (roughly 64 KB) \nand held much of the actual OS itself. The initial purpose of having so much code in \nROM was to avoid filling the limited storage available on a floppy disk, given that \nthe early Macs had no hard disk. It also helped the system to boot faster since that \ncode did not have to be read from the floppy drive. Only the 1991 Mac Classic model \nwas bootable using the ROM alone. This architecture also helped to ensure that only \nApple computers and licensed clones could run the Mac OS. \n 5.3.6 Incremental releases \n As with most OSs, between major releases there are incremental releases. These \nreleases are often given fractional numbers. They are released for various reasons: \nspeedup of some specific function such as the loading of the OS, bug fixes, and \noccasionally some new feature or application that is scheduled for some later major \nrelease that is falling behind schedule. In the Mac OS System 1 there was one such \nrelease, 1.1, that did a bit of all of these. \n 5.4 SYSTEM 2 \n System 2 was theoretically a major release, but there were no features that were \nsignificant from a theoretical point of view. The Finder was somewhat faster. Cer-\ntain icon/commands were eliminated, and icons for creating a New Folder and for \nShutdown of the system were added. Floppy disks could now be ejected merely by \ndragging their icons to the Trash, instead of selecting the Eject Disk command and \nthen dragging the icon to the Trash. A Choose Printer desk accessory was added, \nwhich allowed a user to select a default printer. This utility would later become the \n Chooser, a utility for accessing shared resources, such as printers, modems, and disk \nvolumes hosted on other systems and made available through a network. \n 5.4.1 GUI \n Users of the Mac liked the GUI and the ability to cut and paste information from one \napplication to another. But this meant cutting the data from one program, stopping \nthat program, starting the new program, and then pasting the data into it\u2014an opera-\ntion that usually took minutes. Each new Macintosh model included more RAM \nthan the previous models, and the Macintosh 512K (aka the Fat Mac), contained \nfour times the RAM of the original Mac. This was enough to support some form of \nelm49810_ch05_089-112.indd   96\nelm49810_ch05_089-112.indd   96\n12/10/08   5:56:17 PM\n12/10/08   5:56:17 PM\n",
        "category": "Category"
    },
    {
        "id": "32",
        "title": "Title for Chunk 32",
        "content": "Confirming Pages\n \nChapter 5 A Single-User Multitasking/Multithreading Operating System \n97\nmultitasking. It was first implemented in the  Switcher program. Switcher allowed a \nuser to start several programs. The user could then switch between these applications \nby clicking an icon on the menu bar. The current application would horizontally slide \nout of view, and the next one would slide in. When a user switched to one of the \nrunning programs it was said to \u201c have the focus. \u201d The user could thus cut and paste \nbetween applications in seconds instead of minutes. \n 5.4.2 Multitasking \n Switcher created a number of fixed slots in RAM into which applications were \nloaded. The Switcher program allocated a separate heap for each application that the \nuser started, subject, obviously, to the availability of RAM. When the user toggled \nfrom one process to another the Switcher could perform a context switch and fix the \nOS memory management data so that the OS would begin working with the new \napplication. Since there was no memory or instruction protection the Switcher could \ntweak the OS memory structures to affect a switch. However, this was very limited \nmultitasking, somewhat like the Palm OS in that there was still only one process run-\nning at any one time. The user could switch from one process to another, but while \na process did not have the focus, that process was not actually running. Despite its \nawkwardness, this approach worked with the existing system\u2019s memory manage-\nment scheme, as programs did not need to be changed to work with Switcher. The \nchanges were also transparent to the OS kernel. A typical memory layout with mul-\ntiple processes in the system is shown in  Figure 5.6 . \nApplication 1\npartition\nApplication 2\npartition\nSystem\npartition\nHigh Memory\nA5world\nStack\nHeap\nA5world\nStack\nHeap\nSystem Heap\nSystem Global Variables\nUnallocated\nFIGURE 5.6 \nSystem 2 \u201cSwitcher\u201d \nmemory layout.\nelm49810_ch05_089-112.indd   97\nelm49810_ch05_089-112.indd   97\n12/10/08   5:56:18 PM\n12/10/08   5:56:18 PM\n",
        "category": "Category"
    },
    {
        "id": "33",
        "title": "Title for Chunk 33",
        "content": "Confirming Pages\n98 \nPart 2 Building Operating Systems Incrementally: A Breadth-Oriented Spiral Approach\n 5.5 SYSTEM 3 \n 5.5.1 Hierarchical File System \n Disk drives were getting bigger and users tended to fill them up then as they do now, \nwanting to have quick access to all their information. This meant that the number of \nfiles was growing much larger, so it was getting hard for a user to keep track of files. \nSo a new file system design was released known as the Hierarchical File System \n(HFS). It replaced the old Macintosh File System (MFS). Folders were now actual \nsubdirectories instead of just tags in the directory entries, and folders could contain \nother folders. It was so much more useful that it came to be called the Mac OS \nStandard File System (to distinguish it from a later extended version). The directory \nentries contained timestamps showing when the file was created and when it was last \nmodified, the file type and creator codes, a file name of up to 32 characters, and other \nfile metadata. (The creator code told the OS what application had created the file.) \nThe free space was tracked by a bitmap and the directories are stored as B-trees. \nThese ideas will be further explained in Chapters 12 and 13. \n There were a few bug fix releases until the next real advance in the OS \ncapabilities. \n 5.5.2 Networks \n Local area networks (LANs) were becoming extremely popular. They allowed shared \naccess to expensive devices such as large disk drives, high-end laser printers, modem \npools, and other exotic devices such as microfilm output. They also facilitated com-\nmunication through shared files and directories on central servers. So with System 3.3 \nApple added support for  AppleShare, a proprietary file-sharing protocol. The protocol \nstack also included proprietary technology at other layers:  AppleTalk at the network \nlayer and  LocalTalk at the data link and physical layers. Now the Chooser utility took \non much more importance than just selecting the default printer. LaserWriter printers \ncould be directly connected to the network and shared by several users. The Macin-\ntosh began to be viewed as a powerful desktop publishing system and these printers \nwere a large factor in that view and in the general success of the Mac product line.  \n 5.6 SYSTEM 4 \n System 4 was introduced with the Macintosh SE and Macintosh II. At this stage in the \ndevelopment of OS technology, new releases were often required just to support new \nmodels of a computer. System 4.1 added support for disk drives larger than 32 MB. \n Different references disagree about when the Mac OS supported a version of \nfinder that could launch multiple applications. Most likely this is because the nam-\ning of the releases was somewhat confusing. The main software had one number, \nthe finder had another, and the MultiFinder (to be discussed shortly) had another. \nFor example, one reference  6 lists System Software 5.0 (System 4.2, Finder 6.0, and \n6 http://en.wikipedia.org/wiki/Mac_OS_history \nelm49810_ch05_089-112.indd   98\nelm49810_ch05_089-112.indd   98\n12/10/08   5:56:20 PM\n12/10/08   5:56:20 PM\n",
        "category": "Category"
    },
    {
        "id": "34",
        "title": "Title for Chunk 34",
        "content": "Confirming Pages\n \nChapter 5 A Single-User Multitasking/Multithreading Operating System \n99\nFIGURE 5.7 \nMultiFinder.\nMultiFinder 1.0), while another reference  7 states that System 5 was never released. \nIn addition, because MultiFinder was new and Apple was not certain that all existing \nprograms could operate correctly under it, Finder continued to be distributed with \nthe OS, compounding the release naming issue. \n 5.6.1 MultiFinder \n The consensus seems to be, however, that System 4.2 implemented MultiFinder\u2014\nusers could switch between Finder, which supported only one program at a time, and \nMultiFinder, which could support multiple programs. See  Figure 5.7 . MultiFinder \nextended the OS significantly. Unlike Switcher, which merely switched the OS from \nrunning one application to running another, MultiFinder allowed each program to \nkeep running, giving each application CPU time. Unlike OSs, which we will study \nlater, the Mac OS did not set hard limits on how long a process could continue \nrunning without switching to another process. The technique used in the Mac OS \nis known as  cooperative multitasking. With this technique a process can run as \nlong as it wants to. If the process makes a call to the OS that the OS cannot service \nimmediately, such as a disk read, then it will make the process wait\u2014a mechanism \nknown as  blocking. When a process makes such a blocking call, then the OS will \nadd the blocked process to a queue of processes that are waiting for something and \nwill switch to running another process. If a process makes no blocking calls then \nit can run as long as it likes. In order for all processes to give a quick response to \nuser requests, they all need some CPU time. So if one process runs for too long it \n7 http://www.macos.utah.edu/documentation/operating_systems \ufffd mac_os_x.html \nelm49810_ch05_089-112.indd   99\nelm49810_ch05_089-112.indd   99\n12/10/08   5:56:20 PM\n12/10/08   5:56:20 PM\n",
        "category": "Category"
    },
    {
        "id": "35",
        "title": "Title for Chunk 35",
        "content": "Confirming Pages\n100 \nPart 2 Building Operating Systems Incrementally: A Breadth-Oriented Spiral Approach\ncan make the performance of the system seem uneven. In order to keep this from \nhappening, all processes are supposed to make a special system call fairly often that \ntells the OS that the process is not through but that it is voluntarily relinquishing \ncontrol and is ready to run again. This allows other processes to have a fair share of \nthe CPU time. Of course, some vendors want their software to appear to be the best \nresponding, so they don\u2019t call that routine often enough. In other cases a software \nerror may cause a program to go into a loop and never yield control or make a block-\ning call. In these cases the system will essentially freeze.  \n 5.6.2 The GUI under MultiFinder \n MultiFinder provided a way for windows from different applications to coexist by \nusing a layering model. Now that there could be multiple running applications, they \nmight each have multiple windows open on the desktop at the same time. When a \nprogram got the focus, all of its windows were brought forward together in one layer. \nThis was necessary for compatibility with existing windowing APIs. \n 5.6.3 RAM management with MultiFinder \n MultiFinder also provided a way for applications to communicate their memory \nrequirements to the OS, so that MultiFinder could allocate RAM to each program \naccording to its need. Unfortunately, the amount specified would not be enough for \nsome tasks, so the user was given an interface to override this number. This strongly \nwent against the Apple theory that users should be kept away from such technical \ninformation. In this case their theory was correct, since users often had no idea how \nmuch memory a program might really need. One program was often given much \nmore memory than it really needed and another program was given much too little. \nAs a result, the starved application would perform poorly. When multiple applica-\ntions are running, the management of RAM is usually much more complex than \nwhen a single application is running. But when MultiFinder was being developed, \na key consideration was that programs that ran under the single Finder should work \nwithout change under MultiFinder. So the memory architecture is very similar, just \nslightly more complicated. With one application running the architecture looks like \nthat in  Figure 5.1 . When several applications are running the architecture looks like \nthat in  Figure 5.3 . As execution shifts from one application to another the OS will \nchange the contents of certain system variables to reflect the sizes and locations of \nthe application partition and its pieces for the new application. This change is known \nas a  context switch. As we will see later, with modern OSs a context switch is often \nmuch more complicated than this. \n 5.7 SYSTEM 5 \n As was stated above, some references say that System 5 was never released and oth-\ners say it was released only for a short time. In either case there is nothing significant \nabout it for the purposes of studying OS evolution. \nelm49810_ch05_089-112.indd   100\nelm49810_ch05_089-112.indd   100\n12/10/08   5:56:20 PM\n12/10/08   5:56:20 PM\n",
        "category": "Category"
    },
    {
        "id": "36",
        "title": "Title for Chunk 36",
        "content": "Confirming Pages\n \nChapter 5 A Single-User Multitasking/Multithreading Operating System \n101\n 5.8 SYSTEM 6 \n In the eyes of many observers, System 6 was the first true upgrade of the Mac OS.  8 \nRAM was getting cheaper and larger and users always wanted more of it. So System \n6 began the migration to supporting the Mac in the true 32-bit memory addressing \nmodes that had appeared with the Motorola 68020 CPU. These 32-bit addresses \nallowed the Mac OS to address up to 4 GB of RAM. Earlier versions of the Mac \nOS had used the lower 24 bits for addressing, and the upper 8 bits for flags, which \nindicated, for example, that the block pointed to was marked as \u201clocked,\u201d \u201cpurge-\nable,\u201d or as a \u201cresource.\u201d This had been an effective solution for earlier hardware \nwith limited RAM, but became a liability later. Apple referred to code that used the \n24  \ufffd 8-bit addressing model as being not  32-bit clean, and suggested that develop-\ners remove such code from their applications. As was noted before, much of the Mac \nOS was in ROM. Unfortunately, much of that ROM code was not 32-bit clean, and \nso older Macs could not be migrated to this new mode. The new mode required new \nversions of the hardware. The change to 32-bit addressing mode made for a lot of \ncompatibility issues that linger even into today\u2019s versions of the Mac OS. The OS \nmaintains the capability of running applications in a 24-bit mode, though it is much \nslower than the 32-bit mode. So Apple was now feeling the pinch of supporting \nlegacy applications. \n In the early part of the PC era, developers still saw the RAM in a system as \na very tight resource and would go to great lengths to save a byte or two here and \nthere. As time went by it was often found that such savings had a very negative \nimpact later. Indeed, the  Y2K bug (Year 2000)  9 was another example of this sort \nof problem caused by the desire save a few bytes of RAM by shortening the format \nof the year part of dates to the last two bytes. The end of the century was 20 years \naway and developers assumed that the systems they were developing would not still \nbe in use by then anyway. When the last year of the century rolled around, systems \nthat had stored dates as only two digits would make incorrect conclusions, calculat-\ning that a date in the year \u201c00\u201d (i.e., 2000) came before a date with the year \u201c99\u201d \n(i.e., 1999.) The Mac OS was apparently designed from the start to avoid the Y2K \nproblem, though Apple never officially certified any system release before System 7 \nas being Y2K compliant. \n 5.9 SYSTEM 7 \n System 7 was the biggest change to the system software up to that time. It continued the \nmigration of the Mac OS to full 32-bit addressing and improved its handling of color \ngraphics, networking, and  multitasking,  and it introduced a form of  virtual memory. \n Many features that had been available as options in earlier versions of the Mac \nOS were integrated into System 7. This release dropped the single program version \n8 http://en.wikipedia.org/wiki/Mac_OS_history \n9 http://en.wikipedia.org/wiki/Y2k  \nelm49810_ch05_089-112.indd   101\nelm49810_ch05_089-112.indd   101\n12/10/08   5:56:20 PM\n12/10/08   5:56:20 PM\n",
        "category": "Category"
    },
    {
        "id": "37",
        "title": "Title for Chunk 37",
        "content": "Confirming Pages\n102 \nPart 2 Building Operating Systems Incrementally: A Breadth-Oriented Spiral Approach\nof Finder, eliminating the Finder versus MultiFinder issue. Cooperative multitasking \nthus became the normal mode of operation of the system. Networking via Apple-\nTalk and file sharing via AppleShare were built into the operating system, instead of \nbeing optional. \n 5.9.1 The GUI \n System 7 had several usability improvements, many in the area of the GUI. A menu \nwas added to the right end of the menu bar called the Application menu. It showed \na list of running programs and allowed users to switch among them. Next to the \nApplication menu was the Help menu. Users could now drag and drop\u2014a block of \ntext could be dragged from one program to another with the mouse instead of hav-\ning to copy and paste. System 7\u2019s Finder finally utilized color features and made \nsome interface elements look more three-dimensional. Other usability features were \nalso added to the OS in the System 7 releases. WorldScript provided system-level \nsupport for languages besides English. Technologies such as AppleScript, a macro \nlanguage for task automation; ColorSync, color management utilities; QuickTime \nmultimedia software; and TrueType font management were also released. Over \ntime, many of the features that we associate with modern GUIs were added to the \nMac OS. For the most part we will not detail these features in each release. We will \nonly note that the GUI was evolving in a piecemeal fashion and was becoming more \nusable over time.  \n 5.9.2 Virtual memory \n Sometimes a user wanted to run more programs than would fit into RAM at the \nsame time. Or perhaps the program was used with a data file that was very large. \nFor example, a word processor might normally fit fine in a small space if it was just \nbeing used to write interoffice memos. But if it was used to edit a large report it might \nrequire a great deal more RAM. When performance is poor because more memory is \nrequired but a larger memory is not available or is too expensive, then one solution \nis called  virtual memory, or  VM. VM is a technique that uses some space on a hard \ndisk drive to simulate a larger primary memory. It requires extra memory manage-\nment hardware support to work. Briefly, memory is divided into blocks known as \n pages. When a program starts running, only the first page of the program is brought \ninto RAM. When the running program references a part of the program that is not yet \nin memory the hardware will cause an interrupt called a  page fault,  and the OS will \nread the missing page into RAM from the disk drive. This technique is discussed in \ngreater detail in Chapter 11. \n As was mentioned, special hardware is required in a computer system for the \nOS to be able to support VM. The computer must have a special  memory manage-\nment unit ( MMU ), which is capable of translating the  logical addresses that are \ngenerated by the program running in the CPU and translating them into a  physical \naddress so that the pages of the program can be located anywhere in RAM. Apple\u2019s \n68040- and 68030-based machines have a VM-capable MMU built into the CPU and \ncan thus support VM with no additional hardware. A Macintosh II (68020-based) \nelm49810_ch05_089-112.indd   102\nelm49810_ch05_089-112.indd   102\n12/10/08   5:56:21 PM\n12/10/08   5:56:21 PM\n",
        "category": "Category"
    },
    {
        "id": "38",
        "title": "Title for Chunk 38",
        "content": "Confirming Pages\n \nChapter 5 A Single-User Multitasking/Multithreading Operating System \n103\ncould have a special MMU coprocessor on its main logic board in place of the stan-\ndard address management unit (AMU). 10 This MMU would also support VM. \n VM was first implemented in the Mac OS with System 7. However, the virtual \nmemory support was very preliminary and performed very poorly in many circum-\nstances. The design of the OS Memory Manager used RAM in such a way that it \ncaused excessive page faults under VM.  11 VM features that are commonly found \nin VM implementations of other OSs today\u2014such as protected address spaces, \nmemory mapped files, page locking, shared memory, and so on\u2014were not present. \nMany of these were provided in later releases of the Mac OS. As Apple gained better \nunderstanding of the workings of VM and modified the behavior of certain portions \nof the OS, the system performance when running VM also improved. \n 5.9.3 A new CPU \n Sometime around 1990 Apple formed an alliance with IBM and Motorola to develop \na new processor family based on a combination of the IBM RS6000 architecture, the \nMotorola 68000, and the Intel PC line. It would be known as the PowerPC family, \nand it would determine Apple\u2019s hardware direction until 2006. The initial Mac with \nthe PowerPC CPU was the Power Macintosh 6100, or the Performa 6100 series. \nSupport for this processor family came in System 7.1.2. It required changes in the \ndesign of the Mac OS. This architecture was a RISC design, unlike the CISC design \nused in the Motorola 68000 family, so it represented a radical change in the code \nused by the CPU. It would have taken far too long to completely port an OS based on \nthe 68000 architecture to a RISC architecture, so the design of the PowerPC archi-\ntecture allowed it to emulate the 68000 CPUs. \n A small piece of code dubbed a  nanokernel managed the PowerPC CPU. It \nexecuted in supervisor mode and supplied low-level interfaces for hardware man-\nagement to the rest of the system. The API for this nanokernel was restricted to \nsystem software and debuggers. A 68000 emulator was started by the nanokernel \nat system startup time. It only emulated a 68000 user-mode instruction set with-\nout emulating the MMU. This allowed for more universal compatibility. The OS \nwas thus able to begin to run on the PowerPC-based systems almost immediately. \nHowever, emulation of the execution of a 68000 CPU on a PowerPC is significantly \nslower than execution of native PowerPC code. Programs could be compiled and \nlinked to produce executable modules that contained both native 68000 code and \nnative PowerPC code. This allowed a single version of the program to run on both \nolder machines and newer machines. Such dual-mode programs were known as  fat \nbinaries. Switching between the two modes was done by a set of library routines \ncalled the  Code Fragment Manager. Over time, more and more of the OS was \nmodified to include native PowerPC code as well as code that could still run on the \n68000 family of systems. \n The architecture of Apple computers was always proprietary. This had several \nside effects, some good and some bad. The main Apple system bus in the Macs was \n10 http://developer.apple.com/documentation/mac/Memory/Memory-152.html#HEADING152-0 \n11 http://developer.apple.com/technotes/tn/tn1094.html  \nelm49810_ch05_089-112.indd   103\nelm49810_ch05_089-112.indd   103\n12/10/08   5:56:21 PM\n12/10/08   5:56:21 PM\n",
        "category": "Category"
    },
    {
        "id": "39",
        "title": "Title for Chunk 39",
        "content": "Confirming Pages\n104 \nPart 2 Building Operating Systems Incrementally: A Breadth-Oriented Spiral Approach\ncalled NuBus. Since it was proprietary, Apple could exercise firm control over all \nhardware development. Thus, controllers were more likely to work on a Mac than \non an ISA bus machine, and the drivers were more likely to work as well. On the \nother hand, it meant that there was less competition in this market, and users thus \npaid a higher price for hardware and software than they might have otherwise. \nAlso, fewer vendors could afford to hire extra staff to develop hardware for addi-\ntional buses. Around 1990 work began at Intel on a standardized bus called the \nPeripheral Component Interconnect bus or PCI. By 1993 the full specification was \navailable, card vendors started creating I/O cards for this new bus, and system man-\nufacturers began including them on the new motherboard designs. Apple found that \nthis put them at a competitive disadvantage. Since the volumes vendors could sell \nin the PCI bus market were significantly greater than in the Apple NuBus market, \nthe prices Apple had to pay for interface controllers was much higher, and this \nboth cut into their hardware margins and made the price of their systems less com-\npetitive. Apple Computer therefore incorporated the PCI in the Power Macintosh \ncomputers it introduced in 1995. The System 7.5.2 release supported these new \nmachines and thus had to incorporate new drivers and chip set support for the PCI \nbus and controllers.  \n 5.9.4 Input/output enhancements \n The Macs existed in a world that was being dominated by Intel-based PCs running \nMicrosoft software. As a result, there was considerable pressure to provide bridges \nto that world. Certainly the networking support was evolving in that direction, and \nmany Microsoft-oriented protocols were added to the Mac OS support. Another \nexample was that System 7.1 introduced software called PC Exchange that could \naccess MS-DOS formatted floppies. Earlier releases only supported Apple floppy \ndisk formats. While floppies for the IBM PC and the Apple Mac were physically \nidentical, they are used differently in two ways. First, the  low-level formatting is \ndifferent. New floppy disks in most cases do not have any predetermined number or \nsize of sectors. A process called low-level formatting writes headers on the tracks \nthat later will tell the hardware where each sector starts, what the track and sector \nnumbers are for the sector, and how long it is. Different systems can use different \nnumbers and sizes of sectors, and early on there were many competing formats, both \nwith regard to the sizes of the media and the low-level formats. Today the sizes and \nformats have been fairly well standardized, but in the early 1990s there were still \nseveral competing standards. Once the low-level formatting is done the user can have \nthe OS \u201cformat\u201d the floppy at a higher level, creating an empty file system on the \ndisk. In the case of the IBM and Apple systems the file systems were different as \nwell as the low-level formatting. Adding to the Mac OS the ability to read and write \nMS-DOS floppies made Macs much more acceptable in the office world where easy \nexchange of files among users was a necessity. \n By this time laptop systems were in frequent use, and they often included a  PC \nCard slot. These were called  PCMCIA slots at that time but were since renamed. \nPC Card slots allowed the insertion of a device that was not built in to the original \nlaptop. Typical examples were network cards, controllers for external disk drives, \nelm49810_ch05_089-112.indd   104\nelm49810_ch05_089-112.indd   104\n12/10/08   5:56:22 PM\n12/10/08   5:56:22 PM\n",
        "category": "Category"
    },
    {
        "id": "40",
        "title": "Title for Chunk 40",
        "content": "Confirming Pages\n \nChapter 5 A Single-User Multitasking/Multithreading Operating System \n105\ndisk drives themselves, and RAM cards. A RAM card could not be addressed as pri-\nmary memory because the PCMCIA slot was on the I/O bus. So a common  technique \nfor dealing with such a card was to treat it as a special type of disk drive and create \na file system on it. Because the floppy format was about the right size, these were \noften created with an MS-DOS-compatible file system since they could then also be \nused to move data from IBM-compatible PCs to Macs since the Mac OS could read \nthese devices as well. \n Because of general enhancements to the OS and the fat binaries for use with \nthe PowerPC, the System 7 release was the first version of the Mac OS where a \nfull installation was too large to fit on a 1.44 MB floppy disk. As a result, System \n7.5 and later would not run from a floppy drive but required a hard disk on the \ncomputer.    \n 5.10 SYSTEM 8 \n By this time Apple was adding Macs to their product line that were intended to be \nused as servers. In some cases these new systems had multiple CPUs. System 8 \ntherefore added support for these new Mac multiple-CPU models. These machines \nwould experience better performance in a server role. Support in modern OSs for \nsuch systems is called  symmetric multiprocessing, or  SMP. In such situations the \nOS runs on any CPU that is available.  12 This can pose special problems for the OS \nbecause it can literally be running on two or more CPUs at the same time. This \nmeans that it must take special precautions to prevent having two running instances \nmanipulating any one data element at the same time. Since the Mac OS is primarily \na single-user system, we will defer a more in-depth discussion of SMP to the next \nchapter on Linux, a system designed from the outset to support multiple users and \nrun many other services. \n Personal Web Sharing was also introduced in System 8. This facility allowed \nusers to host Web pages on their computers. \n 5.10.1 Hierarchical File System Plus \n As time went by, hard drives were getting larger and larger. Unfortunately, the file \nsystems that were designed earlier for smaller drives used smaller pointers to save \nvaluable space both on the disk and in RAM. These pointers could not address all \nthe sectors on larger drives, so mechanisms were invented to extend the early file \nsystems to larger drives. The first technique was to allocate multiple blocks instead \nof single sectors. For example, the Hierarchical File System that had been intro-\nduced with System 3 used a 16-bit pointer in its data structures. This meant that \nonly 65,536 sectors could be directly addressed. With the standard sector size of \n12 In asymmetric multiprocessing the OS runs on only one of the CPUs while applications run on \nany CPU. While simpler than SMP, this technique is rarely used today since it limits the total system \nperformance. \nelm49810_ch05_089-112.indd   105\nelm49810_ch05_089-112.indd   105\n12/10/08   5:56:22 PM\n12/10/08   5:56:22 PM\n",
        "category": "Category"
    },
    {
        "id": "41",
        "title": "Title for Chunk 41",
        "content": "Confirming Pages\n106 \nPart 2 Building Operating Systems Incrementally: A Breadth-Oriented Spiral Approach\n512 bytes, this meant that drives larger than 32 MB could not be supported. So \nHFS allowed allocation to be based on blocks of multiple sectors instead of single \nsectors. If the allocation was done on a basis of two sectors, then the same 16-bit \npointer could address a 64 MB drive. This could be increased to any number of sec-\ntors that was a power of two. As with many techniques that Apple introduced into \nthe Mac OS, this was not a new technique. It had been used in the earlier CP/M \nsystem. Allocation of larger blocks had some drawbacks. For example, on a 1 GB \ndisk, even a 1-byte file would take up 16K of disk space. If many short files were \nused this became very inefficient, so a new file system had to be designed to address \nthe larger drives efficiently. System 8.1 therefore included an improved version of \nthe HFS called Hierarchical File System Plus, or HFS  \ufffd . It used a 32-bit pointer \nand was capable of directly addressing a 4 GB drive. Using an allocation block of \n32 sectors, it could support drives up to 128 GB. HFS  \ufffd  also allowed file names to \nbe 255 bytes long.  \n 5.10.2 Other hardware changes \n Hardware continued to evolve in the computer field generally and in the Mac prod-\nucts specifically. System 8.1 was the last version to support 68K Macs since Motor-\nola was putting all development efforts into the PowerPC line. System 8.6 added \nenhanced power management and improved support for new device classes such as \nUSB and FireWire. \n In order to allow a single application to use more than one CPU, System 8.6 \nintroduced the idea of allowing an application to split itself into multiple indepen-\ndent threads (called tasks in the Mac OS), which the OS then schedules to run on \nmultiple processors. We discuss this technique in-depth in Chapter 8. Apple modi-\nfied the nanokernel to support this multithreading. It also added support for priori-\nties to be associated with tasks. This allowed the application to designate some tasks \nas being more important than others. If a task had been waiting on some event that \nwas finished and that task had a priority that was higher than the currently running \ntask, the OS would preempt the CPU by stopping the running task and starting the \nhigher priority task. We saw this feature in the Palm OS in the previous chapter. \nThere was still no process preemption\u2014the system still used cooperative multitask-\ning between processes.  \n 5.10.3 Unicode support \n In System 8.5 Apple begain supporting an new mechanism for displaying other \nlanguages than English using a standard called  Unicode \u2014a worldwide character-\nencoding standard. Compared to older mechanisms for handling character and \nstring data, Unicode simplifies making software work with other languages, a pro-\ncess called  localization. By using Unicode to represent character and string data, \na programmer can facilitate data exchange using a single binary file for every \npossible character code. Unicode supports numerous scripts used by languages \naround the world. It also covers many technical symbols and special characters. \nelm49810_ch05_089-112.indd   106\nelm49810_ch05_089-112.indd   106\n12/10/08   5:56:22 PM\n12/10/08   5:56:22 PM\n",
        "category": "Category"
    },
    {
        "id": "42",
        "title": "Title for Chunk 42",
        "content": "Confirming Pages\n \nChapter 5 A Single-User Multitasking/Multithreading Operating System \n107\nUnicode can represent the vast majority of characters in computer use. It provides \nthe following:\n \u2022 Allows any combination of characters from any combination of languages in \none document \n \u2022 Standardizes script behavior \n \u2022 Provides a standard algorithm for bidirectional text \n \u2022 Defines mappings to legacy standards \n \u2022 Defines semantics for each character \n \u2022 Defines several different encodings of the character set, including UTF-7, \nUTF-8, UTF-16, and UTF-32 \nThere are many different ways that Unicode can be used, and today most OSs sup-\nport Unicode at one level or another. A more comprehensive discussion can be found \nat the website of the Unicode Consortium:  http://www.unicode.org. \n 5.11 SYSTEM 9 \n By this point the development of the Mac OS had become very convoluted. Several \nmajor attempts at creating a new OS were started and either abandoned or sold off to \ncompanies that had partnered in their development. One major event was the acquisi-\ntion of the NeXT Computer, and with it the NextStep OS. This OS would eventually \nevolve into the next release of the Mac OS, System X. In the meantime, releases of \nthe Mac OS had to continue, so over the next several years some important features \nthat were either invented or improved for one of the cancelled OS projects were \nadded to the Mac OS. It was a steady progression from Mac OS 8. The version num-\nber was increased from 8 to 9 to pave the way for the transition to System X. It was \nfelt that a gap in the numbers might have discouraged some users from migrating \nfrom the classic Mac OS to OS X. System 9 was released in 1999, and Apple called \nit the \u201cbest Internet operating system ever.\u201d The rise of the Internet began to impact \nthe OS in several ways. \n 5.11.1 Multiple users \n Originally it was assumed that a personal computer was used by a single person, and \nthe Mac OS reflected that orientation. There was initially no such thing as a login. \nThe design assumed that there was a single user of the system and that if security \nwas an issue then physical access to the machine was limited to that one person. \nMany forces combined to gradually weaken that assumption. In the workplace it was \ncommon to have machines that were shared by users who only needed access for \nshort intervals. At home the younger members of the family had always wanted to \nuse the computer to play games, but now they began to value access to the Internet \nand needed to use software for various assignments, whether writing, researching, or \nusing special applications. They also used it for access to social connections, rang-\ning from multiplayer games to instant messaging to chatrooms. Whether at home or \nin the business world, each of these persons had distinct preferences in the setup of \nelm49810_ch05_089-112.indd   107\nelm49810_ch05_089-112.indd   107\n12/10/08   5:56:23 PM\n12/10/08   5:56:23 PM\n",
        "category": "Category"
    },
    {
        "id": "43",
        "title": "Title for Chunk 43",
        "content": "Confirming Pages\n108 \nPart 2 Building Operating Systems Incrementally: A Breadth-Oriented Spiral Approach\nthe system. These included many options on the GUI, a home page for the browser, \nand so on. They also frequently wanted to have files on the system that others did \nnot have access to\u2014a personal diary, perhaps. So support for multiple users was \nadded in System 9. This required each user to login to the system before using it. \nThis feature lets several people share a Mac while sheltering their private files and \n supporting separate system and application preferences. It is set up and maintained \nthrough a Multiple Users control panel, which lets one user create accounts for oth-\ners, allowing them either normal or limited access to applications, printers, or the \nCD-ROM drive. The multiple users feature does not offer the same level of security \nfound in more modern OSs or in Mac OS X. These OSs have file system-level secu-\nrity while System 9 does not. A knowledgeable user can access protected files by \nbooting off a different volume, for example. Still, the multiple users feature solved a \nlot of the long-standing problems Mac users had when sharing a machine. \n Being able to limit the rights of certain users is a sound practice. Unfortunately, \nmany users are not very experienced with computers and allowing them unrestricted \naccess can mean that they can easily cause problems with the system. In the mini-\nmum case they change things so that they do not work right. In the worse case \nthey can wipe out an entire system, including much valuable data. Good practice \nsays that even knowledgeable users should not normally run with unrestricted rights. \nInstead, they should use a special administrative login when they need to perform \nsystem maintenance. \n Passwords are a perennial problem in computer system administration. Having \nmany passwords and logins for different applications leads users to unsecure prac-\ntices such as writing them on Post-it notes and leaving them on the monitor. Sys-\ntem 9 implemented a mechanism known as  Keychain Access. This feature managed \nusers\u2019 multiple IDs and passwords and stored them securely. Once a user unlocked \nthe Keychain by typing in the password, every application that was Keychain-aware \ncould get the correct application username and password from the Keychain data-\nbase without having to ask the user. \n Since the file protection was not quite secure, System 9 also added a capability \nfor file encryption. While the encryption scheme is very robust, it was proprietary to \nthe Mac OS, so files encrypted in this way could only be decrypted by machines that \nwere also running Mac OS 9. If recipients on Windows or UNIX machines needed to \ndecrypt these files, then a cross-platform encryption program was still needed. But if \nfile protection was not secure enough in a specific multiuser situation, the encryption \nadded a measure of security. \n 5.11.2 Networking \n By the late 1990s the Internet had become such a success that TCP/IP had become \na requirement for all personal computers. Apple had provided support for TCP/IP \nsince System 7, but only for certain functions. System administrators prefer to have \na minimum number of different protocols to administer. Since AppleTalk did not \nprovide any major features that were not also available in TCP/IP, there was con-\nsiderable pressure on Apple to support TCP/IP for all networking functions. So, \nunder System 9, file sharing was modified to support the TCP/IP protocol. Since \nelm49810_ch05_089-112.indd   108\nelm49810_ch05_089-112.indd   108\n12/10/08   5:56:23 PM\n12/10/08   5:56:23 PM\n",
        "category": "Category"
    },
    {
        "id": "44",
        "title": "Title for Chunk 44",
        "content": "Confirming Pages\n \nChapter 5 A Single-User Multitasking/Multithreading Operating System \n109\nAppleTalk was not supported over the Internet, users previously could not easily \naccess files at work on their Mac remotely through the Internet unless they resorted \nto complex, difficult techniques. Adding support for file sharing over TCP/IP meant \nthat Mac users could work more easily from home over their standard Internet \nconnection. \n In addition, a new software update function allowed users to obtain Mac OS \nsoftware updates over the Internet, and would notify users of updates as they became \navailable. This greatly simplified the work of system administrators. \n 5.11.3 APIs \n When System 9 was being developed, OS X was already well underway. As we will \nsee shortly, OS X is essentially a different OS. However, Apple did not want it to \nbe perceived that way. Accordingly, it was essential that many old applications be \nexecutable on the new OS. We have already discussed the emulation that was needed \nduring the transition from the 68000 to the PowerPC. It was similarly possible to \nexecute most older APIs under the new OS, but it was far preferable if an old appli-\ncation could be modified to support the APIs that would be available in OS X. So, \nApple created a new API for System 9 that would be forward-compatible with OS X \nbut still included support for most older API functions. This new API was known as \nthe Carbon API. It included support for about 70% of the legacy Mac OS APIs. \n 5.11.4 Video \n One of the driving forces behind the development of powerful advanced video fea-\ntures for personal computers is computer games. While other applications such as \ndesktop publishing can also benefit from the features, there are many more people \nwho play games than use systems to do desktop publishing. Naturally, the hard-\nware vendors want to develop products for the larger markets. Apple computers \nare no exception, and there are many games available for Macs. One of the fea-\ntures for which support was added in System 9 was support for video cards that \nhad built-in hardware support for accelerated rendering of 3D objects and for soft-\nware APIs for technologies such as OpenGL, which allowed an improved video and \ngaming experience. \n 5.12 MAC OS X \n OS X may be one of the most revolutionary changes in the history of OSs, and not \njust because Apple changed the release naming from System 10 to OS X. In OS X \nApple completely discarded the System 9 kernel and replaced it with another one. \nMicrosoft\u2019s Windows 3.x had been very successful since its release in 1990. They \nhad followed that with the release of another successful OS in 1993, Windows NT. \nNT was an advanced OS designed for high-end applications and included features \nsuch as preemptive multitasking, the ability to run applications written for several \nelm49810_ch05_089-112.indd   109\nelm49810_ch05_089-112.indd   109\n12/10/08   5:56:23 PM\n12/10/08   5:56:23 PM\n",
        "category": "Category"
    },
    {
        "id": "45",
        "title": "Title for Chunk 45",
        "content": "Rev. Confirming Pages\n110 \nPart 2 Building Operating Systems Incrementally: A Breadth-Oriented Spiral Approach\nlegacy OSs, multiple CPU support, and a new file system. Apple needed an OS that \nwould be competitive with these Microsoft products. As was mentioned before, \nthey partnered with various firms in several OS projects, but none provided the \nOS they needed. They also considered building a new OS on top of a kernel from \nSolaris (Sun Microsystems), BeOS (Be), and reportedly even NT (Microsoft). They \nultimately settled on a microkernel based on the Mach kernel and the FreeBSD \nimplementation of UNIX, which were the basis for NextStep, an object-oriented \noperating system developed by NeXT Computer Inc. For performance reasons \nsome of the FreeBSD code was merged with the Mach kernel so that the result is \nnot a true microkernel. The exact evolution of OS X is hard to trace and not very \nrelevant to this text. Much information is available on the WWW for those inter-\nested in the varying opinions. \n Changes were made in OS 9 software to allow it to be booted in the  classic \nenvironment within OS X. So the Classic Environment is an OS X application that \nprovides a compatibility layer that can run a version of the System 9 OS, allowing \napplications that have not been ported to the new APIs to run on OS X. It is fairly \nseamless, but classic applications keep their original OS 8/9 appearance and do not \nlook like OS X applications. \n 5.12.1 New features \n So OS X is actually a different OS that supports the APIs formerly used in the Clas-\nsic versions of Mac OS. Many of the capabilities of OS X came from the UNIX util-\nity packages. In the next chapter we look at another UNIX variant in depth. For now \nwe simply mention some of the features that OS X brought to the Mac world:\n \ufffd A new memory management system allowed more programs to run at once \nand supported full memory protection that kept programs from crashing one \nanother \n \ufffd A command line (part of UNIX terminal emulation) \n \ufffd Preemptive multitasking among processes instead of only among threads \n \ufffd Support for UNIX file system formats \n \ufffd The Apache Web server \n \ufffd Full support for symmetric multiprocessing \n 5.12.2 A new CPU, again \n Since the greater capabilities of OS X put higher demands on system resources, this \nrelease officially required at least a PowerPC G3 processor. \n In June 2005 Apple computers announced that they would be converting the \nMac product line from PowerPC processors to Intel products. In January 2006 Apple \nreleased the first Macintosh computers with Intel processors. The Classic (emula-\ntion) Environment does not work in the x86 version of OS X. Most well-written \n\u201cclassic\u201d applications function properly under this environment, but compatibility \nis only assured if the software did not interact directly with the hardware at all and \ninterfaced solely with the operating system APIs. \nelm49810_ch05_089-112.indd   110\nelm49810_ch05_089-112.indd   110\n12/22/08   1:01:34 PM\n12/22/08   1:01:34 PM\n",
        "category": "Category"
    },
    {
        "id": "46",
        "title": "Title for Chunk 46",
        "content": "Confirming Pages\n \nChapter 5 A Single-User Multitasking/Multithreading Operating System \n111\n 5.13 SUMMARY \n In this chapter, we discussed the features and con-\ncepts of a more complex modern OS\u2014the Mac \nOS developed by Apple Computer, Inc. This OS \nwas developed to bring to market an inexpensive \npersonal computer with a GUI. It is the Macintosh \nOS\u2122 (or Mac OS) developed by Apple Computer, \nInc. It generally supported only a single user. Later \nreleases allowed many processes that execute at the \nsame time and the ability for user applications to \nstart multiple threads. We began this chapter with an \noverview of the Mac OS in Section 5.1. We used a \ndifferent approach in this chapter and followed the \nreleases of the Mac OS, describing the major new \nfeatures in each release. This is because the Mac OS \nbegan as a quite simple system, offering no more \nfunctionality than CP/M except for the GUI, and \neven that was very primitive compared to what we \nthink of today. \n Ultimately the Mac OS evolved into a modern, \nfull-featured OS that can supporting multiple users \nand multiple processes. We ended this saga with only \nbrief mention of that Mac OS X release. Instead, in \nthe next chapter we describe an alternate multiuser \nsystem, Linux. \n BIBLIOGRAPHY \n Apple Computer,  Inside Macintosh series. Pearson \nProfessional Education, 1992. \n Danuloff, C.,  The System 7 Book: Getting the Most from \nYour New Macintosh Operating System. Chapel Hill, \nNC: Ventana Press, 1992. \n Lewis, R., and B. Fishman,  Mac OS in a Nutshell, 1st ed. \nSebastopol, CA: O\u2019Reilly Media, 2000. \n WEB RESOURCES \n http://applemuseum.bott.org (an outsider\u2019s view of Mac \nOS history) \n http://developer.apple.com/documentation/ (contains links \nfor all the Inside Macintosh series, downloadable in \nPDF format) \n http://developer.apple.com/technotes/  \n http://www.apple-history.com (an outsider\u2019s view of Mac \nOS history) \n http://www.macos.utah.edu/documentation/(operating_\nsystems/mac_os_x.html \n http://www.online-literature.com/orwell/1984/ (the book \nbehind the 1984 TV ad) \n http://rolli.ch/MacPlus (links to vMac, a Mac emulator) \n http://en.wikipedia.org/wiki/Mac_OS_history (an \noutsider\u2019s view of Mac OS history) \n http://en.wikipedia.org/wiki/NuBus (the original \nMac bus)  \n http://en.wikipedia.org/wiki/Y2k (an explanation of the \n\u201cY2K bug\u201d) \n http://www.parc.xerox.com/about/history/default.html  \n http://en.wikipedia.org/wiki/Mach_kernel (the kernel in \nMac OS X) \n REVIEW QUESTIONS \n \n5.1 Which was the first system with a GUI?\n a. Xerox Star \n b. UNIX X Windows \n c. Xerox Alto \n d. Apple Lisa \n e. None of the above was the first system with a \nGUI. \nelm49810_ch05_089-112.indd   111\nelm49810_ch05_089-112.indd   111\n12/10/08   5:56:24 PM\n12/10/08   5:56:24 PM\n",
        "category": "Category"
    },
    {
        "id": "47",
        "title": "Title for Chunk 47",
        "content": "Confirming Pages\n112 \nPart 2 Building Operating Systems Incrementally: A Breadth-Oriented Spiral Approach\n \n5.2 True or false? The Apple Macintosh was intro-\nduced somewhat after the IBM PC and was \nslightly less expensive than the IBM system. \n \n5.3 Which CPU did the Macintosh systems use?\n a. The Motorola 68000 family \n b. The Motorola PowerPC family \n c. The Intel 80x86 family \n d. None of the above \n e. All of the above \n \n5.4 What was the great advantage that the Macintosh \nsystems had over most other personal computer \nOSs? \n \n5.5 The Apple Lisa was a precursor of the Mac and \ncould run multiple applications at the same time. \nHow many applications could the original Macin-\ntosh run at one time? Why was that? \n \n5.6 True or false? The original Mac did not support \nmemory protection, which would keep an applica-\ntion from corrupting the OS or its data. \n \n5.7 How many folder (directory) levels did the origi-\nnal Mac OS support? \n \n5.8 How large were the portions of the memory that \nthe 68000 could address at one time?\n a. 16 KB \n b. 64 KB \n c. 128 KB \n d. 1 MB \n e. The 68000 could access all of memory at any \ntime \n \n5.9 True or false? In the Mac OS the kernel runs in \nsupervisor mode and the applications run in user \nmode. \n 5.10 What was the difficulty with the way the appli-\ncation stack and heap were implemented in the \nMac OS?  \n 5.11 What did the Mac OS do to avoid the problem in \nthe previous question? \n 5.12 What is the problem caused by the way that heap \nmemory is managed? How did the Mac OS deal \nwith it? \n 5.13 How does the Mac OS solution to the heap man-\nagement problem differ from the Palm OS? \n 5.14 Unlike most other PC OSs, the Mac OS put much \nof the OS in ROM. Why was that? \n 5.15 With early releases of the Mac OS, a cut-and-paste \noperation typically took minutes instead of sec-\nonds. What new feature of the OS changed this? \n 5.16 Did the change mentioned in  question 5.15  make \nthe Mac OS a multitasking OS? \n 5.17 What major change was introduced with the Hier-\narchical File System? \n 5.18 What did MultiFinder do?\n a. It allowed the user to search a file for multiple \nstrings. \n b. It allowed multiple users to log on to the \nsystem. \n c. It allowed the user to search the network for \nother users. \n d. It searched the Internet much like Google does \ntoday. \n e. None of the above describes MultiFinder. \n 5.19 What interesting new feature was made available \nwith System 5? \n 5.20 System 6 supported new models of the Mac that \nused 32-bit addressing. What problem did that \ncause? \n 5.21 What was a \u201cfat binary\u201d for? \n 5.22 True or false? Virtual memory uses software to \nsimulate missing blocks of memory. \n 5.23 What is the primary use of multithreading? \n 5.24 Quite a few enhancements made it into the various \nSystem 9 releases. Name three. \n 5.25 Why did we not say much about Mac OS X?  \nelm49810_ch05_089-112.indd   112\nelm49810_ch05_089-112.indd   112\n12/10/08   5:56:24 PM\n12/10/08   5:56:24 PM\n",
        "category": "Category"
    },
    {
        "id": "48",
        "title": "Title for Chunk 48",
        "content": "Confirming Pages\n385\n In this chapter: \n 17.1 Introduction 386\n 17.2 Distributed Application Models 388\n 17.3 Abstractions: Processes, Threads, and Machines 391\n 17.4 Naming 394\n 17.5 Other Distributed Models 396\n 17.6 Synchronization 400\n 17.7 Fault Tolerance 406\n 17.8 Summary  409\n D\nistributed systems are becoming very prevalent. We discuss Operating Systems \nbecause they stand between our application programs and the hardware. \nWhen we are developing a casual application there is no need to worry \nmuch about the OS. But when we are developing high-performance applications we \nneed to have a better understanding of what is going on inside of the OS so that we \nare working with the OS and not against it. So it goes with distributed processing. \nAs we will we see shortly, when we are developing systems designed to support a \nlarge number of users we will often be compelled to develop distributed systems\u2014\nsystems that have multiple parts running on different machines. Of course, we may \nbuild an application that is distributed for reasons other than performance or scal-\ning, and in such cases we may still not need to know much about the details of the \nOS as it pertains to distributed systems. But if our system is a high-performance or \nhigh-volume application, we may still profit from knowing how the underlying ser-\nvices work so that we can better utilize them and not do something that forces them \nto do extra work for no purpose. \n This chapter starts with an introduction where we discuss a number of reasons \nwhy this is so. It also introduces the notion of distribution transparency and why it \nis important. Lastly, it introduces the concept of middleware and explains why it \nevolved as it did. We then present a number of different models that are found in dis-\ntributed systems, including both the client server model and more complex models \nas well.  Section 17.3  reviews the topics of processes and threads and discusses how \nthreads can be used in clients and servers to make distributed systems perform  better. \n Distributed Operating Systems \n 17 \n Chapter  17 \n Chapter \nelm49810_ch17_385-412.indd   385\nelm49810_ch17_385-412.indd   385\n12/10/08   8:34:27 PM\n12/10/08   8:34:27 PM\n",
        "category": "Category"
    },
    {
        "id": "49",
        "title": "Title for Chunk 49",
        "content": "Confirming Pages\n386 \nPart 5 Networks, Distributed Systems, and Security\nWhen processes in distributed systems communicate they need to refer to other \nentities, so in  Section 17.4 , we discuss the concept of naming and name spaces. In \n Section 17.5  we present some different paradigms for distributed systems,  including \nremote procedure calls, distributed objects, and distributed documents. We discuss \nsynchronization in  Section 17.6  because distributed systems have special issues con-\ncerning synchronization that make them different from monolithic systems. Then \nin  Section 17.7  we present the topic of fault tolerance and the special problems dis-\ntributed systems have regarding failure of one component in a system that otherwise \ncontinues to run. We conclude with a chapter summary in  Section 17.8. \n 17.1 INTRODUCTION \n There are many reasons why we may need to develop systems that are distributed. \nWe discussed many of them at some length in Chapter 9 with regard to cooperating \nprocesses, so we recap them briefly here:\n \ufffd Performance. Systems running on multiple machines have more CPU time and \nother resources to apply to the problems. Some processes need a lot of power \njust for a single processing run\u2014simulating weather systems, for example. \n \ufffd Scaling. Multiple systems means more transactions can be processed in a given \namount of time. \n\ufffd Purchased components. Many times it is much cheaper to buy a system compo-\nnent than it is to develop it in-house. Sometimes it is developed in such a way \nthat it is essentially only available as a standalone process and may really need a \nseparate system to run on. \n \ufffd Third-party service. Sometimes an application component requires access to \nspecial databases that are not themselves for sale, so the component is only \navailable as an online service (e.g., credit verification). \n \ufffd Components of multiple systems. Often a component is developed in one sys-\ntem but later is needed as a component in other related systems. In such a case it \nmay be better to isolate that component on a dedicated machine. \n \ufffd Reliability. When a system has only a single instance of some component, fail-\nure of that component can cause the entire system to stop. Having multiple \ninstances of each component allows the larger system to keep running, though \nperhaps with degraded performance. \n \ufffd Physical location of information. If a system is supporting multiple physical facil-\nities it may be desirable for parts of the system to be collocated with the facilities. \nConsider a warehouse inventory system supporting multiple warehouses where \nthe bulk of the transactions are applied to a local database but connectivity is \nneeded for a few transactions that have to be serviced out of another warehouse. \n \ufffd Enable application. Some applications require so many resources that they \n literally could not be executed without a highly distributed system. SETI \n(Search for Extra-Terrestrial Intelligence) takes vast amounts of radio telescope \nand searches for patterns that might indicate an intelligent origin. They divide \nit into small data sets to distribute them to volunteers who process them via a \nscreen saver. Otherwise, they literally could not process this data. \nelm49810_ch17_385-412.indd   386\nelm49810_ch17_385-412.indd   386\n12/10/08   8:34:29 PM\n12/10/08   8:34:29 PM\n",
        "category": "Category"
    },
    {
        "id": "50",
        "title": "Title for Chunk 50",
        "content": "Confirming Pages\n \nChapter 17 Distributed Operating Systems \n387\n There are several goals that we ideally would like for distributed systems to have. First, \nthey should connect users and resources. (Note that in this context a \u201cuser\u201d may be another \nprocess.) Second, the systems should exhibit  distribution  transparency. Ideally, a user \nshould not be able to tell that the system is distributed. There are several different ways \nthat a user might notice a lack of transparency. These include transparency of:\n \ufffd Heterogeneity. Different system parts may be running on different hardware \nsystems or different OSs or both \n \ufffd Access. Differences in data representation and access (floating point number \nformats vary from machine to machine) \n \ufffd Location. Where a resource is located (Web pages can be anywhere) \n \ufffd Migration. Whether a resource can move (scripts sent to your browser by a server) \n \ufffd Relocation. Whether a resource moves while it is in use (your cell phone) \n \ufffd Replication. Resource is replicated (Google data servers) \n \ufffd Concurrency. Resource may be shared by many users (websites) \n \ufffd Persistence. Whether a resource is maintained on disk or in RAM \n \ufffd Failure. Whether a resource fails while in use (the Internet routes around failed \nlinks) \n A key aspect of distributed systems is that they depend heavily on  open standards \nto achieve most of the desired transparency. Many standards exist in the computer \nscience industry. Some are proprietary and some are open. Proprietary standards are \nusually not as useful in distributed systems because it is too difficult for different ven-\ndors to test the components for interoperability. Thus, many OS facilities  developed \nfor distributed systems by a single vendor are often eventually placed in an open sta-\ntus so that other vendors can test their systems for interoperability.  Examples include \nNFS (Network File System) by Sun Microsystems and CLR (Common Language \nRuntime) by Microsoft. \n Most OSs have not traditionally supported many of the services that distributed \napplications need. As a result, these services have developed in a category called \n middleware. As seen in  Figure 17.1 , middleware modules are placed functionally \nbetween the OS network services and the application programs. Thus, the OS and \nApplication\nUser\nMode\nSupervisor\nMode\nMiddleware\nNetwork\nServices\nKernel\nSystem 1\nApplication\nMiddleware\nNetwork\nServices\nKernel\nSystem 2\n FIGURE 17.1   \nMiddleware service \nlayer.  \nelm49810_ch17_385-412.indd   387\nelm49810_ch17_385-412.indd   387\n12/10/08   8:34:29 PM\n12/10/08   8:34:29 PM\n",
        "category": "Category"
    },
    {
        "id": "51",
        "title": "Title for Chunk 51",
        "content": "Confirming Pages\n388 \nPart 5 Networks, Distributed Systems, and Security\nthe network modules provide services to the middleware but are otherwise ignorant \nof any distinction between the middleware and the application. The network ser-\nvices may be quite independent from one another, communicating via open network \n standards. The middleware modules also communicate via open standards, but by \ndefinition they cooperate to provide services that cross system boundaries.  \n 17.2 DISTRIBUTED APPLICATION MODELS \n Systems comprised of processes running on separate machines obviously need to \ncommunicate. There are several models that have been developed to describe the \ninteractions between these components. We are describing the following models: a \nclient\u2013server model, a three-layer model, a multilayer model, horizontal distribution, \nand vertical distribution. \n 17.2.1 The Client-Server Model \n The client\u2013server model is shown in  Figure 17.2 . It is so well known that it almost \nneeds no explanation. A client system needs a well-defined service so it contacts a \nserver, which will provide that service. The main question we might need to answer \nin designing a client\u2013server model is how much of the function of an application \nshould be in the client and how much in the server. At one extreme the application \nwill run on a central system and the client will be little more than a terminal. This \nmodel is sometimes referred to as a  thin client. In other cases the application will \nrun mostly at the client station and the server will provide only a very limited service \nsuch as a database to hold the information used by the application. There are many \nhybrid models that can be used as well. We elaborate more on this in the next sec-\ntion, since the principle is the same there, only operating in more layers.  \n 17.2.2 The three-layer model \n After a few years of working with the client\u2013server model it began to be clear that \nthere were really three major functions that were easily identifiable in most systems: \nthe  user interface, the  application logic (sometimes called business rules), and the \n database storage. The model for this architecture is shown in  Figure 17.3 . This extra \ndivision probably came about because database systems began to evolve themselves, \nand it was clear that building such facilities separately for each application was not \neconomical. \nRequest\nResponse\nClient\n(Browser)\n(Web)\nServer\n FIGURE 17.2  \n Client\u2013server \narchitecture.  \nelm49810_ch17_385-412.indd   388\nelm49810_ch17_385-412.indd   388\n12/10/08   8:34:30 PM\n12/10/08   8:34:30 PM\n",
        "category": "Category"
    },
    {
        "id": "52",
        "title": "Title for Chunk 52",
        "content": "Confirming Pages\n \nChapter 17 Distributed Operating Systems \n389\n As with the client\u2013server model, there are many variations that we can have in \nthe three-tier architecture. The user interface can be very simple, perhaps only an \nX- Terminal in the UNIX environment. In other environments a Web browser on a \npersonal computer may provide a simple way to have a GUI presentation for an appli-\ncation. In such an environment we can send a page from a Web server that contains \na form for the user to fill in for the application. The user fills in the form and clicks a \nbutton on the form. This click will cause the browser to submit to the server the data \nthe user input into the form. The server will check the data, and if all is OK the server \nwill process the request and return some result. But we can improve the performance \nof such a design by moving some of the processing to the client side. When a user is \ninputting data into a form to record some business event, if a detectable error is input, \nthe sooner we catch it and get the user to fix it, the better. For example, if we are expect-\ning a field to contain a date and the user enters some alphabetic information (other than \na month name), then the system should reject it. If we wait until the user has submitted \nthe form and sent it to the server and we send an error message back to the user, we \nhave separated the feedback from the input by quite a few steps, and this will render it \nless effective. It also disrupts the thought process of the user, who has mentally moved \non from this transaction, thinking it to be already complete. It would be much better \nfor the application to check the format of the data at the time the user moves the focus \nfrom the date field. Considerable design effort usually goes into deciding what check-\ning can be done on the client side and what should be done on the server side. \n Other features can also be moved to the client side. For example, because com-\nmunication costs can be high or the network connectivity unreliable, it may be useful \nto allow the client side to do a considerable amount of data collection in an offline \nconfiguration and submit the transactions to the server later when the server or the \nconnection is again available. \n The third tier, data storage, is usually provided by a packaged database man-\nagement system. Often these systems do little more than provide a higher-level file \n system that supports very reliable storage and retrieval of data in normalized tables. \nIn other cases the database systems are used to run part of the system logic by execut-\ning procedures stored in the database, improve data validity by verifying referential \nintegrity, summarizing data for reports, and so on. \n 17.2.3 N-tier applications \n The three-tier model is often extended to  N-tiers. This is sometimes called  vertical \ndistribution  and is done when an application can conveniently be broken into several \nparts. An illustrative example is the architecture of the Google search engine, as shown \nRequest\nResponse\nClient\n(Browser)\n(Web)\nServer\nLookup\nReply\nDatabase\nServer\n FIGURE 17.3   \nThree-layer model.  \nelm49810_ch17_385-412.indd   389\nelm49810_ch17_385-412.indd   389\n12/10/08   8:34:30 PM\n12/10/08   8:34:30 PM\n",
        "category": "Category"
    },
    {
        "id": "53",
        "title": "Title for Chunk 53",
        "content": "Confirming Pages\n390 \nPart 5 Networks, Distributed Systems, and Security\nin  Figure 17.4 . It is broken into several portions. Although there is no detailed descrip-\ntion of the architecture available, enough has been published to illustrate the point. \n There is a front-end process that receives the request and parses it into separate \nwords. Another server may be queried for spelling corrections. The front-end server then \ntakes those words and passes them on to other servers, each of which is responsible for \na database of indexes of Web pages that contain a given word. These servers pass a set \nof those pointers on to another server, which merges the sets of pointers to create a set \nof pointers to pages that satisfy the entire search. Usually such searches contain all the \nwords in the query, but other forms of query are possible. Another server is queried that \npulls advertising from a database, selecting ads that are related to the search terms or \nto other searches that this user has made in the past. The pages are ranked to determine \ntheir probable relevance to the user, and the pointers are used to fetch the cached pages \nfrom other servers so that short snippets of the referenced page can be merged into a \nWeb page that is then returned to the client\u2019s browser. Thus, we see at least five different \ntiers in this application. Though they may not be tiers in a strictly vertical sense, they \nare interacting components, which are separate servers serving many clients.  \n 17.2.4 Horizontal distribution \n We also see another paradigm being used in the Google setup in two different ways\u2014\n horizontal distribution. We mentioned that the database is distributed across a group \nof servers, each of which is responsible only for pages that contain a given individual \nword (or set of words). This arrangement is a type of  distributed database, where \npart of the information is contained on one server and part on another. In addition, \nthe servers that Google uses are inexpensive PCs, not high-performance machines. \nExact figures are unknown, and estimates vary, but a research organization estimated \nRequest\nResponse\nLookup\nReply\nLookup\nReply\nLookup\nReply\nLookup\nReply\nClient\n(Browser)\n(Web) \nServer\nIndex \nServers\nDocument \nServers\nAd \nServer\nSpell\nChecker\n FIGURE 17.4   \nGoogle system \narchitecture.  \nelm49810_ch17_385-412.indd   390\nelm49810_ch17_385-412.indd   390\n12/10/08   8:34:30 PM\n12/10/08   8:34:30 PM\n",
        "category": "Category"
    },
    {
        "id": "54",
        "title": "Title for Chunk 54",
        "content": "Confirming Pages\n \nChapter 17 Distributed Operating Systems \n391\nthat they had one million servers in mid-2007 and were adding more at a rate of \n100,000 per quarter. Google expects that servers are going to fail. Accordingly, each \nof those servers that handles documents containing a specific word is actually several \nservers\u2014at least three in a given Google network node. Furthermore, the word data-\nbases are replicated in at least three geographically distributed nodes in order to limit \nfailures due to a disaster in a center containing a node. This is known as a  replicated \ndatabase. The Google databases are therefore both distributed and replicated. \n But it is also the case that each of those other servers that we mentioned before is \nnot a single server. No server in the world could possibly keep up with the number of \nsearch requests that Google gets per hour. Instead, the network is designed such that the \nrequests are passed out among a group of essentially identical search engines. There \nare many instances of the advertising and spelling check servers as well. The entire \nsystem is designed to route around any failed node and use another instance of the data. \nThus, all the various server functions are replicated, just as the database servers are.  \n 17.3 ABSTRACTIONS: PROCESSES, THREADS, AND MACHINES \n Processes are an abstraction that an OS uses to virtualize the CPU so that a running \nprogram does not need to be aware that it does not actually control the CPU. In order \nto have a system do more work on a single application we can have a process create \nother processes that will also run and thus get additional turns at the CPU. However, \nswitching from one process to another requires a context switch on a uniprocessor \nsystem, and context switches cause a serious dip in performance of the system. All \nthe caches must either be flushed, most specifically the TLB, which is caching page \ntable entries, or will not find any cached entries until the new process has run long \nenough to reload the cache from the new process. This will also cause slowdowns \nbecause of the TLB misses, which must be handled until the TLB is reloaded to \n represent the full working set of the process that is being started. \n As a result, threads were developed. They arose from the recognition that the \nstate information held in a process control block really had two parts. One part rep-\nresented the many resources currently being held by the process. The other part held \nthe actual CPU state regarding the current point of execution of the CPU (for any \nprocess that was not actually running). Storage for the latter part could be  duplicated, \nand the second block could then track a different point of execution of the CPU within \nthe same process. So a program could effectively ask the OS to allow  several parts \nof the process to continue to run while other portions were also running, so long as \nthose parts could communicate and synchronize their operations. This allowed one \nprogram to have several parallel points of execution without incurring the penalty of \ncontext switching. \n 17.3.1 Threads \n There are several ways threads can be used beneficially in distributed systems. In \nclient systems threads can be used to allow processing to overlap with asynchronous \ncommunication. A primary example is in a Web browser that is running the HTTP \nelm49810_ch17_385-412.indd   391\nelm49810_ch17_385-412.indd   391\n12/10/08   8:34:30 PM\n12/10/08   8:34:30 PM\n",
        "category": "Category"
    },
    {
        "id": "55",
        "title": "Title for Chunk 55",
        "content": "Confirming Pages\n392 \nPart 5 Networks, Distributed Systems, and Security\nprotocol version 1.0. In this earlier version of the protocol a browser first fetched the \nbase page of a document. It scanned the document for embedded elements and then \nhad to make a separate connection to the server to fetch  each of the other elements, \none after the other. So a browser using this protocol could start separate threads for \nthe retrieval of each element rather than fetching them one by one. This sped up the \nprocess considerably. Similarly, a client that was making a long set of remote proce-\ndure calls (RPCs) could make each call in a separate thread so long as the result of \none call was not required in another call. \n Servers can also make good use of threads. The primary use here is to process \neach incoming request in a separate thread. Initially, the system starts a primary or \n dispatcher thread, which listens for incoming requests. When a request comes, the \nprimary thread will start a  worker thread to process the request. This design has \nthe added benefit of program simplicity. Assuming that we are using kernel-level \nthreads, if the worker thread makes a blocking kernel call, for a disk read, perhaps, \nthen that thread can simply block and the rest of the server can continue. Each thread \nproceeds through a series of (usually) simple steps to process the request, return the \nresult, and terminate. See  Figure 17.5 .  \n 17.3.2 Virtual machines \n Virtual machines are another level of abstraction\u2014virtualizing an entire machine \nrather than only the CPU. There are two different sorts of  virtual machines, or  VMs. \nThis is an unfortunate overloading of the acronym VM since it is also used to refer to \nvirtual memory, but the distinction is normally clear from the context. \n Physical virtual machines \n First, there is the concept of a virtual physical machine. A small OS kernel is loaded \nthat will in turn execute other OSs on top of itself. The OS that is loaded first is \nthe  host OS. These other OSs will be known as  guest OSs. The basic trick is that \nwhen a host OS loads the guest OSs it runs them in user mode. Whenever a guest \nOS tries to execute any operation that would normally require supervisor mode, the \nhardware will cause an interrupt that the host OS will receive. Then the host OS will \ndo the operation, and when the results are ready will return them to the guest OS. \nRequest\nResponse\nClient\n(Browser)\n(Web)\nServer \nDispatcher\nThread\nWorker\nThread\nWorker\nThread\n FIGURE 17.5   \nMultithreaded server.  \nelm49810_ch17_385-412.indd   392\nelm49810_ch17_385-412.indd   392\n12/10/08   8:34:31 PM\n12/10/08   8:34:31 PM\n",
        "category": "Category"
    },
    {
        "id": "56",
        "title": "Title for Chunk 56",
        "content": "Confirming Pages\n \nChapter 17 Distributed Operating Systems \n393\nSee   Figure 17.6 . There are several reasons why it can be useful to run multiple OSs \non the same machine at the same time. As far as distributed processing goes, the main \nreason is to consolidate several servers onto one system. Building a server that is very \nreliable and high performance and placing it in a secure location is quite expensive. \nOften a server purchased today will be much more powerful than is actually required \nto run the service. Using VM allows several servers to be consolidated. This can save \nmoney on hardware since one larger server can replace several smaller ones, using \nless power and air conditioning. It is especially useful if the servers were running on \ndifferent OS platforms, but even if they were running on the same OS, the VM can \nrun multiple copies of any guest OS. This would seem strange, but it helps isolate the \nserver functions since a crash of one guest cannot impact any other guest.  \n Abstract virtual machines \n The other sort of virtual machine is an abstract virtual machine that is a software \nsimulation of a machine designed to run some intermediate language. The primary \nexamples are the  Java virtual machine, or  JVM, developed by Sun Microsystems \nand the  Common Language Runtime, or  CLR, developed by Microsoft as part \nof the .NET system. These are used widely in distributed processing, primarily for \nthree reasons: code mobility, code portability, and security. Mobility allows a com-\npiled program to be downloaded from a server to the client to be run locally. This \nhappens when a Java applet is downloaded from a server to run in a client browser. \nThe client browser contains an implementation of a Java virtual machine, so the Java \nprogram could be copied from the server and run at the client. This could be for any \nof the reasons we mentioned earlier. Code is more portable when run in a virtual \nmachine because the virtual machine can be ported to any hardware and platform. \nThis assures a software vendor a wide market because the target machine is virtual. \nSince the JVM may be running in a browser in the client we have some risk that the \nGuest\nOS\n# 1\nHost OS\nGuest\nOS\n# 2\nGuest\nOS\n# 3\n FIGURE 17.6   \nPhysical virtual \nmachine.  \nelm49810_ch17_385-412.indd   393\nelm49810_ch17_385-412.indd   393\n12/10/08   8:34:31 PM\n12/10/08   8:34:31 PM\n",
        "category": "Category"
    },
    {
        "id": "57",
        "title": "Title for Chunk 57",
        "content": "Confirming Pages\n394 \nPart 5 Networks, Distributed Systems, and Security\ndownloaded applet might present a security problem. So, as a default the browser \nwill be very restrictive about what it will let the applet do\u2014inhibiting accessing of \nthe local hard drive, for example. Usually the client browser can be configured to \nshow that certain sites are to be trusted\u2014the client company headquarters, perhaps, \nand code from these sites will be allowed to do some of these things that would not \notherwise be allowed. As an alternative to execution in the browser\u2019s virtual machine \nsimulation, the program may be compiled into the native machine code of the target \nmachine in an operation called  just-in-time (or  JIT ) compilation. \n 17.4 NAMING \n Distributed applications require communication between the various processes involved. \nWhen the processes communicate they need to refer to other entities such as files, sock-\nets, records, users, and so on. References to entities can take several forms. We will need \nto distinguish between names, identifiers, and addresses.  Names denote entities. Users \nhave names. So do computer systems\u2014for example, webserv.example.com. Names can \nbe reused, so it would be possible for the example domain to replace the system cur-\nrently called webserv with another system and call the new one webserv. This is espe-\ncially likely with servers of any kind. Many other entities we might wish to access also \nhave names. Names are not necessarily unique. Therefore, we create  true  identifiers. \nAn identifier is generally issued by some authority. Identifiers are never reused and are \nnever duplicated so they always refer to the same entity. Examples include a Social \nSecurity Number for a user or a burned-in MAC address for a network interface card \n(NIC). Finally,  addresses denote access points for entities. Examples include a phone \nnumber, an IP address, and a socket (or port), which addresses a specific process or \nthread within a computer system. \n Passing references within a single system is usually simple because the sys-\ntems share a common frame of reference. Thus, for most platforms a simple file \nname without any other surrounding context will first be assumed to be in the cur-\nrent working directory. Failing that, a series of alternative directories is used. This \nset is usually specified in some global set of values defined for the system or for a \ngiven user. On Microsoft OSs these are called  environment variables.  One of them \nis known as the  path.  The path is the series of directories that the OS will search to \nfind a file with no path name. Together these alternatives make up a common frame \nof reference in which a file name will have meaning. All the processes on the system \nshare this reference frame. \n Passing references to entities within a single system is usually not difficult \nbecause of that common frame of reference. However, distributed systems are much \nmore complex. This is one of the problems caused by the heterogeneous nature \nof distributed systems\u2014they do not share a common frame of reference. In order \nto provide common frames of reference the industry has established some global \nreference frames, often called a  name space. Name spaces are organized collec-\ntions of information in which a name can be located. The primary example is the \n domain name system, or  DNS. The DNS is a hierarchical name space defined by \nthe   Internet naming authority, or  INA. It is very simple for a process that has \nelm49810_ch17_385-412.indd   394\nelm49810_ch17_385-412.indd   394\n12/10/08   8:34:31 PM\n12/10/08   8:34:31 PM\n",
        "category": "Category"
    },
    {
        "id": "58",
        "title": "Title for Chunk 58",
        "content": "Confirming Pages\n \nChapter 17 Distributed Operating Systems \n395\nbeen passed a DNS name to look it up and find an IP address that corresponds to \nthe name. Usually the process will have a socket number to use with the IP address \nand that concatenated pair of numbers identifies a particular software entity in the \naddressed system. \n 17.4.1 Discovery services and Jini \n Jini\u2122 (pronounced like genie) is a middleware design for dynamically creating \n distributed systems. It is an open specification that enables developers to create net-\nwork services, either hardware or software, that are highly adaptive to change. This \ndesign specifies a means for clients to find services on the network and then to use \nthe services to accomplish a task. Providers of services send to clients Java objects \nthat furnish the client access to the service. This interaction can use any middleware \ntechnology because the client only sees the object and all network communication is \nconfined to that object and the service it accesses. \n When a service joins a Jini-enabled network it advertises itself by publishing an \nobject that implements a well-known service API. A client finds services by looking \nfor an object that supports the API it wants to use. When it finds the service\u2019s pub-\nlished object, it can download the code it needs to talk to the service. \n 17.4.2 Directory services, X.500 and LDAP \n Directory access protocol (DAP) is a network standard specified by the ITU-T and \nISO for use with an  X.500 directory service. It was intended to be used by client \ncomputers but was not successful because there were few implementations of the \nOSI protocol suite for personal computers. The basic operations of DAP were incor-\nporated in  Novell Directory Service ( NDS ) and later in the  lightweight directory \naccess protocol ( LDAP ). \n LDAP was intended to be a lightweight alternative for accessing X.500  directory \nservices and can run over TCP/IP. The intent of LDAP was that a client could access \nX.500 services through an LDAP-to-DAP gateway. But instead LDAP directory \nservers quickly sprang up. LDAP has become extremely popular in enterprises. It \nis the default directory services for Windows XP and is also usable with most other \nOSs today. It includes an authentication protocol that is quite robust so that accessing \ndistributed services is quite secure. \n 17.4.3 Locating mobile IP entities \n Devices that are communicating over the Internet using IP have a special problem if \nthey are mobile. The problem arises because part of the IP address of a node specifies \nthe network where the node is connected. If the node moves to a different  network, \nthen the IP address should change. But the TCP connectivity model and most other \nprotocols are not designed to allow for a change in the IP address during a session. So \ntracking a mobile IP entity is quite difficult. Mobile IP is most often found in wire-\nless environments where users move their mobile devices across multiple  networks \nas they move from home to school to work. \nelm49810_ch17_385-412.indd   395\nelm49810_ch17_385-412.indd   395\n12/10/08   8:34:31 PM\n12/10/08   8:34:31 PM\n",
        "category": "Category"
    },
    {
        "id": "59",
        "title": "Title for Chunk 59",
        "content": "Confirming Pages\n396 \nPart 5 Networks, Distributed Systems, and Security\n A protocol suite for Mobile IP is defined by RFC 3344. A node that is going \nto use mobile IP will have an IP address called its  home address. It will register \nwith a server on its home network called a mobile IP  home agent. When the node \nmoves to another network it will be given an IP address on the new network. This \nwill be called the  care-of  address. It will then search for a server called a mobile \nIP  foreign agent. It will tell the foreign agent where its home agent is. The foreign \nagent will connect to the home agent and the home agent will store the temporary \nnew IP address in a database and will register itself locally with that IP address. A \nhost that needs to communicate with the mobile node initially connects to the home \naddress of the node. The packets are received by the home agent and it forwards the \npackets to the mobile node\u2019s care-of address with a new IP header. The original IP \npacket is left inside the new packet. The mobile IP software in the node will strip off \nthe outer packet header and deliver the inner packet to the application software in the \nnode. This process is known as  tunneling. The application software does not need \nto be aware that it is running in a mobile environment (i.e., the middleware provides \nmobility transparency). \n 17.5 OTHER DISTRIBUTED MODELS \n We discussed the client\u2013server model and several variations on that model. But there \nare other models that are also useful in distributed systems. \n 17.5.1 Remote procedure call \n Often an existing monolithic system needs to be modified to become a distributed \nsystem. One model for dividing an existing process is to remove subroutines from \nthe existing application and run them on a separate server. This is called  remote \n procedure call ( RPC ). It is a useful technique because it involves a component \nmodel that programmers are already familiar with. In principle the idea is  simple\u2014\ntake a subroutine out of a running system and put it on a server. Replace the removed \nroutine with a new subroutine called a  client  stub that knows the subroutine is \nsomewhere else and invokes the RPC middleware to find it and call it. The model \nfor this process is shown in  Figure 17.7 . But this process is complicated by the \npossible heterogeneous nature of distributed systems. RFC 1831 that defines RPC \nassumes that the systems are heterogeneous. This means that the parameters being \npassed to the subroutine must be converted to the format of the server that is running \nthe subroutine, and the answers must be converted the opposite way on the return. \nThis process is called  marshalling and unmarshalling. On the server system there \nwill be another stub. This server stub takes the place of the original program in that \nit calls the subroutine. It receives the message from the client system, unmarshals \nthe arguments into the formats required by the server platform, calls the subroutine, \nmarshals the returned arguments, and packs them into a message to send back to the \nclient stub. \n Since the client system does not know what platform the server system is run-\nning on, the client stub converts the arguments into an intermediate form called  \nelm49810_ch17_385-412.indd   396\nelm49810_ch17_385-412.indd   396\n12/10/08   8:34:32 PM\n12/10/08   8:34:32 PM\n",
        "category": "Category"
    },
    {
        "id": "60",
        "title": "Title for Chunk 60",
        "content": "Confirming Pages\n \nChapter 17 Distributed Operating Systems \n397\neXternal Data Representation ( XDR ), which was defined in RFC 1832. This \n intermediate format is platform neutral and allows us to represent any data in a \n standardized, platform-independent format. An implementation of RPC for a given \nplatform must define the mapping from the XDR formats to native platform formats. \n When a subroutine is removed from a program, the client stub must be substi-\ntuted for it. Creation of the stub starts with a language called an  interface descrip-\ntion language, or  IDL. Most IDLs are similar to C. The stub is used to declare the \nnature of the arguments to the removed routine. Once the interface is described in \nIDL, an IDL compiler that is specific to the client platform and source language is \nrun against the description. It will produce two things\u2014a header file that will be \ninserted into the original program to describe the missing routine arguments and a \nseparate source program that should be compiled, which will become the client stub \nroutine. This process is shown in  Figure 17.8 . The object form of this routine will be \nlinked with the original application to produce the modified application. The IDL is \n FIGURE 17.7   \nRemote procedure \ncall model.  \nRequest\nResponse\nOriginal\nProgram\nOriginal\nSubroutine A\nOriginal\nSystem\nOriginal\nProgram\nStub for A\nOriginal\nSubroutine A\nStub for Caller\nRPC Client\nSystem\nRPC Server \nSystem\nOriginal Program\nStub\nIDL\nLanguage\nCompiler\nIDL\nInterface\nDescription\nSystem\nHeader\nFile\nStub\nCode\n FIGURE 17.8   \nCreation of an RPC \nstub.  \nelm49810_ch17_385-412.indd   397\nelm49810_ch17_385-412.indd   397\n12/10/08   8:34:32 PM\n12/10/08   8:34:32 PM\n",
        "category": "Category"
    },
    {
        "id": "61",
        "title": "Title for Chunk 61",
        "content": "Confirming Pages\n398 \nPart 5 Networks, Distributed Systems, and Security\nstandardized, so the same IDL file can be used on the server platform to produce the \nserver stub and the modified routine that the stub will call. \n As was mentioned earlier, RPC is defined by an RFC. This specification is then \nimplemented in specific packages. In this case there is a fairly standardized imple-\nmentation called the  distributed computing environment ( DCE ) that was created \nby the Open Group (i.e., the  Object Management Group , or  OMG ) as an open \nsource project. Individual system manufacturers are certainly able to produce their \nown implementations, but using this source has the advantage of producing a pack-\nage that has been rigorously tested already. The Open Group is an ad hoc group \nconsisting of over 800 organizations. \n 17.5.2 Distributed objects \n A model that is very similar to RPC is that of distributed objects. The techniques \nare very similar, but objects are more complex than subroutines. The naming of the \n components is a bit different. The stub on the client system is known as a  proxy and \nthe stub on the server side is called a  skeleton. One additional component usually \nfound on the server side is an  object adapter. Its function is to enforce some admin-\nistrative restrictions on how the object is invoked. There are several such restrictions, \nbut the most common one is a serializer that restricts the object to one invocation at \na time unless the object is known to be thread safe. \n As with RPC, distributed objects are defined by a specification and then imple-\nmented in a specific package. One of the main standards for distributed objects is \nknown as the  common object request broker, or  CORBA. This standard is also \ndefined by the Open Group. In this architecture the middleware layer itself has a \nspecific name\u2014the  object request broker, or  ORB \u2014pronounced \u201corb.\u201d \n 17.5.3 Distributed documents \n Another model that is used in distributed processing is that of  distributed  documents. \nThe most well-known instance of this model is certainly the  World Wide Web \n( WWW ). Originally the WWW was created as a mechanism for providing easy \naccess to research papers related to atomic energy. It included a technique for refer-\nencing other papers called hyperlinks, though this was a concept that was not in itself \nnew. Links could also be imbedded in the text document to reference graphics files \nthat contained figures from the paper. Of course, today that model has grown wildly \nand is much more complex than that of a document. In fact, we normally speak of \nWeb \u201cpages\u201d rather than documents. The idea today is that a Web page should only \ninclude a few thousand words at the most, and should link to other pages as needed. \nWeb pages now include links to other multimedia elements such as sound and movies \nand forms that can allow a user to input information and interact with an application \nrunning on the server. More importantly, pages can now include programmable ele-\nments such as scripts and applets. It is possible to develop very sophisticated appli-\ncations using the tools that were designed to create Web pages. The big advantage \nof such an interface is that the client only needs a browser to access the functions \nof the application. In theory this means that application Web pages can be accessed \nelm49810_ch17_385-412.indd   398\nelm49810_ch17_385-412.indd   398\n12/10/08   8:34:32 PM\n12/10/08   8:34:32 PM\n",
        "category": "Category"
    },
    {
        "id": "62",
        "title": "Title for Chunk 62",
        "content": "Confirming Pages\n \nChapter 17 Distributed Operating Systems \n399\nnot only with a personal computer, but also with PDAs and cell phones. There are \ndifficulties in such use, primarily based on the speed of the access and the smaller \nscreen sizes. Most websites today are designed with an assumption of a fairly large \nuser screen and a fairly fast connection. \n Another less well-known system that uses a document model is  Lotus Notes. It \nis a highly sophisticated application that exposes libraries of notes on various  topics. \nSome topics are automatically pushed to all users as with email. Others are only \naccessed as the user requests them. There are not a great many institutions that are \nusers of Lotus Notes, but they tend to be large organizations with many users, so \nthe system merits at least a mention in any discussion of distributed systems using a \ndocument model. \n Other systems that also use a document model include Internet E-mail and \n Network News. Each works in a different manner to distribute information to clients \nin specific ways using both push and pull protocols. \n 17.5.4 Distributed file systems \n File are a concept that all programmers and most users understand, so naturally \nmany systems have been developed that allow distribution of services by connecting \nthe machines through the file system somehow. In Chapter 7 we mentioned the NFS \nmodel and we examined it more closely in Chapter 13, so we will not repeat that \ndiscussion here. NFS allows directories on a remote machine to appear to the local \nsystem as though they were local, providing location transparency. It was developed \nby Sun Microsystems in the UNIX arena, so it is also now available in the Mac OS X \nand Linux OSs. Microsoft also provides optional NFS client and server support with \nhigher-level versions of its NT OS family. \n Microsoft offers a similar service known under various names\u2014 common \n Internet file system ( CIFS ) and  server message block ( SMB ). These are similar to \nNFS. Compatible clients and servers have been developed through reverse engineer-\ning for non-Microsoft OSs. These are known as Samba. \n Both NFS and CIFS require that a nontransparent connection be made from \nthe client to the server. Other systems have been developed that intend to make this \npart of the process more transparent. For example, Microsoft has a system called \n distributed file system ( DFS ). It is used to build a hierarchical view of file servers \nand shared directories that can be given a unique name. Instead of having to link to a \nbunch of different names a user will only have to remember one name. DFS supports \nreplication of servers and routing a client to the closest available file server. It can \nalso be installed on a cluster for even better performance and reliability. \n Other distributed file systems exist that are less widely used. In particular these \ninclude the  Andrew File System ( AFS ) and  CODA, both developed at Carnegie \nMellon University. AFS was designed to give each client workstation a homoge-\nneous, location-transparent file name space. CODA is a newer product with an \nemphasis on fault recovery and disconnected operation (mobile computing). These \nsystems are supported only in UNIX and derivative OSs. \n The design of the Google search engine is also heavily dependent on a dis-\ntributed file system architecture. They rely on triple redundancy in all systems. \nelm49810_ch17_385-412.indd   399\nelm49810_ch17_385-412.indd   399\n12/10/08   8:34:32 PM\n12/10/08   8:34:32 PM\n",
        "category": "Category"
    },
    {
        "id": "63",
        "title": "Title for Chunk 63",
        "content": "Confirming Pages\n400 \nPart 5 Networks, Distributed Systems, and Security\nUnfortunately for us the design is proprietary and not much detailed information is \navailable.    \n 17.6 SYNCHRONIZATION \n Systems divided into multiple parts need to synchronize their actions, as we saw in \nChapter 9. Distributed systems need to work even harder to enable synchronization. \nWe will discuss several mechanisms for distributed clocks, synchronization, mutual \nexclusion, coordinator election, and concurrency control. \n 17.6.1 Clocks \n In many distributed algorithms it is necessary to know the order of events. If two \npeople make a withdrawal from a bank account at the \u201csame time,\u201d we want to honor \nthe first one before the second. Unfortunately, the speed of light limits the transmis-\nsion time from one system to another. So even if two events do happen at the same \ntime it is impossible to know this until sometime later. Among other things, it makes \nit virtually impossible to be sure that the clocks on two systems are synchronized. \nFortunately, we often don\u2019t really care about the actual time that two events took \nplace. We merely care about the order of the events. This makes the problem some-\nwhat simpler. What we really need are  logical clocks. The idea behind logical clocks \nis that there is some set of events for which we are worried about the order in which \nthey happened. So in each system, whenever one of these events happens we incre-\nment a counter. We associate the value of the counter at that time with that event, \ncalling it a  timestamp. This becomes the logical clock by which we will order the \nevents. For two events, if the timestamp of one event is less than the timestamp of the \nother, then we say that the first  happened before the other. \n There is one other step that we must take in a distributed system. We must also \nbe concerned about messages between processes. We will want to assert that the \nevent of sending the message happened before the event of receiving the message. \nWe associate a timestamp with the sending of a message to another process, and we \nsend that logical clock value with the message. Then when the message is received \nthe receiving system will check the clock value that came in with the message. If that \nclock value of the incoming message is greater than the logical clock at the receiving \nprocess, then the receiving process will set its own clock to the value of the clock \nin the incoming message plus one, accounting for the event of the message arrival. \nOtherwise, it will simply add one to its own clock to account for the arrival. This \nmechanism is called  Lamport timestamps. \n Unfortunately, what we need is sometimes a bit more complex than this. Often \nwe need to know what events at other systems might have had an effect on the event \nbeing described by an incoming message. The mechanism for keeping track of \nthe timestamps of all processes in a distributed system is to attach to each event a \n vector of  timestamps. The index of the vector is a number assigned by the distrib-\nuted  system to each process, and the value of the i\u2019th item in the vector is the latest \ntime stamp we know about from that process. When messages are sent, rather than \nelm49810_ch17_385-412.indd   400\nelm49810_ch17_385-412.indd   400\n12/10/08   8:34:33 PM\n12/10/08   8:34:33 PM\n",
        "category": "Category"
    },
    {
        "id": "64",
        "title": "Title for Chunk 64",
        "content": "Confirming Pages\n \nChapter 17 Distributed Operating Systems \n401\n sending the value of the local event counter as a timestamp, the entire vector of \n timestamps known by that process is sent with them. The receiving system updates \nthe information in its own vector with the corresponding elements of the vector with \nthe incoming message when they are greater than its own. \n 17.6.2 Mutual exclusion \n When two processes are cooperating they often need to synchronize access to shared \ndata in order to avoid conflicting updates. This part of synchronization is called \nmutual exclusion, and in each process it involves a section of code called the critical \nregion in which it is updating the shared information. As we discussed in Chapter 9, \nthis usually is implemented through semaphores, which are locked and unlocked. \nThis works fine in a system running on a single processor, since the OS can coordi-\nnate the locking and unlocking, as we saw. But when the processes are running on \nseparate systems, there is no single OS to do the locking and unlocking. Two differ-\nent approaches have been developed for locking and locking in distributed systems: \nusing a centralized  lock server and using a distributed algorithm. Using a central \nserver is fairly straightforward. A central server is created and all lock and unlock \nrequests are sent to the server, as is shown in  Figure 17.9 . It operates on a first-come, \nfirst-served basis. \n But a centralized server is a single point of failure and a potential perfor-\nmance bottleneck, so a distributed algorithm is sometimes used instead, as shown \nin   Figure 17.10 . In this algorithm a process desiring to enter a critical section will \nask permission of all the other processes, including a logical clock timestamp in the \nrequests. If a process receiving a request does not currently want access to its related \ncritical section, then it will grant permission immediately. If that process does wish \nto access the critical section, then it will compare its own timestamp with that of the \nincoming request. It will grant the request if the timestamp of the request is earlier. \nOtherwise, it will not grant the request until it has finished its own use of the critical \nsection. In  Figure 17.10  all three clients want to access a related critical section in \ntheir processes. Client 3 sends a message to all the other clients with a logical clock \nClient 1\nYes\nNo\nLock\nRequest\nLock\nRequest\nClient 2\nLock\nServer\n FIGURE 17.9   \nA centralized lock \nserver.  \nelm49810_ch17_385-412.indd   401\nelm49810_ch17_385-412.indd   401\n12/10/08   8:34:33 PM\n12/10/08   8:34:33 PM\n",
        "category": "Category"
    },
    {
        "id": "65",
        "title": "Title for Chunk 65",
        "content": "Confirming Pages\n402 \nPart 5 Networks, Distributed Systems, and Security\nvalue of 157. Client 1 has a logical clock value of 155, so it will delay giving lock \npermission to client 3 until it has completed its own access. Client 2 gives client 3 \npermission since the request from client 3 had a lower clock value than its own. (The \nrequests from clients 1 and 2 are not shown.)  \n 17.6.3 Election \n If a distributed system is using a centralized server function such as the lock server \nthat was mentioned in the last section, then one design decision that needs to be \nmade concerns the question of how it was determined that this server would perform \nthat function, assuming that any of them could do so. Similarly, in some algorithms \nwe will have one process that will be the  coordinator of the algorithm. In most cases \na server (or coordinator) is selected by the system administrator and the function \nruns there. However, the coordinator is a single point of failure\u2014if we are interested \nin a more reliable overall system, then we need to be able to have that function run in \nmore than one place in case the primary site is down or unreachable. In the most gen-\neral and most reliable case we will allow the function to run anywhere. In this case \nwe need to dynamically determine which process should run this function. Dynami-\ncally determining the server or coordinator process is called an  election. There are \ntwo algorithms that are commonly used for such an election\u2014the bully algorithm \nand a token ring algorithm. In each case the nodes will each have some preassigned \npriority for being the coordinator and the algorithm should elect the highest priority \nprocess as the coordinator. \n The first question that must be addressed is a simple one. How does a node \ndecide that an election is needed? There are basically three times an election might be \nneeded: when a node joins the group, when a network failure partitions the  network \nso that part of the group cannot connect to the coordinator, and when the coordina-\ntor crashes. When a node joins a group it may have the highest priority for being the \ncoordinator, so in this situation it will always start running the election algorithm. \nIn the other two cases the processes should each be using a timer to detect a lack of \ncommunication with the coordinator. If the timer expires without a message from \nthe coordinator, then the process will start the election. This may necessitate that the \n FIGURE 17.10   \nDistributed locking.  \nClient 1 \nTime\n155\nRequest\n@ 157\nOK\nRequest\n@ 157\nNot\nYet\nClient 2 \nTime\n158\nClient 3\nelm49810_ch17_385-412.indd   402\nelm49810_ch17_385-412.indd   402\n12/10/08   8:34:33 PM\n12/10/08   8:34:33 PM\n",
        "category": "Category"
    },
    {
        "id": "66",
        "title": "Title for Chunk 66",
        "content": "Confirming Pages\n \nChapter 17 Distributed Operating Systems \n403\ncoordinator send  keep-alive notices to the group if there are no other messages so \nthat the other participants do not start an unnecessary election. \n In the  bully algorithm each process is assigned a priority and a process that \nneeds to start an election sends messages to all the other processes in the group, \ngiving its own priority and declaring itself to be the coordinator. Any process, P, \nreceiving this message will compare the priority given in the incoming message with \nits own priority.\n \ufffd If the incoming message priority is higher than its own, then the receiving \n process merely quits the algorithm. \n \ufffd If its own priority is higher than that in the incoming message, then it replies \nwith its own message stating its superiority and the process that sent the original \nmessage retires from the algorithm. \n \ufffd Eventually, the winning process will send a broadcast to the group announcing \nits coordinator status. \n In  Figure 17.11 , we see three processes sending bully algorithm messages. If  Priority 1\nis assumed to be high, then that process will win the algorithm and become the \ncoordinator. \n An alternative algorithm is the  token ring algorithm. In this algorithm each \nprocess is given a number that establishes an order in a logical ring. Each process \nwill need to know the order of the entire ring. The process starting an election sends \nan election message containing its own process number and its priority to the pro-\ncess, which it believes is the next in the ring. If it receives no reply, then it sends \nthe message to the next higher process. Eventually, some process will respond to \nthe message. It will append its own process number and priority to the message and \npass it on around the ring, bypassing any failed processes. When the message gets \nback to the process that started the election, it will contain an ordered list of all the \ncurrent processes and their priorities. This final message will be sent around the ring \nagain. As a result, each process will know the process number that is the coordinator \nand the complete order of the ring. This process is shown in  Figure 17.12 . Client A \nPriority 3 \nClient\nI Win\n# 1\nI Win\n# 1\nI Win\n# 2\nI Win\n# 2\nI Win\n# 3\nI Win\n# 3\nPriority 1\nClient\nPriority 2\nClient\n FIGURE 17.11  \n The bully algorithm.  \nelm49810_ch17_385-412.indd   403\nelm49810_ch17_385-412.indd   403\n12/10/08   8:34:33 PM\n12/10/08   8:34:33 PM\n",
        "category": "Category"
    },
    {
        "id": "67",
        "title": "Title for Chunk 67",
        "content": "Confirming Pages\n404 \nPart 5 Networks, Distributed Systems, and Security\nstarts the message and Client B and C each add their ID and priority to the message \nas it goes around the ring. When the message gets back to A, A will know that it is \nthe coordinator. The message will be sent around the ring one more time so that all \nprocesses will know the total group membership and the order of the ring.  \n 17.6.4 Reliable multicast communication \n Cooperating groups of processes frequently need to reliably communicate with \nevery member of the group. Sending a message to all the members of a group and \nnot to any other entities is called a  multicast. 1 Unfortunately, TCP/IP does not sup-\nport multicasting except within a single IP network, and MAC layer multicasting is \nrestricted to a single LAN. UDP supports multicasting, but it is unreliable. So we \nhave to figure out how to do reliable multicasting at the Application layer. The only \nmechanism that will work in all cases is for each member of the group to have a \npoint-to-point connection to each of the other members. This is fairly easy to do over \nthe Internet, though in a large group it will not scale well. So when a process wants \nto send a message to all the members of the group, it simply sends it to each of them \nover a point-to-point connection. That cumbersome process is unavoidable given the \nfacilities available in the lower networking layers today. If we want to be sure that \nall the processes see all the messages, then we need to use some method of acknowl-\nedgment. We could use TCP, which has such assurance built-in. But TCP is very \ninefficient for this and would not scale very well to large numbers of  processes. So \nwe would rather use UDP and do the acknowledgments ourselves. This still entails a \nlarge number of  acknowledgment messages ( ACKs ) coming back to the sender. As a \nresult, several methods of minimizing these acknowledgments have been  developed. \n 1 Theoretically multicasting includes the idea of sending the message only once into the network and \nhaving the network deliver it to all the destinations simultaneously, delivering the messages over each \nlink of the network only once and only creating copies when links to the destinations split. We are \nignoring that optimization here. \nPriority 3 \nClient B\nA, 1\nB, 3\nC, 2\nA, 1\nB, 3\nA, 1\nPriority 1\nClient A\nPriority 2\nClient C\n FIGURE 17.12  \n A token ring election.  \nelm49810_ch17_385-412.indd   404\nelm49810_ch17_385-412.indd   404\n12/10/08   8:34:34 PM\n12/10/08   8:34:34 PM\n",
        "category": "Category"
    },
    {
        "id": "68",
        "title": "Title for Chunk 68",
        "content": "Confirming Pages\n \nChapter 17 Distributed Operating Systems \n405\nThe first is to rely on the high reliability of today\u2019s networks and only have the \nreceivers send a  negative acknowledgment ( NACK ) if they infer from the incom-\ning message sequence numbers that they have missed a message. This is seen in \n Figure 17.13 , where process D has sent message 83 to the other processes.  Process C \nshows that the last message it received was 81, so it knows it missed message 82. In \nthis case process D will retransmit the missing message to all receivers who missed \nit. Other refinements have also been developed but are neither as significant nor as \nwidely deployed.  \n 17.6.5 Distributed transactions \n In interactive systems we often are processing transactions that involve several \nupdates to a database. A typical example would be an inventory transaction that \nmoved an item from one warehouse (A) to another (B). This would normally require \nseveral steps:\n 1. Read the count for the item in warehouse A. \n 2. Subtract 1 from the count and update that item count in the database. \n 3. Read the count for the item in warehouse B. \n 4. Add 1 to the count and update that item count in the database. \n If the system happens to crash after step 2 is completed and before the write of step \n4 is completed, then the database will show an  inconsistent state \u2014we will have \nlost track of one item in the inventory. We could avoid losing track of anything \nby doing the two updates in the opposite order, but then we would run the risk of \nthinking that we had an extra item. This problem can be avoided with a mechanism \nknown as a  transaction. This looks like an overloaded term because we use that \nword to indicate something a user might want to do with a system. But that closely \nparallels the steps we are looking at here. Most user transactions involve updates to \nA\nLast Msg.\n= 82\nMsg. 83\nMsg. 83\nMsg. 83\nNAK 82\nB \nLast Msg.\n= 82\nD\nC\nLast Msg.\n= 81\n FIGURE 17.13   \nReliable multicasting \nwith NACKs.  \nelm49810_ch17_385-412.indd   405\nelm49810_ch17_385-412.indd   405\n12/10/08   8:34:34 PM\n12/10/08   8:34:34 PM\n",
        "category": "Category"
    },
    {
        "id": "69",
        "title": "Title for Chunk 69",
        "content": "Confirming Pages\n406 \nPart 5 Networks, Distributed Systems, and Security\nseveral files or database tables and we want the entire system to accurately reflect \nthe event we are recording. We say that this type of update is  atomic, meaning that it \nshould result in all steps being recorded or none of them, even if one of the systems \ncrashes during the sequence of updates. When a process is going to record such a \nseries of updates, it issues an API call for a  transaction start. As each update to the \ndatabase is written, it may succeed or it may fail. The database system will make \nthese updates in a temporary fashion, putting them in the database in such a manner \nthat they can be recognized as something that was in progress but not finished. If \nany of the updates is rejected, the process will issue a  transaction abort system call \nand the database will erase all the temporary updates. If all the steps are success-\nful, then the process will issue a  transaction commit system call and the database \nsystem will commit the updates, making them permanent and deleting any previous \nrecords. \n In a system with a distributed database the operation is very similar, but since \nthere are several different database servers working together on a single  transaction, \nthe commit process is a bit more complicated because a failure of one of the pro-\ncesses might have happened since the original update call was issued. One of the \nprocesses that is managing one of the elements of the distributed database may have \ncrashed or the network may have failed and we may not be able to communicate \nwith that process. In either case, the operation can\u2019t continue. With a nondistributed \ndatabase the system is unlikely to fail in such a divided manner. In order to allow for \nsuch conditions, distributed transaction processing relies on a protocol known as a \n two-phase commit. We discuss this protocol in the next section. \n One other problem with distributed database transactions is that in order to \nimprove performance a database may try to interleave updates from different pro-\ncesses on the same data tables. As long as no two processes try to update the same \ndata, then there will be no conflict so the operations can proceed in an interleaved \nfashion. If two processes attempt to update the same data at the same time, then one \nof the operations will be rejected. Note that at this point the best choice for the appli-\ncation that was rejected is to simply retry the operation. This is not something that \nwould arise in a uniprocessing system, so it violates distribution transparency. \n 17.7 FAULT TOLERANCE \n In our discussion of transparency we said that one goal was to make failures trans-\nparent to the user. There are many mechanisms that can be used to increase the fault \ntolerance of a distributed application, but they mostly center on redundancy. \n 17.7.1 Introduction \n Failure is a more complex topic in distributed systems than in monolithic systems. \nWhen a monolithic system fails, all of it stops. When a distributed system fails, \nonly a part of it may stop. Since the parts are not necessarily communicating con-\nstantly, the first problem is for the various components to figure out that another part \nhas stopped. This can be very tricky to do. Usually we start with the idea of using \nelm49810_ch17_385-412.indd   406\nelm49810_ch17_385-412.indd   406\n12/10/08   8:34:34 PM\n12/10/08   8:34:34 PM\n",
        "category": "Category"
    },
    {
        "id": "70",
        "title": "Title for Chunk 70",
        "content": "Confirming Pages\n \nChapter 17 Distributed Operating Systems \n407\n timeouts. When a client asks a server to do something it starts a timer. If there is no \nreply within some certain time limit the client may infer that the server is down. But \nthe server may not be down. It may be that there is a network problem and the server \nis not currently reachable. There may be a sudden burst of traffic at some point in \nthe network such that an intermediate router was forced to drop either the request \nor the response. It may be that the server is currently overloaded and that the action \nhas been executed already but the reply either has not been yet sent or it is still in \ntransit. If we retry the operation, that might cause problems. If the operation was to \nsubtract an item from an inventory count, we don\u2019t want the operation repeated. On \nthe other hand, if we just counted the inventory and we are setting the count to the \nvalue we know is in the warehouse bin, then it would be OK to repeat the request as \nlong as no other change to the inventory was processed in the interval. We say that \nthe second operation is  idempotent, meaning that it is recorded in such a way that \nit can be repeated without altering the result. It is worth noting that if we recorded \nthe subtraction as a read of an old value and the write of a new value, it would be \nidempotent as well. \n 17.7.2 Process resilience \n We can make functions more robust by distributing them across several processes \nrunning on different systems\u2014if one fails the others can still run. We speak of such \nsystems as having  process groups. Process groups can be organized in either a \n hierarchical group, as seen in  Figure 17.14 , or a  flat group, as seen in  Figure 17.15 . \nIn a hierarchical group there is one process that is the coordinator. The other pro-\ncesses all report to the coordinator process with point-to-point links. Having a single \ncoordinator means that the group has a single point of failure, though we can elect \na new coordinator, as we saw in the last section. During that election time (and the \ntimeout required to recognize the failure), the group is basically nonfunctional, so \nthe system will appear unstable. Such systems are easy to implement and have a low \ncommunication overhead. \nA\nB\nC\nD\n FIGURE 17.14  \n A hierarchical \nprocess group.  \nelm49810_ch17_385-412.indd   407\nelm49810_ch17_385-412.indd   407\n12/10/08   8:34:34 PM\n12/10/08   8:34:34 PM\n",
        "category": "Category"
    },
    {
        "id": "71",
        "title": "Title for Chunk 71",
        "content": "Confirming Pages\n408 \nPart 5 Networks, Distributed Systems, and Security\n In a flat group the control is distributed throughout the group. Each process \ncommunicates directly with each other process. Thus, the communication overhead \nis much greater than with a hierarchical group. The group is more robust since a \nsingle failure will not shut the group down, but such systems are more complex to \nimplement than hierarchical groups. \n 17.7.3 Reliable client\u2013server communication \n We already mentioned that a client has some special considerations to make if a server \nfails to respond. We may not want to resend the request because we do not want the \noperation to be redone. Similarly, if a server crashes we are in a quandary because we \ndo not know if the server got the request and processed it and crashed before it could \nsend the reply. However, sometimes it is very important that the request be acted \nupon. Perhaps we are sending in a fire alarm. Sending it more than once is not a big \nproblem. This situation is known as  at least once semantics. Sometimes it is highly \nundesirable to send the request more than once. Imagine a request to pay a bill out of \nour bank account! We would not want that to happen more than once. This is known \nas  at most once semantics. Other times we are more or less indifferent\u2014perhaps \nwith a stock ticker that is only listing the latest transactions for a stock. This is known \nas  no guarantee semantics. Finally, we would like for the middleware to guarantee \nthat a transaction will be processed  exactly once. It is possible for middleware to \nachieve this level of guarantee, but it requires extensive logging and double-checking \nand is thus relatively expensive to implement. In general, we must analyze each type \nof transaction separately and see what level of semantics guarantee is warranted.  \n 17.7.4 Distributed commit \n When discussing distributed transactions in a previous section we introduced a \nnotion of a distributed commit. This algorithm is discussed here separately because \nit is relevant to failure transparency. It is known as a two-phase commit. One process \nA\nB\nC\nD\n FIGURE 17.15   \nA flat process group.  \nelm49810_ch17_385-412.indd   408\nelm49810_ch17_385-412.indd   408\n12/10/08   8:34:35 PM\n12/10/08   8:34:35 PM\n",
        "category": "Category"
    },
    {
        "id": "72",
        "title": "Title for Chunk 72",
        "content": "Confirming Pages\n \nChapter 17 Distributed Operating Systems \n409\nwill be the coordinator of the algorithm. It will send a message to each other process \nasking if it can commit the updates it was requested to do. If all the processes are \nstill running and the network is working, then they will all reply affirmatively and \nthe coordinator will then tell them all to commit the updates. If any of the processes \nhas failed or the network is not working, then the coordinator will not receive an \naffirmation from at least one process, so eventually it will timeout the operation and \nwill send an abort request to each of the other processes. There are complications if a \nprocess crashes. When a failed process restarts, it can learn from examining log files \nthat it was in the midst of a commit operation. What it needs to do then will depend \non the state it was in when it crashed. If it was in an abort state, then it should simply \nabort the operation. Similarly, if it was in a commit state, then it should continue \nwith the commit. Each of these states could only be reached if the coordinator had \ninstructed it accordingly. If the recovering process was in the ready state, waiting \nto hear from the coordinator, then it can simply ask the coordinator to repeat its \ninstruction. \n The big problem occurs when the coordinator crashes. In this case the other par-\nticipants will timeout the coordinator. If the participant is in either the abort or com-\nmit state, then it acts accordingly. If it is in the ready state then it cannot tell what to \ndo by itself. It will ask all of the other processes what state they are in. If any of the \nother processes is in an abort or commit state, then all of them can act accordingly, \nsince that will mean that the coordinator had reached a decision and had started \nsending out instructions before it failed. \n There is a small possibility that the algorithm can hang because the coordinator \ncrashed before sending a commit message. For this purpose a three-phase commit \nvariant of this algorithm was developed. In practice this situation is so rare that the \nthree-phase commit is almost never used. \n 17.8 SUMMARY \n If they are not already, distributed systems will \nsoon be the norm rather than the exception. This \nchapter reviewed a number of reasons why we \nfind distributed systems more common each day. It \nalso explained the notion of distribution transpar-\nency and introduced the idea of middleware and \nexplained why it takes the forms it does. We then \npresented several different models often used with \ndistributed systems, including the client server \nmodel, three-tier and N-tier models, and horizontal \ndistribution.   Section 17.3  went over the principles \nof processes and threads and explained how threads \ncan be used in distributed systems to make clients \nand servers perform better, or at least appear to do \nso. Processes in distributed systems need to com-\nmunicate, and to do so they need to refer to other \nentities. Accordingly,  Section 17.4  introduced the \nconcept of naming and name spaces. In  Section 17.5  \nwe covered some different paradigms for distributed \nsystems, including remote procedure calls, distrib-\nuted objects, distributed documents, and distributed \nfile systems. We then discussed synchronization \nbecause distributed systems have special problems \nwith  synchronization that are different from uni-\nfied systems.  Section 17.7  was about fault tolerance \nbecause distributed systems have special problems \nsince failure of one component can allow the rest of \nthe system to continue to run. \n In the next part of the book we take a look at a \nfew important modern OSs and see how they imple-\nment some of the features we have described in these \nin-depth topic chapters. Some of these OSs were \nelm49810_ch17_385-412.indd   409\nelm49810_ch17_385-412.indd   409\n12/10/08   8:34:35 PM\n12/10/08   8:34:35 PM\n",
        "category": "Category"
    },
    {
        "id": "73",
        "title": "Title for Chunk 73",
        "content": "Confirming Pages\n410 \nPart 5 Networks, Distributed Systems, and Security\ncovered in Part 2, but there we only discussed the \nkinds of features that such OSs needed to have to \nsupport a given level of features. We revisit some of \nthose OSs in Part 6 of the text to look at them in \ngreater detail and see how they use the mechanisms \nwe have been discussing. \n BIBLIOGRAPHY \n Barroso, L., J. Dean, and U. Hoelzle, \u201cWeb Search for a \nPlanet: The Google Cluster Architecture,\u201d Research \nPaper, Google, Inc., 2005. \n Chandy, K. M., and J. Misra, \u201cDistributed Deadlock \nDetection,\u201d  ACM Transactions on Computer \nSystems, Vol. 1, No. 2, May 1983, pp. 144\u2013156. \n Knapp, E., \u201cDeadlock Detection in Distributed \nDatabases,\u201d  ACM Computing Surveys, Vol. 19, No. 4, \nDecember 1987, pp. 303\u2013328. \n Lamport, L., \u201cTime, Clocks, and the Ordering of Events \nin a Distributed System,\u201d  Communications of the \nACM, Vol. 21, No. 7, July 1978, pp. 558\u2013565. \n Obermarck, R., \u201cDistributed Deadlock Detection \nAlgorithm,\u201d  ACM Transactions on Database \nSystems, Vol. 7, No. 2, June 1982, pp. 187\u2013208. \n Ricart, G., and A. K. Agrawala, \u201cAn Optimal Algorithm \nfor Mutual Exclusion in Computer Networks,\u201d \n Communications of the ACM, Vol. 24, No. 1, January \n1981, pp. 9\u201317. \n Rivest, R., A. Shamir, and L. Adleman, \u201cOn Digital \nSignatures and Public Key Cryptosystems,\u201d \n Communications of the ACM, Vol. 21, No. 2, \nFebruary 1978, pp. 120\u2013126. \n Sandberg, R., et al., \u201cDesign and Implementation of \nthe Sun Network File System,\u201d  Proceedings of the \nUSENIX 1985 Summer Conference, June 1985, \npp. 119\u2013130. \n WEB RESOURCES \n http://www.opengroup.org/dce/ (the OSF Distributed \nComputing Environment [DCE], an RPC \nimplementation) \n http://www.w3.org (World Wide Web Consortium [W3C]) \n http://www-306.ibm.com/software/lotus/ (Lotus Notes \nand Symphony, among other distributed products) \n http://en.wikipedia.org/wiki/Two-phase_commit \n REVIEW QUESTIONS \n 17.1 We listed eight reasons why distributed systems \nare being found more and more often. Name four \nof the eight. \n 17.2 We listed nine facets of distributed systems that \nshould ideally be transparent to users. List five. \n 17.3 Briefly define middleware. \n 17.4 We gave four models for building distributed sys-\ntems. What is the model that underlies the World \nWide Web? \n 17.5 What was the layer that was added to the WWW \nmodel to derive the three-tier model? \n 17.6 A further generalization of a distributed systems \nmodel as seen in Google was called what? \n 17.7 A different sort of model was described that was \ncalled horizontal distribution. Give an example of \nthe type of system described by this model. \n 17.8 Early Web browsers using the HTTP 1.0 proto-\ncol had to open a separate connection to retrieve \neach component referenced by a Web page. \nWhat technique was used to make this more \nefficient.  \n 17.9 Describe two ways that servers typically use \nthreads. \n 17.10 When a physical virtual machine host OS loads a \nguest OS, what does it do to ensure that the host \nOS maintains control of the system? \n 17.11 Briefly describe the operation of an abstract virtual \nmachine.  \n 17.12 True or false? The Jini design allows applications \nto access services without any prior knowledge of \nthe network mechanisms that will be used by the \nservice. \nelm49810_ch17_385-412.indd   410\nelm49810_ch17_385-412.indd   410\n12/10/08   8:34:35 PM\n12/10/08   8:34:35 PM\n",
        "category": "Category"
    },
    {
        "id": "74",
        "title": "Title for Chunk 74",
        "content": "Confirming Pages\n \nChapter 17 Distributed Operating Systems \n411\n 17.13 What is the basic reason why mobile entities using \nIP are such a problem? \n 17.14 One of the middleware applications we looked at \nallows us to take an existing program and move \npart of it to another system. What was the non-\nobject-oriented design for doing this? \n 17.15 What do we call the main standard for developing \nsystems of distributed objects? \n 17.16 What does the Lamport timestamp mechanism do \nwhen receiving a message to ensure that the local \nlogical clock reflects correct information about \nthe order of occurrence of events in a distributed \nsystem? \n 17.17 How does a centralized mechanism for supporting \nmutual exclusion in a distributed system work? \n 17.18 What were the two different distributed algorithms \nfor election a coordinator process for a system? \n 17.19 True or false? TCP supports reliable multicasting \nover the Internet. \n 17.20 Why are database transactions more difficult in \ndistributed systems?  \nelm49810_ch17_385-412.indd   411\nelm49810_ch17_385-412.indd   411\n12/10/08   8:34:35 PM\n12/10/08   8:34:35 PM\n",
        "category": "Category"
    },
    {
        "id": "75",
        "title": "Title for Chunk 75",
        "content": "elm49810_ch17_385-412.indd   412\nelm49810_ch17_385-412.indd   412\n12/10/08   8:34:36 PM\n12/10/08   8:34:36 PM\n",
        "category": "Category"
    },
    {
        "id": "76",
        "title": "Title for Chunk 76",
        "content": "Confirming Pages\n413\nPart\nPart\n In this part:\n Chapter 18: Windows NT\u2122 through Vista\u2122 415 \n Chapter 19: Linux: A Case Study 445 \n Chapter 20: Palm OS: A Class Case Study 469 \n T\nhe first two parts of the book gave us some initial background and introduced \na series of more complex operating systems in what we dubbed a \u201cspiral \napproach.\u201d This approach was used in order to motivate the features being \nintroduced and to give some perspective to the material. The next three parts treated \nvarious technical OS aspects in depth. In this part we once again turn to real OSs, \nnow in the form of case studies. We describe in more depth how several modern OSs \nincorporate and implement the features described in Parts 3\u20135. \n Chapter 18 covers the Windows NT family starting with the first release and \nthrough the existing release known as Vista. Some historical material is included to \ngive perspective to the student. Other subtopics in this chapter include a discussion \nof the single-user OS environment, process scheduling, memory management, file \nsupport, basic I/O, GUI programming, networking, symmetric multiprocessing, a \nnote about the significance of the startup speed of the later releases, and a few words \nabout the new features in the Vista release. \n Chapter 19 on Linux covers additional topics that were not covered in the second \npart of the text and how it implements some of the standard features that we expect \nto see in any modern OS. After a brief review of Linux we discuss the memory man-\nagement features of Linux, and the organization of file systems. This chapter also \ncover basic I/O functions, support for GUI programming, networking support, and \nsymmetric multiprocessing. We then introduce some interesting variants of Linux, \nprimarily hard real-time systems. \n Chapter 20 covers additional topics on the Palm OS. Subtopics include other \ninteresting functions of the OS that were not necessary to the spiral approach sec-\ntion, the programming environments that are required when dealing with such sys-\ntems, and similar developments in the cell phone market and how they contrast with \nthe PDA market. Finally, the chapter discusses new applications that are being devel-\noped for these OSs because they are mobile, and how this impacts OS features. \nCase Studies 6\nelm49810_ch18_413-444.indd   413\nelm49810_ch18_413-444.indd   413\n12/11/08   3:59:43 PM\n12/11/08   3:59:43 PM\n",
        "category": "Category"
    },
    {
        "id": "77",
        "title": "Title for Chunk 77",
        "content": "Confirming Pages\n414\nelm49810_ch18_413-444.indd   414\nelm49810_ch18_413-444.indd   414\n12/11/08   3:59:44 PM\n12/11/08   3:59:44 PM\n",
        "category": "Category"
    },
    {
        "id": "78",
        "title": "Title for Chunk 78",
        "content": "Confirming Pages\n47\n Chapter \n Chapter \n A Simple, Single-Process \nOperating System  \nIn this chapter: \n \n3.1 Introduction: Monitors and CP/M 48\n \n3.2 Characteristics of a Simple PC System 50\n \n3.3 Input/Output Management 52\n \n3.4 Disk Management and the File System 54\n \n3.5 Process and Memory Management 58\n \n3.6 Summary 63\n W\ne now start the \u201cspiral\u201d part of the book, where each chapter discusses a type \nof operating system based on a particular real OS. We start with a real but \nsimple OS with limited capability and discuss progressively more complex \nOSs in the following chapters. We base most of our presentation in this chapter on the \nfeatures of an early personal computer operating system\u2014CP/M\u2014and the  hardware \ncommonly used to run this system. We discuss how these OSs were designed as well \nas the rationale behind the design. Although these systems were single-process, lim-\nited functionality systems, they provided sufficient power for hundreds of applications \nto be written for millions of personal computers. Thus, they provide a good practical \nexample of a simple operating system. The issues discussed in this chapter\u2014such \nas I/O management, the file system, and memory and process management\u2014are \nexpanded upon in subsequent chapters as more complex operating systems are intro-\nduced. However, we start here with a basis: real but simple functionality. \n This chapter is organized as follows.  Section 3.1  describes the predecessors \nof simple operating systems, called monitors, and discusses how they evolved into \nearly operating systems because of the need for standardization. In  Section 3.2 , \nwe describe the characteristics of the early PC systems for which this type of OS \nwas used. Then we discuss how input/output was managed in such an early OS in \n Section 3.3 , followed by description of the file system in  Section 3.4 , and process \nand memory management in  Section 3.5 . \n The systems of this era were quite limited\u2014they ran only one user application at \na time. Process management was initially limited to loading and starting a particular \napplication program. Late in the life of CP/M a background printing function was \n 3  3 \nelm49810_ch03_045-066.indd   47\nelm49810_ch03_045-066.indd   47\n12/11/08   7:01:35 PM\n12/11/08   7:01:35 PM\n",
        "category": "Category"
    },
    {
        "id": "79",
        "title": "Title for Chunk 79",
        "content": "Rev. Confirming Pages\n48 \nPart 2 Building Operating Systems Incrementally: A Breadth-Oriented Spiral Approach\nadded. This facility was the beginning of the concept of multiprocessing as it is car-\nried out in more modern OSs. Memory management in the OS was limited to which \npart of memory to use for the OS, the interrupt vector, the user program, the program \ndata, and so on. But because memory was quite limited, large programs often did not \nfit completely into memory or were limited in the amount of data they could handle. \nIt was necessary for an application programmer to break down such programs into \nsections, and to replace one section in memory with another as needed. This memory \nmanagement technique, known as  overlays, is discussed in  Section 3.5 . Again, these \ntechniques foreshadow the more complex memory management techniques found in \na modern OS. \n 3.1 INTRODUCTION: MONITORS AND CP/M \n We start this section with a discussion on why a need emerged for a PC operating \nsystem. The predecessors of these OSs were called  monitors, 1 and had very limited \ncapabilities. There was no standard for monitors\u2014each manufacturer of early PC \nsystems used to write their own monitor program, which had unique commands and \nconventions. This variety meant that early application programs had to be rewritten \nfor each monitor. \n 3.1.1 Introduction to monitors: The predecessors of simple OSs \n When personal computing was young and single-chip microprocessors made it pos-\nsible to build small, relatively inexpensive computers, there was a software crisis. \nThe advent of cheap microprocessors allowed small startup companies to sell kits for \nhome hobbyists who wanted to build their own computer. These kits typically con-\ntained a circuit board, a microprocessor, some memory, and some additional device \ncontroller chips. The additional chips were for controlling various input and output \ndevices\u2014for example, cassette tapes, floppy disks, external video terminals, and \nprinters. There were a large number of companies selling PC kits. At first they were, \nby any standard, very limited. In early systems of this type, memory size was one \nto four kilobytes\u2014or sometimes even less. Application programs were written in \nmachine language or assembly language. There was typically no operating system. \nInstead, there was a small  monitor program usually stored in  ROM \u2014read-only \nmemory\u2014that would allow an application to do simple, common tasks, such as:\n \ufffd output a character to a device such as a video display or Teletype \n \ufffd get a character from the keyboard device \n \ufffd save the contents of all or part of memory to a cassette tape or floppy disk \n \ufffd restore memory from a saved image on tape or disk \n \ufffd print a character to the printer \n The monitor did only these basic tasks and not much else. \n1 We are talking about a software module that is a precursor to an OS, not a video display terminal, \nsometimes also called a monitor and often used on computers. \nelm49810_ch03_045-066.indd   48\nelm49810_ch03_045-066.indd   48\n12/22/08   12:58:30 PM\n12/22/08   12:58:30 PM\n",
        "category": "Category"
    },
    {
        "id": "80",
        "title": "Title for Chunk 80",
        "content": "Confirming Pages\n \nChapter 3 A Simple, Single-Process Operating System \n49\n An application program could print a character (e.g., a \u201c1\u201d) on the  console \u2014a \nvideo display or Teletype\u2014by calling the monitor using the following steps:\n 1. Put the character in a specific register as specified by the monitor (assume that \nthis is register E). In this case, the value 31 Hex (the ASCII value of \u201c1\u201d) is \nplaced in register E. \n 2. Select a particular monitor function, in this case, the \u201cprint a character\u201d func-\ntion, which has value 2. Place the number corresponding to the selected monitor \nfunction in register C. \n 3. Finally, a call to the monitor is executed through Interrupt 5. This would cause \nthe monitor to execute the print function called for by the function code stored \nin register C using the character stored in register E. \n 4. After the monitor outputs the character, it returns a status code in register A that \nindicates OK or not OK. Not OK indicated some exceptional condition such as \na device that is not responding or illegal values for some of the parameters to the \nfunction. The application should look at the status code in register A to determine \nan appropriate action in case of errors. Typical early applications did not always \ncheck for errors because there was little they could do for most errors anyway.  \n 3.1.2 Why CP/M? What was the software crisis? \n There were many companies building computer kits, and each had to provide the \nsoftware for a small monitor. These monitors were not large in terms of memory \nrequirements\u2014a few hundred or a few thousand bytes. Typically, a monitor pro-\nvided only a dozen functions or so, but these functions required time and expertise \nto develop, debug, and build. Even worse, there was no standard monitor or interface \nto a monitor. Each manufacturer simply implemented whatever functions they imag-\nined that programmers wanted. For example, passing parameters to functions might \nuse registers in one monitor. In another monitor, the parameters might be passed in \nmemory locations. They might use some combination of both methods in a third \nmonitor. This created a problem for application programming. How could a pro-\ngram be written that was  portable \u2014that is, it would run on different manufacturer\u2019s \ncomputers? 2 Because of the different monitor programs, application programs would \nneed to be specially written for each manufacturer\u2019s computers. This situation led to \nthe development of  CP/M ( Control Program/Monitor ). Created for microcomput-\ners based on the Intel 8080/8085 CPU circuits, it was initially the product of one \nperson, Gary Kildall of Digital Research, Inc. \n 3.1.3 Components of CP/M \n CP/M ( Control Program/Monitor ) was written to allow software developers, users, \nand manufacturers to have one single, simple, standard interface. The hardware devices \nwould be isolated from the operating system by a layer of software: the  BIOS ( Basic \nInput/Output System ). This BIOS would be similar to a monitor but with standard \n2 Since the early application programs were written in machine language, the CPUs had to be identical, \nor at least compatible\u2014that is, one CPU\u2019s instruction set had to be a superset of the other. \nelm49810_ch03_045-066.indd   49\nelm49810_ch03_045-066.indd   49\n12/11/08   7:01:40 PM\n12/11/08   7:01:40 PM\n",
        "category": "Category"
    },
    {
        "id": "81",
        "title": "Title for Chunk 81",
        "content": "Confirming Pages\n50 \nPart 2 Building Operating Systems Incrementally: A Breadth-Oriented Spiral Approach\nspecified functions and interfaces. Each manufacturer would adapt the BIOS to the set \nof devices included with their particular machine.  3 The interface to the BIOS, how-\never, was the same, no matter how the underlying devices might work. Porting CP/M \nto a new system consisted mostly of writing the BIOS routines for the hardware. \n The core of the operating system was called the  BDOS ( Basic Disk Operating \nSystem ). It was what we call the kernel today. It would be independent of the hardware \nand would call the more primitive services in the BIOS. The BDOS software would be \nthe same for any system that CP/M was to run on. This kind of standardized interface \nthat provides general system functions but hides the messy hardware details is called \nan  abstraction. We refer to the technique of abstraction many times in this book. \n The last part of the OS was a user interface to the operating system called the \n CCP ( console command processor ). The other commands that the CCP executed \nwere mostly programs on the disk. These three components of a CP/M operating \nsystem were quite small. Each component was 2,000\u20134,000 bytes in size and all of \nCP/M fit on a few sectors of a floppy disk for booting the computer. \n The existence of a de facto standard in CP/M encouraged software writers \nto develop application software for personal computers built by a wide variety of \nmanufacturers. The software could support many input and output devices\u2014such \nas different capacity floppy disks, hard disks, and video terminals. Applications did \nnot need to be custom written for each type of computer. There were hundreds of \nprograms written within a very short time. For programmers there were text editors, \ncompilers for many programming languages, and debuggers. There were word pro-\ncessors, accounting packages, simple file systems, games, and many other programs \nwritten that created a booming market for personal computers. And since the operat-\ning system was well designed, with a clearly specified interface at each layer, there \nwere several replacements for the CCP that offered different interfaces. \n When IBM decided to enter the personal computing market, the decision was \ninitially made to use the well-established CP/M standard. Since the CPU for the IBM \nPC (Intel 8088) was not exactly compatible to the CP/M-80\u2014which was based on \nIntel 8080 and Zilog Z-80 processors\u2014some small modifications were made. The \nIBM hardware was well known and specific, so the BIOS could take advantage of \nthose characteristics. 4 \n In the following sections, we take the liberty of abstracting the hardware of early \nIBM PCs and CP/M computers. Our purpose is not to teach CP/M, but rather to use \nit as an example to illustrate the features and functionality of a simple OS. \n 3.2 CHARACTERISTICS OF A SIMPLE PC SYSTEM \n Early PC systems consisted of a main circuit board\u2014the  motherboard of the PC. \nThe motherboard had a microprocessor chip (CPU), some random access memory \n(RAM), a ROM memory that contained the BIOS, and several other integrated \n3 It was also possible for a hobbyist user to do this adaptation, since instructions and examples came with \nthe software. Even something as simple as adding memory to a system required recreating the BIOS. \n4 In the end, IBM adopted the MS/DOS operating system\u2014developed by Microsoft\u2014for their PC. \nelm49810_ch03_045-066.indd   50\nelm49810_ch03_045-066.indd   50\n12/11/08   7:01:40 PM\n12/11/08   7:01:40 PM\n",
        "category": "Category"
    },
    {
        "id": "82",
        "title": "Title for Chunk 82",
        "content": "Confirming Pages\n \nChapter 3 A Simple, Single-Process Operating System \n51\nKeyboard\nMain\nMemory\n(RAM and\nROM)\nVideo\nMonitor\nDisplay\nVideo\nController\nKeyboard\nController\nSystem Bus (on Motherboard)\nHard\nDisk\nController\nPrinter\nFloppy Disk Drive\nHard Disk Drive\nCPU\n(Processor)\nExpansion\nCard\nFloppy\nDisk\nController\nFIGURE 3.1 \nHardware \ncomponents \nin an early PC \nsystem.\n circuits (ICs) that interfaced these chips together. The motherboard had some slots \nto insert additional expansion circuit boards\u2014called  cards in early PC terminol-\nogy. These cards included a video controller that was connected to a video moni-\ntor by plugging the monitor\u2019s cable into the video controller card. Other expansion \ncards could include additional RAM and floppy disk and hard disk controllers. User \ninput/output was through a video monitor and keyboard. The keyboard was plugged \ndirectly into the motherboard, which had a keyboard controller chip built in. There \nwas also a simple clock or timer chip on the motherboard. \n A simple system schematic view of the typical hardware components in an early \nPC computer system is illustrated in  Figure 3.1 . Some of the characteristics of this \ntype of system that had major effects on the design of the operating system were the \nfollowing:\n 1.  Main memory was quite limited in size. This led to the OS design decision that \na single application program would be loaded into memory at a time. Because \nthe CP/M OS was quite small, it would be permanently placed in memory. This \nincludes the loader, interrupt handler, and device drivers. If an application pro-\ngram did not fit into the remaining available memory, the application would \nhave to be written so that it is divided into sections that individually fit in mem-\nory. When a new section is needed, a memory management technique known \nas  overlays could be used by the application to replace the old section with the \nnew one. \n 2.  Disk format was standardized. The disk block size and format was fixed for \nboth floppy and hard disks in early PCs. This led to a standardized file system \ndesign that was based on the standard disk format. \nelm49810_ch03_045-066.indd   51\nelm49810_ch03_045-066.indd   51\n12/11/08   7:01:41 PM\n12/11/08   7:01:41 PM\n",
        "category": "Category"
    },
    {
        "id": "83",
        "title": "Title for Chunk 83",
        "content": "Confirming Pages\n52 \nPart 2 Building Operating Systems Incrementally: A Breadth-Oriented Spiral Approach\n 3. Interrupt handling was mainly for I/O devices. Since one application would \nbe running at a time, there was no need for switching between applications. No \nCPU scheduling was needed in the OS. The main types of interrupts were for \nhandling I/O devices. \n 3.3 INPUT/OUTPUT MANAGEMENT \n I/O handling was limited in early OSs since the types of I/O devices were quite lim-\nited compared to the wide variety available nowadays. Most application programs \nfor early PCs needed the following I/O services:\n 1. Read characters from the keyboard. \n 2. Write characters to the video screen. \n 3. Print a character to the printer. \n 4. Utilize the disk file system to create a new file, read and write to the file, and \nclose a file. \n One problem for many programs was the lack of flexibility in handling keyboard \ninput and screen output. Because there were many different companies making com-\nputer hardware that worked differently, the OS tried to provide a standard way of \ndealing with these differences. \n Another problem was performance: executing some I/O commands by direct calls \nto the BIOS or the hardware was often much faster and more flexible than calling the \nappropriate OS command. This led to a tradeoff between  portability \u2014if application \ndesigners used only OS calls to perform I/O\u2014versus the flexibility and higher speed \nthat was possible if application designers used direct calls to BIOS and hardware func-\ntions. As an example, we discuss these tradeoffs with respect to the two most common \nI/O devices in early systems: keyboard for input and video monitor for output.  \n 3.3.1 Keyboard input\u2014Portability versus flexibility \n Keyboards came in many types. They might have 65 to 95 keys placed in different \nplaces on the keyboard. The data transferred from the keyboard might be serialized \nor parallel and characters might be represented by seven or eight bits. How could this \nbe standardized? The BIOS was customized for each type of keyboard, but would \nprovide the same set of BIOS interface functions to the rest of the OS. The BDOS \nwould then use those BIOS functions to create a simple OS interface for the key-\nboard. These functions\u2014OS system calls\u2014for the keyboard were: (1) read a charac-\nter from the keyboard and (2) check if a key has been pressed. For many applications \nthis was adequate. If an application used these standard functions for its keyboard \ninput, it would be portable to any computer system. \n But some applications needed additional flexibility. For example, a word pro-\ncessor may want to use \u201cmodified\u201d keys\u2014a \u201ccontrol  \ufffd S\u201d might save the file, and \na \u201ccontrol  \ufffd C\u201d might pop up a command list menu. These special keystrokes or \nkeystroke combinations created a problem because they were not recognized by the \nBDOS and hence could not be passed on to an application. Even worse, some com-\nbinations like \u201ccontrol  \ufffd C\u201d might be interpreted by the BIOS or BDOS and cause \nelm49810_ch03_045-066.indd   52\nelm49810_ch03_045-066.indd   52\n12/11/08   7:01:42 PM\n12/11/08   7:01:42 PM\n",
        "category": "Category"
    },
    {
        "id": "84",
        "title": "Title for Chunk 84",
        "content": "Confirming Pages\n \nChapter 3 A Simple, Single-Process Operating System \n53\nsome OS action such as a reboot. In this case, it would obviously not pass the key-\nstroke combination to the application. \n Applications that wanted additional flexibility to handle the keyboard so that \ncombinations of keystrokes had meaning to the application bypassed the BDOS. \nThis was trivial to do. It might mean simply reading keys from the BIOS rather than \nthe BDOS, or even reading keys directly from the keyboard hardware (actually the \nkeyboard interface chip). It was easy to bypass the operating system (BDOS) because \nin early systems there was no memory protection. Any application could address any \npart of memory. It was just as easy to use BIOS calls as to use BDOS calls, and the \nBDOS call would not do what was needed by the application. The problem with this \napproach is that programs would not be portable anymore, especially if the applica-\ntion went directly to the hardware. \n 3.3.2 Video monitor output\u2014Portability versus functionality \nand performance \n The screen\u2014or  video monitor \u2014posed even more significant problems. First, the \nfunctions available through the BDOS and BIOS interface functions was rather lim-\nited. There were many features of video systems that could not be used directly \nby the simple OS system calls. For example, one could not use color, write mul-\ntiple \u201cpages\u201d of video memory to simulate motion by rapidly displaying a series of \nimages, or move the cursor independently of writing to the screen. Second, and even \nmore critical, screen output using BDOS was very slow. Many applications would \nwrite characters directly to the screen memory and access the video controller hard-\nware directly. Many applications would also move the cursor using BIOS calls. The \nmain reason for bypassing BDOS was to improve application performance. \n Writing directly to video memory provided not only more functionality but was \nalso much faster than going through an OS system call. Depending on the program-\nming language used, it could be 100 times faster or even more! Bypassing the OS to \ndisplay characters created the same type of portability problems that bypassing the \nkeyboard did. But the performance benefits were so significant that many applica-\ntion programs ignored portability to improve performance. This was especially true \nof game programs, which always tried to wring every possible ounce of performance \nout of the hardware. Games have always driven the rapid progress of PC hardware \ndevelopment. \n For example, to put a white-colored \u201c \ufffd \u201d on a black screen background required \na call to a single machine instruction: \u201cMove 0F800, 2B07.\u201d Writing text directly \nto video memory was relatively straightforward. Video memory began at location \n0F800 Hex, which corresponded to the first visible character on the upper left corner \nof the screen. It was followed by the  video attributes of that character. In the case of \na color adapter this was 8 bits of information: 3 bits of color information for the fore-\nground 5 ; 3 bits of background color; one bit for \u201chigh intensity foreground\u201d (bright); \nand the last bit for blinking the character. So the character \u201c \ufffd \u201d (\u201c2B\u201d ASCII) was \nwritten to the screen at location upper left corner (F800) and was set to a foreground \n5 Color was specified using 1 bit each for red, green, and blue; white is all 3 bits as 1\u2019s. \nelm49810_ch03_045-066.indd   53\nelm49810_ch03_045-066.indd   53\n12/11/08   7:01:42 PM\n12/11/08   7:01:42 PM\n",
        "category": "Category"
    },
    {
        "id": "85",
        "title": "Title for Chunk 85",
        "content": "Confirming Pages\n54 \nPart 2 Building Operating Systems Incrementally: A Breadth-Oriented Spiral Approach\nDisk\nrotation\nTrack 76\nCenter hole\nRead/write arm\nmovement direction\nRead/write \nhead\nCurrent track\nIndex hole\nTrack 0\nFIGURE 3.2 \nA floppy disk \nfor early PCs.\nof white (\u201c7\u201d) on a black (\u201c0\u201d) background. A black character on a white background \nwould simply have the attribute \u201c70.\u201d \n 3.4 DISK MANAGEMENT AND THE FILE SYSTEM \n Since so many applications bypassed the keyboard and video OS system calls, what \ndid the OS really provide? One of the main services that such an early OS provided \nwas a standard and portable file system. About 75% of OS system calls were disk file \nrelated. In this section, we discuss the file system for CP/M but first we describe the \ndisk system that is the basis for the file system. \n 3.4.1 The Disk System \n In early PC systems, there was a standard for the hardware disk devices for use with \nthe file system\u2014the 8-inch floppy, illustrated in  Figure 3.2 . This floppy had a hole \nin the middle where the floppy disk drive would position it on a spindle. The spindle \nis connected to a disk drive motor that would spin the disk at 360 revolutions per \nminute. The standard disk had 77  tracks numbered from track 0 at the outside track \nfurthest from the hole to track 76 at the innermost track. Tracks were concentric \ncircles\u2014each track began and ended equidistant from the center hole. A track con-\ntained 26  sectors (sometimes called  blocks ), the first sector numbered 1 and the last \nsector 26.  6 Each sector contained 128 bytes of data, plus some control information, \nsuch as which sector number it was. Floppy disks were two-sided, with the sides \nnumbered, not surprisingly, 0 and 1. There was a small hole called the  index hole \nnear the center hole that was used by the disk controller to find out where the first \nsector of each track was. Since all tracks had 26 sectors, the tracks were longer on \nthe outside and shorter on the inside, but each track held the same amount of data. 7  \n6 Tracks started at 0, but sectors started at 1. \n7 This is no longer true in modern hard disks. \nelm49810_ch03_045-066.indd   54\nelm49810_ch03_045-066.indd   54\n12/11/08   7:01:42 PM\n12/11/08   7:01:42 PM\n",
        "category": "Category"
    },
    {
        "id": "86",
        "title": "Title for Chunk 86",
        "content": "Rev. Confirming Pages\n \nChapter 3 A Simple, Single-Process Operating System \n55\n The disk system was comprised of the  disk drive  and  disk controller. The disk \ndrive held and rotated the disk media (a floppy disk), which actually contained the \nstored data. The disk controller was usually built on to the computer\u2019s motherboard \nor on a circuit card plugged into the motherboard. Disk drives can move a  disk \nhead \u2014which contains read and write magnetic sensors\u2014from track to track. To \nread any individual sector on a track, the drive must wait for the sector to rotate \nunder the disk head. \n A disk controller can take commands to read or write a sector or multiple sectors \non a given track and on a given side of the disk. When the disk drive head movement \nmotor moved the head it might sometimes miss (go to the wrong track). The con-\ntroller would notice this (each sector of each track has the track number on it) and \nwould reposition the disk head correctly. Sometimes sectors may be incorrectly read \nand again the disk controller would notice this and try to read again. The controller \nwould also reorient itself to start looking for sectors on tracks starting after the index \nhole rotates around. All of these activities are invisible to the OS or even the BIOS. \nThey are implemented either at the hardware level of the disk controller itself or on \nthe software controlling the specialized processor on the disk controller. This soft-\nware embedded in ROMs on controllers is often known as  firmware. \n Such a standard disk for early PC systems contained: 77 (tracks)  *  26 (sec-\ntors per track)  *  128 (bytes per sector)  *  2 (sides)  \ufffd 512,512 bytes of raw data \n(500 Kbytes), after being formatted by the OS.  Disk formatting is the process of \nwriting control information on the disk to divide the disk tracks into sectors. This \nstandard disk was used as the basis for implementing the OS file system for PCs, \nwhich we discuss in the next section.  \n 3.4.2 The File System \n The OS had a simple file system built on top of the BIOS to store user and system files. \nA part of the system files that can be stored on a disk contain the binary OS code itself. \nIn addition, each disk has a directory that stores information about all files stored on \nthe disk, their sizes, the physical disk locations (sectors) where they are stored, and so \non. The files stored on disk may contain any of the following types of data:\n \ufffd application-produced data (documents, spreadsheets, source code) \n \ufffd application program executables (binary code) \n \ufffd directory information (the names of the files, date created, location\u2014where it is \nstored on the disk) \n \ufffd the binary executable of the operating system (the OS executable, used to load \nor \u201cboot\u201d the OS) \n To accommodate the different types of information stored on a disk, each physical \ndisk is divided into three areas for a BIOS file system, as shown in  Figure 3.3 :  \n \ufffd a  reserved area, where the OS executable is placed (also called the  disk boot \narea ) \n \ufffd the  file directory area containing entries with information about each file stored \non disk \nelm49810_ch03_045-066.indd   55\nelm49810_ch03_045-066.indd   55\n12/22/08   12:58:32 PM\n12/22/08   12:58:32 PM\n",
        "category": "Category"
    },
    {
        "id": "87",
        "title": "Title for Chunk 87",
        "content": "Rev. Confirming Pages\n56 \nPart 2 Building Operating Systems Incrementally: A Breadth-Oriented Spiral Approach\nDisk Boot Area\nFile Directory Area\nData Storage Area\nTrack 0\nTrack 76\nFIGURE 3.3 \nTypical CP/M file \nsystem layout.\n \ufffd the  data storage area for data and program files, which occupies the remainder \nof the disk and is the largest part of the disk. \n The BIOS has a built-in table that gives the size of each of these areas. We now dis-\ncuss the contents of each of these areas in more detail. \n Disk boot area \n The simplest part of the file system is this reserved area, which holds the OS binary \nfor booting the PC. This area is not visible from the file system\u2014it has no directory \nentry and no name. The loadable image of the BIOS, BDOS, and CCP are written \nin this area, sector-by-sector, track-by-track, starting at track 0, sector 1. These are \nnot part of any \u201cfile.\u201d They simply occupy the first few tracks of a disk. The BIOS is \nusually 2 KB, the BDOS is 3.5 KB, and the CCP is 2 KB, so together the OS binaries \noccupy the first three tracks. \n When the computer is turned on or rebooted a small program in ROM is run that \ncopies the OS executable image from disk to memory and then starts executing this \nprogram\u2014the Operating System. This is called  booting or  OS loading. 8 \n File directory area \n The size of the directory area is fixed and is recorded in a table in the BIOS. For a \nfloppy disk the directory holds up to 64 entries of 32 bytes each.  9 A disk directory \nentry layout is shown in  Figure 3.4 . Each entry in a directory contains the following:  \n 1. A  user number. This is actually a group number from 0 to 15, which allows mul-\ntiple users or groups to share a disk and collect their files into a group. Notice \nthat there are actually no subdirectories\u2014all files are in one directory. Group \nnumbers provide an illusion of having single-level subdirectories. In effect these \nare virtual subdirectories. \n 2. A  file name and file type. These may be considered as one item, which is 1\u20138 \ncharacters of file name and 0\u20133 characters of file type\u2014often called  8.3 file \n8 In modern PCs, a similar booting is usually done from the hard disk rather than a floppy. The hard disk \nis usually preloaded with an OS by the PC manufacturer. \n9 For hard disks, it is of course much larger. \nelm49810_ch03_045-066.indd   56\nelm49810_ch03_045-066.indd   56\n12/22/08   12:58:32 PM\n12/22/08   12:58:32 PM\n",
        "category": "Category"
    },
    {
        "id": "88",
        "title": "Title for Chunk 88",
        "content": "Confirming Pages\n \nChapter 3 A Simple, Single-Process Operating System \n57\nUser Number - 1\nFile Name - 8\nFile Type - 3\nExtent Counter - 2\nReserved - 1\nNumber of records - 1\nAllocation - 16\nFIGURE 3.4 \nCP/M file directory \nentry.\nnames. If the actual file names are smaller than 8.3 they are padded with spaces. \nNot all characters are allowed in file names. A period is used to separate the file \nname and type (e.g., MYFILE.DOC) but is not stored in the directory, so using \nperiods or spaces is not allowed. While utility programs that come with the OS \ndo not allow illegal names, the OS calls that an application program uses to cre-\nate, open, or rename a file do not actually check the names, so an application can \ncreate files that may not be accessible to other programs. \n 3. An  extent counter. An extent is the portion of a file controlled by one directory \nentry. If a file takes up more blocks than can be pointed to by one directory entry \nit is given additional directory entries. The extent is set to zero for the first part \nof the file and then is sequentially numbered for each of the remaining parts of \nthe file. Large files will have multiple directory entries with the same file name \nbut different file extent numbers and a different group of allocation pointers in \neach entry. Since files may be deleted and their directory entries reused, the \nextents may not be in order in the directory. \n 4. The  number of records. This is actually the number of 128-byte records used in \nthis extent. If the count is 080x, this extent is full and there may be another one \non the disk. File lengths are rounded up to the nearest 128 bytes, so applications \nhad to know how much data was really in the last record. This lead to the con-\nvention of a Control-Z character to mark the end of a text file. \n 5. An  allocation map. This is a group of numbers of (or pointers to) the disk blocks \nthat contain the data for the file. There are eight pointers of 16 bits each. Each \nvalue points to a sector on the disk that contains part of the file. If the file is so \nsmall that it contains fewer than eight sectors, then the unused pointers are set to \nzero. If the file is too large and eight sectors are not enough to contain the file\u2019s \ndata, then an additional extent is allocated and another directory entry filled in. \nOn some systems there were 16 pointers of eight bytes each. Such inconsisten-\ncies were one of the main problems that restricted the growth of CP/M. \n Data storage area \n The data storage area contains the data blocks for the files. For the system to \naccess a file, the user or application program would provide the file name and the \nelm49810_ch03_045-066.indd   57\nelm49810_ch03_045-066.indd   57\n12/11/08   7:01:44 PM\n12/11/08   7:01:44 PM\n",
        "category": "Category"
    },
    {
        "id": "89",
        "title": "Title for Chunk 89",
        "content": "Rev. Confirming Pages\n58 \nPart 2 Building Operating Systems Incrementally: A Breadth-Oriented Spiral Approach\nfile system would search the disk directory to determine if a file with that name \nwas stored on the disk. If the file name was found, the directory entry would have \nthe addresses of the sectors where the file was stored, so the file data could be \naccessed. \n Note: Actually, the disk structure is just a bit more complicated. If you count \nup the total number of file pointers as described above, in all files, 64 (directory \nentries)  *  8 (file pointers per entry) gives 512 sectors, but there are more sectors \n(77  * 26  \ufffd 2002) on a floppy disk! This would not allow one to use most of the \nfloppy space. So, in reality, rather than pointing to an individual sector, sectors are \ngrouped together into  allocation blocks, which are consecutive sectors grouped \ntogether. The size of these allocation blocks is determined by the size of the disk, but \nin typical early floppies it is eight sectors, or 1024 bytes. So in reality each directory \nentry points to up to eight allocation blocks of 1024 bytes each. \n Here are a few observations about and limitations of this file system structure:\n \ufffd There are no dates or times in the directory. \n \ufffd There is no explicit file size entry, so the file size must be calculated roughly \nfrom the number of pointers in its directory entry and possible extents. \n \ufffd There is only a single directory with no subdirectories, but group numbers give \nthe illusion of a one-level subdirectory. \n \ufffd A file must be stored entirely on one disk. \n \ufffd If the directory is full, so is the disk. The directory is a fixed size, so only 64 files \nor fewer can be stored on a floppy disk. \n An Observation: One of the biggest complaints against CP/M was the 8.3 file names, \nsomething that should have been relatively easy to fix. Directory entries, where \nfile names are stored, are 32 bytes long. They could have easily been lengthened to \n48- or 64-byte directory entries, allowing 23.3 or even 40.3 names. But the original \ndesign was simple, and the designer did not want to use too much disk space for the \ndirectory. The design compromise was made to minimize the disk space (and mem-\nory space) for each directory entry. This was particularly important for floppy disks \nwhere the file contents and directory entries together were a few hundred kilobytes. \n 3.5 PROCESS AND MEMORY MANAGEMENT \n In the more complex OSs that we will study later, the topics of process and memory \nmanagement are covered first since processes correspond to what a user wants to get \ndone, so they are of primary importance. But in this simple OS, process manage-\nment and memory management are rather limited, since only one program at a time \nis executing. And the issues of hardware abstraction and file systems were therefore \nmore significant. \n Still, even with this limited functionality, there are several process and memory \nissues that the OS must handle. First, we discuss the typical flow during program \nexecution. Then we discuss command processing. Finally, we discuss memory man-\nagement and an overlay technique that can be used when the program to be created \nis larger than the main memory space available. \nelm49810_ch03_045-066.indd   58\nelm49810_ch03_045-066.indd   58\n12/22/08   12:58:33 PM\n12/22/08   12:58:33 PM\n",
        "category": "Category"
    },
    {
        "id": "90",
        "title": "Title for Chunk 90",
        "content": "Confirming Pages\n \nChapter 3 A Simple, Single-Process Operating System \n59\n 3.5.1 Creating and executing an application program \n An application program is usually written by typing the program language instruc-\ntions into a text editor. It is then compiled or assembled (or both) and finally linked \ntogether with library routines using a link editor. This results in a  program image \nfile that is ready to be loaded into memory and run. The program image has been \ngiven many names, for example  program executable,  program binary, or  run-\nnable program. After a few rounds of debugging this program is ready for use. \n In order for a program to begin running, its executable binary code file must be \nloaded into memory. This loading process is usually done by the CCP. The CCP is \nitself an application program that provides a few  built-in functions \u2014for example, \nthe \u201cDIR\u201d command gives a directory listing of all files, and the \u201cERA\u201d command \nerases a file or a group of files. CCP accomplishes its work by making only BDOS \ncalls\u2014it never calls the BIOS or hardware directly. This makes the BDOS more \neasily portable to a new hardware system. When a name is entered to the CCP, it \nfirst looks to see if it is the name of a built-in command. If so, then that command is \nexecuted. If the name is not that of a built-in command, then the CCP tries to find an \nexecutable program file on the disk with that name. If one exists, then the contents of \nthat file are loaded into memory and the program starts running. There was a special \ncode in the program header that would identify the file as being an executable pro-\ngram. Alternatively the command the user entered might name a text file that was a \nstring of commands that the CCP should read and execute one at a time. These were \ncalled  subfiles in CP/M after the standard extension \u201c.sub,\u201d which was the second \npart of the file name. Command files of this sort are commonly known as  scripts or \n batch files. \n In CP/M, normal application programs are always loaded into RAM beginning \nat address 0100 Hex. Having a fixed load address for all programs makes it easy for \ncompilers and linkers to create executables, since the program starting address will \nbe known in advance. \n Programs typically need additional memory for static data\u2014for example, \npredefined fixed-size data such as static strings. In addition, a stack is needed for \ndynamic data\u2014for example, temporary variables. The predefined static data are \nloaded into memory following the loading of the program binary file. Additional \nmemory following static data is reserved for other data.  Figure 3.5  illustrates the \ngeneral memory map for the various parts of an executing program. \n The stack is initially placed at the highest location in memory that is just below \nthe OS code. The stack grows in memory toward lower memory addresses (see \n Figure 3.5 ). After loading is complete, the OS calls the first instruction of the pro-\ngram as though it were calling a subroutine. The program executes until it has fin-\nished its work, at which time control simply returns to the CCP program that loaded \nit. The CCP might still be in memory, but if it is not then it is simply reloaded from \nthe disk. As a program executes it may use all available memory anytime it wants to \nexcept for reserved memory containing the OS or parts of the OS. \n The process executes from start to finish. If it requires I/O, the CPU will remain \nidle until the required I/O is completed. For example, the process may wait for user \ninput from the keyboard. For large programs that do not fit entirely in memory, the \nelm49810_ch03_045-066.indd   59\nelm49810_ch03_045-066.indd   59\n12/11/08   7:01:53 PM\n12/11/08   7:01:53 PM\n",
        "category": "Category"
    },
    {
        "id": "91",
        "title": "Title for Chunk 91",
        "content": "Confirming Pages\n60 \nPart 2 Building Operating Systems Incrementally: A Breadth-Oriented Spiral Approach\nprogram code is typically divided into several segments that are brought into  memory \nseparately. When one segment calls a function whose code is not in memory, a tech-\nnique called memory overlay is used to bring in the new code segment in place of \nthe other code segment currently in memory. Implementing overlays was left up to \nthe application program, though it usually had some assistance from the application \nlibraries. We discuss this technique further in  Section 3.5.3 .  \n 3.5.2 Command processing via the CCP \n In our simple OS the CCP is a program pretty much like any other. The CCP is per-\nhaps better structured than some programs since it only uses OS system calls and \nnever bypasses the OS. In other OSs, the component similar to the CCP is sometimes \ncalled a  shell or  command interpreter. A user can directly invoke CCP commands \nby typing a CCP command or the name of an executable program file. Still another \nname for this kind of command interpreter is  command line interface, since each \ncommand is entered on a screen line and is submitted to the command interpreter \nwhen the user presses the <carriage return> or <enter> key. The CCP was linked to \nload in high memory just under the BDOS. When a program was finished running, it \nwould exit by returning control to the BDOS, which would check to see if the CCP \nwas still intact in the memory. If it was, then the BDOS would return control to the \nCCP without reloading it. \n Many users prefer additional functions or a different \u201clook and feel,\u201d menus \nor graphics, for instance. It was fairly common to replace the CCP with a shell \nmore suited to a one\u2019s likes. In many OSs one has a choice of several different \nshells. Writing a command processor or shell is a fun exercise. But like many \nprograms, as you and others use it, it will need new and more complex func-\ntions added, such as recalling past commands or the ability to chain commands \ntogether.  \nInterrupt Vector\nLow memory\nHigh memory\nProgram Header\nProgram Executable\nFixed Data\n(Heap)\nProgram Stack\nBDOS\nFIGURE 3.5 \nTypical memory \ncontents when \nexecuting \na program.\nelm49810_ch03_045-066.indd   60\nelm49810_ch03_045-066.indd   60\n12/11/08   7:01:53 PM\n12/11/08   7:01:53 PM\n",
        "category": "Category"
    },
    {
        "id": "92",
        "title": "Title for Chunk 92",
        "content": "Confirming Pages\n \nChapter 3 A Simple, Single-Process Operating System \n61\n 3.5.3 Memory management \n As we discussed in  Section 3.5.1 , the basic handling of memory by the CP/M OS is \nquite simple. All programs are loaded at a fixed address in memory. Programs are \ndivided into two parts: (1) the program executable code and (2) fixed (static) data\u2014\nsuch as constant values in the program, character strings, and so forth. \n The software that copies these two parts into memory from disk is called a \n loader, and is a part of the CCP command processor. A program also needs some \n stack space to store temporary variables, pass parameters to called subroutines, and \nreturn data from those routines. The stack was placed at the highest location in mem-\nory, immediately below the OS itself. This allowed the stack to \u201cgrow\u201d downward in \nmemory and not \u201ccollide\u201d with the program data\u2014unless no more memory is avail-\nable.  Figure 3.5 illustrates this memory structure. \n But CP/M had no provision for detecting a collision between the stack and fixed \ndata. Such an occurrence would usually either crash the program or produce strange \nresults because the CPU had no memory management registers for memory protec-\ntion. Such memory overwriting bugs were difficult to find and fix and occurred fre-\nquently on CP/M systems. \n For programs written in some high-level programming languages\u2014for instance, \nPascal or C\u2014there is a large pool of memory that can be dynamically allocated and \nreturned called the  heap. The heap was set aside by the loader, but managed by rou-\ntines in the high-level language runtime libraries. Not all programs used a heap. If \nthere was one, it would be located in memory between the fixed data and the stack. \n A  program header was located in memory immediately preceding the exe-\ncutable binary code. The program header contained pointers to memory addresses \nwhere the stack is located and where the fixed data is located. It also contained a \npointer to strings passed as parameters to the program when the user typed the com-\nmand and supplied arguments to the program. For example, if a user entered a com-\nmand to run a text editor, the command line would probably also include the name \nof the file to be edited. \n Why was the OS located in the highest part of memory rather than in low mem-\nory? Because CP/M systems did not all have the same amount of memory. Some \ncomputers might have 32 KB of memory, others 48 or 64 KB. So the operating \nsystem would be generated (configured) to occupy the highest locations in mem-\nory, leaving a fixed address\u2014always 100 Hex\u2014to load programs. If the OS became \nlarger it would start at a lower address in memory, but not force any program to \nchange addresses, although a user program would have less memory remaining in \nwhich to run. This meant that when the OS was upgraded to a new version it was not \nnecessary to relink all the application programs. \n 3.5.4 Overlays \n The maximum size of memory in a CP/M system was constrained by the amount of \nmemory that the CPU could address. Initially, this was 64 KB but some later versions \nof the CPU allowed more memory and some computers had additional hardware \nadded to provide \u201cbanks\u201d of memory that could be mapped into memory spaces by \nprogram control. What happened if a program would not fit in the available space? \nThis problem had been an issue since the earliest days of computers. \nelm49810_ch03_045-066.indd   61\nelm49810_ch03_045-066.indd   61\n12/11/08   7:01:54 PM\n12/11/08   7:01:54 PM\n",
        "category": "Category"
    },
    {
        "id": "93",
        "title": "Title for Chunk 93",
        "content": "Confirming Pages\n62 \nPart 2 Building Operating Systems Incrementally: A Breadth-Oriented Spiral Approach\n Of course, programs that manipulated large amounts of data could keep some \nof the data on disk, rather than in memory, bringing in only what was needed at a \ngiven time. But what could be done about programs whose binary code was large? \nThose programs could similarly bring in only those parts of the program needed for \nsome part of the processing. These parts or programs would \u201coverlay\u201d each other \nin the same locations in memory and were called  overlays. Programs that had large \namounts of code would be divided into a main part of the program and other pro-\ngram sections. The main part of the program would always reside in memory. Those \nsections of the program that were only needed sometimes would be brought into \nmemory as overlays that replaced other sections. Typical candidates for overlays \nwere some large computations or error-handling routines. \n The programmer would have to identify those parts of the program that should \nbe grouped together into an overlay. When designing overlays, it is important to avoid \none overlay calling into a different overlay that would take the place of the first one \nin memory. The actual loading of overlays was done by the programming language \nruntime library, which used CP/M system calls to load an overlay. The program-\nmer would indicate to the compiler which parts of a program\u2014which functions and \nprocedures\u2014would be in each overlay, and the compiler produced the loadable over-\nlay code.  Figure 3.6  illustrates these concepts. Here, a program has one main part and \nthree overlays. Only one of the overlays would be in memory at any particular time.  \n An example of a program that might use overlays is an assembler. The source \nprogram is typically read twice. During the first pass the assembler is building a \nsymbol table and allocating space for both code and data. Then the source program \nis reread and the actual code generation takes place. Now the assembler has suf-\nficient information to generate the instructions and fill in the addresses they refer-\nence. Clearly these two passes over the source program do not reference one another \ndirectly and can thus overlay one another. In this case there are often at least two other \nLow memory\nInterrupt Vector\nProgram Header\nMain Program Executable\nFixed Data\n(Heap)\nProgram Stack\nBDOS\nOverlay\n1\nOverlay\n2\nOverlay\n3\nHigh memory\nFIGURE 3.6 \nOverlays in memory \nwhen executing \na program.\nelm49810_ch03_045-066.indd   62\nelm49810_ch03_045-066.indd   62\n12/11/08   7:01:55 PM\n12/11/08   7:01:55 PM\n",
        "category": "Category"
    },
    {
        "id": "94",
        "title": "Title for Chunk 94",
        "content": "Confirming Pages\n \nChapter 3 A Simple, Single-Process Operating System \n63\npossible overlays. One would be an initialization phase that takes in the user control \noptions, opens the input file, allocates the symbol table, and so on. A second might \nbe providing additional printed output about the file such as a listing of the generated \ncode with the user comments. While that full assembler might run in a large machine \nwithout overlays, smaller machines might not be able to run it. In addition, the size of \nthe source program that can be handled is limited by the storage space for the symbol \ntable, so that an overlaid assembler can handle much larger programs.  \n 3.5.5 Processes and basic multitasking \n Even in early systems with limited memory and slow processors, users wanted to do \nsome work in parallel. One very common request was the ability to print a file in a \n background process while editing (or playing a game) in a  foreground process. \nThis processing of printing while allowing another foreground program to run was \na very widely requested feature. Printers were slow, and starting a print job and then \nleaving your computer printing and walking away for 30 minutes or an hour was \nvery boring, and wasteful of a most valuable resource\u2014a person\u2019s time. This was \nespecially true if something went wrong and the user returned 30 minutes later to \nfind that the printer was waiting for user attention. \n CP/M\u2019s solution was a background printing process. A small program was \nloaded into memory at the highest location of memory, immediately below the OS. \nThis program initialized itself and then returned control to the CCP, allowing another \nprogram to run. When a user wanted to print in the background, the name of the file \nto print was passed to the background print handler. This would print a little bit of \nthe file\u2014a line or two\u2014whenever it got control. The background process would \ntypically get control any time a foreground process did a system call, or possibly by \nsetting a timer and causing an interrupt of the foreground process. \n Background printing gave the appearance of the computer doing two things at \nonce, something called multitasking. The background print handler would allow only \nprinting in the background, and nothing else. Users liked the idea of doing work in \nparallel, especially input and output that was very slow, like printing on early print-\ners. We will see that all newer OSs, even those on very small devices, have some sort \nof multitasking facility. \n 3.6 SUMMARY \n In this chapter, we presented the typical components \nof a simple OS with limited capability. We based our \npresentation on the features of an early personal com-\nputer operating system, CP/M, and the basic hard-\nware of early PC systems. We started by describing \nthe predecessors of simple operating systems, called \nmonitors, and discussed how they evolved into early \noperating systems because of the need for standard-\nization. We then described the characteristics of the \nearly PC systems for which this type of OS was \nused. Next, we discussed how input/output was man-\naged in such an early OS. We saw that application \nprograms often ignored the use of standardized I/O \nfunctions provided by the OS to achieve better per-\nformance and more flexibility. \n We then continued with a description of the file \nsystem in such a simple OS, and the standard disk \ndevices that the file system was based on. We then \nelm49810_ch03_045-066.indd   63\nelm49810_ch03_045-066.indd   63\n12/11/08   7:01:55 PM\n12/11/08   7:01:55 PM\n",
        "category": "Category"
    },
    {
        "id": "95",
        "title": "Title for Chunk 95",
        "content": "Confirming Pages\n64 \nPart 2 Building Operating Systems Incrementally: A Breadth-Oriented Spiral Approach\nmoved on to discuss process and memory manage-\nment. We saw that a program binary was always \nloaded starting at a fixed predefined memory location \nbecause only one program was in memory at a time. \nOther parts of memory stored the OS binaries and fixed \nprogram data. A stack area was reserved for storing \ndynamic data. We discussed the techniques of overlays \nfor large programs that could not fit in memory. Over-\nlays allowed programmers to divide a program into \nsections that would replace one another in memory \nwhen needed. Finally, we discussed an early example \nof multitasking\u2014that of background printing.  \n BIBLIOGRAPHY \n Barbier, K.,  CP/M Solutions. Englewood Cliffs, NJ: \nPrentice-Hall, 1985. \n Barbier, K.,  CP/M Techniques. Englewood Cliffs, NJ: \nPrentice-Hall, 1984. \n Cortesi, D. E.,  Inside CP/M: A Guide for Users and \nProgrammers with CP/M-86 and MP/M2.  \nAustin, TX: Holt, Rinehart and Winston, 1982.  \n Dwyer, T. A., and M. Critchfield,  CP/M and the Personal \nComputer. Reading, MA: Addison-Wesley, 1983. \n WEB RESOURCES \n http://www.digitalresearch.biz/ (the creators of CP/M) \n http://www.seasip.demon.co.uk/Cpm/ (outsider archive site) \n http://www.osdata.com (Operating System technical \ncomparison) \n http://www.pcworld.com/article/id,18693-page,\n3-c,harddrives/article.html (hard disk characteristics) \n REVIEW QUESTIONS \n \n3.1 What kinds of limited functions did early PC \nmonitor programs provide? \n \n3.2 What kind of error checking was done on the argu-\nments to the calls to the monitor program? What \nwas the likely result? \n \n3.3 In the PC era there were a multitude of small \nstartup hardware vendors and all of their users \nwere clamoring for software. What was the char-\nacteristic of early monitors in this environment \nthat led to the development of a real OS? \n \n3.4 What was the overriding characteristic of the \nhardware systems that CP/M and MS-DOS were \ndesigned to run on and what were some of the \ndesign decisions that were made as a result? \n \n3.5 The basic I/O needs of early programs were fairly \nmodest. Some applications, however, had some-\nwhat more complex needs. In many cases the \nfunctions provided by the monitor were much \nslower than equivalent functions that were in the \nBIOS code. What did the application program-\nmers do when the functions the OS provided \nhid the  functions that the application needed or \nwere so slow that the performance of the appli-\ncation was unacceptable? What problems did that \ncause?  \n \n3.6 Besides the keyboard and video, what was the \nother major I/O system that was very important in \nthe early OSs? \n \n3.7 To the command interpreter, most of the com-\nmands that a user types are executed by finding a \nprogram on the disk with that name and running it. \nA few commands are not mapped to programs on \nthe disk. Where do they reside? \n \n3.8 On a floppy disk (or a hard disk) the heads on all \nof the surfaces will be in the same relative position \nover the surfaces measured in from the outside \nof the disk. As the disk rotates a certain portion \nof a surface will pass under each head. What is \nthat portion of the surface called? That portion is \ndivided up into smaller pieces. Those pieces are \nthe smallest addressable portion of the disk. What \nare these pieces called? \nelm49810_ch03_045-066.indd   64\nelm49810_ch03_045-066.indd   64\n12/11/08   7:01:55 PM\n12/11/08   7:01:55 PM\n",
        "category": "Category"
    },
    {
        "id": "96",
        "title": "Title for Chunk 96",
        "content": "Confirming Pages\n \nChapter 3 A Simple, Single-Process Operating System \n65\n \n3.9 CP/M divided the contents of a floppy disk into \nthree parts. What were these three parts? \n 3.10 Why does the CP/M OS reside in high memory \ninstead of low memory? \n 3.11 True or false? Overlays are an obsolete technique \nused when system memories were very small and \nare no longer used in modern systems.  \n 3.12 While CP/M did not allow true application mul-\ntiprocessing, it did allow one sort of background \nprocessing. What was that?     \nelm49810_ch03_045-066.indd   65\nelm49810_ch03_045-066.indd   65\n12/11/08   7:01:56 PM\n12/11/08   7:01:56 PM\n",
        "category": "Category"
    },
    {
        "id": "97",
        "title": "Title for Chunk 97",
        "content": "elm49810_ch03_045-066.indd   66\nelm49810_ch03_045-066.indd   66\n12/11/08   7:01:56 PM\n12/11/08   7:01:56 PM\n",
        "category": "Category"
    },
    {
        "id": "98",
        "title": "Title for Chunk 98",
        "content": "Rev. Confirming Pages\n331\n Chapter \n Chapter \n Introduction \nto Computer Networks \n In this chapter: \n 15.1 Why Do We Want to Network Computers? 332 \n 15.2 The Basics 333 \n 15.3 Application Layer Protocols 338 \n 15.4 TCP/IP 341 \n 15.5 The Data Link Layer 345 \n 15.6 WANs 350 \n 15.7 The Physical Layer 352 \n 15.8 Network Management 354 \n 15.9 Summary 356  \n W\ne study operating systems because we cannot write large high-\nperformance applications without a sound understanding of the functions \nand mechanisms of an operating system. It is fair to say that today we \nstudy networks for the same reason\u2014it is rare that a large application is written \ntoday that does not make some use of networking technology. What was true of \noperating systems in general is also true of networks. If we do not have a sound \nunderstanding of the basics of networking we cannot build and deploy large distrib-\nuted application systems. \n This chapter starts with a brief introduction to explain some of the many reasons \nwhy we want to have computers connected in a network. In  Section 15.2  we pre-\nsent a layered model of network functionality, which is traditionally used in discuss-\ning computer networking.  Section 15.3  describes some typical protocols used in the \napplication layer. Then in  Section 15.4 , we discuss the TCP/IP protocols as examples \nof the transport and network layers. In  Section 15.5 we present the topic of the Data \nLink layer in LANs as typified by Ethernet. We give an overview of WAN data link \ntechnology in  Section 15.6 .  Section 15.7  covers the technologies used in the Physical \nlayer.  Section 15.8 is a brief introduction to the topic of network management. We \nconclude with a chapter summary in Section 15.9. \n 15 \n 15 \nelm49810_ch15_329-358.indd   331\nelm49810_ch15_329-358.indd   331\n12/22/08   1:11:00 PM\n12/22/08   1:11:00 PM\n",
        "category": "Category"
    },
    {
        "id": "99",
        "title": "Title for Chunk 99",
        "content": "Confirming Pages\n332 \nPart 5 Networks, Distributed Systems, and Security\n 15.1 WHY DO WE WANT TO NETWORK COMPUTERS? \n At a more detailed level there are several reasons why we might want to build an appli-\ncation that was distributed across a network. As computer systems were maturing the \ninitial reason we wanted to use networks had to do with sharing access to expensive \nresources. At first, that resource was a mainframe computer and we accessed the \ncomputer with simple terminals rather than through a personal computer. We were \naccessing data that was on the mainframe and programs that ran there. Later, as local \narea networks began to become common, we started using them to access other shared \ndevices\u2014a departmental file server, an expensive laser printer, a pool of modems, \nand attached communication lines. These resources were too expensive to provide to \neach user, and were typically not used full time. Therefore, making them accessible \nthrough a network spread the cost over many users. A shared resource might not be as \neasy to use as a local one, but the price more than made up for that. Another specific \ninstance of sharing an expensive device is backing up individual systems to a single \nmachine that had a tertiary storage device attached\u2014probably a tape drive. \n As networks became more common it became apparent that there were some \nspecial things that could be done with them. One of these special things was building \na system by combining several smaller machines in a redundant configuration so that \nif one of the machines was lost, the system would continue to function, even if in a \ndegraded manner. \n Sometimes we will distribute the computation of a process across multiple \nmachines to speed up the computation. We divide the processing into smaller parts \nthat can be handled by individual machines. In a similar way, it is possible to config-\nure multiple smaller machines into a system in such a way that additional machines \ncan be added as the scale of the application grows. For example, this allows a com-\npany to start a website with a single machine and if the site is successful to add \nadditional systems as the demand grows. Related to aggregating systems for speed \nimprovement is the factor of cost. In some cases there are applications that simply \ncould not be done at all with a single large system because of the mass of data and \nprocessing involved. Or in some cases a single large computer could do the job, but \nis not usable because of the cost. But systems can be designed using many smaller \nprocessors. Probably the first example of such a system is the SETI project. This \nproject collects large amounts of radio telescope data and sends it out through the \nInternet to users who voluntarily process the data with a \u201cscreen saver\u201d application \nthat normally runs only in the background. The application is looking for signals \nthat might represent intelligent life on another planet. Today, there are millions of \nregistered users of the SETI screen saver. Viewed as a single, loosely coupled system \noperating in parallel on multiple streams of data, this is the fastest supercomputer in \nthe world. There is no way that a nonprofit organization could afford to buy a single \nsystem that would have that much processing power, so without this technique they \nliterally would not ever get the job done. SETI was the first such system, but today \nthere are many other systems processing data doing research in cryptography, DNA, \nmathematics, gravity waves, and other scientific projects. We will visit this topic \nagain in the next chapter on distributed systems. \nelm49810_ch15_329-358.indd   332\nelm49810_ch15_329-358.indd   332\n12/18/08   12:28:43 PM\n12/18/08   12:28:43 PM\n",
        "category": "Category"
    },
    {
        "id": "100",
        "title": "Title for Chunk 100",
        "content": "Confirming Pages\n \nChapter 15 Introduction to Computer Networks \n333\n After the great growth of the Internet in the last few years it has become clear \nthat the most profound impact of networking lies in increased access to information. \nThe relatively quick response time of the Internet has made practical the exchange \nof information in ways that were not economical before. An example is the idea of \n \u201ctelecommuting\u201d\u2014working from home. Many jobs require frequent, ongoing interac-\ntion between employees. To some extent this interaction can be closely approximated \nby email. Even closer interaction is available with instant messaging software\u2014\nan interactive \u201cchat\u201d facility. In other cases this interaction might require voice com-\nmunication, a \u201cshared whiteboard,\u201d or even videoconferencing. All of these can be \ndone today through the Internet, provided enough bandwidth is available at a low \nprice, and may enable more of us to work from a home office rather than commute to \na central office, at least on a part-time basis. Thus, networking may contribute to the \nsolution of some societal problems by lessening the consumption of resources (and \nthe resultant pollution) necessary for commuting. \n Other instances of sharing information over the Internet also exist. It may be \npossible for us to collaborate on a project with other persons who live in distant parts \nof the world. For example, consider those people who work together to create the \nlibraries of utilities that make the Linux OS a complete system rather than just an \ninteresting example of a kernel. It is probable that most of those people have never \nmet in person. Most of them work together only through the Internet. \n On a less intense scale, think about the average user of the Internet. Most of \nus now use email daily and frequently employ the resources of the Web to answer \nquestions, find people, buy products, download software updates, do our personal \nbanking and other financial transactions, and so on. Such uses would not be possible \nwithout the Internet. It initially existed largely for other reasons, but information \nsharing was always a primary feature. We suggest that in the future it will be likely \nthat the majority of the applications you might work on will be running in multiple \nparts on multiple hosts, and you will not be able to design sound applications with-\nout some understanding of networks and how they are used by operating systems. \n 15.2 THE BASICS \n 15.2.1 Models \n In order to study and implement networks, models have traditionally been created \nthat divided the subject into smaller topics by considering them as layers of soft-\nware. In these models each lower layer provides some set of services to the next \nhigher layers. While there is generally pretty good agreement about what functions \nare performed in what layers, the models are not perfect and they are not always fol-\nlowed exactly. As a result, functions are sometimes found in more than one layer. For \nexample, we can find security functions available in almost every layer. In addition, \nin some cases it is useful to take a lower-level layer network protocol and run it as \na layer on top of another higher-level protocol. In these cases the layer models can \nbecome quite confusing. These models are still quite useful in organizing our think-\ning and a large part of the literature about networking is structured around them, so \nelm49810_ch15_329-358.indd   333\nelm49810_ch15_329-358.indd   333\n12/18/08   12:28:43 PM\n12/18/08   12:28:43 PM\n",
        "category": "Category"
    },
    {
        "id": "101",
        "title": "Title for Chunk 101",
        "content": "Confirming Pages\n334 \nPart 5 Networks, Distributed Systems, and Security\nwe discuss them briefly. Furthermore, OS software is often modularized along the \nlines of these layers. \n The most widely known network layer model is called the  OSI model, shown \nin  Figure 15.1 . It was developed by the International Standards Organization, or \nISO. It was an abstract design that did not reflect any existing protocol, though a \nset of protocols was later designed around this model. At one point the U.S. Gov-\nernment even mandated the implementation of the protocol on all computer sys-\ntems purchased by the government under the umbrella term \u201cGOSSIP.\u201d However, \nthat effort never was very successful and was eventually abandoned. As an abstract \nmodel the OSI model has some problems, the most notable being that it has two \nlayers that are almost never implemented as such, the Session layer and the Presen-\ntation layer. \n In response to the OSI model, another model was constructed as a description \nof the TCP/IP protocol suite, which already existed. This model focused heavily on \nthe upper layers (TCP and IP, for the most part) and pretty much ignored the lower \nlayers, apparently assuming that the hardware and drivers were merely commodities \nand that one just ordered them from a vendor. \n In this chapter we use a common hybrid model that is roughly the bottom two \nlayers of the OSI model and the top three layers of the TCP/IP model. This model is \nshown in  Figure 15.2 . The  Physical layer defines the actual medium used for com-\nmunicating and the techniques for getting the information on and off of the medium. \nThe medium might be a metal wire or cable, an optical fiber or an electromagnetic \nsignal. The  Data Link layer is responsible for accessing the shared medium. It is \nconcerned with packaging information in discrete packets and arbitrating access to \nthe network media. Today, Data Link layer devices called bridges (or switches) are \nused for connecting devices as though each pair of devices were directly connected, \nso the function of media access arbitration is largely unused and growing more so. \nThe  Network layer is responsible for routing the information through a complex \ninternet composed of multiple networks, often of differing Physical layer technolo-\ngies. The  Transport layer is responsible for creating a reliable connection between \ntwo network entities, though not all applications require either a connection or a \nguarantee of reliability. Finally, the  Application layer consists of a process in one \nhost exchanging data with a process in (usually) a different host. \n In a device attached to the network there will be an entity at each layer that is \nresponsible for the functions of that layer in that device. At the Physical layer this \nentity will be in hardware. Some functions at the Data Link layer may be in hardware \nas well. For most devices, the entities at the other layers are all software. Each entity \nrelies on the entity in the layer below it to provide services to it through an API. In \nturn, each entity provides services to the layer above it. As a packet in a sending \ndevice travels down the layers from one entity to the next, each entity will add a \nsmall block of information to the front of the packet. This block is called a header. \nFor example, a data packet might have an application header, a TCP header, an IP \nheader, an Ethernet header, and a Physical layer header. As the packet flows up the \nstack in a receiving device each entity strips off the header for its layer and hands the \npacket to the next higher layer. These headers carry a dialog between the correspond-\ning entities in the sending and receiving devices. \n7 - Application\n6 - Presentation\n5 - Session\n4 - Transport\n3 - Network\n2 - Data Link\n1 - Physical\nFIGURE 15.1 \nThe OSI network \nlayer model.\nFIGURE 15.2 \nA practical network \nlayer model.\n5 - Application\n4 - Transport\n3 - Network\n2 - Data Link\n1 - Physical\nelm49810_ch15_329-358.indd   334\nelm49810_ch15_329-358.indd   334\n12/18/08   12:28:43 PM\n12/18/08   12:28:43 PM\n",
        "category": "Category"
    },
    {
        "id": "102",
        "title": "Title for Chunk 102",
        "content": "Confirming Pages\n \nChapter 15 Introduction to Computer Networks \n335\n This division of networking technology into layers has both good and bad \naspects. On the good side, small modules are easier to understand, develop, and \ndebug. They can be replaced with newer equivalent modules if improved versions \nare developed. Different organizations can specialize in different layers and develop \nbetter algorithms and implementations. On the other hand, it is extremely important \nthat we have very good definitions of the interfaces between the layers and the dialog \nbetween the entities in the sending and receiving hosts. As a result, there are many \ndifferent sources of standards. In some cases we have  de facto standards where one \nvendor comes up with a good idea and other vendors follow the lead or some organi-\nzation of vendors and users comes together and agree upon a standard. In other cases \nwe have  de jure standards, which technically have the force of law behind them. \nThese standards are set by professional, national, or international organizations such \nas the IEEE, ANSI, and the ISO. In the networking arena many standards were cre-\nated by members of the  Internet Engineering Task Force ( IETF ). Each of these \nstandards is known as a  Request for Comments ( RFC ). There is a website that \ncontains these documents at  http://www.ietf.org/rfc.html.  From time to time we refer \nto an RFC that defines some aspect of the Internet protocols. \n 15.2.2 LANs and WANs \n There are several different ways to view the variety of possible network technolo-\ngies. Each different view will shed some light on the differences among networks \nand their performance characteristics. The first major characteristic we want to \nconsider is topology\u2014what is the pattern of connections between the individual \nmachines? Part of the difficulty in understanding networks arises from the fact that \nthe physical topology of a network might be different from the logical topology of \nthe network. The first broad division of network topologies is between  local area \nnetworks ( LANs ) and  wide area networks ( WANs ). 1 , 2 Generally speaking, in \nWANs the network connections are point-to-point. That is to say that when two sys-\ntems are connected, the communication goes only between the two hosts and is not \nseen by any other host. The packets therefore do not need an address in them since \nthere is only one device to read them. Since there are no addresses, there is no way \nto send a  broadcast packet (one intended for all devices attached to the network) or \na  multicast packet (one intended for devices interested in one specific transmission \nstream). Frequently WAN links are  full duplex, meaning that both of the hosts can \ntransmit at the same time. In addition, since the link can be used in both directions at \n 1 Some networking texts also describe metropolitan area networks (MANs) as a different class, but the \ndistinction is not useful in this context. \n 2 Some authorities specify that the difference between LANs and WANs is a matter of geography\u2014\nLANs being small in area and WANs being spread over a wide area. Actually, geography makes \nvery little difference in the characteristics of connections. FDDI LANs can cover distances of over a \nhundred kilometers. Historically it was very common to find two modems sitting on top of one another \nconnecting two hosts through a WAN mechanism with a wire that was only a foot or two long because it \nwas the only interface that two systems had in common. This was technically a WAN connection but was \ncertainly not distributed geographically. \nelm49810_ch15_329-358.indd   335\nelm49810_ch15_329-358.indd   335\n12/18/08   12:28:44 PM\n12/18/08   12:28:44 PM\n",
        "category": "Category"
    },
    {
        "id": "103",
        "title": "Title for Chunk 103",
        "content": "Confirming Pages\n336 \nPart 5 Networks, Distributed Systems, and Security\nthe same time there is no need to arbitrate access to the media\u2014a host that is ready \nto transmit just does so.\n On the other hand, LANs traditionally are broadcast connections. When two \nhosts are communicating with one another on a LAN their communication is across \nsome medium that is shared among many devices. Devices communicating on a \nLAN therefore have to share access to the medium with all other devices connected \nto it. Since the packets must have addresses, it is possible to use special addresses \nlike a  broadcast or a  multicast. And finally, since many hosts share a single link, it \nis necessary for the hardware to control access to the media. \n Switching is a fairly new technology that has blurred the distinction between \nLANs and WANs. Individual devices are connected directly to ports on a network \nswitch using technologies such as Ethernet, which was originally used to connect \nthose devices to LANs. However, the switch reads the addresses in the packets and \nforwards them only to the port connecting to the correct device. Thus, the devices \nconnected to the switch do not share a medium as with previous shared access tech-\nnologies, so the connection can be full duplex and any device can transmit at the full \nspeed of the network as long as the switch can handle the traffic, and most of them \ncan handle all that can be sent their way. However, the packets still have to have \naddresses and both broadcasts and multicasts are still supported. \n 15.2.3 Topologies \n With both WAN and LAN networks there are multiple topologies by which many \ndevices can be connected. In WANs we can have hosts connected in pairs in any of \nthe following topologies:\n \ufffd Linear ( Figure 15.3 ) \n \ufffd Hierarchical ( Figure 15.4 , the top node is the focus point) \n \ufffd Star ( Figure 15.5 , the central node is the focus point) \n \ufffd Ring ( Figure 15.6 ) \n \ufffd Partly connected mesh ( Figure 15.7 ) \n \ufffd Fully connected mesh ( Figure 15.8 ) \nFIGURE 15.3 \nA linear topology.\nFIGURE 15.4 \nA hierarchical or tree \ntopology.\nelm49810_ch15_329-358.indd   336\nelm49810_ch15_329-358.indd   336\n12/18/08   12:28:44 PM\n12/18/08   12:28:44 PM\n",
        "category": "Category"
    },
    {
        "id": "104",
        "title": "Title for Chunk 104",
        "content": "Confirming Pages\n \nChapter 15 Introduction to Computer Networks \n337\n Each of these possible topologies has some distinct characteristics. First, let us \nconsider these topologies when used in a WAN. Each WAN connection between two \ndevices is relatively expensive, so the linear, star, and hierarchical topologies have \nthe lowest cost because they have the fewest connections. The linear topology has \nthe longest path to get information to all nodes, so communication to all devices in \nthe network can be somewhat slow. The hierarchical topology is used when all the \nnetwork devices are attempting to reach some centralized service. It was very typi-\ncal in the era of large mainframes. The ring and mesh topologies are progressively \nmore reliable (assuming that communication can go both ways on a ring) because \nthere is often a redundant path for communication. In particular, the loss of a single \nlink will not result in a loss of communication with any host in a ring topology. The \nfully connected mesh topology is the most expensive because it has so many links. \nIt is also the fastest because every node is only one link away from every other node \nand the most reliable because the loss of a link only means that the two nodes on the \nopposite sides of the broken link have to use one intermediate node to communicate. \nThe partially connected mesh is a compromise and is fairly typical. It is the topology \nused in the Internet. Networks with redundant pathways require more complex rout-\ning decisions for the packets at the Data Link or Network layers. \n In LANs the two most common forms are a linear bus and a ring. A linear bus \nlooks somewhat like the bus shown in  Figure 15.3 , but is actually connected as shown \nin  Figure 15.9 . In  Figure 15.3  each node had a connection to the next node, and for \na node on one end to communicate to a node on the other end the message had to be \nrelayed through each intermediate node. In a LAN that is a linear bus topology, the \nbus is a separate medium and every node is connected to it. In order for the two end \nnodes to communicate, they merely have to gain access to the medium and then they \ncan exchange their message directly. In a technical sense, a LAN in a ring topology \ndoes actually pass the message from host to host, but most of the hosts never process \nthe message. Such LANs act as though each node were connected to the ring much \nlike a linear bus, and when a device wants to send a message to another host it just \nwaits its turn and transmits the message on the ring. The receiving host will read the \nmessage and hosts that are not addressed by the message will merely pass it along. \n A sort of blending of these two technologies is also possible\u2014a physical linear \nbus in which the access to the medium is controlled by passing around a logical \ntoken as though the LAN were a ring. This is called a token passing bus. There were \ntwo instances of such protocols. One, ARCNET \u2122 , was once widely used for small \nnetworks but today is mostly confined to special applications such as inside of auto-\nmobiles. The other, 802.4, was primarily confined to a single industry, automobile \nmanufacturing, and is not under further development today. \nA bit of confusion can arise in determining the topology of LANs. A ring may \nbe physically connected to resemble a star, as shown in  Figure 15.10 . The box in \nthe center of the figure is a central connection point. The media appear to run from \neach node to a central point, but the central point is not a node and the signal actu-\nally passes from node to node in the manner of a ring.    3 Similarly, a linear bus can be \n3 The central hub may contain a node for purposes of management and data collection, but the node is \nnot a part of the hub function.\nFIGURE 15.5 \nA star topology.\nFIGURE 15.6 \nA ring topology.\nFIGURE 15.7 \nA partially connected \nmesh topology.\nFIGURE 15.8 \nA fully connected \nmesh topology.\nelm49810_ch15_329-358.indd   337\nelm49810_ch15_329-358.indd   337\n12/18/08   12:28:45 PM\n12/18/08   12:28:45 PM\n",
        "category": "Category"
    },
    {
        "id": "105",
        "title": "Title for Chunk 105",
        "content": "Confirming Pages\n338 \nPart 5 Networks, Distributed Systems, and Security\ncollapsed into a single concentrator, or hub, and appear to be a physical star or a phys-\nical hierarchical network, but the signals are broadcast throughout the network all at \none time, so the electrical connectivity is that of a bus, not a tree or a star, in the sense \nthat all the nodes will see the signal but will not have to relay it to another node.\n Today, most LANs are actually switched networks. Again, the network might \nlook like a star topology, but the central box is a high-speed switch that reads the \npackets sent by connected devices and sends them only to the device addressed. \nSwitches can typically forward all the traffic that can be sent to them on all ports at \none time. This is known as  wire speed. If the switch has many ports or the ports are \nhigh-speed ports, then this requires considerable bandwidth in the switch. We dis-\ncuss LANs and switches further in the section on the Data Link layer. \n 15.3 APPLICATION LAYER PROTOCOLS \n 15.3.1 The Application layer \n At each of the layers of the protocol stack, every network attached device will have \nsome entity that is interacting with a corresponding entity in another network device. \nIn the Application layer there is an entity in one end system that is interacting with \nanother application in another end application on a server system across a network. \nFor example, one might use a Telnet client on a PC to talk to a Telnet server on \na shared UNIX system. Each application will use a specific protocol, often one \ndesigned specifically for that application. Sometimes they will use a generic pro-\ntocol designed to serve a wide variety of custom applications. In this section we \nbriefly look at several Application layer protocols. Many of these Application layer \nprotocols are widely used and have been assigned a  port number for the server to \nuse. This port number is used by the next lower layer, the Transport layer, to deter-\nmine which application should receive an incoming message. Consider that a system \nrunning an FTP server may also be running other services such as Telnet, www, \nand so on. Messages arrive from the network at random, so each layer needs some \ninformation in the header that the sending entity applies to the packet to determine \nFIGURE 15.10 \nA LAN with a ring \ntopology.\nFIGURE 15.9 \nA linear bus topology.\nelm49810_ch15_329-358.indd   338\nelm49810_ch15_329-358.indd   338\n12/18/08   12:28:45 PM\n12/18/08   12:28:45 PM\n",
        "category": "Category"
    },
    {
        "id": "106",
        "title": "Title for Chunk 106",
        "content": "Confirming Pages\n \nChapter 15 Introduction to Computer Networks \n339\nwhich entity at the next higher layer should be given the incoming packet. For a \ngiven application the port number to be used may be a  well-known port number, \nthat is, one that was reserved by the IETF to be used only for that application. If it is \nnot a well-known number it may use a port number of 1024 or greater and less than \n49151. Numbers greater than 49151 are used for dynamic assignment to clients by \nthe OS software. \n Today most networking uses the TCP/IP protocol suite.  Figure 15.11  shows the \nformat of the header used by IP layer. It shows the source and destination port num-\nbers as well as other fields discussed in this chapter. \n 15.3.2 HTTP \n HTTP, or  HyperText Transfer Protocol is the protocol used to exchange messages \nbetween World Wide Web servers and browsers. The well-known port for Web serv-\ners is port 80. HTTP messages are sent in ASCII and as a result they can be easily \nread by a human, though they usually are not. Each message sent by a browser starts \nwith one of only a few commands, such as GET, PUT, POST, or OPTIONS. The \nserver sends back a response message. This message contains a code that gives the \nresult of the browser\u2019s input and returns a requested page element when it is applica-\nble. When a browser requests a page it makes a connection to the server and requests \nthe page with a  uniform resource locator ( URL ). The page referenced by the URL \nis returned by the server in its response message. Most pages contain much more \nthan a few lines of text, however. Usually, there will also be references to other items \nsuch as pictures to include with the page. Each of these contained elements must be \nseparately requested from the server. In early versions of HTTP the server would \nbreak the connection after each request for a single element, so the browsers would \noptionally open several connections at the same time if there were multiple elements \nto fetch to complete the page. Later versions of HTTP optionally do not break the \nconnection immediately, so that after the initial page is returned the browser can \nissue additional requests for many elements at the same time. \nFIGURE 15.11 \nTCP header format.\nelm49810_ch15_329-358.indd   339\nelm49810_ch15_329-358.indd   339\n12/18/08   12:28:45 PM\n12/18/08   12:28:45 PM\n",
        "category": "Category"
    },
    {
        "id": "107",
        "title": "Title for Chunk 107",
        "content": "Confirming Pages\n340 \nPart 5 Networks, Distributed Systems, and Security\n While HTTP was designed specifically for fetching Web pages from servers, it \nhas found other uses as well. Since access to the Web is so desirable, most institutions \nthat have implemented firewalls to protect their networks from harm allow HTTP mes-\nsages to pass through the firewall and freely admit connections to port 80. As a result, \nHTTP is often used in custom-distributed applications to minimize support problems. \n 15.3.3 FTP \n Another common Application layer protocol is  file transfer protocol, or  FTP. FTP is \nunusual in that it uses two ports instead of one. The main port, 20, is used for transfer-\nring data. Port 21 is also used by the FTP protocol, but only for sending control mes-\nsages. This design allows a large transfer to be interrupted, for example, by a user who \nsuddenly realizes that the very large file that is now being downloaded is not the file \nthat is needed after all. Another unusual aspect of FTP is that it is not only the name \nof the protocol, it is also the name of a program that uses the protocol. This program \nis a command-line utility and is somewhat difficult to learn to use well. One solution \nis to use stored scripts to run the program, but another common solution is to embed \nthe protocol in a more user-friendly application. Many GUI utility programs are avail-\nable for transferring files that incorporate the FTP protocol. Even most browsers are \ncapable of using the FTP protocol when the URL starts with ftp:// instead of http://. \n While the commands used by FTP are strictly ASCII messages, the files being \ntransferred might be programs, for example, and often contain binary data. They \nmight, therefore, contain strings that looked like FTP commands by accident. This \nis another reason why the data transfer uses a channel separate from the command \nchannel. FTP includes a BINARY setting so that it can transfer programs and other \nfiles containing arbitrary binary data. \n 15.3.4 SMTP/ POP/ IMAP \n SMTP is the  simple mail transfer protocol.  It is used in email applications to send \nemail from a user\u2019s email client program and also to forward email from one email \nserver to another. Interestingly, a different protocol is used by the email client to \nfetch email from the server. This protocol is usually  POP3 ( post office protocol \nversion 3 ) on port 110 or  IMAP ( interactive mail access protocol ) on port 143. \nPOP is an older protocol and is widely supported but not as flexible. IMAP is newer \nand more flexible but not as widely supported by email servers. \n All the mail transfer protocols use plain ASCII commands and were originally \ndesigned to transfer text messages only. ASCII is a 7-bit code and modern computers \ntypically use 8-bit bytes and ignore the extra bit. Some time ago it became clear that \nit was desirable to be able to attach all kinds of files to email messages such as sound \nand video files and binary programs. So ignoring the extra bit was not an option for \nthese attachments. As a result, extensions were designed for SMPT to handle other \nfile types.  MIME ( multipurpose Internet mail extensions ) supplements SMTP \nand supports encapsulation of nontext messages inside standard SMTP messages. \n All of these Application layer protocols use TCP at the Transport layer because \nof the reliability of the delivery. Other applications use UDP. These applications do \nelm49810_ch15_329-358.indd   340\nelm49810_ch15_329-358.indd   340\n12/18/08   12:28:45 PM\n12/18/08   12:28:45 PM\n",
        "category": "Category"
    },
    {
        "id": "108",
        "title": "Title for Chunk 108",
        "content": "Confirming Pages\n \nChapter 15 Introduction to Computer Networks \n341\nnot need the extra reliability of TCP. In particular, multimedia applications often use \nUDP. Unlike data applications, streaming multimedia applications do not normally \nrequire 100% accurate data delivery. A missed packet in a sound stream will often \nnot be noticed at all if the stream is not highly compressed. At the Application layer \nthese programs mostly use proprietary protocols rather than IETF standards. \n 15.4 TCP/IP \n Application layer protocols are supported by entities that implement a Transport layer \nprotocol. Only a few years ago there were a number of different sets of network-\ning protocols (called \u201csuites\u201d) at this layer. The phenomenal success of the Internet, \nhowever, has changed this situation. With few exceptions all computer installations \nlarge enough to want a network also want to connect to the Internet. In order to \naccess the Internet they must use the TCP/IP protocol suite. Within their own net-\nwork they can also use other protocol suites. For example, it was a simple matter to \nload the IPX protocol on a computer in addition to TCP if one wanted to use IPX \nto access Novell Netware servers. Each additional protocol suite adds complexity, \nhowever, and the people managing the systems want to avoid that complexity when-\never they can since it is expensive to support multiple options. Accordingly, they \nhave put increasing pressure on system vendors to support TCP. As a result, almost \nall vendors now support the TCP/IP protocol suite. Since the other protocol suites \ndo not provide significant services that TCP/IP does not provide, then most network \nmanagers have dropped the other protocols. Thus, TCP/IP has come to dominate the \nnetworking landscape. \n 15.4.1 The Transport layer \n In the TCP/IP protocol suite,  IP is the major Network layer protocol.  TCP, or \n transmission control protocol, is one of two principle Transport layer protocols, \nwith  UDP, or  user datagram protocol, being the other. Given an IP Network layer \naddress, the IP protocols will try to deliver a packet of data to that address. UDP \nmerely extends that function to the Application layer. This limited functionality is \ncalled an \u201c unreliable datagram. \u201d In this case the word \u201cunreliable\u201d does not mean \nthat it is likely to fail\u2014only that the protocol doesn\u2019t make any guarantees about \nthe delivery. In many cases this \u201c best efforts \u201d functionality is all that is needed or \ndesired. If the application is exchanging messages with a corresponding application \non the other end of a connection, the two application parts can usually tell if some-\nthing has gone awry. For example, most network management tools use UDP to send \nrequests and responses. If the manager does not get a particular response when it is \nexpected, then it will simply retry the operation. \n In contrast, the TCP protocol provides \u201c connection-oriented, reliable \u201d com-\nmunication. Given an IP address and a port number the TCP layer will attempt to \ncontact an entity running at that port address on the addressed system and establish \na connection. It will then transmit data to the entity at the other end and receive \nresponses, relaying them to the calling application until one of the Application layer \nelm49810_ch15_329-358.indd   341\nelm49810_ch15_329-358.indd   341\n12/18/08   12:28:46 PM\n12/18/08   12:28:46 PM\n",
        "category": "Category"
    },
    {
        "id": "109",
        "title": "Title for Chunk 109",
        "content": "Confirming Pages\n342 \nPart 5 Networks, Distributed Systems, and Security\nentities breaks the connection. This protocol uses various mechanisms such as mes-\nsage numbers and acknowledgments to ensure that the data are delivered once and \nonly once to the other end and are delivered in the order they were sent. It also uses \nother mechanisms to cope with senders that are too fast for the receivers and for \ncongestion in the network. \n 15.4.2 IP addressing and routing \n As was mentioned, connection to another host requires that the calling host knows \nthe  IP address of the destination host. IP addresses are 32 bits long. When they are \ndisplayed for humans they are normally written in a specific style known as  dot-\nted decimal notation. This style breaks the 32 bits into 4 bytes and displays each \nbyte as a decimal number separated from the other bytes with a period. Thus an \naddress of all 1 bits would be written as 255.255.255.255. Each IP network that is \nconnected to the Internet has a distinct network number. Within that network number \nthe administrator of the network would assign individual addresses to each host sys-\ntem. At one time IP addresses were divided into  classes depending on what portion \nof the address was to be used as the network number and what portion was the host \naddress. These classes were known as A, B, and C. (There were also classes D &\nE for special purposes.) In 1993 this mechanism was replaced with a new mecha-\nnism called  CIDR, or  classless interdomain routing, and the technical distinction \nbetween the classes of address has mostly gone away, though people often still refer \nto a particular address as belonging to one of these classes. \n A class of devices called  routers are responsible for delivering IP packets from \nthe source device to the destination device. Each router will look at the IP address in \nthe packet and try to determine the best path to the destination network. It is there-\nfore making decisions about where to send each input packet based on information \nat the Network layer. We therefore sometimes say that they are making forwarding \ndecisions at layer three. IP network addresses are not assigned geographically (for \nthe most part), so the routers that connect IP networks together need to learn how to \nfind any other network in the world. They learn this information mostly by talking \namong themselves. They use a variety of protocols for this exchange of informa-\ntion. The protocol that two routers will use between themselves depends on their \nadministrative relationship, among other things. There are several such protocols. \nThey can be divided into groups depending on the underlying algorithm. The larger \ngroup is the  distance vector algorithm group, including  RIP (routing information \nprotocol), RIP2 (routing information protocol version 2), IGRP (interior gate-\nway routing protocol),  EIGRP (enhanced  interior  gateway routing protocol), \nand  BGP (border gateway protocol. ) The  link state algorithm group currently has \none major representative,  OSPF (open shortest path first). \n Routers in the Internet will be connected in a partial mesh topology with many \nredundant links so that loss of one link will not normally  partition the network into \npieces that cannot communicate. Loss of a link may still cause some degradation \nof the service since some portions of the network will have to carry a heavier load. \nIn the early days of networking, the term  gateway was used to refer to the class \nof device we now call a router. You may still see the term used when configuring \nelm49810_ch15_329-358.indd   342\nelm49810_ch15_329-358.indd   342\n12/18/08   12:28:46 PM\n12/18/08   12:28:46 PM\n",
        "category": "Category"
    },
    {
        "id": "110",
        "title": "Title for Chunk 110",
        "content": "Confirming Pages\n \nChapter 15 Introduction to Computer Networks \n343\nthe IP protocol on any device, especially as part of the phrase  default gateway. \nThis name refers to the local router that a host is to use when it has no idea of the \nbest path to use to access a host that it wants to communicate with. The phrase \n default router should be used these days. The term gateway is now more correctly \napplied to a service that connects two agents running at the Application layer. A \ngood example would be an email gateway connecting a mainframe-oriented email \nsystem such as IBM\u2019s OfficeVision and a TCP/IP email system running SMTP and \nPOP3 protocols. \n It is possible for each network device to be specifically configured with a prede-\ntermined,  static IP address, but this is difficult to administer. Servers that are known \nby name throughout the Internet will usually have a permanently assigned address. \nIn other cases it is far easier to let the address be assigned dynamically. Comput-\ners are often moved as people change departments, for example. Laptops make the \nsituation even worse as they are moved from the office to home to a neighborhood \nhot spot. So a protocol was designed to facilitate this moving around:  DHCP, or \n dynamic host configuration protocol. Each network administrator will set up a \nDHCP server, which will be configured with a range of IP addresses that the network \nhas been assigned. A host that is just turned on will send out broadcast messages \nlooking for the DHCP server. The DHCP server will reply to the host and will tell \nit which IP address to use, among other things it will need to know. This address is \n leased to the workstation for some period of time after which it must be renewed. \nThe DHCP server can also be configured to deliver the same IP address each time \nto a specific machine. This is normally only done for servers, printers, and such sys-\ntems that normally do not change often. \n 15.4.3 Name resolution \n Humans find that remembering IP addresses is not easy, so the TCP/IP protocol suite \nincludes mechanisms for translating from a user-friendly name to an IP address. \nThe protocol that is used to make this translation is called  DNS, the  domain name \nservice. DNS relies on a hierarchy of servers to make these translations. A host \nmight use a DNS server, for example, to translate the name \u201cwebserv\u201d on the local \nnetwork to an IP address. The DNS server might return an IP address like 223.1.2.1 \nif the user were in the domain where the name was located. Outside of that domain, \na user trying to find this same server would have to use a different form of the name, \ncalled a  fully qualified name such as webserv.example.com. In such a name, each \nof the parts between the periods is called a domain. The domains are organized \ninto a tree structure. Various higher domains are owned and managed by different \nauthorities, with the  top level domain, or  TLD (.com in this case) being adminis-\ntered under the authority of the IETF. If a host wants to look up such a fully quali-\nfied name, it begins by asking its default DNS server. The IP address of this server \nis either learned through DHCP or is configured manually into the host when the \nIP protocol is configured. If the local DNS server does not know the IP address of \nwebserv.example.com, then it will ask the server at the next level in the DNS hier-\narchy. Eventually, the address will be found and returned to the host that started the \nrequest.  \nelm49810_ch15_329-358.indd   343\nelm49810_ch15_329-358.indd   343\n12/18/08   12:28:46 PM\n12/18/08   12:28:46 PM\n",
        "category": "Category"
    },
    {
        "id": "111",
        "title": "Title for Chunk 111",
        "content": "Confirming Pages\n344 \nPart 5 Networks, Distributed Systems, and Security\n 15.4.4 IP Version 6 \n By the early 1990s it began to look as though the world was going to quickly run out \nof IP addresses. As a result, there was a big push to define a new format for the TCP/IP\nprotocol and IP addresses. This new format is known as IP version 6, or  IPv6. \nAmong other things, IPv6 would allow much bigger IP addresses, to the point that \nit is very unlikely that we would run out of IP addresses while we were still using \nTCP/IP. Several things happened that lessened this exploding demand. First,  CIDR    \nallowed the reuse of many IP addresses that had previously been allocated to institu-\ntions that would never need them. Second, DHCP allowed the dynamic reuse of IP \naddresses when hosts were frequently turned off for long periods or regularly came \nand went from the network so that institutions could get by with fewer IP addresses. \nAnd finally,  network address translation ( NAT ) was developed. NAT is a tech-\nnique for using one set of addresses inside a network and translating those addresses \nto a different (and much smaller) set of addresses that are seen outside the local \nnetwork on the Internet. Together, these techniques meant that the pressure for going \nto IPv6 was largely removed. This migration will probably still happen in the long \nrun because of other features of IPv6. Fortunately, IPv6 was designed to allow for a \ngraceful migration. Most router vendors are already supporting IPv6 and new ver-\nsions of most OSs include support for it, but not many users appear to be migrating \nto IPv6 yet. There is a research network parallel to the Internet known as the Internet \n2 that uses IPv6 exclusively. \n 15.4.5 Common utility programs \n There are a number of utility programs that are commonly distributed with TCP/IP \nprotocol stacks. A few are designed for accessing common services such as:\n browsers for HTTP (Web) servers \n ftp clients for FTP servers (sometimes also done by a browser) \n telnet for a remote command shell \n pine for SMTP POP3, and IMAP for email \nOther commonly distributed utilities are designed for network management. Knowl-\nedge of these tools will help any system designer understand the operation of the \nlocal network and how it affects the system design. These tools are discussed more \nin  Section 15.8 . \n 15.4.6 Other protocols \n Although the other protocols running at the Network layer have largely gone by the \nwayside, there is still a significant install base of systems running the IBM proto-\ncols in the SNA/APPC family. Some of these protocols predate the TCP/IP stack. \nSome devices running these protocols are not programmable and cannot easily be \nupgraded. Furthermore, these protocols have special features that make them more \nuseful in high-demand situations, so they are likely to remain in use for some time to \ncome. Another very common protocol from the past is IPX, popularized by Novell \nelm49810_ch15_329-358.indd   344\nelm49810_ch15_329-358.indd   344\n12/18/08   12:28:46 PM\n12/18/08   12:28:46 PM\n",
        "category": "Category"
    },
    {
        "id": "112",
        "title": "Title for Chunk 112",
        "content": "Confirming Pages\n \nChapter 15 Introduction to Computer Networks \n345\nfor use with their Netware \u2122 servers. IPX had one feature that made it very popular. \nThe MAC layer address was used as a part of the Network layer address and a cli-\nent system could automatically learn the remaining part of the address. This meant \nthat the IPX protocol drivers in a client workstation did not have to be configured \nwith an address, even when a system was moved to another physical network. This \ngreatly simplified network administration and was probably a significant factor in \nthe popularity of this operating system. But the popularity of the Internet eventu-\nally overwhelmed this factor and lead to the ultimate withdrawal of the protocol by \nNovell. However, IPX has found a niche in online multiplayer gaming, so it will also \nprobably be with us for some time to come. Various other protocols were also used, \nmostly related to specific OSs. Examples include DECNet and LAT used with Digi-\ntal Equipment hardware and Vines used with Banyan systems. The NetBIOS pro-\ntocol was developed originally for IBM for small LANs. It was eventually adopted \nby Microsoft and has only begun to disappear with the later releases of Windows \nNT. Other vendors have been bought out, merged, or vanished. In some cases there \nare remnants of the NetBIOS protocol developed by IBM and used extensively by \nMicrosoft. In particular these include the  server message block ( SMB ) protocol and \nthe Open Source Samba package used with UNIX/Linux to access Microsoft serv-\ners. However, the latest releases of the Windows NT family have made it clear that \nTCP/IP is their preferred direction. \n 15.4.7 Firewalls \n Unfortunately, the world contains people who are ignorant, incompetent, or malevo-\nlent. Bad things can come into a network that is exposed to the world through the \nInternet (or any similar network). As a result, devices have been developed that are \ndesigned to protect networks from such traffic. In general, these devices are routers. \nThe routers are placed at the ingress to the network from the Internet and accept \nthe packets from the Internet as usual. Before they forward the packets to LANs \ninside the network, they perform an extra function of looking inside the packets and \nchecking for things that the network administrators decide they do not want to pass \nthrough the router. These checks can include many things. Here are a few representa-\ntive examples. (We discuss many of these in Chapter 16.) \n \ufffd PINGs \n \ufffd SPAM email \n \ufffd Viruses \n \ufffd Known denial of service (DOS) attacks \n \ufffd Access to undesirable websites (e.g., parental control) \n \ufffd Access to ports that are not in use \n 15.5 THE DATA LINK LAYER \n The types of networks called LANs originally had a special characteristic: the data \nare transmitted in such a way that all the hosts connected to the same link will actu-\nally \u201csee\u201d every transmission. Each host will normally be configured so that it will \nelm49810_ch15_329-358.indd   345\nelm49810_ch15_329-358.indd   345\n12/18/08   12:28:47 PM\n12/18/08   12:28:47 PM\n",
        "category": "Category"
    },
    {
        "id": "113",
        "title": "Title for Chunk 113",
        "content": "Confirming Pages\n346 \nPart 5 Networks, Distributed Systems, and Security\nonly \u201cread\u201d information that is actually addressed to it. Another phrase often applied \nto such LANs is \u201cmultiaccess networks.\u201d Since many such hosts connected to one \nphysical medium there had to be a mechanism devised to allow them to share access \nto the medium. These mechanisms are known as  media access control, or MAC. \nAnother term derived from this name is a  MAC address. Every host is connected \nto the LAN with a  network interface card, or  NIC, sometimes called a network \nadapter. Every NIC has a 6-byte address assigned by the manufacturer. The first \n3 bytes identify the manufacturer and the last 3 identify that specific adapter. For the \nmost part one can safely assume that these addresses are globally unique, though \nthere have been reports of unscrupulous vendors manufacturing cards under another \nvendor\u2019s identification number. \n There have been many different contending mechanisms for the MAC function. \nOnly four were very successful:  Ethernet \u2122,  ARCNET \u2122,  Token Ring, and  FDDI \n( fiber distributed data interface ). ARCNET was one of the first LAN technologies \nbut had substantial limitations. These same limitations turn into advantages in embed-\nded systems, and ARCNET survives today in such environments but has virtually \ndisappeared as a general LAN technology. Ethernet and Token Ring were eventually \nstandardized by the IEEE as 802.3 and 802.5, respectively. FDDI was an ANSI stan-\ndard. Although it is not precisely correct, we will simply refer to \u201cEthernet\u201d since that \nis fairly common usage. Ethernet had a distinct advantage in that it is a simpler tech-\nnology than either Token Ring or FDDI. It was therefore generally easier to install cor-\nrectly and it was cheaper. There was, however, a serious set of drawbacks to Ethernet. \n 15.5.1 Ethernet \n Ethernet relied on the probability that most of the time the network was not busy. \nIf it was busy then the sender would wait until the network was free and then trans-\nmit. If two stations started transmitting at the same time, their transmissions would \ninterfere with one another, causing a  collision. The Ethernet MAC mechanism was \nknown as  carrier sense multiple access/collision detection, or  CSMA/CD. It led \nto two major problems. First, the bandwidth was not fully usable. In heavily loaded \nnetworks the throughput would reach a maximum at 40\u201350% utilization in most situ-\nations. Second, if the network was pushed past this point it would eventually reach a \nstate where collisions were happening all the time and the network would stop trans-\nmitting data at all. Token Ring and FDDI did not suffer from these problems. They \nwere not stochastic, as was Ethernet, but rather were deterministic. When a device \nwas added to the LAN the average response time for a single host would drop by a \npredictable amount. Each station always got equal access and it was fairly easy to \nrun the LAN at very nearly 100% utilization. Installations such as banks, hospitals, \nand police stations that could not tolerate failures and needed to be able to predict the \nresponse times would often spend the extra money for Token Ring or FDDI. \n 15.5.2 Bridging and switching \n Eventually, a solution was developed that allowed Ethernet to overcome these dif-\nficulties. The shared wiring concentrator (or  hub ) was replaced with a switch. A hub \nwas a simple Physical layer device that merely repeated an input signal from any \nelm49810_ch15_329-358.indd   346\nelm49810_ch15_329-358.indd   346\n12/18/08   12:28:47 PM\n12/18/08   12:28:47 PM\n",
        "category": "Category"
    },
    {
        "id": "114",
        "title": "Title for Chunk 114",
        "content": "Confirming Pages\n \nChapter 15 Introduction to Computer Networks \n347\nport out to all the other ports. A  switch is a multiport device that only sends a packet \nof data out the port that leads to the device it is addressed to. The address used at this \nlevel is the Ethernet address of the NIC. So this forwarding decision is being made \nat the Data Link layer (or Media Access Control layer). This is sometimes knows \nas  layer two switching. Furthermore, such switches are able to accept and forward \ninput on all ports at the same time (subject to limitations of the switch backplane). In \naddition, changes were made that allowed the attached devices to run in full duplex \u2014\nsending and receiving at the same time\u2014and to run at either 10 or 100 Mbps. Newer \nequipment can automatically sense the best mode of operation of the switch and \nthe attached device so that installation is really as simple as a hub. Inexpensive \nswitches now can commonly run the ports at Gigabit Ethernet speeds as well. This \nseries of developments took Ethernet from a system where the top throughput was \nroughly 5 Mbps to a system where a fairly modest switch can deliver one Gbps of \nthroughput at 100 Mbps. Larger, more expensive switches can deliver even higher \nperformance. \n Before multiport switches became common, smaller switches (known then as \n bridges ) were used to divide large LANs into small sections. Dividing networks \ninto smaller sections allowed better throughput and response time for the devices on \neach segment. Bridges were initially devices with only two ports. By reading all the \ntraffic on the LANs they were connected to they would learn that MAC addresses \ncould be reached through each port. When they saw a packet on one port that was \naddressed to a device that they had learned to be reachable through the other port, \nthey would forward the packet out that other port. This was called a  transparent \nbridge or a  learning bridge. A problem with transparent bridges would arise if two \nbridges were connected in parallel between two LANs. (This is a desirable thing to \ndo since it provides a redundant link in case of the failure of one bridge.) The bridges \nwould form a loop and the packets would be continuously transmitted around the \nloop. A feature was developed for transparent bridges that allowed them to be con-\nnected in parallel (or in more complex mesh networks) without actually making a \nloop. The bridges would coordinate among themselves, and by not forwarding traffic \non selected paths would form a  spanning tree that would forward data everywhere \nbut would contain no loops. If a bridge (or a port) failed, then the bridges would \nsense this and form a new spanning tree. The biggest problem with this solution \narose when some of the connections were not LAN connections but WAN connec-\ntions. The WAN lines are fairly expensive (relative to the other network costs) and \nhaving a bridge that shut a WAN path off to keep from forming a loop was a luxury \nthat few could afford. \n When multiport switches were introduced to the market they could usually for-\nward traffic from all the input ports to output ports as rapidly as it could be sent by \nthe attached hosts. This was known as  wire speed forwarding. The marketing staff \nwanted to distinguish this behavior from the earlier bridges, so they adopted the \nword  switch. The performance of multiport switches began to cut into the market \nfor routers. By redesigning routers and using  application-specific integrated cir-\ncuits ( ASICs ), engineers were able to build devices that could make the forwarding \ndecisions at the Network layer but could do this at wire speed as did the layer two \nswitches. So the marketing people once again got involved and they called these new \nhigh-speed routers  layer three switches. \nelm49810_ch15_329-358.indd   347\nelm49810_ch15_329-358.indd   347\n12/18/08   12:28:47 PM\n12/18/08   12:28:47 PM\n",
        "category": "Category"
    },
    {
        "id": "115",
        "title": "Title for Chunk 115",
        "content": "Confirming Pages\n348 \nPart 5 Networks, Distributed Systems, and Security\n 15.5.3 Token Ring \n Token Ring hardware had a MAC mechanism that was entirely different from Ethernet. \nThe hardware used a special empty packet known as a token that was passed from host to \nhost until it reached a host that needed to transmit a frame. At that point the host changed \nthe token into a data frame and sent it on its way. Although this sounds inefficient, it \nactually worked very well. As was mentioned before, Token Ring hardware could eas-\nily reach 98% utilization of the bandwidth. Shared Ethernet, on the other hand, rarely \nreached 60% utilization and usually not even that. \n Token Ring bridges could operate in the same manner as Ethernet bridges, but \nthey also had a more complex mode known as source route bridging. In this mode \nthe attached hosts would learn a path through the bridges and each packet would \ncontain this routing information. Several advantages arose from this alternative:\n \ufffd Bridges did not have to learn addresses and were simpler and cheaper. \n \ufffd Bridges could be connected in a mesh and still utilize all links. \n \ufffd Load across redundant links tended to self-balance itself. \n Unfortunately, the source routing feature required some configuration (relative to the \ntransparent bridge, which required essentially none). They also used broadcasts to \nfind the preferred route and were often accused of causing  broadcast storms. When \nEthernet overcame its problems by utilizing fast switching, the Token Ring option \nlost out, along with source route bridging. \n 15.5.4 Other data link methods \n FDDI is a technology that was initially developed for use over optical fibers rather than \nover copper wire. It was thus intrinsically more expensive to build and to install. It ran at \n100 Mbps, long before Fast Ethernet did. FDDI rings could be over 200 km in circumfer-\nence. Because of its cost it is normally not used for attachment of individual hosts but \nrather for a  backbone LAN that connects bridges, switches, or routers between buildings \non a campus. FDDI was later modified to also run over copper wires at shorter distances. \n There have been many other technologies that have contended for the LAN. One \nthat has enjoyed limited success has been  asynchronous transfer mode ( ATM ). \nAs was Token Ring, ATM is a rather complex technology. However, ATM offers \nfeatures that make it attractive in situations where it is desirable to mix data trans-\nmission with voice and video transmissions over a single network and guarantee the \nmost appropriate  quality of service ( QoS ) to all users. ATM has been a clear winner \nin the WAN arena. In the LAN arena the goal of delivering services that require dif-\nferent QoS has been achieved by overbuilding the network so that any application \ncan have any service it wants. This has been possible because bandwidth cost is \ncurrently so low. The best overall performance would be achieved if communication \nwere done using ATM end-to-end. Where it has been used the success rate is high. At \nthis point it is doubtful if ATM will be a major factor in the LAN arena. \n ARCNET was also once very popular. It was an ANSI standard rather than an \nIEEE standard, and lost out mostly because it did not support bridging and it had a \nNetwork layer address that was only one byte and was configured with hardware \nswitches\u2014an error-prone process. \nelm49810_ch15_329-358.indd   348\nelm49810_ch15_329-358.indd   348\n12/18/08   12:28:47 PM\n12/18/08   12:28:47 PM\n",
        "category": "Category"
    },
    {
        "id": "116",
        "title": "Title for Chunk 116",
        "content": "Confirming Pages\n \nChapter 15 Introduction to Computer Networks \n349\n 15.5.5 Mapping IP addresses to MAC addresses \n We mentioned before that humans usually refer to human-friendly names like \nwebserv.example.com, and that the Network layer used DNS to translate the name to \nan IP address. We also said that on the LAN the information is actually addressed to \nthe MAC address of the NIC. The obvious question, then, is how does the software \nmap from the IP address to the MAC address? The answer is that it uses a special \nprotocol called  address resolution protocol, or  ARP. A host looking for a server \nwill make an ARP packet that contains the IP addresses of both the host and the \nserver. In the MAC header it will include its own MAC address, but it does not yet \nknow the MAC address of the server, so it will send the packet to all hosts by using a \nbroadcast MAC address (of all 1 bits). Every host will read the packet and pass it to \nthe IP software. The IP module will pass the packet on to the ARP module. The ARP \nmodule in the correct server will recognize that it is being addressed by the ARP and \nwill prepare an ARP response packet. This packet will be sent directly back to the \ninquiring host and that host will then continue the conversation using the new MAC \naddress. The IP software in all the other hosts except the one addressed will merely \nignore the packet. The OS will typically cache the MAC addresses in an  arp table. \n 15.5.6 Functional migration into hardware \n As networking has become more established, some of the functions that were ini-\ntially done in software by the device drivers have migrated into the hardware. This \nevolutionary step takes some time, because a function should not be migrated to \nhardware until it is very well understood. Mistakes in hardware are quite expensive \nto fix. Two examples of functional migration to hardware have occurred in NICs. \nFirst is the calculation of  cyclic redundancy checks ( CRCs ). CRCs are a class of \nfunctions that are computed on blocks that are transmitted over a network. They \nwere discussed at some length in Chapter 14. The CRC is transmitted with the block \nand the receiver makes the same calculation as the sender. If the calculated CRC \ndoes not match the CRC sent with the packet, then the receiver knows that an error \nwas made. Originally this function was computed by the software driver for the NIC. \nIt was fairly expensive to compute in terms of CPU cycles. However, hardware engi-\nneers discovered a fairly trivial way to do the same computation as the packet was \nbeing transmitted. This was an inexpensive way to take a considerable load off the \nCPU. This function might not make much difference in modern machines, but at the \ntime it was developed machines were much slower so it was a bigger deal. \n Another function that has migrated into the NIC hardware is the recognition of \n multicast addresses. Multicast packets are sent out over the network and every NIC \nwill see them. Several multicast streams might be in use on a given LAN at any one \ntime. A specific system might or might not be interested in a particular stream. A good \nexample of a multicast would be a stock ticker application that might run in a stock \nbrokerage. Not all systems would need to see that stream, but many of the brokers \nmight want to watch the ticker, so they would run a specific application that would \nlook for the particular multicast address that was assigned to that stream. At one time \nall multicasts were received by all adapters and passed up to the Network layer where \nelm49810_ch15_329-358.indd   349\nelm49810_ch15_329-358.indd   349\n12/18/08   12:28:48 PM\n12/18/08   12:28:48 PM\n",
        "category": "Category"
    },
    {
        "id": "117",
        "title": "Title for Chunk 117",
        "content": "Confirming Pages\n350 \nPart 5 Networks, Distributed Systems, and Security\nthey might be dropped if the system were not interested in that stream. This was \nespecially unproductive in systems that were not interested in any streams. They still \ngot interrupted by every multicast packet and the software had to examine the address. \nEventually, this function was also migrated to the NICs. The protocol stack would \nnotify the NIC of any multicast addresses it had applications interested in. Packets to \nthose addresses would be passed to the protocol stack and any other multicast packets \nwould be dropped by the NIC and the CPU would not be interrupted.  \n 15.6 WANS \n In contrast with LANs where the hosts are usually in the same building or at least \nthe same campus, wide area networks, or WANs, are connections between devices \nwhere the data must pass over a serial point-to-point connection. Often these connec-\ntions are between two bridges or routers but sometimes a host will link to a bridge \nor router, especially if the connection is a dial-up link. For dial-up links through \n plain old telephone service ( POTS ), the highest speed available is 56 Kbps. When \na WAN link is connected permanently, the link is known as a leased line. These \nlines are usually digital (as opposed to the dial-up link, which is analog). Typically \nthe slowest leased line speed is 56 Kbps, though 64 Kbps is also common. The next \nspeed line available is a  T1 line, which runs at 1.544 Mbps. Speeds between 64 Kbps \nand T1 are sometimes available as well. These lines are called  fractional T1 lines, \nor  Frac-T1. Higher speed lines are also available that are multiples of T1 speeds. T1 \nlines were originally designed to carry voice traffic. These calls were analog signals \nthat had been digitized to a 64 Kbps stream. Up to 24 such slow digital streams could \nbe combined by synchronous  time division multiplexing ( TDM ) onto one T1 line \nthat ran between phone company switching centers. \n 15.6.1 Frame relay \n When a large network is built with WAN lines, a big factor in the total line cost is \nthat portion of the circuit that goes from the customer premise to the local phone \ncompany office\u2014called the  last mile. If the customer has a number of leased \n56 Kbps lines connecting different sites from the home office, they can usually mul-\ntiplex them in groups of 24 onto a single T1 line. This can result in tremendous line \ncost savings since that T1 line can usually be run over one standard twisted-pair \ncopper line. Another technology was also developed that goes even further in this \ndirection. Rather than use synchronous time division multiplexing as was described \nabove, the line is used to send packets instead of streams of data and each packet is \naddressed and switched through the network separately. This technology is known \nas  frame relay. It makes good sense because often the capacity of some of the indi-\nvidual 56 Kbps circuit is underutilized. A network using synchronous TDM circuits \nis designed for something near the peak load traffic rates. Since the worst case does \nnot often arise, there is usually unused bandwidth. Thus, a T1 line might actually be \nable to carry all the packets for 40\u201350 lines running 56 Kbps when using frame relay \nelm49810_ch15_329-358.indd   350\nelm49810_ch15_329-358.indd   350\n12/18/08   12:28:48 PM\n12/18/08   12:28:48 PM\n",
        "category": "Category"
    },
    {
        "id": "118",
        "title": "Title for Chunk 118",
        "content": "Confirming Pages\n \nChapter 15 Introduction to Computer Networks \n351\ninstead of TDM. Alternatively, a single 56 Kbps frame relay circuit to the carrier\u2019s \noffice might carry all the frames from three to five 56 Kbps circuits that were not \nheavily used all the time. Thus, frame relay networks can save their users a lot of \nmoney.  \n 15.6.2 Other WAN technologies \nOne LAN protocol that enjoyed a brief period of popularity was  integrated ser-\nvices for digital networks, or  ISDN. A single copper circuit could be brought to a \nhome or small office, which could carry two 64 Kbps channels.  4 This type of service \nwas called  basic rate interface ( BRI ). These channels could each carry a single \ndigitized voice call or a data channel. The two data channels could also be logically \ncombined and used as a single 128 Kbps channel. This was substantially better than \na POTS line. A large attraction for ISDN came at the core of the network where the \ninterface was a  primary rate interface ( PRI), which carried 23 channels of 64 Kbps \neach plus one 64 Kbps channel for signaling. The main advantage to PRI was that \nthe calls could be either digital calls originating from an ISDN BRI device or analog \ncalls originating at a regular modem. The analog calls would be digitized by the car-\nrier at their office and delivered digitally. ISDN PRI services are also still used today \nin telephone support offices for pure voice traffic.\n As was mentioned earlier, another technology was developed specifically for \nWANs: ATM. ATM is frame relay carried to an extreme. The essence of ATM is that \nall traffic is broken into small pieces\u201448-byte cells. These cells can be switched rap-\nidly and cheaply and can give each user exactly the types of traffic service needed. \nThis is highly desirable for the carriers since they have contracts to offer all kinds of \ndifferent services, from Teletype traffic to ultra high-speed data circuits. With ATM \nthey actually deploy only one network and use different equipment at the entrance \nand exit points to the network that make it look like the service the user contracted \nfor. The carrier only has to train operators and technicians to maintain one network; \nthey only need one kind of management software; and so on. It is not hard to see why \nATM has captured many of the WAN backbones. \n For homes and small businesses there are two other competing technologies \nfor high-speed WAN services:  cable modems and  digital subscriber lines ( DSL ). \nThese two services use ATM and similar technology to provide permanent connec-\ntions to the Internet at the same time as they provide some other service. In the case \nof cable modems, that other service was originally cable TV. In the case of DSL, that \nother service is POTS. Since ATM technology is employed, cable modems can also \nbe used to deliver POTS service, but that is a later add-on to the original concept. As \nfiber optic cables are extended further into the local community, the available band-\nwidth to each customer is going up and eventually should reach directly into the \nhome or office. Such technology goes by many different names, mostly like  fiber to \nthe Curb, or  FTTC.     \n4 Technically there was also a 16 Kbps channel that was used for network signaling or low-speed \napplications such as credit card authorizations.\nelm49810_ch15_329-358.indd   351\nelm49810_ch15_329-358.indd   351\n12/18/08   12:28:48 PM\n12/18/08   12:28:48 PM\n",
        "category": "Category"
    },
    {
        "id": "119",
        "title": "Title for Chunk 119",
        "content": "Confirming Pages\n352 \nPart 5 Networks, Distributed Systems, and Security\n 15.7 THE PHYSICAL LAYER \n For information to flow from one device to another there must be some medium \nthat connects the two devices. That medium must be capable of being changed in \nsome way such that the change can be sensed by the other device. Historically, for \ncomputer data this has meant that a metal wire of some type has connected the two \ndevices and conducted a flow of electricity. In the last few years the copper wire has \noften been replaced by glass or plastic, which conducts light. Wireless transmission \nvia electromagnetic transmission is also frequently used for sending information. \nFor decades it was used only for analog audio and video transmission and telegraph \ntransmission of text. In the last few years wireless has become more common for data \ntransmission. Originally this was for digital transmission of analog data, but is now \nbeing used for data transmission, especially for laptop and handheld computers. \n 15.7.1 Copper wire specifications \n The metal in communication wiring is most often copper and there are usually two \nwires for each line. Sometimes there are two wires that are identical and are twisted \ntogether. This is known as  twisted pair. Wires that are twisted together are less likely \nto pick up radiated signals from other wires and to radiate signals that can be picked \nup externally. There may also be a layer of foil wrapped around a pair of wires or \naround several pair of wires that are grouped together as a single cable. This is known \nas  shielded twisted pair wiring, or  STP. Without the shield it is called  unshielded \ntwisted pair, or  UTP. STP is less susceptible to outside interference and to having \nthe signal be picked up outside the network than is UTP. The wire that was histori-\ncally used to install telephone wires in homes and businesses is one type of twisted \npair. The UTP wire used for data needs to be higher quality than standard telephone \nwire. Quality in UTP wiring is standardized in terms of  Category or  Cat by the \n Telecommunications Industry Association (TIA). The lowest category currently \napproved for new data installations is Cat 5, rated at about 100 Mbps. The newest \nstandard is for Cat 6 at 250 Mbps. The next step is for a Cat 7 standard that will run \n10 gigabit Ethernet over 100 m of copper cabling. \n There is another configuration of copper wiring called  coax, shorthand for  coaxial \ncable. In this case there is a single center conductor wrapped with an insulation mate-\nrial. Then a layer of very thin wires are braided around this insulating layer. (Occa-\nsionally the outer layer is solid, like a tube.) This layer becomes the second \u201cwire\u201d in \nthe pair. The center wire is at the center (or axis) of the outer layer, so the two wires \nare coaxial. Coax is even less likely to radiate its signal or to pick up external signals \nthan is STP. However, it is more expensive so it is limited to special uses. Coaxial \ncable is the type of wire used for cable TV. The cable TV coax used inside a building \nis about the size of a pencil and is somewhat inflexible compared to UTP wire.  \n 15.7.2 Fiber optic specifications \n Fiber is almost totally free from problems with radiated signals. It is also somewhat \nexpensive, roughly twice the cost of copper cabling, but it is widely used because \nit is almost totally free from errors. In addition, it can send data over rather long \nelm49810_ch15_329-358.indd   352\nelm49810_ch15_329-358.indd   352\n12/18/08   12:28:49 PM\n12/18/08   12:28:49 PM\n",
        "category": "Category"
    },
    {
        "id": "120",
        "title": "Title for Chunk 120",
        "content": "Confirming Pages\n \nChapter 15 Introduction to Computer Networks \n353\ndistances. Indeed, in 2001 a vendor demonstrated transmission across the continen-\ntal United States over a single fiber without a repeater. It has very high bandwidth \ncapability, so the price per bit transmitted can be very low where large volumes of \ndata need to be handled. The vast majority of new WAN circuits are fiber and it is \nvery common in the backbone LAN in a building or campus. \n When the telephone carriers first put in fiber optic links they worked very \nwell. They have very low error rates, for one thing. Each fiber was limited by the \nphysics of the receiver circuits to about 5 Gbps of data. After they had been in use \nfor a while, however, engineers realized that there was a simple, inexpensive, and \nreliable optical way to combine several signals over the same fiber by using a prism \nat each end. This technology is called  wavelength division multiplexing, or  WDM \n(or sometimes  DWDM for  dense WDM ). As a result, each fiber that was installed \ncan now carry 64 to 128 times as much data as was first thought. Since the cost of \nthe right-of-way and of installing the fiber itself is a major factor, this has meant a \nprecipitous drop in the cost of wide area bandwidth. This drop has manifested itself \nin a rapid drop in long-distance telephone rates over the last few years. Indeed, in \nmany cases the local phone companies can afford to give their customers access to \nlong-distance lines for free if they will agree to buy the local service. \n 15.7.3 Wireless networking \n As was mentioned earlier, a relative newcomer to the transmission of digital data \nis communication over wireless media\u2014essentially digital radio. 5 This technol-\nogy is obviously applicable in laptop and handheld computers, but it is also appli-\ncable where hosts must be moved frequently or where physical limits preclude \ndirect cabling. Another promising area is in mobile systems\u2014robots, if you will. \nThere is an IEEE standard for wireless communication, 802.11, known by its \nmarketing term  Wi-Fi. Devices are readily available to connect to wireless LANs\u2014\nPC Card NICs, bridges, routers, PCI NICs, and so on. These devices will prob-\nably continue to fill these niches. Another wireless protocol, Bluetooth, facilitates \nexchange of information between wireless devices such as personal digital assis-\ntants (PDAs), mobile phones, laptops, computers, printers, and digital cameras via \na secure, low-cost wireless link. Bluetooth is being standardized by the IEEE as \n802.15. The protocol variants in this family are designed for very short range and \nare sometimes referred to as  personal area networks ( PAN s) or  body area net-\nworks ( BAN s.) \n Wireless is very susceptible to picking up interference from external sources and \nto being picked up by other devices, either accidentally or intentionally. Its chief vir-\ntue is that it does not require a physical connection between the two communicating \ndevices. Because of the problems with noise, wireless communication has resulted in \nmore robust error detection and correction and security mechanisms. Development \nof these mechanisms had been allowed to lag somewhat because cable and fiber \nwere so free from errors. \n5 There have been wireless networks used before. They traditionally have been used in military \napplication or locations such as the Hawaiian Islands where it was prohibitively expensive to lay cable.\nelm49810_ch15_329-358.indd   353\nelm49810_ch15_329-358.indd   353\n12/18/08   12:28:49 PM\n12/18/08   12:28:49 PM\n",
        "category": "Category"
    },
    {
        "id": "121",
        "title": "Title for Chunk 121",
        "content": "Confirming Pages\n354 \nPart 5 Networks, Distributed Systems, and Security\n 15.7.4 A note on network troubleshooting \n As a practical aside, when troubleshooting network problems one should always \nbegin the study by checking the Physical layer. Physical layer problems, especially \nintermittent problems, can cause all manner of problems to manifest at other layers. \nTherefore, one should always begin network troubleshooting by verifying that there \nis an error-free connection between the two devices at the Physical layer. \n 15.8 NETWORK MANAGEMENT \n 15.8.1 Simple management tools \nTwo special protocols are used with TCP/IP for network management:  ICMP ( inter-\nnet control message protocol ) and  SNMP ( simple network management proto-\ncol ). ICMP serves several functions, but the most visible to the network manager is \nthat it provides the basis for the  ping and  tracert (sometimes traceroute) utilities. \nThe ping utility is a very simple tool primarily used to verify connectivity between \ntwo devices. It sends an ICMP echo command to a destination host. That host will \nnormally reply to the echo command with an ICMP echo reply. Options on the ping \nutility allow sending a large block of data, retrying the ping operation in a loop, \nand so on. Measuring the response time and its variability can also help a network \noperator identify performance problems in the network. Tracert uses a succession of \npings to discover the series of routers connecting two network hosts. It gives reports \nfor each hop on the route and this can further assist in locating network performance \nproblems.\n 15.8.2 SNMP and network device management \n SNMP has historically been the protocol that network management software used \nto communicate with network devices to monitor, configure, and troubleshoot \nthem. Most network devices that were manageable would have a set of parameters \nthat they would furnish information about or allow to be changed. These param-\neters would be described by a  MIB, or  management information base. From the \noutside it is easy to believe that the device actually stores the MIB itself. Actually, \nthe MIB is just a convenient, structured way to describe the data and its seman-\ntics and the format used to transfer the data. The device stores the data values in \nwhatever fashion is convenient for it. The IETF has standardized quite a number \nof MIBs, including ones for specific hardware classes such as Ethernet ports and \nfor protocols such as TCP and UDP, but vendors have also added many proprietary \nextensions. \n Managers rarely see SNMP directly. Rather, the MIB for a networking device \nlike a router was used to develop a software tool that would allow remote manage-\nment of network devices using SNMP but with a GUI interface. Some of these tools \nwere quite elaborate, showing images of devices with blinking lights and maps with \ncolors indicating network status. Unfortunately, they were all proprietary, so many \nlarge  network operation centers ( NOC s) were filled with dozens of workstations \nelm49810_ch15_329-358.indd   354\nelm49810_ch15_329-358.indd   354\n12/18/08   12:28:49 PM\n12/18/08   12:28:49 PM\n",
        "category": "Category"
    },
    {
        "id": "122",
        "title": "Title for Chunk 122",
        "content": "Confirming Pages\n \nChapter 15 Introduction to Computer Networks \n355\nall running different software packages. This required extensive cross-training of \noperators who knew the vagaries of each software package. \n The trend today is to put a dedicated specific HTML server entity in the device \nand manipulate it with a Web browser using the HTTP Application layer protocol. \nThis means that proprietary management software is less often required, and that \nthe cross-training demand has lessened. It is still necessary to know the specific \ncharacteristics of the network devices, but much less training is demanded since the \nbrowser is standard to all such devices. \n 15.8.3 Packet capture \n When Ethernet networks were built with hubs, every NIC on the network would see \nevery packet that was sent over a LAN. Normally, an adapter would only read pack-\nets with a broadcast address, a multicast address, or the address of the adapter itself. \nHowever, some adapters could be placed into a  promiscuous mode, in which case \nthey would read every packet on the network. This became a useful tool for trouble-\nshooting network protocols. Very elaborate tools were developed. The best known \nwas the Sniffer\u2122 line made by Network General Corporation. Such tools had many \noptions. For example, they could be set up to capture only traffic meeting certain \ncriteria, start capturing only after some trigger event was seen, save captured packets \nto a hard drive, and create a decoded display of the packets using only the layers of \ninterest. Unfortunately, such tools had a dark side as well, as unscrupulous users \ncould use capture programs to see privileged information and capture passwords if \nthey were not encrypted. \n The development of switched Ethernet has largely solved this latter problem, \nfor these switches only forward traffic addressed to a specific device out the port \nwhere that device is attached. Thus, a packet capture device will see only broadcasts, \nmulticasts, and traffic intended for the capture device itself. Of course, this means \nthat the capture technique cannot be used for the purpose for which it was originally \nintended. For this reason, switches that are intended for use in a large environment \nwill often have a feature called  port mirroring. This feature will allow a manager \nto tell the switch to take all packets to and from a specific port and copy it to another \nport. The packet capture device can then be plugged into that mirror port and can \ncapture the session as before, but only the network management folks will be able to \nturn on this feature. \n 15.8.4 Remote monitoring \n One of the MIBs that is defined by the IETF covers  remote monitoring ( RMON ) \nof networks. Traveling to remote network sites for troubleshooting and maintenance \ncan be very costly, so it is much preferable to be able to diagnose network problems \nremotely through the network. Routers are in a unique position to perform this func-\ntion since they are already examining every packet they forward. The RMON MIBs \ndefine counters that an RMON agent in a router can maintain that go far beyond \nthose in the basic router MIBs. They can include full trace facilities, statistics based \non Application layer protocols, and other useful information. \nelm49810_ch15_329-358.indd   355\nelm49810_ch15_329-358.indd   355\n12/18/08   12:28:50 PM\n12/18/08   12:28:50 PM\n",
        "category": "Category"
    },
    {
        "id": "123",
        "title": "Title for Chunk 123",
        "content": "Confirming Pages\n356 \nPart 5 Networks, Distributed Systems, and Security\n BIBLIOGRAPHY \n Abramson, N., \u201cThe ALOHA System\u2014Another \nAlternative for Computer Communications,\u201d \n Proceedings,  Fall Joint Computer Conference, 1970. \n ANSI/IEEE Standard,  Carrier Sense Multiple Access with \nCollision Detection (CSMA/CD) Access Method and \nPhysical Layer Specifications, Std. 802.3-1985, May \n1988. \n ANSI/IEEE Standard,  Token Ring Access Method and \nPhysical Layer Specification, Std. 802.5-1985, \nDecember 1987. \n ANSI/IEEE Standard,  Token-Passing Bus Access Method \nand Physical Layer Specification, Std. 802.4-1985, \nMarch 1986. \n ATM Forum,  LAN Emulation Over ATM LNNI \nSpecification Version 2.0 (AF-LANE-0112.000), \nFebruary 1999. \n Beck, M., et al.,  Linux Kernel Programming, 3rd ed., \nReading, MA: Addison-Wesley, 2002. \n Bertsekas, D., and R. Gallager,  Data Networks. \nEnglewood Cliffs, NJ: Prentice Hall, 1987. \n Comer, D.,  Internetworking with TCP/IP Principles, \nProtocols, and Architecture. Englewood Cliffs, NJ: \nPrentice Hall, 1988. \n Martin, J., and K. K. Chapman,  SNA: IBM\u2019s Networking \nSolution. Englewood Cliffs, NJ: Prentice Hall, 1987. \n Martin, J., and K. K. Chapman,  Local Area Networks \nArchitectures and Implementations. Englewood \nCliffs, NJ: Prentice Hall, 1989. \n McQuillan, J. M., I. Richer, and E. Rosen, \u201cThe New \nRouting Algorithm for the ARPANET,\u201d  IEEE \nTransactions on Communications, Vol. COM-28, \nMay 1980, pp. 711\u2013719. \n Metcalfe, R., and D. Boggs, \u201cEthernet: Distributed Packet \nSwitching for Local Computer Networks,\u201d  CACM, \nVol. 19, No. 7, July 1976. \n Perlman, R.,  Interconnections: Bridges, Routers, \nSwitches, and Internetworking Protocols,  2nd ed., \nReading, MA: Addison-Wesley, 1999. \n Postel, J. B., C. A. Sunshine, and D. Cihen, \u201cThe ARPA \nInternet Protocol,\u201d  Computer Networks, 1981. \n Stallings, W.,  ISDN: An Introduction. New York: \nMacmillan, 1989. \n Voydock, V. L., and S. T. Kent, \u201cSecurity Mechanisms in \nHigh-Level Network Protocols,\u201d  Computing Surveys, \nVol. 15, No. 2, June 1983, pp. 135\u2013171. \n Zimmerman, H., \u201cOSI Reference Model\u2014The \nISO Model of Architecture for Open Systems \nInterconnection,\u201d  IEEE Transactions on \nCommunications, Vol. COM-28, No. 4, April 1980, \npp. 425\u2013432. \n 15.9 SUMMARY \n In this chapter, we gave an overview of the basic \ncomponents of networked systems. We started with \nsome motivational material about why the study of \nnetworks is important to the understanding of com-\nputer systems in general and operating systems in \nparticular. We laid the groundwork for a discussion \nof networking by discussing some of the fundamen-\ntal concepts and describing a model of networking \nthat would be used for the remainder of the chapter. \nWe discussed a few Application layer protocols and \nthe most well-known protocol used at the Transmis-\nsion and Network layers, TCP/IP. We also discussed \nthe continuing significant role of IBM and SNA. We \ndiscussed the Data Link layer, with special empha-\nsis on Ethernet and we also discussed Token Ring \nand FDDI and compared them with Ethernet. We \ndiscussed the shortcomings of shared Ethernet and \nshowed why switched Ethernet at all speeds has \ncome to dominate LAN architecture. We covered \nWANs and a few unusual WAN protocols and why \nthey are sometimes used. The topic of the next sec-\ntion was the Physical layer and some of the options \ntherein. Finally, we covered network management, \nincluding simple utilities, SNMP and normal net-\nwork management operations and the migration to \nHTTP and browsers. RMON was also profiled. \nelm49810_ch15_329-358.indd   356\nelm49810_ch15_329-358.indd   356\n12/18/08   12:28:50 PM\n12/18/08   12:28:50 PM\n",
        "category": "Category"
    },
    {
        "id": "124",
        "title": "Title for Chunk 124",
        "content": "Confirming Pages\n \nChapter 15 Introduction to Computer Networks \n357\nREVIEW QUESTIONS\n 15.1 What was one of the main initial motivations for \nnetworking computers?\n 15.2 Ultimately what became the most significant ben-\nefits of networking computers?\n 15.3 In the networking models we discussed, each \nlayer is represented by an entity in each computer. \nEach such entity has a conversation with another \nentity for each connection. What other entity is it \ntalking to?\n a. The next higher layer\n b. The next lower layer\n c. The peer entity in the other system\n d. None of the above\n 15.4 In a WAN, which topology is the most efficient \nin terms of speed of reaching all nodes from a cen-\ntral site?\n a. Linear\n b. Tree\n c. Star\n d. Ring\n e. All of the above are the same in terms of com-\nmunication speed\n 15.5 Which WAN topology is the most expensive in \nterms of line costs?\n a. Star\n b. Ring\n c. Partially connected mesh\n d. Fully connected mesh\n e. All of the above have equal line costs\n 15.6 Some shared LAN topologies were not very \nefficient\u2014notably, shared Ethernet rarely ran \nover 60% efficiency. What major development \nallowed such LANs to operate at much higher \nthroughput?\n 15.7 What is the DHCP protocol used for?\n a. To translate IP addresses to MAC addresses\n b. To translate names to IP addresses\n c. To obtain an IP address and other information\n d. To update pages on a Web server host\n e. None of the above describes the use of DHCP\n 15.8 What was the main thing that saved us from a pre-\ncipitous migration to IPv6?\n a. DHCP\n b. NAT\n c. CIDR\n d. DNS\n e. None of the above helped us delay using \nIPv6\n 15.9 Each protocol layer must have some information \nin its header to tell the receiving entity what entity \nto pass an incoming PDU to. What information \nin the Transport layer header tells TCP or UDP \nwhich application to give the packet to?\n 15.10 What protocol is used to translate IP addresses to \nMAC addresses?\n a. ARP\n b. NAT\n c. DHCP\n d. IGRP\n e. None of the above protocols involve mapping \nIP addresses to MAC addresses\n 15.11 Which physical medium has the best immunity \nagainst interference?\n a. Coax\n b. STP\n c. Wi-Fi\n d. Fiber\n e. All of the above have equal immunity against \nnoise\n 15.12 We mentioned that a LAN and a WAN were dif-\nferent in what significant way?\n 15.13 We mentioned that the FTP protocol had some \nunusual things about it compared to the other two \nprotocols we discussed. Name one.\n WEB RESOURCES \n http://www.bluetooth.com/bluetooth/ (commercial \nproducts) \n https://www.bluetooth.org (standards organization) \n http://www.ietf.org (Internet Engineering Task Force; \ndefines all RFCs, including IP, TCP, UDP, NAT, RIP, \nRIP2, PPP, IPv6, CIDR, SLIP) \n http://www.ipmplsforum.org (Internet Protocol Multi-\nProtocol Label Switching forum\u2014succeeded the \nATM forum) \nhttp://www.w3.org/Protocols (mostly about HTTP)\nelm49810_ch15_329-358.indd   357\nelm49810_ch15_329-358.indd   357\n12/18/08   12:28:50 PM\n12/18/08   12:28:50 PM\n",
        "category": "Category"
    },
    {
        "id": "125",
        "title": "Title for Chunk 125",
        "content": "Confirming Pages\n358 \nPart 5 Networks, Distributed Systems, and Security\n 15.14 What is the mechanism by which most network \ndevices are coming to be managed, especially the \ncheaper ones?\n 15.15 When troubleshooting networks, which layer \nshould you check first?\n 15.16 We say that UDP is an \u201cunreliable\u201d protocol. Why \ndid we not design a \u201creliable\u201d protocol?\n 15.17 True or false? Ethernet is the only LAN media \naccess control protocol in use today.\n 15.18 What does Cat 5 refer to?\n 15.19 What is a SNIFFER?\n a. A bomb detection device\n b. A proprietary device for analyzing network \nprotocols\n c. A person addicted to inhaling volatile chemicals\n d. A software program for stealing passwords\n e. None of the above describes a sniffer.\n 15.20 When we use a PING command and get a response \nfrom a host we learn quite a few things all at one \ntime. Assuming that we did not already know \n anything at all about the situation, what are some \nof the things we might have just learned?\n 15.21 What is the DNS used for?\n a. To translate IP addresses to MAC addresses\n b. To translate names to IP addresses\n c. To obtain an IP address and other information\n d. To update pages on a Web server host\n e. None of the above\n 15.22 An IP address typically would be shown like this: \n129.107.56.23. Such an address has two parts. \n129.107 is one part and 56.23 is the other part. \nHow are these parts used?\n 15.23 A router that is routing IP traffic also might use \na protocol called RIP. What is that protocol used \nfor?\n 15.24 Email uses two distinct kinds of protocols, SMTP \nand POP3, for example. What is the difference \nbetween these two protocols?\nelm49810_ch15_329-358.indd   358\nelm49810_ch15_329-358.indd   358\n12/18/08   12:28:50 PM\n12/18/08   12:28:50 PM\n",
        "category": "Category"
    },
    {
        "id": "126",
        "title": "Title for Chunk 126",
        "content": "Confirming Pages\n19\n Chapter\nChapter 2 2 \n Operating System \nConcepts, Components, \nand Architectures  \n In this chapter: \n \n2.1 Introduction: What Does the OS Do?  20\n \n2.2 Resources Managed by the OS and Major OS Modules 22\n \n2.3 The Process Concept and OS Process Information 25\n \n2.4 Functional Classes of OSs 29\n \n2.5 Architectural Approaches to Building an OS 33\n \n2.6 Some OS Implementation Techniques and Issues 35\n \n2.7 Minimalist versus Maximalist Approaches to OS Functionality \nand Backward Compatibility 40\n \n2.8 Summary 42\n I\nn this chapter, we discuss in general what the operating system does, and give \nan overview of OS concepts and components so that a student has some overall \nperspective about OSs. We also discuss some common techniques employed in \nnearly all OSs. \n To gain some understanding of how the OS is involved in practically all system \noperations, we start in  Section 2.1  with a simple user scenario and describe some \nof the actions within the scenario that are undertaken by the OS.   In  Section 2.2  we \ngive an overview of the main types of system resources that the OS manages. These \nresources include the processor (CPU), main memory, I/O devices, and files. We \nthen give an overview of the major OS modules, and the services that each module \nprovides. These include the process management and CPU scheduling module, the \nmemory management module, the file system module, and the I/O management \nand disk scheduling module. These may or may not be implemented as separate \nmodules in any particular OS, but looking at each of these separately makes it \neasier to explain OS concepts. \nelm49810_ch02_019-044.indd   19\nelm49810_ch02_019-044.indd   19\n12/10/08   9:27:32 PM\n12/10/08   9:27:32 PM\n",
        "category": "Category"
    },
    {
        "id": "127",
        "title": "Title for Chunk 127",
        "content": "Confirming Pages\n20 \nPart 1 Operating Systems Overview and Background\n Then in  Section 2.3 we define the concept of a process, which is central to what \nthe OS does, and describe the states of a process and some of the information that \nthe OS maintains about each process. A process (sometimes called job or task)  1 is \nbasically an executing program, and the OS manages system resources on behalf of \nthe processes. In  Section 2.4  we discuss the characteristics of different types of OSs, \nfrom systems that can run or execute a single process at a time, to those that manage \nconcurrently executing processes, to time sharing and distributed systems. \n In  Section 2.5  we present some of the different architectural approaches that \nhave been taken for OS construction. These include monolithic OS, microkernels, \nand layered architectures. We then describe some implementation techniques that \nare used repeatedly by various OS modules in  Section 2.6 . These include the queues \nthat are maintained by multitasking OSs to keep track of the jobs that are waiting \nto acquire resources or to have certain services performed. For example, processes \ncould be waiting for disk I/O or CPU time or printing services. We also describe \ninterrupts and how they are handled in some detail, object-oriented OS design, and \nvirtual machines.  Section 2.7  gives a philosophical discussion concerning what func-\ntionality should be part of an OS. Finally, in  Section 2.8 we summarize this chapter. \n 2.1 INTRODUCTION: WHAT DOES THE OS DO? \n In this section, we go over a small example scenario, in order to see how the OS is \ninvolved in nearly every aspect of computing. Consider the following simple user \nscenario: \n A user wants to type a small note to himself.  2 Coming into work this morning he \nheard a radio advertisement that his favorite music group is coming to town, and he \nwants to have a reminder to buy tickets and invite some friends. So he starts a sched-\nuling program (or possibly a text editor or a word processing program), types in his \nreminder, saves the document, and exits. The user could have used a PDA (personal \ndigital assistant), a Windows-based system (e.g., Mac, MS Windows or Linux with a \nGUI-based text editor), or simply a text-based command shell such as UNIX. Let\u2019s \nassume he is using a GUI-based text editor to write a separate note and save it as a \nfile. Regardless of the type of system used, this scenario caused the OS to create, \nmanage, and terminate software components to accomplish the work. When the user \nstarted the editor or some other program he created a  process (also called  task or \n job ). 3 A process is basically a program in  execution. A process may be waiting to \nrun, currently running, waiting for something to happen, or finishing. Some of the \nevents that a process may be waiting for include a keystroke from the user, or some \ndata to be read from a disk drive or to be supplied by another program. \n Before a process can be started, the executable program file (binary) that will be \nrun must be brought into main memory. This is usually loaded from a disk or some \n 1 The terms  job and  task are used to refer to the same concepts in some of the literature, and to different \nconcepts in other literature. We discuss this as needed in the footnotes. \n 2 For grammatical simplicity, this text will assume the user is a male. \n 3 Starting a program is sometimes called instantiating, executing, loading, or running the program. \nelm49810_ch02_019-044.indd   20\nelm49810_ch02_019-044.indd   20\n12/10/08   9:27:34 PM\n12/10/08   9:27:34 PM\n",
        "category": "Category"
    },
    {
        "id": "128",
        "title": "Title for Chunk 128",
        "content": "Confirming Pages\n \nChapter 2 Operating System Concepts, Components, and Architectures \n21\nelectronic memory such as a flash drive. Several major OS activities are needed to \naccomplish this. First, a portion of main memory is needed to hold the program\u2019s \nexecutable code. Additional memory is needed for the program\u2019s data, variables, and \ntemporary storage. In our example, the data would be the entry that the user is creat-\ning in the memo file. These activities to allocate memory are part of the  memory \nmanagement that the OS must do. Often several programs may be in memory at the \nsame time. The OS memory manager module controls which processes are placed \ninto memory, where they are placed, and how much memory each is given.  Process \nmanagement \u2014deciding which process gets to run, for how long, and perhaps at \nwhat priority (or level of importance)\u2014is another key management activity of the \nOS, usually handled in part by the OS CPU scheduler. \n Once the editor process is running, it needs to accept some keystrokes and \ndisplay what has been typed on the screen. Even if the device is a PDA with no \nkeyboard, characters are input and accepted by the OS in some manner. Acquiring \nkeystrokes or characters and displaying those characters on the screen are done in a \nseries of steps through the  I/O and device management component of the OS. \n When our user hits a key, he enters a character that must be read by the sys-\ntem. The device\u2014in this case a keyboard\u2014inputs the information about the raw key \naction. This information\u2014the row and column of the key\u2019s position on the keyboard \nand whether it was pressed or released\u2014is stored in a temporary buffer. In a PDA \nor PC, there may be a special keyboard controller chip that saves the key action \ninformation and then sends an interrupt to the processor. The processor may have its \nown keyboard device controller in addition to the controller chip on the keyboard. \nThe interrupt causes the CPU to stop the process that is running. This may be done \nimmediately if the CPU is doing lower priority work, or it may be done later if the \nCPU had been doing higher priority work. Then an interrupt service routine is started \nby the OS to handle the keyboard action. The interrupt service routine is a part of the \ninterrupt handling and device control in the OS. This processing is repeated for each \ncharacter typed. The character must be sent to the editor process and displayed on \nthe screen\u2014another action that goes through the OS. In this case, an output opera-\ntion to the video monitor is performed. \n When our user finishes typing his note, he saves his note as a file. This may involve \nmoving a pointing device such as a mouse to point to the file menu on the screen. The \nmouse movement and clicking are handled first by a device controller\u2014which tracks \nthe mouse coordinates and sends them to the OS. The mouse tracking icon (e.g., an \narrow) must be moved and displayed on the monitor display screen\u2014another output \nto the screen. When the mouse button is clicked, the controller sends that informa-\ntion to the OS, which forwards the coordinates where the clicking occurred to the \nwindowing system that is managing the user interface. The windowing system will \nhave information concerning which window is currently active and the positions of \nvarious buttons and other icons within that window. Using this information, it will \nmatch the coordinates of the cursor when the user clicked the mouse button to the \nparticular screen button icon (or symbol) that was \u201cclicked.\u201d The windowing system \nthat handles user interaction is usually quite complex. It is considered by some to be \na  systems program,  separate from the OS, and by others to be an integral part of the \nOS (see  Section 2.7 for a discussion on what is and is not part of the OS). \nelm49810_ch02_019-044.indd   21\nelm49810_ch02_019-044.indd   21\n12/10/08   9:27:34 PM\n12/10/08   9:27:34 PM\n",
        "category": "Category"
    },
    {
        "id": "129",
        "title": "Title for Chunk 129",
        "content": "Confirming Pages\n22 \nPart 1 Operating Systems Overview and Background\n Continuing with our scenario, our user may now choose a directory called \u201cpersonal \nnotes\u201d within which he wants to store his file. This brings into play the  file management \ncomponent of the OS. When the user selects the directory (e.g., by double-clicking on a \nfolder icon), this causes the OS file manager to take several actions. First, it must open \nthe directory by retrieving the directory information from the OS internal tables. The \ndirectory information includes the names of files (and possibly other directories) stored \nunder this directory as well as where the directory is stored on disk. The user must then \ntype a file name such as \u201cconcert _remind,\u201d  and the file system will check to make sure \nthat no existing file in that directory has the same name. It may then invoke the disk \nspace allocation module to find an area of free space on disk to store the file. Finally, the \nOS file manager will create a file entry in the directory to contain the information about \nthe new file such as its name, file type, and disk location. \n As we can see from this very simple example, the OS is involved in practically \nevery aspect of user and program interaction\u2014from low-level actions such as pro-\ncessing keyboard strokes and mouse movements, to resource allocation algorithms \nsuch as allocating memory space and processor time, to higher-level actions such as \nmanaging file names and directories. We describe how the OS handles all these vari-\nous tasks throughout this book. \n 2.2 RESOURCES MANAGED BY THE OS AND MAJOR \nOS MODULES \n A major role of an OS is the management of the system resources, so this section \ncovers the main types of resources that the OS manages. Then it covers a conceptual \nview of a typical OS, showing the major OS modules, the resources that each module \nmanages, and the services and functions that each module provides. \n 2.2.1 Types of resources managed by an OS \n This section first addresses some of the major resources managed by a typical OS. \nThese resources are CPUs (processors), main memory and caches, secondary stor-\nage, and I/O devices at the lowest level, and file system and user interface at a higher \nlevel. The OS also manages network access and provides security to protect the vari-\nous resources it is managing. \n CPU  \nThe OS needs to schedule which process to run on each CPU at any point in time. \nIn older single-process systems, this is very simple because only one process will be \nmemory resident so the OS would mainly be responsible for starting the memory-\nresident process by giving it control of the CPU. However, even in such a simple sys-\ntem, the OS must do other tasks such as setting up any memory protection registers \nand switching to user execution mode before giving the process control of the CPU. \n In multitasking systems, managing the CPU resource is quite complex since \nmultiple processes will be memory resident. It may be further complicated by having \nmultiple CPUs in the system. The OS will maintain various queues of processes. The \nqueue most relevant to CPU scheduling is called the  ready queue, which  contains all \nelm49810_ch02_019-044.indd   22\nelm49810_ch02_019-044.indd   22\n12/10/08   9:27:34 PM\n12/10/08   9:27:34 PM\n",
        "category": "Category"
    },
    {
        "id": "130",
        "title": "Title for Chunk 130",
        "content": "Confirming Pages\n \nChapter 2 Operating System Concepts, Components, and Architectures \n23\nprocesses that are ready to execute. If processes have different priorities a  separate \nready queue may exist for each priority level. Each process is typically given control \nof the CPU for a maximum period of time, called a  time quantum. If the time quan-\ntum expires before the process finishes execution, a timer interrupt would initiate \nan OS process called  context switching that would switch CPU control to another \nprocess. We discuss how the OS manages the CPU resource and CPU scheduling \nalgorithms in detail in Chapter 9. \n Main memory and caches  \nThe OS needs to assign memory space to a process before it can execute. The execut-\nable code of a program will typically be stored on hard disk (or some other secondary \nstorage medium). When a user or program wants to execute a disk-resident program, \nthe OS must locate the program code file on disk and it must allocate enough mem-\nory space to hold an initial part of the program. Since many programs are quite large, \nthe OS might load only part of the program from the disk. One of the main memory \nmanagement functions is to allocate initial memory space to a process, and perhaps \nto load additional parts of the program from disk as the process needs them. If all \nmemory space is full, the memory management module of the OS must  swap out \nsome of the memory-resident information so it can load additional portions needed \nby the process. We discuss memory management techniques in Chapters 10 and 11. \n Secondary storage  \nAnother important resource managed by the OS is secondary storage, which is typi-\ncally hard disk. Most program code files and data files are stored on hard disk until \nthere is a request to load some parts of them into main memory. Whenever a process \nrequires data or code that are not in memory, a request is sent to the disk schedul-\ning module of the OS. The OS would typically suspend the requesting process until \nthe required data are read into memory. In a multitasking system, there could be \nmany requests to read (load into memory) and write (store to disk) disk data. The \nOS typically maintains one or more queues for the disk read and write requests, and \nuses various algorithms to optimize the servicing of these requests. We discuss disk \nscheduling in Chapter 14 as part of our discussion of I/O management. \n I/O devices  \nThe OS must also control and manage the various input and output devices con-\nnected to a computer system.  4 The OS will include modules called  device drivers \nthat control access to these devices. Since there are many different types of I/O \ndevices and users often add new I/O devices to their systems, modern OSs have the \ncapability to detect new hardware and install the appropriate device drivers dynami-\ncally. A device driver handles low-level interaction with the device controllers, and \npresents a higher-level view of the I/O devices to the rest of the OS. That way, the OS \ncan handle similar devices in an abstract, uniform way. We discuss I/O management \nin Chapter 12. \n 4 It is not uncommon to consider disk management as part of I/O management since both disks and I/O \ndevices either input (read) or output (write) bytes to/from main memory. \nelm49810_ch02_019-044.indd   23\nelm49810_ch02_019-044.indd   23\n12/10/08   9:27:35 PM\n12/10/08   9:27:35 PM\n",
        "category": "Category"
    },
    {
        "id": "131",
        "title": "Title for Chunk 131",
        "content": "Confirming Pages\n24 \nPart 1 Operating Systems Overview and Background\n File systems  \nThe resources discussed so far are considered low level because they are all hardware \nresources. The OS also manages higher-level resources that are created through software. \nOne of the main such resources is the  file system. The file system is an OS module that \nprovides a higher-level interface that allows users and programs to create, delete, mod-\nify, open, close, and apply other operations to various types of files. The simplest type of \nfile is just a sequence of bytes. More complex file structures are possible\u2014for example, \nstructuring file contents into records. The file system allows users to give names to files, \nto organize the files into directories, to protect files, and to access those files using the \nvarious file operations. We discuss file management in more detail in Chapter 12.  \n User interfaces  \nMany modern OSs include another high-level component to handle user interaction. \nThis includes the functionality for creating and managing windows on a computer \nscreen to allow users to interact with the system. By having such a component in the \nOS, the user can access various resources in a uniform way. For example, access to the \ndirectory of the file system or to Internet documents would be handled through a uni-\nform interface. 5 We discuss user interfaces in various chapters throughout the book.  \n Network access  \nAnother resource that the OS manages is network access to allow users and programs \non one computer to access other services and devices on a computer network. An OS \ncan provide both low- and high-level functionality for network access. An example \nof low-level functionality is the capability given to a program to create network ports \nand to connect to a port on another machine. An example of high-level functionality \nis the capability to access a remote file. We will discuss networks and distributed \nsystems in Chapters 15 and 17. \n Providing protection and security  \nThe OS also provides mechanisms to protect the various resources from unauthor-\nized access, as well as security techniques to allow the system administrators to \nenforce their security policies. The simplest type of security is access authorization \nthrough passwords, but generally this is not sufficient. We will discuss security and \nprotection in Chapter 16. \n 2.2.2 Major modules of an OS \n Figure 2.1  is an illustration of some of the major modules of an OS at an abstract level. \nNot surprisingly, many of these modules correspond closely to the resources that are \nbeing managed. Other modules provide common support functions used by several \nother modules. The modules provide functions that are accessed by system users and \nprograms as well as by the other OS modules. Some functionality is restricted so that \nit can only be accessed in privileged mode by other OS modules\u2014for example, device \n5 As we mentioned earlier, user interfaces are sometimes considered to be part of the systems programs \nrather than an integral part of the OS. \nelm49810_ch02_019-044.indd   24\nelm49810_ch02_019-044.indd   24\n12/10/08   9:27:35 PM\n12/10/08   9:27:35 PM\n",
        "category": "Category"
    },
    {
        "id": "132",
        "title": "Title for Chunk 132",
        "content": "Confirming Pages\n \nChapter 2 Operating System Concepts, Components, and Architectures \n25\ndriver functions are often restricted to OS access. Other functionality is available to \nOS modules, users, and application programs\u2014for example, file system functions. \n   In  Figure 2.1 , we do not show how the OS modules interact with one another. \nThis is because the types of interactions depend on the particular architecture used \nto implement the OS. For example, in a  layered architecture, the modules would be \nseparated into layers. Generally, modules at one level would call the functions pro-\nvided by the modules at either the same level or at lower levels. On the other hand, \nin an  object-oriented architecture, each module would be implemented as one or \nmore objects with services, and any object can invoke the services provided by other \nobjects. In a  monolithic architecture, all modules would be implemented as one \ngiant program. We discuss the most common OS architectures in a later section. \n 2.3 THE PROCESS CONCEPT AND OS PROCESS INFORMATION \n We now introduce the concept of a process, as it is central to presenting OS concepts. \nFirst, we define what a process is, and describe the various states that a process can \ngo through and the types of events that cause process state transitions. Next, we dis-\ncuss the types of information that an OS must maintain on each process in order to \nmanage processes and resources. We also introduce the concept of a PCB (process \ncontrol block), the data structure that the OS maintains to keep track of each process. \nFinally, we categorize various types of processes. \n 2.3.1 Process definition and process states \n A  process is a running or executing program. To be a process, a program needs to \nhave been started by the OS. However, a process is not necessarily running all the \ntime during its existence\u2014for example, it may be waiting for I/O (say, a key to be \npressed) or it may be waiting for the OS to assign it some resource (say, a block of \nRAM). Every process has a particular sequence of execution, and hence a  program \ncounter that specifies the location of the next instruction to be executed. It will also \nhave various resources allocated to it by the OS. For example, it will need some \n memory space in which to store all or part of its program code and data (such as \nDevice\nDrivers\nHigher-Level\nModules\nCPU\nScheduling\nMemory/Cache\nManagement\nI/O\nManagement\nDisk\nScheduling\nNetwork\nManagement\nLower-Level\nModules\nProcess\nManagement\nFile\nManagement\nGUI\nManagement\nSecurity and\nProtection\nFIGURE 2.1 The major OS modules.\nelm49810_ch02_019-044.indd   25\nelm49810_ch02_019-044.indd   25\n12/10/08   9:27:35 PM\n12/10/08   9:27:35 PM\n",
        "category": "Category"
    },
    {
        "id": "133",
        "title": "Title for Chunk 133",
        "content": "Confirming Pages\n26 \nPart 1 Operating Systems Overview and Background\nprogram variables). It will almost certainly be accessing files, so it will probably \nhave some  open files associated with it. A process has also been called a  job 6 or a \n task, and we use these terms interchangeably. \n Once a process is created, it may be in one of several states:  running (if it has \ncontrol of the CPU),  ready to run (if other processes currently are using all of the \nCPUs),  waiting (for some event to occur), and so on. The typical states that a pro-\ncess can go through are illustrated in  Figure 2.2 , which is called a  state transition \ndiagram. The  nodes (shown as hexagons) in  Figure 2.2 represent  process states, \nand the  directed edges (arrows) represent  state transitions. We now discuss these \nstates, and the events that cause state transitions. 7 \n State transition 0 (zero) creates a new process, which can be caused by one of \nthe following events:\n 1. A running OS process may create or spawn a new process. For example, when \nan interactive user logs onto a computer system, the OS process that handles \nlogins typically creates a new process to handle user interaction and commands. \nThe OS may also create new processes to handle some OS functions such as an \ninterrupt handler or error handler process. \n 6 The term  job historically referred to a sequence of control that may invoke various tasks using a \nlanguage called  JCL, or  Job Control Language. This interpretation is primarily used in older batch \nsystems. \n 7 This state diagram is typical, but for any particular OS there may be other states that the OS designers \nwant to distinguish among, so one might see fewer or more states internally and in the documentation. \n0 - Program\nloaded\nNew\n1 - Process\ninitialized\nReady\n4 - Got what\nit needed\n2 - Gets\nCPU time\nRun\n3 - Needs\nsomething\n5 - Interrupted\n6 - Finished\nor aborted\nExit\n7 - Exits\nsystem\nWait\nFIGURE 2.2 \nSimplified diagram \nof process states \nand transitions.\nelm49810_ch02_019-044.indd   26\nelm49810_ch02_019-044.indd   26\n12/10/08   9:27:35 PM\n12/10/08   9:27:35 PM\n",
        "category": "Category"
    },
    {
        "id": "134",
        "title": "Title for Chunk 134",
        "content": "Confirming Pages\n \nChapter 2 Operating System Concepts, Components, and Architectures \n27\n 2. A user process may also create another process by calling the OS function for \nnew process creation. For example, a Web browser might create a new process \nto run an external \u201cplug-in\u201d module to handle a particular type of multimedia \ncontent accessed on a website. \n 3. When a job is started by the OS as a scheduled event (e.g., a \u201ccron\u201d job on a \nUNIX system), the OS creates a process to execute that job. \n As a new process is being created, it is in the  new state. The OS must build the table \nthat will hold information about the process (see  Section 2.2.2 ), allocate necessary \nresources (e.g., memory to hold the program), locate the program executable file and \nany initial data needed by the process, and execute the appropriate routines to load \nthe initial parts of the process into memory. State transition 1 in  Figure 2.2  shows \nthat the OS moves a process from the new state to the  ready state, which indicates \nthat the process is now ready to execute. Note that before this transition can occur \nthe OS must be ready to add a new process\u2014for example, some OSs may have a \nmaximum number of allowed processes at a given time and hence would not permit \na new process to be added if the maximum is already reached. In a large mainframe \nsystem or cluster system there might also be resource requirements that the job must \nhave available before it can run\u2014perhaps a specific I/O device or a certain number \nof CPUs. After all this initialization has occurred, the process can be moved to the \nready state. \n Even after a process is in the ready state, it does not start executing until the \nOS gives it control of the CPU. This is state transition 2 in  Figure 2.2 . The process \nis now executing, and is in the  running state. If there is more than one process in \nthe ready state, the part of the OS that chooses one of those to execute is called \nthe  CPU scheduler or  process scheduler.  We discuss process scheduling in detail in \nChapter 9. \n If a process executes until its end or has an error or exception that causes the \nOS to abort it, these events\u2014a process reaching its end or having a fatal error\u2014will \ncause state transition 6 in  Figure 2.2 . This leads a process to the  terminated state, at \nwhich point the OS will do cleanup operations on the process\u2014for example, delete \nthe process information and data structures and free up the process memory and \nother resources. When this cleanup is completed, this indicates state transition 7 in \n Figure 2.2 , which causes the process to exit the system. \n Two other state transitions may occur when a process is in its running state\u2014\ntransitions 3 and 5 in  Figure 2.2 . State transition 3 occurs if the process requires \nsome resource that is not available or if it needs some I/O to occur\u2014for example, \nwaiting for a keystroke or reading from a file\u2014before it can continue processing. \nThis leads a process to the  wait or  blocked state. A process remains in the wait \nstate until the resource it needs is allocated to it or its I/O request is completed, at \nwhich point state transition 4 occurs to move the process from the wait state back \nto the ready state. On the other hand, state transition 5 from running state directly \nto ready state typically occurs when the OS decides to suspend the process because \nit has more urgent processes to run. This may be because of a timer or some other \nkind of interrupt, which can occur for various reasons. The most common reason is \nto allocate the CPU to another process because of the CPU scheduling algorithm, as \nwe describe in Chapter 8. \nelm49810_ch02_019-044.indd   27\nelm49810_ch02_019-044.indd   27\n12/10/08   9:27:36 PM\n12/10/08   9:27:36 PM\n",
        "category": "Category"
    },
    {
        "id": "135",
        "title": "Title for Chunk 135",
        "content": "Confirming Pages\n28 \nPart 1 Operating Systems Overview and Background\n 2.3.2 Process information maintained by the OS \n To keep track of a process, the OS typically assigns to it a unique  process identifier \n(or  process ID ). It also creates a data structure called a  process control block (or \n PCB ) to keep track of the process information, such as the process ID, resources it \nis using or requesting, its priority, its access rights to various system resources or \nfiles, and so on. The PCB will also include references to other OS data structures that \ninclude information on how to locate the memory space and open files being utilized \nby the process. For processes not in the running state, the PCB will save informa-\ntion on the hardware  processor state for the process, such as the values stored in the \nprogram counter register and other processor registers. This information is needed \nto restart the process when it moves back to the running state.  Figure 2.3  illustrates \nsome of the information that is typically kept in a process control block. \n The information on open files that the process is using is typically kept in a \nseparate OS data structure, which is created and used by the OS file manager module \n(see Chapter 12). The information on which areas of memory are occupied by the \nprocess is usually kept in page tables or limit registers that are created and used by \nthe OS memory management module (see Chapters 10 and 11). Both these tables are \nreferenced from the PCB data structure. Additional information, such as the process \npriority level, and a reference to the security or protection levels of the process (see \nChapter 16) will also be included in the PCB. \n 2.3.3 Types of processes and execution modes \n We can categorize processes into several types:\n 1. User or application processes. These are processes that are executing applica-\ntion programs on behalf of a user. Examples include a process that is running an \naccounting program or a database transaction or a computer game. \nUnique process identifier\nProcess priority information\nProcessor state\n(CPU register contents,\ncurrent instruction location)\nPointer to data structure to access process\nmemory (typically page tables or limit registers)\nPointer to data structure to access process\nfiles (usually called open files table)\nOther process information\nProcess security and authorization information\nFIGURE 2.3 \nInformation the \nOS maintains in \na process control \nblock.\nelm49810_ch02_019-044.indd   28\nelm49810_ch02_019-044.indd   28\n12/10/08   9:27:36 PM\n12/10/08   9:27:36 PM\n",
        "category": "Category"
    },
    {
        "id": "136",
        "title": "Title for Chunk 136",
        "content": "Confirming Pages\n \nChapter 2 Operating System Concepts, Components, and Architectures \n29\n 2. Systems program processes. These are other application programs that perform \na common system service rather than a specific end-user service. Such programs \noften interact closely with the OS and need special information about interfaces \nand system structures such as the layout of a relocatable program module or an \nexecutable program file. Examples include programming language compilers \nand program development environments. Other programs such as Internet brows-\ners, windowing user interfaces, and OS shell programs are considered by some to \nbe in this category, and by others to be part of the OS itself (see  Section 2.7 ).  \n 3. OS processes. These are also known as daemons and are processes that are exe-\ncuting OS services and functions. Examples include memory management, pro-\ncess scheduling, device control, interrupt handling, file services, and network \nservices. \n Almost all processors have two execution modes for processes: privileged mode \nand nonprivileged or regular (user) mode. OS kernel processes typically execute \nin  privileged mode \u2014also known as  supervisor mode, kernel mode, or  monitor \nmode \u2014allowing them to execute all types of hardware operations and to access all \nof memory and I/O devices. Other processes execute in  user mode, which prohibits \nthem from executing some commands such as low-level I/O commands. User mode \nalso brings in the hardware memory protection mechanism, so that a process can \nonly access memory within its predefined memory space. This protects the rest of \nmemory\u2014used by the OS and other processes\u2014from erroneous or malicious access \nto their memory space that may damage their data or program code. \n 2.4 FUNCTIONAL CLASSES OF OSs \n There are many different types of OSs. Some OSs are quite restricted and provide lim-\nited services and functions, whereas other OSs are very complex, and provide many \nservices and a wide range of functionality. We now give a brief overview of five types \nof OSs: single-user, multitasking, time-sharing, distributed, and real-time systems.  \n 2.4.1 Single-user single-tasking OS \n A  single-user  single-tasking OS runs a single process at a time. The first OSs were \nof this type, as were OSs for early personal computers such as CP/M and earlier ver-\nsions of MS-DOS. Similar OSs may be found today in systems with limited resources \nsuch as embedded systems. Such an OS is not as complex as the other OSs we discuss \nbelow. However, there are still a lot of details and issues that it must handle. The main \nservices it provides would be handling I/O and starting and terminating programs. \nMemory management would be fairly simple since only the OS and one process \nreside in memory at any particular time. There would be no need for CPU schedul-\ning. Following our spiral approach, we describe the basic services and functionality \nprovided by a single-user OS in Chapter 3. We use primarily CP/M as an example to \nillustrate how these concepts were implemented in a real system. We also mention \nMS-DOS from time to time since it dominated the OS market for quite some time.  \nelm49810_ch02_019-044.indd   29\nelm49810_ch02_019-044.indd   29\n12/10/08   9:27:36 PM\n12/10/08   9:27:36 PM\n",
        "category": "Category"
    },
    {
        "id": "137",
        "title": "Title for Chunk 137",
        "content": "Confirming Pages\n30 \nPart 1 Operating Systems Overview and Background\n 2.4.2 Multitasking OS \n The next level in OS complexity is a  multitasking or  multiprogramming OS. \nSuch an OS will control multiple processes running concurrently. Hence, it must \nhave a CPU scheduling component to choose which of the ready processes to run \nnext. The majority of modern-day computers support multitasking. One of the ini-\ntial reasons for creating multitasking OSs was to improve processor utilization by \nkeeping the CPU busy while I/O is performed. In a single-tasking system, if the \nsingle running process requests I/O and needed to wait for the operation to com-\nplete, then the CPU would remain idle until the I/O request was completed. By hav-\ning several processes ready to execute in memory, the CPU can switch to running \nanother process while I/O is performed. Changing from running one process to run-\nning another is known as  context switching. But there is a high cost for a context \nswitch. The entire CPU state must be saved so that it can be restored when the pro-\ncess is later restarted. Basically, when a running process\u2014say process A\u2014requests \nI/O that can be handled by an I/O controller, the OS CPU scheduler module would \ncheck to see if there are any processes in the ready state. If there are, one of the \nready processes\u2014say, process B\u2014will be selected based on the CPU scheduling \nalgorithm. The OS will save the processor state of process A (in A\u2019s PCB) and load \nthe processor state of process B (from B\u2019s PCB) into the appropriate CPU registers. \nThe OS will then give control of the CPU to process B, which moves to the running \nstate, while process A moves to the waiting (or blocked) state until the I/O opera-\ntion is complete. \n Multitasking is now available in most computer OSs, including personal com-\nputers. Even though a PC typically has a single interactive user, that user can \ncreate multiple tasks. For example, if there are multiple windows on the display \nscreen, each is often handled by a separate task or process. In addition, other tasks \nmay be running in the background. Some early multitasking OSs could handle \nonly batch jobs\u2014which were loaded on disk in bulk through card readers or other \nold-fashioned I/O devices. Many current systems handle both batch jobs and inter-\nactive jobs. Interactive jobs are processes that handle a user interacting directly \nwith the computer through mouse, keyboard, video monitor display, and other \ninteractive I/O devices. \n We can further distinguish between two types of multitasking OSs: those that \nusually interact with a  single user and those that support  multiple interactive users. \nSingle-user multitasking systems include most modern PCs that support windowing. \nIn such systems it is common that one user is interacting with the system but that the \nuser may have several tasks started simultaneously. For example, the user may have \nan email program, a text editor, and a Web browser, all open at the same time, each in \na separate window. The task that has the current user focus is called the foreground \ntask, while the others are called background tasks. The other type of multitasking \nsystem handles multiple interactive users concurrently, and hence is called a time-\nsharing OS. We discuss these next. \n In our spiral approach part we describe two examples of single-user multitasking \nOSs: an OS for a handheld Palm Pilot device in Chapter 4 and the Mac OS from Apple \nin Chapter 5.  \nelm49810_ch02_019-044.indd   30\nelm49810_ch02_019-044.indd   30\n12/10/08   9:27:36 PM\n12/10/08   9:27:36 PM\n",
        "category": "Category"
    },
    {
        "id": "138",
        "title": "Title for Chunk 138",
        "content": "Confirming Pages\n \nChapter 2 Operating System Concepts, Components, and Architectures \n31\n 2.4.3 Time-sharing OS and servers \n A  multiuser or  time-sharing OS also supports multitasking, but a large number of the \ntasks (processes) running are handling users interacting with the machine. These were \ncalled time-sharing systems because the computer time was \u201cshared\u201d by the many \ninteractive concurrent users. In terms of OS internals, the main difference between \ninteractive and batch processes is in their response requirements. Interactive jobs typi-\ncally support many short interactions, and require that the system respond rapidly to \neach interaction. But quick response to interactive users\u2019 requirements calls for a high \nlevel of context switching and this introduces a lot of nonproductive overhead. Batch \njobs, on the other hand, have no live user so rapid response is not a requirement. \nTherefore, less context switching is needed and more time is spent on productive \ncomputing. A time-sharing OS will support both interactive and batch jobs and will \ntypically give higher priorities for interactive jobs. Early time-sharing systems in the \n1960s and 1970s, such as IBM\u2019s OS 360 TSO  8 and Honeywell\u2019s MULTICS, sup-\nported large numbers of interactive users, which were all logged in to the same system \nthrough dumb monitors and terminals. This was because terminals cost many orders \nof magnitudes less than the computer system itself in those days. \n As the price of hardware and processors was being dramatically reduced, the \nneed for time sharing declined. In modern computing the new generation of systems \nthat can be considered to be the successors of interactive time-sharing systems are \nthe systems that are used in file, database, and Web servers.  File servers and  data-\nbase servers handle requests for file and database access from tens to thousands of \nusers. Instead of being located at dumb terminals attached to processes running on \nthe server, the users are working at PCs or workstations and the service requests are \ncoming to the server through the network. Large database servers are often called \n transaction processing systems, because they handle very many user transactions \nper second.  Web servers handle requests for Web documents, and often retrieve \nsome of the document information from database servers. Database and Web servers \nrequire OSs that can handle hundreds of concurrent processes. \n 2.4.4 Network and distributed OS \n Most computers today are either permanently connected to a network, or are equipped \nso that they can be connected and disconnected from some type of network. This \nallows information and resource sharing among multiple machines, and requires that \nthe OS provide additional functionality for these network connections. This addi-\ntional functionality can be categorized into two main levels:\n 1.  Low-level network access services. The OS will typically include additional \nfunctionality to set up network connections, and to send and receive messages \nbetween the connected machines. \n 2.  Higher-level services. Users want to be able to connect to other machines to \nbrowse through information, download files (text, pictures, songs) or programs of \n 8 OS 360 TSO stands for Operating System 360 Time Sharing Option. \nelm49810_ch02_019-044.indd   31\nelm49810_ch02_019-044.indd   31\n12/10/08   9:27:36 PM\n12/10/08   9:27:36 PM\n",
        "category": "Category"
    },
    {
        "id": "139",
        "title": "Title for Chunk 139",
        "content": "Confirming Pages\n32 \nPart 1 Operating Systems Overview and Background\nvarious types, or access databases. This is typically done through Web  browsers \nor specialized services, such as  telnet for logging on to remote machines or  ftp \nfor file transfer. As we mentioned earlier, these services are considered by some \nto be independent systems programs and by others to be part of the OS. \n The standard network protocols actually provide several levels of service, from the \nbasic hardware level to the user interaction level, as we will see in Chapter 15. Sepa-\nrately from the network connection, a distributed OS can provide a wide spectrum of \ncapabilities. A very basic distributed OS, sometimes called a  network OS, provides \nthe capability to connect from a machine where the user is logged in\u2014called the \n client \u2014to a remote machine\u2014called the  server, and to access the remote server. \nHowever, the client user must know the name or address of the specific machine \nthey want to access. Most current systems provide at least this level of service. For \nexample, telnet and ftp services fall in this category. \n At the other end of the spectrum, a completely general  distributed OS may \nallow a user logged in at a client machine to transparently access all possible services \nand files they are authorized to access without even knowing where they reside. The \nOS itself will keep directory information to locate any desired file or service, and to \nconnect to the appropriate machine. This is known as  location transparency. The \nfiles and services may be physically replicated on multiple systems so the OS would \nchoose the copy that is most easily or most efficiently accessible\u2014known as  repli-\ncation transparency. 9 The OS could also do  dynamic load balancing to choose a \nmachine that is not heavily loaded when choosing a server. Such OSs would obvi-\nously be very complicated, and hence do not yet exist except in the realm of special-\npurpose systems or research prototypes! \n Between the two ends of the spectrum, one can consider many types of distrib-\nuted OSs that can provide more than the minimum capabilities but less than the full \nwish list of capabilities. \n 2.4.5 Real-time OS \n Real-time OSs are multitasking systems that have the additional requirement of time \ndeadlines for completing some or all of their tasks. Two types of deadlines are:\n 1.  Hard deadlines. A task with a hard deadline of, say,  n milliseconds  must be \ncompleted within  n milliseconds of submission; otherwise, it would be useless \nand there may be very bad consequences for missing the deadline. Examples of \nsuch tasks include industrial control tasks in a steel mill or an oil refinery, or a \ntask in a weapons guidance system. \n 2.  Soft deadlines. A process with a soft deadline of  n milliseconds  should be \ncompleted within  n milliseconds of submission; however, the deadline may \nbe missed without catastrophic consequences. An example could be a task to \nupdate the display in a virtual reality game as the user moves about. \n Hard real-time OSs have scheduling algorithms that take into account the deadline \nof each process and its estimated running time when deciding which process to run \n 9 There are many additional transparency levels that a distributed OS can achieve; see Chapter 17. \nelm49810_ch02_019-044.indd   32\nelm49810_ch02_019-044.indd   32\n12/10/08   9:27:37 PM\n12/10/08   9:27:37 PM\n",
        "category": "Category"
    },
    {
        "id": "140",
        "title": "Title for Chunk 140",
        "content": "Confirming Pages\n \nChapter 2 Operating System Concepts, Components, and Architectures \n33\nnext. These OSs are mainly used in embedded systems that are found in devices such \nas aircraft or process control systems, where a software process that makes a crucial \ndecision must be completed within its specified deadline. Soft real-time systems, on \nthe other hand, only need to give high priority to the tasks that have been designated \nas real-time tasks. So most current OSs\u2014for example, Windows 2000 or Solaris\u2014\nprovide soft real-time support. \n Unfortunately, most of the techniques that have evolved to give smooth average \nresponse in most OSs are based on statistical decision making. These techniques will \nnot work in a hard real-time system. Such systems require unique algorithms for \nscheduling time-critical events. As a result, we will not spend much time discussing \nsuch systems. They are best treated separately. \n 2.5 ARCHITECTURAL APPROACHES TO BUILDING AN OS \n 2.5.1 Monolithic single-kernel OS approach \n The first OSs were written as a single program. This approach to building the OS is \ncalled the  kernel or  monolithic kernel approach, and was illustrated in Figure 1.3. \nAs the monolithic kernel OS included more functionality its size grew, in some cases \nfrom a few thousand bytes to many millions of bytes. With limited and expensive \nmemory, the OS size overhead (the percentage of main memory occupied by the OS) \nwas considered too large. This bloated OS not only occupied memory, but like most \nlarge programs, the OS was less efficient than a more minimal system, had more \nbugs, and was difficult to maintain, either to add features or to fix bugs. This led OS \ndesigners to develop OSs based on a more modular, layered design. \n 2.5.2 Layered OS approach \n The modular approach that was developed was a  layered architecture. The OS \nwould be divided into modules that were limited to a specific function such as pro-\ncessor scheduling or memory management. The modules were grouped into layers \nof increasing abstraction\u2014each layer provides a more abstract view of the system \nand relies on the services of the layers below it. The layered approach would hide \nthe peculiarities and details of handling hardware devices, and provide a common \nabstract view to the rest of the OS. Thus, when new devices entered the market-\nplace, new device drivers could be added to the kernel without drastically affecting \nthe other OS modules, which provide memory management, processor schedul-\ning, and the file system interface. This is illustrated in a very rudimentary way in \n Figure 2.4 . \n This approach can be extended to implement an OS with several layers. One \nvariation would allow modules at layer  n to call only the modules in the next lower \nlayer  n-1. Another variation would allow modules at layer  n to call modules at any of \nthe lower layers ( n-1,  n-2, and so on). A further variation would allow level  n modules \nto interact with other level  n modules, in addition to lower-level modules. Because \nof the difficulty of separating complex OS functionality into multiple  layers, usually \nelm49810_ch02_019-044.indd   33\nelm49810_ch02_019-044.indd   33\n12/10/08   9:27:37 PM\n12/10/08   9:27:37 PM\n",
        "category": "Category"
    },
    {
        "id": "141",
        "title": "Title for Chunk 141",
        "content": "Confirming Pages\n34 \nPart 1 Operating Systems Overview and Background\nonly two or three layers are used in practice. We examine more specific instances \nof layered designs in later chapters. Most modern OSs are built on a layered archi-\ntecture. However some OS programmers felt that the layered approach was not suf-\nficient, and that OS design should return to a minimum amount of code in the kernel \nand the concept of microkernel. \n 2.5.3 Microkernel OS approach \n The  microkernel approach is illustrated in  Figure 2.5 . Here only basic functional-\nity, usually the interfaces to the various types of device drivers, is included in the \nmicrokernel. Specifically, the only code in these modules is code that must run in \n supervisor mode because it actually uses privileged resources such as protected \ninstructions or accesses memory not in the kernel space. The remainder of the OS \nfunctions are still part of the resident OS, but they run in user mode rather than \nprotected mode. Code running in protected mode literally can do anything, so an \nerror in this code can do more damage than code running in user mode. So the \ntheory of the microkernel is that the benefits to this approach arise partly from the \nfact that the amount of code that is running in supervisor mode is smaller, making \nthem more robust. It also makes them easier to inspect for flaws. Also, the extra \ndesign effort required makes it more probable that the implementation will be cor-\nrect. Finally, it is easier to port a small microkernel to a new platform than it is to \nport a large, layered, but monolithic kernel. On the other hand, a microkernel must \nmake use of interrupts to make the necessary calls from the user mode portions \nof the OS to the supervisor mode portions. These interrupts will often necessitate \ncontext switches. Critics of the microkernel approach say that this makes a micro-\nkernel OS run more slowly. (It should be noted that this issue is not resolved in the \nOS community.) \nShell\n(Command\nInterpreter)\nUtilities\nUser Programs\n(browsers, games,\nword processing)\nMemory\nManagement\nProcessor\nScheduling\nDevice Drivers\nDevices \n(disks,\nkeyboards)\nCPU\nMemory\nFile\nSystem\nAPI\nKernel\nFIGURE 2.4 \nLayered model of \nan Operating System.\nelm49810_ch02_019-044.indd   34\nelm49810_ch02_019-044.indd   34\n12/10/08   9:27:37 PM\n12/10/08   9:27:37 PM\n",
        "category": "Category"
    },
    {
        "id": "142",
        "title": "Title for Chunk 142",
        "content": "Confirming Pages\n \nChapter 2 Operating System Concepts, Components, and Architectures \n35\n 2.6 SOME OS IMPLEMENTATION TECHNIQUES AND ISSUES \n As we discussed in  Sections 2.2  and  2.5 , an OS is a complex software system with \nmany modules and components. As with any such system, there will be many data \nstructures and algorithms implemented within a typical OS. In this section, we dis-\ncuss a few implementation techniques that are part of most or all OSs. These subjects \ninclude the normal method used for handling interrupts, queues and data structure \nused in many OS components, an object-oriented approach to OS implementation, \nand the topic of Virtual Machines. \n 2.6.1 Interrupt handling using interrupt vectors \n As we have already mentioned several times, an  interrupt is a mechanism used by \nan OS to signal to the system that some high-priority event has occurred that requires \nimmediate attention. Many interrupt events are associated with I/O. Some of these \ntypical interrupt events are signaling that a disk block read or write has been com-\npleted, signaling that a mouse button has been clicked, or signaling that a keyboard \nbutton has been pressed. As we can see, most of these interrupts correspond to some \nhardware action. The hardware associates with each interrupt event a particular inter-\nrupt number. The interrupting controller typically places this interrupt number in an \ninterrupt register when the corresponding event occurs. Depending on the particular \ntype of interrupt event, the OS has to take certain actions. The question that comes up \nis, How can the OS efficiently determine which particular interrupt event has occurred, \nand how does it start up the appropriate process that services that interrupt? \n The normal technique for interrupt handling uses a data structure called an  inter-\nrupt vector (see  Figure 2.6 ). The vector has one entry for each interrupt number. \nThat entry contains the memory address of the interrupt service routine for that type \nof interrupt. The interrupt number placed in the interrupt register is used as an index \ninto the interrupt vector. The interrupt vector entry is picked up by the hardware as \nShell\n(Command)\nInterpreter)\nUser\nMode\nAPI\nKernel\nMode\nUtilities\nUser Programs\n(browsers, games,\nword processing)\nMemory\nManagement\nProcessor\nScheduling\nMicrokernel\nFile\nSystem\nDevices \n(disks,\nkeyboards)\nCPU\nMemory\nFIGURE 2.5 \nMicrokernel model \nof an Operating \nSystem.\nelm49810_ch02_019-044.indd   35\nelm49810_ch02_019-044.indd   35\n12/10/08   9:27:37 PM\n12/10/08   9:27:37 PM\n",
        "category": "Category"
    },
    {
        "id": "143",
        "title": "Title for Chunk 143",
        "content": "Confirming Pages\n36 \nPart 1 Operating Systems Overview and Background\nan address and the hardware effectively calls the appropriate interrupt routine as a \nsubroutine. When the interrupt routine is finished it will simply return from the call, \nresuming the process that was interrupted. \n In a small embedded system with only a few I/O devices the hardware may not \nprovide an interrupt system. The alternative is known as a  status-driven system. In \nsuch a system the application (or the OS) is mostly a large loop. It will check the \nstatus of each device in turn to see whether it needs servicing. \n 2.6.2 System calls \n Application programs normally need to use data and services managed by the OS. \nFor example, OSs typically manage all the hardware devices on the system, such as \nsound cards, and applications are not allowed to access them directly. Also, applica-\ntions may need to communicate between one another and the OS has to act as an \nintermediary. \n Any normal application needs such abilities and the way it asks the OS for ser-\nvices is by using a  system call.  A system call is much like any other function call. \nFirst, the application will load certain registers with information describing the ser-\nvice required and then will execute a system call instruction. However, instead of \ndirectly calling a section of code that will do the function, the system call instruction \nwill usually cause an interrupt, which the OS will handle. The OS will perform the \nrequested service and then return control to the application. This mechanism also \nallows the OS to implement some security by first checking to see if the application \nis allowed to access the resource in the requested way. \n Generally, application development systems provide a library that loads as part \nof application programs. This library handles the details of passing information to \nthe kernel and executing the system call instruction. Having this function provided \nby the library reduces the strength of the connection between the operating system \nand the application and make the application more portable. \nInterrupt register\nIndex into interrupt vector\nInterrupt vector\nAddress of interrupt service routine 1\nAddress of interrupt service routine 2\nAddress of interrupt service routine 3\nAddress of interrupt service routine N\nFIGURE 2.6 \nAn interrupt vector \nfor handling \ninterrupts.\nelm49810_ch02_019-044.indd   36\nelm49810_ch02_019-044.indd   36\n12/10/08   9:27:38 PM\n12/10/08   9:27:38 PM\n",
        "category": "Category"
    },
    {
        "id": "144",
        "title": "Title for Chunk 144",
        "content": "Confirming Pages\n \nChapter 2 Operating System Concepts, Components, and Architectures \n37\n 2.6.3 Queues and tables \n An OS manages many data structures to accomplish its tasks. Two of the common \ndata structures used are tables and queues. Tables are used to store information about \nvarious objects that the OS manages. For example, the PCB, described in  Section \n2.2 , is an example of a table that the OS maintains to keep track of the informa-\ntion associated with each process. Another frequently found table is the  page table, \nwhich is used to keep track of the address space of a process when the hardware sup-\nports paged memory (see Chapter 11). The OS will maintain one PCB and one page \ntable for each process. Another typical table is the  open files table, which keeps an \nentry for each file open in the system. \n The OS also maintains a number of queues to keep track of information that is \nordered in some way. Each resource that can be shared by multiple processes would \nneed a queue to hold service requests for that resource. For example, since multiple \nprocesses may need to read and write disk pages, the OS maintains a  disk schedul-\ning queue that has a list of processes waiting for disk I/O. Requests for printer ser-\nvices may be maintained in a  printer queue. A list of processes that are ready to run \ncan be maintained in a  ready process queue. \n Many of these \u201cqueues\u201d are not strictly speaking queues at all since a queue is \nalways managed on a first-in-first-out (FIFO) basis. But the scheduling algorithm \nthat utilizes the queue determines the order of entries in a queue. For example, if the \npolicy of choosing which process to run next were a priority policy, the scheduler \nfor the ready process queue would implement that policy. In the FIFO case each \nnew entry is placed at the end of the queue. When the CPU needs to execute a new \nprocess, it would remove an entry from the beginning of the queue for processing. As \nwe will see, there are various ways for organizing queues depending on the particu-\nlar requirements for each type of queue. \n Each entry in a queue must contain all the information that the OS needs to \ndetermine the action that must be taken. For example, each ready queue entry may \ncontain a pointer to the PCB of a ready process. By accessing the PCB through the \npointer, the OS can retrieve the needed process information. \n 2.6.4 Object-oriented approach \n One approach to OS development is to use the principles and practices developed \nfor object-oriented software engineering and apply them to OS design and imple-\nmentation. In this approach, each OS module would be designed as a collection of \n objects and each object will include  methods that are provided as services to other \nparts of the OS or to application programs. Building the OS with objects provides the \nmany advantages of object-oriented software engineering, such as encapsulation of \nobject data structures, separating an interface from its implementation, extensibility \nand ease of reuse of objects, and many other advantages. In simpler terms, the key \nfeature of an object is that the internal structure of an object is hidden and any access \nto the data contained in an object is through the methods of the object. This makes \nit less likely that an application can misuse an object and cause problems for other \nmodules. \nelm49810_ch02_019-044.indd   37\nelm49810_ch02_019-044.indd   37\n12/10/08   9:27:38 PM\n12/10/08   9:27:38 PM\n",
        "category": "Category"
    },
    {
        "id": "145",
        "title": "Title for Chunk 145",
        "content": "Confirming Pages\n38 \nPart 1 Operating Systems Overview and Background\n There have been several attempts at making an OS that is object oriented, most \nnotably the NEXTSTEP OS from NeXT and BeOS from Be Inc. A few research \nprojects have created\u2014most notably Choices, Athene, Syllable, TAJ, and JNode\u2014\nan OS written in Java. But it seems that there is no major OS that is truly based on \nobjects. Usually a kernel module is written in C or assembler and a library provides \nan API of object-oriented interfaces that can be invoked in most high-level languages \nthat provide support for objects. Windows NT is typical of such OSs. Data structures \nthat are internal to a single module are not objects. \n 2.6.5 Virtual machines \n Yet another approach to OS design is the technique of using a software emulator for \nabstracting or  virtualizing a total system (devices, CPU, and memory). This concept \nis referred to as a  virtual machine ( VM ). One prime reason for VMs is that it allows \nthe different emulation environments to be protected from one another so that a crash \nin one program does not crash others. The system design being abstracted can be \neither an actual hardware design or an idealized application virtual machine. \n Hardware virtual machines  \nIn this approach, a program or kernel subsystem will provide a software emulation of \nan actual hardware machine. There are two different sorts of such emulation, one in \nwhich the host hardware system itself is being emulated and another where another \nCPU is being emulated. The latter sort was traditionally developed by a manufac-\nturer to assist the migration of customers from an older system to a newer one by \nproviding a program that would emulate the older system. Various emulation pack-\nages were created by IBM, for example, to help customers migrating from the 1401 \nsystems, then in common use, to the 360 series. In such cases the emulation is usu-\nally done by an application program running in user mode. \n Emulation of the host machine is often used to allow multiple OS kernels to \nrun simultaneously, as illustrated in  Figure 2.7 . In such cases the emulation is done \nby the kernel of a special  host OS. This model allows one or more OS kernels \nto run on top of a virtual machine layer as  guest OSs. The VM layer creates an \ninterface that abstracts the hardware, so that each kernel believes that it alone is \nrunning on the hardware. Kernels may be from different OSs or may be different \ninstances of the same OS.  10 One of the prime difficulties in the VM model is to cre-\nate a VM that accurately emulates the hardware\u2014so that kernels may run on a VM \nthe same way they ran directly on the real hardware (only slower, because they are \nactually sharing the hardware with other kernels). One of the first, if not  the first, \nsuch emulation packages was created by IBM for a modified version of the 360 \nmodel 40 and was known as CP-40. It ran multiple instances of client operating \nsystems\u2014particularly CMS, the Cambridge Monitor System. That early package \nhas been reimplemented several times and the current version,  z/VM,  runs on their \nz9 series of mainframes. \n 10 In fact, the VM concept was created in part (by IBM) to allow OS programmers to test a kernel, since \neven if the kernel being debugged crashed, other kernels would continue to run. \nelm49810_ch02_019-044.indd   38\nelm49810_ch02_019-044.indd   38\n12/10/08   9:27:38 PM\n12/10/08   9:27:38 PM\n",
        "category": "Category"
    },
    {
        "id": "146",
        "title": "Title for Chunk 146",
        "content": "Confirming Pages\n \nChapter 2 Operating System Concepts, Components, and Architectures \n39\n   VM systems are becoming quite common now. As one can easily imagine, having \none OS run on top of another OS is not terribly efficient. So contemporary VM OSs \nare usually running a slightly modified version of the guest OS that is aware that it is \nrunning in a VM environment and does things in a slightly different way so that the \nVM emulation can be more efficient. In addition, newer CPUs often have additional \ninstructions and other features that assist in virtualization.  \n Application virtual machines  \nIt is now common to apply the term  virtual machine (VM) to any software that \ncreates an abstraction of a machine. Sometimes the machine being emulated is not \nan actual CPU but rather is an idealized machine specification designed to support \neither a specific language or a broad class of languages. Such systems are some-\ntimes known as  application virtual machines. One early such design was known \nas the  p-code system and was designed by the University of California San Diego \nto support their Pascal system. A VM that is currently very popular is the  Java vir-\ntual machine ( JVM ), which creates an abstract machine that runs Java programs. \nSometimes the JVM runs as a separate package that enables the execution of Java \nprograms. In other cases the VM emulation may be internal to another program \nsuch as a Web browser. In such cases the Java programs are more restricted in what \nthey are allowed to do. Another such package is the  Common Language Runtime \n( CLR ) created by Microsoft for support of their .net architecture. In this case the \nabstract machine was designed for supporting a broad class of languages rather than \na single language. \n Since emulation of a virtual machine can be somewhat inefficient, code created \nto run in an application virtual machine can usually also be compiled into native \nDevices\n(disks, keyboards)\nMemory\nCPU\nVirtual Machine\nShell, \nUtilities,\nor\nPrograms\nShell, \nUtilities,\nor\nPrograms\nShell, \nUtilities,\nor\nPrograms\nKernel 1\nKernel 2\nKernel 3\nFIGURE 2.7 \nA hardware virtual \nmachine.\nelm49810_ch02_019-044.indd   39\nelm49810_ch02_019-044.indd   39\n12/10/08   9:27:38 PM\n12/10/08   9:27:38 PM\n",
        "category": "Category"
    },
    {
        "id": "147",
        "title": "Title for Chunk 147",
        "content": "Confirming Pages\n40 \nPart 1 Operating Systems Overview and Background\nmachine code so that it will run faster. This technique is known as  just-in-time \n compilation, or  JIT. The binary code produced by JIT compilation is normally dis-\ncarded after execution but it can also be saved permanently for later reuse. \n 2.7 MINIMALIST VERSUS MAXIMALIST APPROACHES \nTO OS FUNCTIONALITY AND BACKWARD COMPATIBILITY \n We conclude this chapter with a discussion on what functionality should be included \nin the OS. In other words, what exactly should the OS do? That is a big question. \nLet us take a somewhat philosophical look at it. At one end of the spectrum is the \n minimalist philosophy\u2014only those things that really must go into the kernel (or \nmicrokernel) are included in the OS. Other components may be added into library \nroutines or as \u201cuser\u201d programs (not part of the kernel, but usually not written by the \nuser). At the other end of the spectrum is the  maximalist philosophy\u2014to put most \nof the commonly used services in the OS. For example, if a maximalist philosophy \nwere adopted, a service such as screen window management would be included in \nthe OS kernel, since almost everyone uses this service. \n Minimalists argue that their approach allows each user to choose what they \nwant. For example, a user may pick from a large group of window managers, and in \nfact may pick two or more if desired. This makes it easier to select components and \nbuild the desired configuration. A user may even write new components. Minimalists \nalso argue that this approach makes the OS modules easy to design and program, \nand easier to debug. They often say that the resulting system is more \u201celegant\u201d or \n\u201ccleaner.\u201d \n Maximalists will counterargue that user choice in some fundamental areas is a \nproblem\u2014it is  too flexible. They say a common  \u201clook and feel\u201d for common appli-\ncations functions such as scroll bars, menus, and moving a cursor allow for a more \nconsistent usage and more satisfied users. This makes it easier for users to know the \nbasics of how applications work and creates consistency among applications. They \ncontend that common functions such as drawing on a screen, moving a mouse, and \nmenus, are used by almost every application program and should be accomplished in \none place efficiently and consistently\u2014the OS. They will claim that some functions \nmay be done more efficiently in the OS and other functions\u2014for example, security \nfeatures\u2014 must be done in the kernel. \n In reality very few OSs really are minimalist or maximalist\u2014as in most argu-\nments the choice is made by a big dose of the \u201creal world\u201d injected into the dis-\ncussion. For example, if we examine OSs for handheld small computers (personal \ndigital assistants), many of these real-world issues affect the design choices. These \nissues include very limited memory, and hence making as many functions available \nin the OS as possible in order to use less memory in the applications by sharing \nroutines. Another issue was to make a common look and feel, but to include only the \nmost commonly needed routines so that not everyone needs to pay the price of extra \nmemory use for infrequently used services. \nelm49810_ch02_019-044.indd   40\nelm49810_ch02_019-044.indd   40\n12/10/08   9:27:39 PM\n12/10/08   9:27:39 PM\n",
        "category": "Category"
    },
    {
        "id": "148",
        "title": "Title for Chunk 148",
        "content": "Confirming Pages\n \nChapter 2 Operating System Concepts, Components, and Architectures \n41\n 2.7.1 Backward compatibility \n One last issue, that of backward compatibility, is the price of success. This issue \nhas caused more difficulty for OS system designers and implementers than can pos-\nsibly be imagined.  11  Backward compatibility is the ability to run old application \nprograms on newer versions of the OS. This ability is a selling point of almost every \nnew version of any OS\u2014in fact, even new OSs that have  no previous versions may \nclaim to be able to run applications done for  other (popular) OSs without change\u2014\n transparently. Note that this means that the executable program (the binary code) \nmust run unchanged on the new system. \n Some systems claim that the new system is \u201csource code compatible\u201d\u2014that the \nsource code for the application must be recompiled, but not necessarily changed, to \nmove from old to new system. This does not help someone who purchased a program \nand has only the executable! Not only does this require that every new version of the \nOS contain all services in the previous versions\u2014they must work the same way, even \nthough newer services doing the same or similar things may be more efficient and \nmore secure. One of the most horrible problems is that even bugs\u2014those that may \nhave been discovered\u2014must remain since some applications may have taken advan-\ntage (used features!) of those bugs. For example, a famous bug in Microsoft DOS \nthat allowed one to truncate the size of a file\u2014make a file size  shrink \u2014has remained \nfor decades in many versions of the OS\u2014even through Windows\u2014because in the \noriginal \u201cbuggy\u201d version, there was no other way to truncate files. It had been fixed \nin a version soon afterward, but to allow compatibility with already existing execut-\nable, it was fixed as an extension\u2014a new service. The old service remained \u201cbuggy.\u201d \n(Compatibility issues are sometimes hidden under the famous statement: \u201cIt\u2019s not a \nbug\u2014it\u2019s a feature!\u201d)  \n 2.7.2 User optimization versus hardware optimization \n One final point: Personal computers have stood the traditional goals of OSs on their \nhead. Until PCs came along, one of the chief goals of an OS was to optimize the \nutilization of a bunch of very expensive hardware. This meant using every bit of \nexpensive memory (leading to the infamous Y2K bug), every instruction cycle of the \nslow CPU, and every sector of the limited-capacity, expensive disk drive. Once the \nlevel of integration of the circuitry made it fairly cheap to produce a personal com-\nputer, the most expensive part of the total system became the unit sitting in front of \nthe monitor, not the unit sitting behind it. This means that the OS needs to be very \nresponsive to the keyboard and to update the screen displays as fast and as smoothly \nas possible, even if that means using the CPU in a less efficient manner. GUIs are a \ngood example. They would most likely be much less common if we were still using \nonly mainframe systems that cost a million dollars each. \n 11 After all, how difficult is it just to leave old code in the system? \nelm49810_ch02_019-044.indd   41\nelm49810_ch02_019-044.indd   41\n12/10/08   9:27:39 PM\n12/10/08   9:27:39 PM\n",
        "category": "Category"
    },
    {
        "id": "149",
        "title": "Title for Chunk 149",
        "content": "Confirming Pages\n42 \nPart 1 Operating Systems Overview and Background\n BIBLIOGRAPHY \n Bach, M. J.,  The Design of the UNIX Operating System. \nEnglewood Cliffs, NJ: Prentice Hall, 1986. \n Beck, M. et al.,  Linux Kernel Programming, \n3rd ed., Reading, MA: Addison-Wesley, 2002. \n Hayes, J. P.,  Computer Architecture and Organization. \nNew York: McGraw-Hill, 1978. \n Lewis, R., and B. Fishman,  Mac OS in a Nutshell. \nSebastopol, CA: O\u2019Reilly Media, 2000. \n Russinovich, M. E., and D. A. Solomon,  Microsoft \nWindows Internals, 4th ed. Redmond, WA: Microsoft \nPress, 2005. \n WEB RESOURCES \n http://developer.apple.com/technotes/  \n http://www-03.ibm.com/systems/z/os/zos/index.html \n(IBM mainframe OSs) \n http://www.academicresourcecenter.net/curriculum/\npfv.aspx?ID=7387 (Microsoft \u00ae Windows \u00ae Internals, \nFourth Edition: Microsoft Windows Server \u2122 2003, \nWindows XP, and Windows 2000 by Russinovich, \nM.E., and D.A. Solomon) \n http://www.linux.org (the home of Linux kernel \ndevelopment) \n http://www.kernel.org (a repository of historic kernel \nsources) \n http://www.osdata.com (Operating System technical \ncomparison) \n http://www.tldp.org (The Linux Documentation Project) \n REVIEW QUESTIONS \n \n2.1 What are some of the types of resources that an \nOS must manage? \n \n2.2 What is the difference between a program and a \nprocess? \n \n2.3 What are the states that a process can be in? \n \n2.4 How many processes can be in the run state at the \nsame time? \n \n2.5 What sort of events can cause a transition from the \nrun state to the terminate state? \n \n2.6 Name at least a few things that a process might be \nwaiting on. \n \n2.7 Some information stored in a PCB is not always \nkept current. What are some examples of such \ninformation? \n 2.8 SUMMARY \n In this chapter, we started with a simple user scenario \nand described some of the actions within the sce-\nnario that are undertaken by the OS. We then gave an \noverview of the main types of system resources that \nthe OS manages, and discussed the major OS mod-\nules. Then we defined the process concept, which is \ncentral to what the OS does, and described the states \nof a process and some of the information that the OS \nmaintains about each process. We then discussed the \ncharacteristics of different types of OSs, from sys-\ntems that can execute a single process at a time to \nthose that manage concurrently executing processes \nto time-sharing and distributed systems. \n Following that, we presented some of the different \narchitectural approaches that have been taken for con-\nstructing an OS. These include monolithic OS, micro-\nkernels, and layered architectures. We discussed some \nof the common data structures that an OS maintains, \nnamely interrupt vectors and queues, object-oriented \nsystems, and virtual machines. Finally, we concluded \nwith a philosophical discussion on the minimalist ver-\nsus maximalist approaches to OS functionality.  \nelm49810_ch02_019-044.indd   42\nelm49810_ch02_019-044.indd   42\n12/10/08   9:27:39 PM\n12/10/08   9:27:39 PM\n",
        "category": "Category"
    },
    {
        "id": "150",
        "title": "Title for Chunk 150",
        "content": "Confirming Pages\n \nChapter 2 Operating System Concepts, Components, and Architectures \n43\n \n2.8 Give examples of the three types of processes: \nuser, system, and OS. \n \n2.9 The chapter discussed five different overall design \ntypes for OSs. What design types do these exam-\nples belong in?\n a. OSs in handheld computers and PDAs \n b. UNIX \n c. Novell Netware \n d. VCRs \n e. Automobile engine \n 2.10 If we are writing applications, what are some of \nthe reasons that we need an OS to manage the \nhardware for us? \n 2.11 What are some of the reasons why we divide an \nOS into separate modules? \n 2.12 What is a \u201cmicrokernel\u201d OS? \n 2.13 Generally speaking, object-oriented programming \nis less efficient than procedural programming. \nWhy would we want to use a less efficient tool to \nmake an OS? \n 2.14 When an OS gets an interrupt from a device, what \nmechanism does it usually use to select the code \nto handle the interrupt? \n 2.15 How does an application ask the OS to do \nsomething? \n 2.16 True or false? The evolution of OSs has resulted \nin the present state in which most modern OSs are \nvirtual machine OSs. \n 2.17 What are the two modern software virtual machine \narchitectures? \n 2.18 Do you feel that an OS should include many \ncommon system functions or that it should con-\ntain only a minimum level of functions, leaving \nas much as possible to be in additional layers and \nlibraries? Justify your answer. \n 2.19 What is the most standard OS API that applica-\ntions can be designed around?  \nelm49810_ch02_019-044.indd   43\nelm49810_ch02_019-044.indd   43\n12/10/08   9:27:39 PM\n12/10/08   9:27:39 PM\n",
        "category": "Category"
    },
    {
        "id": "151",
        "title": "Title for Chunk 151",
        "content": "elm49810_ch02_019-044.indd   44\nelm49810_ch02_019-044.indd   44\n12/10/08   9:27:40 PM\n12/10/08   9:27:40 PM\n",
        "category": "Category"
    },
    {
        "id": "152",
        "title": "Title for Chunk 152",
        "content": "Confirming Pages\n45\n Part \n Part \n Building Operating Systems \nIncrementally: A Breadth-Oriented \nSpiral Approach \n2 2 \n In this part:\n Chapter 3: A Simple, Single-Process Operating System 47\n Chapter 4: A Single-User Multitasking Operating System 67\n Chapter 5:  A Single-User Multitasking/Multithreading Operating \nSystem 89\n Chapter 6: A Multiuser Operating System 113\n Chapter 7:  Parallel and Distributed Computing, Clusters, \nand Grids 127\n P\nart 2 of this book is the part that makes the book different from others. Other \nbooks tend to treat a series of separate topics concerning different aspects of \ntypical OS in depth, but isolated from one another. Instead, this part of the \nbook presents a series of chapters that treat selected operating systems to show how \noperating systems were forced to evolve as the underlying hardware evolved and the \nexpectations and demands of users grew. The systems that were selected all run on a \npersonal computer of some sort. This choice was deliberate. It was based partly on \nthe belief that such computers will be familiar to most students, perhaps having seen \nmany of these machines and OSs before. They are also the systems that students are \nmost likely to have access to, at least the more modern systems. At the same time, \nthe evolution of the OSs for personal computers paralleled that of OSs for larger \nmachines. As a result, examples exist of personal computer OSs that range from the \nmost primitive to the most complex. Many of these OSs are also available on larger \nmachines, including some of the largest mainframes available today. \n Part 2 consists of five chapters. Chapter 3 discusses an early personal computer \nOS, CP/M. This is a single-user, single-tasking OS with no graphical user interface, \nelm49810_ch03_045-066.indd   45\nelm49810_ch03_045-066.indd   45\n12/11/08   7:01:33 PM\n12/11/08   7:01:33 PM\n",
        "category": "Category"
    },
    {
        "id": "153",
        "title": "Title for Chunk 153",
        "content": "Confirming Pages\n46\nor GUI. It supported only a flat file system. As such, it was very similar to many of \nthe early mainframe OSs such as IBSYS for the IBM 709x series. We show all of the \nbasic mechanisms required of the OS in these simple systems. These mechanisms \ninclude separation of the kernel from the OS and file system support. \n In Chapter 4 we look at an OS that introduces two additional concepts: the idea \nof running multiple programs at the same time and the use of a GUI. The OS that is \ncovered is the Palm OS, used in many PDAs and cellular phones. These two addi-\ntional requirements necessitate additional OS mechanisms to support them, most \nnotably the idea of CPU abstraction and a process control block. PDAs and cell \nphone systems usually do not have secondary storage devices, but they still have the \nconcept of a file system because the metaphor is so familiar to application program-\nmers. They do have a GUI, but the use of the screen is limited by its very small size. \nWe discuss the impact these two restrictions had on the design of the OS. \n The OS series discussed in Chapter 5 introduces additional requirements. It is \nthe Macintosh OS series, and it was designed from the start with secondary storage \nin mind. The evolution of this family is interesting in that it is in itself an example \nof a spiral evolution. The only feature that the MAC OS initially offered that was \nnot discussed in the Palm OS was that the MAC OS GUI could have overlapping \nwindows. It was still a single-user system and had a flat file system, just as did CP/M \nand the Palm OS. However, as the MAC OS evolved, Apple added many new fea-\ntures such as multitasking, a hierarchical file system, multiple users (though not con-\ncurrently), multiple CPUs, and eventually a virtual memory system. Each of these \nmechanisms is discussed in turn, and the virtual memory topic leads naturally into \nthe next chapter. \n Chapter 6 covers Linux as an example of an OS that has been ported to many \ndifferent hardware platforms ranging from embedded systems to real-time systems \nto supercomputers. The main distinction made here for Linux is that it was designed \nwith the assumption of multiple users at multiple terminals. In order to provide this \nfunctionality an OS must provide more protection mechanisms in the OS, and espe-\ncially in the file system. Linux is also an example of an open source OS, and this \ndistinction is explored in this chapter as well. A later portion of the book covers \nLinux in greater detail. \n Chapter 7 explores the issues that arise when an OS is designed that spans mul-\ntiple computer systems. Often, such systems cross administrative domains. Almost \ncertainly the policies and interests of the institutions involved are not the same. \nIndeed, they may even conflict with one another. Still, the institutions involved have \nfound some common interests that compel them to establish systems that cross such \nboundaries, and GLOBUS is used in this chapter to illustrate some of the issues \ninvolved. Other systems are discussed as well. \nelm49810_ch03_045-066.indd   46\nelm49810_ch03_045-066.indd   46\n12/11/08   7:01:35 PM\n12/11/08   7:01:35 PM\n",
        "category": "Category"
    },
    {
        "id": "154",
        "title": "Title for Chunk 154",
        "content": "Confirming Pages\n359\n Chapter \n Chapter  16 \n 16 \n Protection and Security  \nIn this chapter: \n 16.1 Introduction: Problems and Threats 360\n 16.2 OS Protection 366\n 16.3 Policies, Mechanisms, and Techniques 370\n 16.4 Communication Security 373\n 16.5 Security Administration 380\n 16.6 Summary  381\n A\nt one time there were few thoughts given to problems of security in computer \noperating systems. In most cases security was provided by controlling physi-\n cal access. Computers were huge things locked away in a room with lots of \nair-conditioning. A user who could access a system was allowed to access any file \nand any program that was running. As time has gone by the situation has changed. \nTime sharing began the biggest change since there would commonly be many pro-\ngrams running at the same time on behalf of many users who might have competing \ninterests. Today it is quite common to share access to systems, especially in our \nhomes. Even when systems are not shared, they are more often than not connected \nto a network. In many cases, even at home, they are on a LAN. At the least, many \nmachines can connect to the Internet via a dial-up connection. However, intermittent \nthat connection might be, while the connection is made our system is exposed to the \nentire Internet world\u2014a place where threats reside as well as wonders. \n In  Section 16.1  we discuss the origins of some of the security problems. We \nthen break them down into several different categories and describe the mechanisms \nan OS needs to deal with them. Some of these mechanisms need to reside outside \nthe OS itself. We then move on in  Section 16.2  to a general discussion of the nature \nof the protection services that OSs need to offer to users, primarily to provide pri-\nvacy to files. We describe how these services are designed in general. Beyond the \nservices the OS must provide for users, a different level of services is needed for \nprocesses. We have built significant barriers between running processes and the OS \nin order to protect them all. In  Section 16.3  we continue with a look at some of the \nservices that are needed by processes that are trying to communicate and cooperate \nwith one another.  Section 16.4 covers security as it pertains to networks in general \nand the Internet in particular. It includes discussions of encryption, authentication, \nelm49810_ch16_359-384.indd   359\nelm49810_ch16_359-384.indd   359\n12/11/08   7:35:33 PM\n12/11/08   7:35:33 PM\n",
        "category": "Category"
    },
    {
        "id": "155",
        "title": "Title for Chunk 155",
        "content": "Confirming Pages\n360 \nPart 5 Networks, Distributed Systems, and Security\nand digests. It also discusses the related topics of network security and protection \nfound outside of individual OSs.  Section 16.5  covers the problems that arise in the \nadministration of security in a network and an OS. The chapter concludes with a \nsummary in  Section 16.6 . \n 16.1 INTRODUCTION: PROBLEMS AND THREATS \n There are many reasons why we should not blindly trust all programs. Program-\nmers can be bored, exhausted, lazy, careless, ignorant, unintelligent, malicious, or \nthoroughly evil. Any of these, or all of them together in some cases, can produce \na program that can damage our work or even our systems. There are generally two \nclasses of people we need to worry about. Hackers are very dangerous for home \nusers because they attack system weaknesses that most home users are not knowl-\nedgeable enough to even recognize, much less fix. Hackers are also the most notori-\nous, but they are only one portion of the problem. A problem that is less well known \nis unauthorized use by persons who have legitimate access to the system. Such inter-\nnal problems are wide ranging. They include sending abusive or threatening emails, \nstealing money from accounts or goods from inventory, wasting time visiting web-\nsites not relevant to work or playing games on the computer, snooping on personal \ninformation of other employees, copying projects or papers from fellow students, \nbribery, extortion, taking company secrets to sell to the competition, and so on. Most \nof these problems are hard to spot and control because the person engaging in these \nactivities has legitimate access to the system. We generally have to identify them \nthrough some means other than the OS controls. We rely on physical inventories, \naudits, and so on. In some ways the hackers are easier to control because they are \nforced to use a small set of illegitimate mechanisms to gain access. If we are diligent \nenough we may eventually be able to identify and secure most of those mechanisms. \nUntil this happens, securing large systems is very difficult (some say impossible) \nbecause of the complexity of the systems. \n Hackers are generally exploiting some problem in the OS that allows them to \nexecute an operation that they are not supposed to be able to execute. Often this \nallows them to gain access to a system with the permissions that a supervisor or \nadministrator must have\u2014permissions that basically allow them to do anything they \nwant. Most often these mechanisms exploit a bug in the OS. Usually the OS vendors \nwill quickly learn about these bugs and will release fixes for the OS that will shut \noff the hacker\u2019s ability to exploit that bug. Unfortunately, these fixes are not as well \ntested as a full release of the OS, so not all users are willing to install all these fixes, \nleaving the bugs exposed. This is especially true for corporate administrators who \nmust manage many diverse systems doing many different tasks. Whereas an individ-\nual might be able to determine fairly quickly that a bug fix was causing a problem, a \ncorporate administrator might be responsible for many systems and therefore might \nbe less willing to risk such exposure. \n The hacker threats that we might see can be grouped so that we can assess how \nto deal with them. First is the general category that we call today  malware. Malware \nis a fairly new word that groups together several subcategories including virus pro-\ngrams, worms, Trojans, and spyware. \nelm49810_ch16_359-384.indd   360\nelm49810_ch16_359-384.indd   360\n12/11/08   7:35:37 PM\n12/11/08   7:35:37 PM\n",
        "category": "Category"
    },
    {
        "id": "156",
        "title": "Title for Chunk 156",
        "content": "Confirming Pages\n \nChapter 16  Protection and Security  \n361\n 16.1.1 Computer viruses \n Computer viruses are portions of programs that insert themselves into other pro-\ngrams in a manner analogous to the way that biological viruses insert themselves \ninto living cells. When a program containing a virus is run on a computer system the \nvirus will insert itself into other programs on secondary storage. The hardest part for \nthe virus writer is getting a user to run the program containing the virus. Today, this \nis accomplished most commonly by attaching the virus program to an email in such \na way that a user will execute it. When most software was distributed on floppy disks \na common technique was to infect the program found in the boot sector of the floppy. \nIf the system was rebooted after a software installation (as was often required) and \nthe last floppy disk was not removed from the drive, the floppy would usually be \nbooted and the virus propagated to the hard drive. From there it would infect every \nother floppy that was inserted into the system. Once such a virus got loose in a \ncorporate environment it was almost impossible to eradicate completely because of \nthe many floppy disks that were stored in various desk drawers, inside briefcases, at \nhome on top of the dresser, and so on. \n Today, we have protective programs known as virus scanners that reside in mem-\nory and watch for signs that a program containing a virus is about to be copied or run \nand prevent the copying or execution. These scanners work by matching known pat-\nterns of instructions or unusual behavior such as a series of system calls or attempts to \nmodify certain system files or portions of the registry. Unfortunately, the databases of \npatterns of data and behaviors have to be maintained since new viruses are constantly \nbeing created. While the programs themselves have often been free, after some trial \nperiod the maintenance of the database has not been. As a result, many people do not \nbother to run the scanners or don\u2019t pay for the updates, so viruses continue to circu-\nlate that should have been eliminated long ago. Just as in the biological world, some \nviruses are only annoying but some cause catastrophic harm. The ones that crash \nsystems are less likely to spread as far as the ones that are less damaging. Crashing a \nsystem gets the attention of the user and will probably result in the eradication of the \nvirus on that machine. But a small slowdown might not be noticed or might be toler-\nated because the cure is too expensive or would take too much time.  \n 16.1.2 Trojans \n Trojans are programs that are not what they appear to be. The term comes from a \ntechnique allegedly employed during the Trojan war, when one side appeared to \nwithdraw from the battlefield but left behind a large wooden statue of a horse. Hid-\nden inside the horse was a team of soldiers. The army of the city dragged the horse \ninside the city and had a great celebration of the supposed victory. During the night \nthe hidden soldiers came out of the horse and opened the city gates to admit the \nreturning army who then sacked the city. Trojan programs appear to be one thing but \neither do something else entirely, or do what they appear to do, but do something else \nas well\u2014something unnoticed by the user. For example, the program might appear \nto work as a screen saver but also installs a process that would log all passwords and \nsend them to some website in another country. Generally, the same techniques that \nwork against virus programs will also work against Trojans. \nelm49810_ch16_359-384.indd   361\nelm49810_ch16_359-384.indd   361\n12/11/08   7:35:37 PM\n12/11/08   7:35:37 PM\n",
        "category": "Category"
    },
    {
        "id": "157",
        "title": "Title for Chunk 157",
        "content": "Confirming Pages\n362 \nPart 5 Networks, Distributed Systems, and Security\n 16.1.3 Worms \n Worms are programs that are similar to viruses and Trojans, but slightly different. \nThey do not infect other programs and do not pretend to do something. When a worm \nprogram is run for the first time it simply tries to send itself to other machines and \ntrick the OSs into running it. From there it will try to send itself to other machines, \nand so on. In 1988 a doctoral student at Cornell University launched a small program \nthat was destined to be known as The Internet Worm. His intention was that the pro-\ngram would do nothing visible. It was designed to spread itself to as many computers \nas possible without giving away its existence. If the code had worked correctly it \nwould have been only a single process running on many Internet-connected comput-\ners. Unfortunately, the code didn\u2019t work as intended. The worm propagated itself too \naggressively, and an infected machine often sent the worm back to the same machine \nthat it had come from. The result was that these small processes, which didn\u2019t take \nup much CPU time individually, began to swamp the systems as more and more \ninfected processes were started on each machine. In most cases in less than 90 min-\nutes the worm had made the infected system unusable. Nobody is actually sure how \nmany machines were infected by this worm, but it is estimated that it involved about \n6,000 machines. It essentially shut down the Internet for about a day. Fortunately, \nit only attacked VAX and Sun machines running a specific version of BSD UNIX. \nWorms can also be detected and eradicated by virus scanners. \n Worms are not necessarily destructive. The initial development of worms was \nat the Xerox PARC installation in the early 1980s. These worms were used for such \nactivities as distributed processing, broadcast communication, and software distribu-\ntion that took place during the off hours on the network. \n 16.1.4 Spyware \n Spyware is a special class of Trojans. Such programs are relatively benign in the sense \nthat they do not damage the computer they are running on or any of the user data. What \nthey typically do is report local activity to some unrelated website. In the most benign \ncase this information merely identifies which websites are being accessed and helps \nthe system place ads on the websites that might be of more interest to the user. There \nis a gray area in which this activity could be viewed as being actually helpful. Unso-\nphisticated users are misled by unscrupulous advertisers to install \u201cscreen savers\u201d \nand \u201cbrowser toolbars\u201d that are actually Trojans containing such spyware. At the very \nleast, the user is not usually notified that these additional functions are being installed. \nIn the worst case vendors of music CDs and tax software installed spyware packages \nwhen one of their DVDs was played on the computer or their software was installed \nin misguided attempts to enforce  digital rights management, or  DRM. These instal-\nlations were done without any notice to the user of this software. In both cases the \nperformance of the system was degraded and new security flaws were exposed to \nthe Internet. In more malicious instances spyware can be used to steal passwords to \nwebsites and even credit card numbers. Fortunately, special scanners exist that can \nrecognize and remove most spyware. The degradation caused by one spyware pro-\ngram is not usually too substantial. But when running scanner software for the first \ntime on machines owned by naive users it is not unusual to find  hundreds of instances \nelm49810_ch16_359-384.indd   362\nelm49810_ch16_359-384.indd   362\n12/11/08   7:35:37 PM\n12/11/08   7:35:37 PM\n",
        "category": "Category"
    },
    {
        "id": "158",
        "title": "Title for Chunk 158",
        "content": "Confirming Pages\n \nChapter 16  Protection and Security  \n363\nof spyware, and these systems are often essentially useless under the load. As of this \nwriting the spyware detectors are beginning to merge with virus scanners into a more \ngeneral category of malware scanners.  \n 16.1.5 DoS attacks  \n The Internet Worm just described was intended to be benign. Unfortunately, as a side \neffect of its operation it is also an example of another class of attacks,  denial of ser-\nvice, or  DoS. The effect of this worm was that authorized users could not access the \nmachines or that operating systems failed because they had seldom been tested at the \nlimits of stress they were being put to. This effect is called denial of service. Usually \na DoS attack is an intended consequence rather than a side effect. There are many \nsuch attacks\u2014we describe two. The first is called the  Ping of Death. A ping is a \nspecial message used by network administrators to test network connections. A ping \ncommand received by a server is echoed back to the sender, so the sender will know \nthat the target machine is reachable. To make the program more useful the sender \ncan send a large packet and send it several times to see what the average response \ntime is. There is supposed to be a maximum of 64 KB on the attached packet, but \nit is possible to maliciously create a ping packet that contains more than 64 KB. \nUnfortunately, more than a few OSs had a ping utility that would try to receive this \npacket into a buffer that could be up to 64 KB, but no larger. If a larger packet were \nreceived, then the data would overwrite something unintended, often with fatal con-\nsequences. This would not cause any benefit to the sender\u2014only harm to the target.  \n Another DoS attack is called a  SYN Flood. TCP network connections start with \na \u201cthree-way\u201d handshake. The initiator of the connection sends a packet that contains \na SYN flag, which tells TCP that it is starting a connection and that the receiver \nshould allocate some buffers and reset some data fields regarding that connection. \nThe receiver replies and the sender sends another packet that completes the con-\nnection. In a SYN flood attack the sender sends many initial SYN packets starting \nnew connections but never responds to the receiver\u2019s reply, thereby tying up mem-\nory resources. After a sufficient number of unfinished connections are opened, the \nreceiving system may either crash or simply be unable to accept further connections, \nthus denying service to authorized users.  \n Both of these problems have been fixed in all current OS protocol stacks, but \nthey may persist in older network equipment that cannot be easily upgraded. Other \nsuch problems are discovered often and eventually get repaired. If we were not con-\ntinually developing new protocols these problems would eventually all be solved. \nBut other kinds of attacks are not so simple to prevent. An example is a coordinated \nattack using  zombies. A zombie is a machine where security has been compromised \nto the extent that a remote user can run an unauthorized program at will. Given a \nlarge set of zombie computers a malicious user can synchronize them to all run a \nspecific program at the same time. Networks of tens of thousands of zombie systems \nare not unusual because so many users are naive about the security on their machines \nand a zombie machine might not exhibit symptoms that are easy to detect. (Zombie \nmachines are sometimes called  robots or  bots and a large set of such machines is \ncalled a  botnet. ) The program could consist of legitimate requests\u2014perhaps to ask \na Web server to deliver a specific page. Or the requests might be bogus, but legal \nelm49810_ch16_359-384.indd   363\nelm49810_ch16_359-384.indd   363\n12/11/08   7:35:37 PM\n12/11/08   7:35:37 PM\n",
        "category": "Category"
    },
    {
        "id": "159",
        "title": "Title for Chunk 159",
        "content": "Confirming Pages\n364 \nPart 5 Networks, Distributed Systems, and Security\nfrom a protocol standpoint, and therefore difficult to detect or prevent. For example, \nwe might send a page to a Web server. This is usually only used for maintenance, so \nmost users are unauthorized, but the request itself looks legitimate. If several thou-\nsand zombie computers can be used at the same time they can overload a server to \nthe point that legitimate users are denied access. Even if the server is not overloaded, \nthe entire communication connection to the server may be filled, again denying ser-\nvice. No single zombie will appear to be under any load, so the systems\u2019 owners may \nnot even be aware that anything is happening. \n 16.1.6 Buffer overflows \n In order to do much damage, a virus or worm needs to somehow fool the system into \nrunning its code in supervisor mode. One of the most common ways that a virus or \nworm manages this feat is to exploit a type of program coding error called a buffer \noverflow, or buffer overrun. The ping of death we mentioned was one example. A \nbuffer overflow occurs when a process stores data beyond the end of a buffer. What \nhappens is that the extra data overwrites nearby memory locations. Buffer overflows \ncan cause a process to crash or output wrong information. They can be triggered \nby inputs intended either to run malicious code or only to make the program oper-\nate in an unintended way by changing the data. Buffer overflows are the cause of \nmany software vulnerabilities and the basis of many exploits. Bounds checking can \nprevent buffer overflows. Programmers often don\u2019t think about the problem, naively \nassuming that the input data will be valid. Compilers can generate code that always \ndoes bounds checking, but programmers typically turn such options off for the sake \nof efficiency. \n In the following example, X is data that was in memory when the program began \nexecuting. Y is right next to it. Both are currently 0. \nX\nX\nX\nX\nX\nX\nX\nY\nY\n00\n00\n00\n00\n00\n00\n00\n00\n00\n  If the program tried to store the string \u201ctoo much\u201d in X, then it would overflow the \nbuffer (X) and wipe out the value in variable Y. \nX\nX\nX\nX\nX\nX\nX\nY\nY\n\u2018t\u2019\n\u2018o\u2019\n\u2018o\u2019\n\u2018 \u2019\n\u2018m\u2019\n\u2018u\u2019\n\u2018c\u2019\n\u2018h\u2019\n00\n Although the programmer did not intend to change Y at all, Y\u2019s value has now been \nreplaced by a number formed from part of the character string. In this example, on a \nbig-endian system that uses ASCII, \u201ch\u201d followed by a zero byte would become the \nnumber 26624. Writing a very long string could cause an error such as a segmenta-\ntion fault, crashing the process. \n The methods used to exploit a buffer overflow vary by the architecture, operat-\ning system, and memory area. Besides changing values of unrelated variables, buffer \nelm49810_ch16_359-384.indd   364\nelm49810_ch16_359-384.indd   364\n12/11/08   7:35:38 PM\n12/11/08   7:35:38 PM\n",
        "category": "Category"
    },
    {
        "id": "160",
        "title": "Title for Chunk 160",
        "content": "Confirming Pages\n \nChapter 16  Protection and Security  \n365\noverflows can often be used by attackers to trick the program into executing  arbitrary \ncode that came from the malicious input. The techniques used by an attacker to gain \ncontrol depend on the part of memory where the buffer resides. For example, it might \nbe in the stack area, where data is pushed onto the stack and later popped off. But \nthere are also heap overflow exploits as well. \n Typically, when a function begins executing, local variables are pushed onto \nthe stack, and are accessible only during the execution of that function. This is a \nproblem because on most systems the stack also holds the return address\u2014the loca-\ntion in the program that was executing before the current function was called. When \nthe function ends, execution jumps back to the return address. If the return address \nhas been overwritten by a buffer overflow it will now point to some other location. \nIn the case of an accidental buffer overflow as in the first example, this will almost \ncertainly be an invalid location, not containing any program instructions, and the \nprocess will crash. But by carefully examining the code in a system an attacker can \ncleverly arrange things so that the system will begin executing code supplied by the \nattack. Modern OSs are now starting to locate code and data randomly in the logical \naddress space to make such exploits more difficult to create. \n 16.1.7 Scripts and applets \n Another variety of malware is sometimes found on malicious websites. Several \nmechanisms have evolved that allow a website to send programs to client systems. \nThese include scripting languages such as  JavaScript and  VBScript and  applets \nintended to run on software virtual machines such as the  Java virtual machine \n( JVM ) from Sun Microsystems and the  Common Language Runtime ( CLR) from \nMicrosoft. Both of these mechanisms normally execute programs inside the browser \nin a manner known as a  sandbox. See  Figure 16.1 . This means that the actions of the \nprogram are restricted so that it cannot cause harm. For example, normally programs \nrunning in a browser are not allowed to access the local disk drives. Most browsers \nallow a user to override these limits so that a trusted program can do things we might \nApplet A\nBrowser Program\nClient System\nApplet A\nWeb Server\nServer System\nApplet\nfiles\nFIGURE 16.1 \nSandbox execution \nmodel.\nelm49810_ch16_359-384.indd   365\nelm49810_ch16_359-384.indd   365\n12/11/08   7:35:38 PM\n12/11/08   7:35:38 PM\n",
        "category": "Category"
    },
    {
        "id": "161",
        "title": "Title for Chunk 161",
        "content": "Confirming Pages\n366 \nPart 5 Networks, Distributed Systems, and Security\nnot want a program we are unsure about to do. If we got the applet from our company \nwebsite we would probably trust it. If it came from another source we might not.  \n One additional mechanism that is widely believed to cause security problems \nis that of  cookies. By design, Web servers are stateless\u2014they do not keep any infor-\nmation about individual clients. (Applications that run in Web servers can do so, \nbut it is not a feature of the server itself.) This stateless nature limits what servers \ncan do. In order to expand on these capabilities, browsers were enhanced to allow \na server to record information about a website on the browser system. These are \nfairly short strings of text. The server can read the cookie when a browser requests \na page. These can help the server appear to be stateful. They can store a customer \nnumber, a last question asked, a last page visited, shopping cart information, and so \non. They can be used to temporarily tell a website that you have logged in as you \nmove from page to page on the site. It is a common misconception that cookies \ncan contain viruses or other malware. Cookies called  tracking cookies can be con-\nstructed to share information across multiple websites for advertising purposes, but \nthere is no way that a cookie can harm a computer or other information or programs \non the computer.  \n 16.2 OS PROTECTION \n 16.2.1 OS protection \n In earlier chapters we discussed several different aspects of OS protection, but they \nare worth mentioning again in this context. One example is the separation of Super-\nvisor Mode for running the OS and User Mode for running application programs. \nThis separation allows the OS to monitor various operations in an attempt to make \nsure that they do not do anything disastrous. It is possible for the OS to make sure, \nfor example, that an I/O request does not overwrite part of the file system metadata. \nHowever, in many cases it can\u2019t prevent some abuses, such as deleting a file that a \nuser might want. Some of this sort of abuse can be mitigated by file system protec-\ntions, which we discuss a bit further on. \n Similarly, the OS protects the use of the CPU by starting a timer and preventing \nuser programs from changing the timer. This allows the OS to abort any program \nthat goes into a loop, intentionally or not. In batch systems a runtime estimate is \ngiven when a program is started and the program will be terminated if it exceeds that \nestimate by more than a certain percentage. In interactive systems it is assumed that \neventually the user will abort an operation and either retry it or do something else. \nIn either case, a rogue program can\u2019t completely tie up the system since the OS is \nprobably multitasking and the user will still be able to interact with the OS to kill a \nlooping program. \n One final aspect of the OS protection is memory protection. The hardware can \nusually check the addressing bounds of the logical address space. In addition, many \nsystems can mark certain pages as allowing read-only access or execute-only access, \ngiving an added measure of protection. These features allow the OS to protect itself \nfrom any user program and also keeps programs from interfering with each other.  \nelm49810_ch16_359-384.indd   366\nelm49810_ch16_359-384.indd   366\n12/11/08   7:35:38 PM\n12/11/08   7:35:38 PM\n",
        "category": "Category"
    },
    {
        "id": "162",
        "title": "Title for Chunk 162",
        "content": "Confirming Pages\n \nChapter 16  Protection and Security  \n367\n 16.2.2 Authentication \n When users remotely access computer systems we may be concerned that they only \naccess resources we want them to access, though sometimes we don\u2019t care what they \naccess. Most Web servers, for example, will allow any user to access any page. How-\never, an online banking system accessed by a Web interface certainly does not want \nany user to access all of the information on the server. We want users to access only \naccounts they are authorized to access. Controlling what a user can access on a sys-\ntem actually has two parts to it: authentication and authorization.  Authentication is \nverifying the identity of a party to a communication. In the case of a user accessing \na bank account we need to authenticate both parties. Obviously the bank wants to \nauthenticate the user. Until recently it was not so obvious that when using an online \nbanking system we want to authenticate the bank as well. A new class of computer \nfraud has arisen that is known as  phishing. A phishing fraud is most often sent in \nan email. It directs a user to a website that pretends to be something it is not\u2014your \nbank, for example. It asks that you enter some confidential information such as your \ncredit card number or bank account number and ID and password. It uses some \nplausible-sounding reason for requesting the information, usually saying that it is \nneeded to authenticate you, and often stating that the system needs this information \nbecause the system security has been compromised in some way. As a result, we \nnow understand that it is important to authenticate the host system to the client as \nwell as authenticate the client to the host system. \n Authentication usually takes one of three forms: something you  have, some-\nthing you  know, or something you  are. Examples of something you have include \nyour ATM card or your house key. Cards and keys can be stolen, however. Something \nyou know might be your login ID and password or your account number. Any such \ninformation can be captured if a third party sees you enter it or reads the message \nfrom the communication line. Something you are might be a voiceprint, thumbprint, \nor a retinal scan. Such systems are just now coming into use and in theory should \nbe harder to fool once they are further developed. Using two different methods of \nauthentication at the same time is called  two-factor  authentication. This is seen \nwhen one uses an ATM card and must also supply a PIN. \n Passwords are problematic because of social factors. The very worst password \nis the default password that sometimes comes with software or hardware. Surpris-\ningly often these passwords are never changed. If passwords are not chosen care-\nfully they can be easily guessed. Such passwords are considered weak. The Internet \nWorm mentioned earlier used several mechanisms for guessing passwords and was \nremarkably successful. So the use of  strong passwords is recommended. Passwords \nare generally considered strong if they contain a combination of upper- and lower-\ncase letters, symbols, and numbers and do not contain any names or words, repeated \nsymbols, or sequences such as 123 or tuv. Passwords that are names or words can \noften be broken be guessing common words or names associated with the account. \nThis is known as a  dictionary attack. But the problem with strong passwords is that \nthey are difficult to remember. This is especially true since it is normally recom-\nmended that you do not use the same password on different systems. As a result, \nstrong passwords are often found on notes attached to computer monitors, seriously \nelm49810_ch16_359-384.indd   367\nelm49810_ch16_359-384.indd   367\n12/11/08   7:35:39 PM\n12/11/08   7:35:39 PM\n",
        "category": "Category"
    },
    {
        "id": "163",
        "title": "Title for Chunk 163",
        "content": "Confirming Pages\n368 \nPart 5 Networks, Distributed Systems, and Security\ncompromising their effectiveness. A good technique is to make up a sentence and \nuse the first letter of each word in an acronym. For example, \u201cWorld War 2 began \nin 1939!\u201d could yield a password of WW2bi1939! That is a nice strong password. \nWhen you try to use it and you can\u2019t remember the year, just go to Google and enter \n\u201cyear wwii started.\u201d Now your note can contain some cryptic hint like \u201cW2\u201d that will \nbe meaningful only to you. \n 16.2.3 Authorization \n Once an OS knows who a user is, the next task is to decide what operations that \nuser is allowed to do. More specifically, the allowed operations depend on the object \nbeing accessed\u2014we normally do not have the same rights to all files on a computer. \nWe have been discussing a user as a person, but in the context of an OS, a process \ncan be a user as well. Deciding what operations a user can perform on an object \nsuch as a file is called  authorization. Abstractly the OS could have a data table \ncalled an  access control matrix, or  ACM. One dimension of the matrix would be \nthe user and the other would be the object to be operated on. The entries in the \nmatrix cells would be the operations that would be allowed for that user on that \nobject.  Figure 16.2  shows a hypothetical ACM. In it we see that the rows are labeled \nwith user names and the columns are labeled with objects. In this case we see three \nfile objects and one printer object. Wendy is a designer in the art department and is \nauthorized to use the laser printer but not the C compiler. Ann and Fred can read and \nwrite their own resum\u00e9s, but nobody else can. Ann and Fred can both execute the C \ncompiler, but neither can read it as data or write to it. Note that the set of possible \noperations for one object are likely not the same as the set of possible operations for \nanother object of a different type. A file would not have a Stop Queue operation like \na printer might.  \n One thing is clear even from this small piece of an ACM\u2014most of the cells are \nempty. Trying to store an entire ACM would waste a tremendous amount of memory. \nRead\nWrite\nAnn\u2019s\nResum\u00e9\nFile\nAnn\nFred\nFred\u2019s\nResum\u00e9\nFile\nLaser\nPrinter\ngcc\nRead\nWrite\nnil\nnil\nExecute\nExecute\nWendy\nnil\nnil\nnil\nWrite\nStop Queue\nStart Queue\nnil\nnil\n. . .\n. . .\nFIGURE 16.2 \nAn access control \nmatrix.\nelm49810_ch16_359-384.indd   368\nelm49810_ch16_359-384.indd   368\n12/11/08   7:35:39 PM\n12/11/08   7:35:39 PM\n",
        "category": "Category"
    },
    {
        "id": "164",
        "title": "Title for Chunk 164",
        "content": "Confirming Pages\n \nChapter 16  Protection and Security  \n369\nA large machine might have tens of thousands of users and hundreds of thousands \nof files and most users would be allowed to access only a small set of the files. For \nthis reason, OSs do not use an ACM. Instead, they either use an access control list or \na capability list. An  access control list, or  ACL, is attached to an object and would \ncontain only the users who were authorized to perform some operation on an object. \nThe list elements would list each specified user who could access the object and the \noperations they could perform on the object.  Figure 16.3  shows some ACLs that cor-\nrespond to the ACM in  Figure 16.2 . \n Alternatively, an OS can use a  capability list, or  CL. A CL is shown in  Figure 16.4 \nthat also matches the ACM in  Figure 16.2 . The elements of the list show the objects \nthat a user is authorized to operate on and lists the operations the user is authorized \nto perform. \n Creating the entries in these lists the way that we have shown them, however, \nstill creates many more references than we might like. Consider the problem of \nsetting up rights for students at a large university to access the general system utili-\nties on a computer. Not only are there thousands or tens of thousands of students, \nthey change every semester\u2014some enroll and some move on, one way or another. \nSetting up all the necessary rights for each individual student would be a signifi-\ncant administrative problem. Instead, we utilize  groups or  roles. We create a group \ncalled \u201cstudent\u201d and we assign the rights to the necessary objects to the group. \nThen, as students arrive and leave all the administrators have to do is to add the new \nAnn\nFred\nLaser\nPrinter\nRead\nAnn\u2019s\nResum\u00e9\nFile\nAnn\ngcc\nExecute\nExecute\nWendy\nWrite\nStop Queue\nStart Queue\nFIGURE 16.3 \nSome access control \nlists.\nRead\nWrite\nAnn\u2019s\nResume\nFile\nAnn\nLaser\nPrinter\ngcc\nExecute\nWendy\nWrite\nStop Queue\nStart Queue\n. . .\n. . .\nFIGURE 16.4 \nSome capabilities \nlists.\nelm49810_ch16_359-384.indd   369\nelm49810_ch16_359-384.indd   369\n12/11/08   7:35:39 PM\n12/11/08   7:35:39 PM\n",
        "category": "Category"
    },
    {
        "id": "165",
        "title": "Title for Chunk 165",
        "content": "Confirming Pages\n370 \nPart 5 Networks, Distributed Systems, and Security\nstudents to the group and remove them when they no longer have access  privileges. \nThe rights that are given to the group are inherited by the students. Roles are simi-\nlar in that they allow for us to have a user in the system and have that user be \nassigned to a role. A role might correspond to being a member of a specific project \nteam. All users who are members of that team inherit a set of rights in a set of \nobjects shared by the team. When members leave the team and go to another, then \nall that the administrator has to do is change their roles and all their rights will be \nchanged as well. \n A question that must be answered is when the authorization should be checked. \nOne option is to check the authorization when an object is first accessed\u2014a file is \nopened, a socket connection is made, spooling to a specific printer is requested. \nAfter that, a set of operations implied by the initial access is allowed without fur-\nther checking. If we opened a file for input, for example, reads to that file would \nbe allowed, but not writes. Depending on the level of security desired in the OS we \nmay feel that this is not enough. We may require that every separate option will \nbe specifically checked against the lists\u2014perhaps the user\u2019s privileges have been \nrevoked since the initial access was made. For example, the user is going to be \nfired, finds out about it, and begins writing over files on the OS trying to remove \nevidence of malfeasance. The administrator revokes the user\u2019s passwords, but the \noperations are already ongoing. We discuss this more under the topic of security \nlevels. Note that this is a case where the OS designer must decide whether to pro-\nvide the mechanism in the OS to support a feature and the system administrator \nmust then decide whether to invoke it. In a department store such security might \nnot be worth the system and administrative cost to maintain; in a bank it might be a \ndifferent story altogether. \n Yet another question is at what level the authorization is to be made. Normally, \nthe objects in a system are organized in one or more tree structures\u2014as an example, \nthe file system on a hard drive. We often will grant a user access to a specific home \ndirectory. By implication the rights to a directory will extend to a subdirectory unless \nthey are overridden. Typically we can also override the rights to any file in a direc-\ntory. In some systems we can also assign rights to individual portions of a data-\nbase\u2014sometimes a set of fields. Thus, a clerical worker in the HR department might \nbe able to see the home contact information of all employees, but not the payroll \ninformation. Sometimes the restriction might be to a set of values\u2014a set of records, \nfor example. So a payroll clerk might be able to access the payroll records of most \nemployees, but not those above a certain management level. Again, the OS designer \nmust decide whether to supply those mechanisms and the administrators must set \npolicies about their use. \n 16.3 POLICIES, MECHANISMS, AND TECHNIQUES \n There are a number of types of security mechanisms that are commonly found in \nmost larger OSs. In this section we look at a few of these common mechanisms. But \nbefore we worry about mechanisms it is important to establish policies that unequiv-\nocally establish what users can and cannot do and what they must do. \nelm49810_ch16_359-384.indd   370\nelm49810_ch16_359-384.indd   370\n12/11/08   7:35:40 PM\n12/11/08   7:35:40 PM\n",
        "category": "Category"
    },
    {
        "id": "166",
        "title": "Title for Chunk 166",
        "content": "Confirming Pages\n \nChapter 16  Protection and Security  \n371\n 16.3.1 Security and protection policies \n Any network that is to be secure must have a set of policies that clearly spell out \nseveral things:\n \ufffd what users are allowed to do, \n \ufffd what users are not allowed to do, \n \ufffd what users are required to do, and \n \ufffd what the punishments are if the procedures are not followed. \n Even in a home environment, if parents wish to restrict access to certain types of \nwebsites they should clearly spell out what the restrictions are. Firewall mechanisms \nare not perfect and it is likely that the children in the family will end up being more \ncomputer literate than their parents and able to thwart many security mechanisms. \nThe punishments for doing the things that are prohibited should be established \nbeforehand. Firing an employee for sending a threatening email is difficult if the \nrestriction was not spelled out clearly beforehand. \n Similarly, employees must be clearly told what their responsibilities are with \nrespect to backing up information, using encryption in certain environments, secur-\ning their computers, and so on. If they are supposed to run a virus checker and a \nfirewall and to keep the software updated, then they should be told so in advance of \nany problems that might occur if they do not and what the penalties are for failing to \nadhere to the policies. \n 16.3.2 Crash protection: Backups \n Crashes will happen. OSs must provide mechanisms to deal with them. First, the running \nsystem may crash. OSs are much better than they used to be, but no nontrivial program \nis ever truly debugged. When they crash we must be able to recover from these crashes. \nWe have already discussed some mechanisms for dealing with these crashes. First is the \nmechanism of transactions. Often we have a series of file or database updates that work \ntogether to define a transaction. Perhaps we are moving a piece of expensive equipment \nfrom one warehouse location to another. If these are separate files or databases, then \none update needs to reflect that the item left one warehouse and the other update needs \nto reflect that it is now in the other warehouse. If the system crashes before one of these \nupdates is done, then we will either lose track of the item or we will think we have one \nmore of them than we really do. By coupling the updates together as a single transac-\ntion the system can ensure that either both updates are done or neither is. We discussed \nthe implementation of transactions through logging, checkpoints, and rollbacks. \n Another possible source of data loss is the physical crash of a disk drive. Some-\ntimes the read\u2013write heads literally crash into the platters and scrape the coating off. \nOther times we have a failure of a bearing or the electronics. Recovering some or all of \nthe data off a dead disk drive is sometimes possible but is certainly expensive. It is also \ntime-consuming. A far better method to cope with this possibility is to back up the data \nto a removable medium. Historically, this copying was done to magnetic tape because \nof the low cost of the media. For small systems, floppy disks or their slightly higher \ncapacity relatives were utilized. Today, personal computer backups are most often done \nvia CDs or DVDs. Not only do disk drives crash, users sometimes \u201ccrash\u201d too. Every \nelm49810_ch16_359-384.indd   371\nelm49810_ch16_359-384.indd   371\n12/11/08   7:35:40 PM\n12/11/08   7:35:40 PM\n",
        "category": "Category"
    },
    {
        "id": "167",
        "title": "Title for Chunk 167",
        "content": "Confirming Pages\n372 \nPart 5 Networks, Distributed Systems, and Security\nsystem administrator gets used to hearing that a user has deleted a file that they really \nneed accompanied by a fervent request to please recover it. So backups are also desir-\nable because files can be deleted or corrupted by human error or software problems. \n There are many approaches we can take to backing up a system, but there is \none that works best. It involves the fact that most OSs have an indication in the file \ndirectories that shows whether a file has been changed since it was last backed up. It \nis often called an  archive bit.  The details of the best procedure can vary, but for the \nsake of illustration we will assume that we want to keep the system backups fairly \neasy to use, so every weekend we will create a backup copy of the entire system. \nThis backup will clear the archive bit on all the files, showing that we have a backup \ncopy. As the system runs during each day, it will set the archive bit on any file that \nis changed. At the end of the day we can run a different backup procedure that will \ncopy only the files that have been changed that day. We will label this backup with the \ndate. We will do that each day. Then when a user requests a file that was deleted, we \ncan search all the daily backups in reverse order until we find it. In a large centralized \noperation the backup mechanism can keep track of which files are on which daily \nbackups so that it is not necessary to search them all. There are a couple of other key \nfeatures of such a system. First, the backups should not be in the same room as the \ncomputer. In case of a fire, backups in the same room would likely also be destroyed. \nEven more important, the backup media from the week before should not even be \nkept in the same building for the same reason. A flood might make the entire build-\ning inaccessible for some time. If an off-site backup is available, then the data can be \nrestored to systems in another facility and operations resumed more quickly.  \n An alternative mechanism can be considered in environments where the data \nrepresent a great deal of money. Such data might include engineering or artistic \ndesigns where the value can be hard to even estimate because of the creative effort \nthat went into them. They might literally be irreplaceable. In such situations we can \nemploy a dynamic backup system that will write each file to a remote backup mech-\nanism as it is changed. Such a solution is obviously more expensive, mostly because \nof the administration involved. But in such situations it can be well worth it, even if \njust for the peace of mind of knowing that the files are safe. It is still important to \ntake the media to an off-site storage location. \n If files are on laptops or the media used for backups are often physically taken \noutside the facility, then using encryption on the files or the media is a sound idea so \nthat if the computer or the backup is stolen, the data will not be compromised. \n An alternative to constant backups is the use of RAID disk organizations, as \ndiscussed in Chapter 14. Some of the RAID configurations provide substantially \nimproved reliability at fairly low cost and mitigate the problems of losing data due \nto drive failures. They will not solve problems of file loss due to human or software \nerrors, however. \n 16.3.3 Concurrency protection \n We have mentioned that we build OSs with a great deal of protection between run-\nning processes. We also said that we want to build high-level systems out of mul-\ntiple processes. Building systems out of multiple processes requires the ability to \ncommunicate among the processes. We therefore need mechanisms to facilitate \nelm49810_ch16_359-384.indd   372\nelm49810_ch16_359-384.indd   372\n12/11/08   7:35:40 PM\n12/11/08   7:35:40 PM\n",
        "category": "Category"
    },
    {
        "id": "168",
        "title": "Title for Chunk 168",
        "content": "Confirming Pages\n \nChapter 16  Protection and Security  \n373\nthat  communication. One of those mechanisms that an OS can provide for such \n applications is the ability to share memory. In this case we provide a means for \nprocesses to stipulate that they want to cooperate and share access to some portion \nof memory. In Chapter 9 we discussed some potential problems that can arise with \nthe use of shared memory and said that we could solve this problem with the use of \nlocking mechanisms, which the OS also must provide. This opened up yet another \npotential problem involving a deadlock. In this instance, the processes can avoid \ndeadlocks by the consistent ordering of setting and releasing the locks. \n 16.3.4 File protection \n With multiuser systems the OS must also provide a mechanism to make files private. \nPrivacy does not necessarily mean that only a single user can access a given file. It \nmust be possible for multiple users to share a file. In Chapter 6 we discussed the \nmechanism used in older versions of UNIX and Linux for specifying the access rights \nof the file owner, a group whose membership is defined by the system administrator \nand all other users. These rights are set with the chmod utility. In Chapter 18 we cover \nthe mechanism for specifying access rights to files in the Windows NT OS family and \nin Chapter 19 we mention the newer mechanisms available in Linux systems. \n Sometimes communication between concurrent processes involves sharing infor-\nmation at a file level. Most OSs allow concurrent accesses to files by separate processes \nas a default. In order to avoid problems when one or more of the processes is writing in \na file, the processes must use the same locking mechanisms and proper ordering of lock-\ning and unlocking to synchronize the use of the files just as we do to synchronize the use \nof shared memory. We discuss file protection further in the encryption section below.  \n 16.4 COMMUNICATION SECURITY \n Often a process running on one system will need to communicate with a process run-\nning on a different system. When we send information across a communication link \nfrom one computer to another there are three potential classes of problems that can \noccur at the level of sending the message. These can be seen in  Figure 16.5 . Commu-\nnication in security systems is normally shown as being between two parties, known \nas Alice (A) and Bob (B). First, an outside party can  read (or intercept) the message. \nSecond, an outside party can  send (or insert) a bogus message. And finally, an out-\nside party can  change a message that an authorized user sends. We are concerned \nwith protecting a system against all of these problems.  \n One class of mechanisms that we will commonly use consists of elaborate \nprotocols for specific functions such as authentication. As an example, a protocol \nknown as Kerberos has been developed for authentication. It is widely used, having \nbecome almost a de facto standard. For example, as of Windows 2000, Kerberos \nis the default authentication protocol. Designing such protocols so they are secure \nis a very complex matter and a specialty in its own right. Using such secure protocols \nallows us to be certain that we are communicating with the other party we think we \nare communicating with. This mitigates most problems of having a third party insert \nmessages into the communication stream undetected. \nelm49810_ch16_359-384.indd   373\nelm49810_ch16_359-384.indd   373\n12/11/08   7:35:40 PM\n12/11/08   7:35:40 PM\n",
        "category": "Category"
    },
    {
        "id": "169",
        "title": "Title for Chunk 169",
        "content": "Confirming Pages\n374 \nPart 5 Networks, Distributed Systems, and Security\n 16.4.1 Encryption \n Another class of algorithms has been developed for making sure that messages are \nnot subject to any of the three problems outlined above. These algorithms are used to \nencrypt the messages between the systems in such a way that they cannot be easily \nread by a third party. If they can\u2019t be read, then they can\u2019t be changed. Thus,  encryp-\ntion can eliminate or at least mitigate two of these three problems. Encryption takes a \nmessage (often referred to as the  plaintext ) and uses a known algorithm to scramble \nthe message. A special number called a key is used with these algorithms. Unscram-\nbling the received message will reveal the original message and is called  decryption. \nA schematic of this procedure is seen in  Figure 16.6 . These algorithms rely on the \nfact that when a third party captures an encrypted message it will be  computation-\nally infeasible to decrypt the message without knowing the key. An interceptor could \ntheoretically try every possible key value in what is called a  brute force attack. The \nphrase \u201ccomputationally infeasible\u201d therefore means that it would take so long to \nrun the algorithm with all possible keys that the information would no longer be of \nvalue once it is discovered. Unfortunately, the meaning of computationally infeasible \nconstantly changes. We know that the speed of processors doubles roughly every \n18 months, so what was computationally infeasible 5 years ago may be easy now.  \n We have been discussing encryption mainly in the context of message trans-\nmission. But encryption also can be used in file systems. It can be very useful in \nprotecting information that is very sensitive in case the computer is stolen or lost. As \nsystems are becoming more and more portable, this can be a very useful feature. It is \nTransmission Channel\nPlaintext\nEncryption\nKey\nAlice\nPlaintext\nDecryption\nKey\nBob\nFIGURE 16.6 \nEncryption.\nInsecure\nTransmission\nChannel\nMessage\nAlice\nBob\nIntercepting\nChanging\nInserting\nMessage\nFIGURE 16.5 \nCommunication \nthreats.\nelm49810_ch16_359-384.indd   374\nelm49810_ch16_359-384.indd   374\n12/11/08   7:35:41 PM\n12/11/08   7:35:41 PM\n",
        "category": "Category"
    },
    {
        "id": "170",
        "title": "Title for Chunk 170",
        "content": "Confirming Pages\n \nChapter 16  Protection and Security  \n375\ntrue for PDAs and cell phones as well as laptop computers. They have files stored in \nRAM instead of in secondary storage, but they can often still be encrypted. \n Symmetric key encryption \n Sometimes the decryption uses the same key as the encryption. In this case the key \nmust be known only to the sender and the receiver (though there may be many receiv-\ners of a given encrypted message, and they must all know the key). Algorithms that \nuse such keys are referred to as  symmetric, or sometimes as  shared key or  secret \nkey algorithms.  Figure 16.7 shows how a shared key system works. The secret key \nshared between Alice and Bob is shown as K A,B . \n There are several different algorithms for using symmetric keys. For many years \nthe standard algorithm used was  DES, or  data encryption standard, but it is no \nlonger considered secure. In 2001 a new algorithm known as  AES, or  advanced \nencryption standard, was established. DES used a 56-bit key and AES uses a key \nthat is either 128, 192, or 256 bits long, depending on the needs of the user. When \nAES was released, DES could be broken in a few hours by brute force with a spe-\ncialized hardware system costing under $10,000. Breaking AES with a similar but \nmuch faster machine would take 149 trillion years. One problem with using shared \nsecret keys arises when Alice and Bob do not know each other so they are reluc-\ntant to exchange secret keys. An older method of solving this problem was to use \na  trusted third party ( TTP ) to generate a key and send it to both of them. This \nsolution requires that both users really trust the TTP and also that the TTP always \nbe online and available. Today there are new protocols like Diffie-Hellman and RSA \nthat allow two users to dynamically generate a pair of keys like those discussed in \nthe next paragraph and exchange them over a nonsecure network. \n Asymmetric key encryption \n Other algorithms use a pair of keys that are generated together. One of the keys is used \nfor the encryption and the other is used for the decryption, so these algorithms are called \n asymmetric, or  public  key algorithms. There are two interesting facts about these algo-\nrithms. The first is that one of the pair of keys can be known to the entire world. This \nkey will be called the  public key. The other key will not be public and is therefore called \nthe  private key. In fact, this usually is the case. How this works is seen in  Figure 16.8 . \nBob\u2019s public key is shown as K B  \ufffd  and his private key is shown as K B  \ufffd  .  \n If Alice wants to send an encrypted message to Bob, she can use Bob\u2019s public key \nto encrypt the message. Only Bob knows the matching private key, so only Bob will \nbe able to read the message. Interestingly enough, it does not matter which key is used \nTransmission Channel\nPlaintext\nEncryption\nKA,B\nAlice\nPlaintext\nDecryption\nKA,B\nBob\nFIGURE 16.7 \nSymmetric key \nencryption.\nelm49810_ch16_359-384.indd   375\nelm49810_ch16_359-384.indd   375\n12/11/08   7:35:41 PM\n12/11/08   7:35:41 PM\n",
        "category": "Category"
    },
    {
        "id": "171",
        "title": "Title for Chunk 171",
        "content": "Confirming Pages\n376 \nPart 5 Networks, Distributed Systems, and Security\nfor the encryption as long as the other is used for the decryption. Bob could encrypt a \nmessage with his private key and send it to Alice. If Alice is confident that the public \nkey she has for Bob really does belong to Bob, then she knows the message really \ncame from Bob. (This assumes that the message can otherwise be validated by the pro-\ntocol.) Another interesting fact about the use of public key encryption is that different \nkey pairs can be applied in any order. So Alice can encrypt a message with Bob\u2019s pub-\nlic key and then with her private key. Bob can decrypt the keys in the reverse order or \nthe same order. This property is used in some electronic commerce systems. There are \nseveral algorithms for public key encryption, just as there were for secret key encryp-\ntion. The standard for many years has been  RSA, or  Rivest, Shamir, Adleman after \nthe names of the developers of the algorithm. It is based on prime numbers and relies \non the fact that there are efficient algorithms for testing whether or not a number is \nprime but no efficient algorithm is known for finding the prime factors of a number.  \n 16.4.2 Message digests \n In some circumstances we don\u2019t necessarily want to hide the contents of the message. \nWe only want to make sure that it didn\u2019t get changed. In such cases we can compute \na simpler, faster function known as a  message digest or a  hash. This function is \nseen in  Figure 16.9 . These functions chop a long message into short pieces (typi-\ncally about 512 bits) and combine them with a one-way function\u2014one that cannot \nbe easily reversed. The result is a message digest of a fixed length\u2014usually about \n128 bits. Two algorithms are presently in use,  MD5, which produces a 128-bit hash, \nTransmission Channel\nPlaintext\nEncryption\nKB\n+\nAlice\nPlaintext\nDecryption\nKB\n\u2212\nBob\nFIGURE 16.8 \nAsymmetric key \nencryption. \nPlaintext\nAlice\nBob\nEncryption\nHash\nDigest\nHash\nDecryption\nYes = \nSender \nSigned\nDigest\nTransmission\nChannel\nKeyA\n\u2212\nKeyA\n+\n=?\nFIGURE 16.9 \nMessage signing.\nelm49810_ch16_359-384.indd   376\nelm49810_ch16_359-384.indd   376\n12/11/08   7:35:41 PM\n12/11/08   7:35:41 PM\n",
        "category": "Category"
    },
    {
        "id": "172",
        "title": "Title for Chunk 172",
        "content": "Confirming Pages\n \nChapter 16  Protection and Security  \n377\nand  secure hash standard, or  SHA, which outputs a 160-bit hash. MD5 is com-\nmonly used to validate files downloaded from the Internet via HTTP or FTP, espe-\ncially for programs. The file is downloaded along with a message digest of the file, \ncommonly with an extension of .md5. Then a publicly available utility is run against \nthe downloaded file and a new digest is computed. If the new one matches the \ndownloaded one, then one can be assured that the file was not changed after it was \nuploaded to the server and that the download also did not change it. Unfortunately, \nMD5 is now known to be breakable with only modest amounts of computing power, \nso it is mainly useful to ensure that a file was downloaded correctly. \n 16.4.3 Message signing and certificates \n By combining a message digest with public key encryption Alice can effectively sign \na message electronically. Alice will take a message M and create a digest of the mes-\nsage. She will encrypt the digest with her private key and send both the message and \nthe encrypted digest to  Bob. Bob knows her public key, so he can decrypt the digest. \nHe can then run the publicly available digest algorithm on the message and compare \nthat computed digest to the decrypted one. If they are equal, then he knows (and can \nprove) that Alice sent the message. This ensures that Alice cannot later  repudiate the \nmessage. Note that in order to prove this at a later date Bob must keep the message, \nthe signed digest, and Alice\u2019s public key, since Alice might later change her public \nkey. Note also that Bob cannot change the message and still claim that Alice sent it, \nso it also protects Alice against having Bob change the message. \n A special use of signing of messages is used to authenticate either clients or serv-\ners. This process produces a  certificate that verifies identity. A special program is run \nthat produces a preliminary certificate. A bank would do this on their server. The pre-\nliminary certificate is sent to a  certificate authority, and the CA encrypts the certificate \nwith its private key and returns it to the requesting entity as a finished certificate. The \nbank now installs this certificate on their server. The bank can now send this certificate \nto clients to prove its identity. So when a browser tries to make a secure connection to \nthe bank\u2019s server, the server will send back the certificate to the browser. The browser \ncan decrypt the certificate by using the public key of the certificate authority to verify \nthe identity of the bank. The public key of popular certificate authorities are built-in to \nmost browsers. So the browser decrypts the bank\u2019s certificate with the public key of \nthe CA and the user now knows that the browser has really connected to the bank. \n We mentioned before that Alice can send Bob a message by encrypting it with \nhis public key. The problem there is that Alice must be sure that the key really is \nBob\u2019s public key. The way that she can ensure that is for Bob to use a certificate \nauthority to sign his public key with their own private key. Alice can use the public \nkey of the certificate authority to open the key and verify that it is Bob\u2019s key inside. \nMessages signed electronically in such a way are legally admissible in court. \n 16.4.4 Security protocols \n As we saw in the last chapter, network support is divided into several layers. Each \nlayer provides certain capabilities. An interesting question is, what layer in the proto-\ncol stack provides security? As it happens, security functions have been specified at \nelm49810_ch16_359-384.indd   377\nelm49810_ch16_359-384.indd   377\n12/11/08   7:35:42 PM\n12/11/08   7:35:42 PM\n",
        "category": "Category"
    },
    {
        "id": "173",
        "title": "Title for Chunk 173",
        "content": "Confirming Pages\n378 \nPart 5 Networks, Distributed Systems, and Security\nseveral different layers. In the TCP/IP protocol used in the Internet, security has been \nspecified for both the Transport layer and the Network layer. If we are using 802.11 \nwireless networking, then there may also be encryption at the Data Link layer. In the \nTransport layer security features are defined in a protocol called  SSL, or  secure socket \nlayer (also called  TLS, or  transport layer security ). This protocol is commonly used \nbetween Web servers and browsers for secure communication in combination with an \napplication layer protocol called  HTTPS or secure HTTP. The server is authenticated, \nas discussed in the last section, with a certificate assuring the client process that it is \ntalking to the correct server. The two entities will initially use their own public and \nprivate keys for asymmetric encryption. They will then decide on a temporary secure \n session key  and continue the session with symmetric encryption. Symmetric keys are \nmore efficient to use than asymmetric keys but repeated reuse of them is risky, so they \nare commonly generated for a single connection and then discarded. \n Security is also available at the Network layer with a protocol known as  IPsec, \nor  IP security. IPsec is a set of protocols developed by the IETF to support secure \nexchange of packets at the IP layer. It supports two encryption modes: transport \nand tunnel. Transport mode encrypts only the data inside the messages but ignores \nthe header. Tunnel mode is more secure since it encrypts both the header and the \nmessage. IPsec uses shared public keys for both the sender and receiver. These are \nexchanged by a protocol known as  Internet Security Association and Key Man-\nagement Protocol/Oakley ( ISAKMP/Oakley ) which allows the receiver to obtain \na public key and authenticate the sender using digital certificates. IPsec is more flex-\nible than TLS since it can be used with all the Internet Transport layer protocols, \nincluding TCP, UDP, and ICMP, but is more complex and has processing overhead \nbecause it cannot use Transport layer functions that increase security. \n Security is also available at the Application layer with a protocol known as  PGP, \nor  pretty good privacy. PGP uses a public key system in which each user has a public\u2013\nprivate key pair. For creating digital signatures, PGP generates a hash from the user\u2019s \nname and other signature data. This hash code is then encrypted with the sender\u2019s pri-\nvate key. The receiver uses the sender\u2019s public key to decrypt the hash code. If it matches \nthe hash code sent as the digital signature for the message, then the receiver is sure that \nthe message was sent by the stated sender and was not changed, either accidentally or \nintentionally. PGP has two versions, one using RSA to exchange session keys and the \nother using a Diffie-Hellman protocol. The RSA version uses the MD5 algorithm to \ngenerate the hash code while the Diffie-Hellman uses the SHA-1 algorithm.  \n 16.4.5 Network protection \n There are several facilities that can be used in a network to improve security that are \nnot actually inside an OS, but we will discuss them briefly because they impact the \nsecurity features inside an OS. Actually, most of these facilities are applications that \nrun inside a dedicated computer. \n Most homes and organizations that run a local area network are connected to \nthe Internet at only one point (though some businesses have dual connections if they \ncan justify the cost of the extra reliability). This one connection is an ideal point to \ninspect communication messages for various problems. The facility that provides \nelm49810_ch16_359-384.indd   378\nelm49810_ch16_359-384.indd   378\n12/11/08   7:35:42 PM\n12/11/08   7:35:42 PM\n",
        "category": "Category"
    },
    {
        "id": "174",
        "title": "Title for Chunk 174",
        "content": "Confirming Pages\n \nChapter 16  Protection and Security  \n379\nthis function is called a  firewall. Normally, this function is embedded in the router \nthat connects to the Internet since the router is looking at the packets anyway. A typi-\ncal firewall configuration is shown in  Figure 16.10 . There are several functions that a \nfirewall can do. First, it can block certain types of connections altogether by looking \nat the port numbers used by the connection requests. It can also inspect the insides of \nthe packets and disallow certain types of traffic\u2014pings, for example. Some firewalls \nalso are configured to disallow traffic from IP addresses that are considered to be \nunsafe or unsavory. Firewalls can be supplied with  signatures, data patterns known \nto be associated with specific attacks. They can also include a  traffic monitor that \nwatches for patterns that indicate a significant deviation from normal traffic patterns. \nThis monitoring is also known as  anomaly detection. Network protection systems \nusing signatures or anomaly detection are usually called  intrusion detection sys-\ntems ( IDSs ) and  intrusion prevention systems ( IPSs ). The firewall in the figure \nalso shows a  demilitarized zone, or  DMZ. This military term in this case refers to a \nseparate network that can be accessed either from the outside network or the inside \nnetwork. This allows local staff to maintain the contents of servers located there and \nstill have those servers accessed from the Internet. \n One problem with firewalls at the network connection point is that not all machines \nin the network need the same types of connections. While a large university with a \nbig UNIX server would likely want to allow Telnet sessions to be set up through the \nfirewall, it is not likely that a Telnet session is needed to a personal computer. There-\nfore, it is common to also provide a firewall function in a personal computer that will \ndisallow such sessions. Interestingly, it often will be configured to disallow many \noutbound connections as well as inbound connections since a common technique of \nmany viruses is to connect to rogue hosts to report purloined information. A local \nfirewall will be an application program rather than a part of the OS, but in order to \ninspect the connections that are being requested and the traffic coming and going, \nthey will need to be able to insert their functionality in the protocol stack. This is an \nunusual requirement for an application to make of a protocol stack, but OS designers \nhave learned of the necessity to provide it for this special class of applications. Thus \nthese programs are not only able to watch for text patterns in the messages but can \nPublic\nServers\nInside Network\n\u201cDMZ\u201d Network\nFirewall\nConnections to\nOutside Networks\nFIGURE 16.10 \nA modern firewall.\nelm49810_ch16_359-384.indd   379\nelm49810_ch16_359-384.indd   379\n12/11/08   7:35:42 PM\n12/11/08   7:35:42 PM\n",
        "category": "Category"
    },
    {
        "id": "175",
        "title": "Title for Chunk 175",
        "content": "Confirming Pages\n380 \nPart 5 Networks, Distributed Systems, and Security\nalso monitor other system activity to detect behavior that is characteristic of viruses \nsuch as accesses to certain system files not normally accessed by applications.  \n 16.5 SECURITY ADMINISTRATION \n There are several things that a system administrator must do to ensure the security of \nthe systems connected to a network. We have already discussed the need for a regular \nbackup system, firewalls, and traffic monitoring. In addition, several actions should \nbe logged and the logs reviewed regularly. First would be the log of failed login \nattempts. A small number of failed logins will be normal\u2014passwords should expire \nfrom time to time, users will accidentally type something wrong or use a password \nfrom another system, and so on. Any spike in the number of failed logins should \ngive cause for alarm as a likely indication of attempts at penetrating a system. Other \nfailures should also be logged and analyzed, such as a failure to find a requested Web \npage on a Web server. Such errors may only show bad links, but close examination \nmight expose attempts at hacking the server. \n Some systems have substantially higher security requirements than do others. A \nhome personal computer probably needs little security beyond keeping out viruses \nand hackers. A bank needs a higher level of security because of the money involved. \nA hospital system charged with patient care probably needs still higher security \nbecause problems with the system can literally be a matter of life or death for a \npatient. A military system might need still higher security because a failure could put \nmillions of lives at risk. As a result, the National Computer Security Center (NCSC), \nan agency of the U.S. government, has published a definition of four major levels of \nsecurity with some minor variants. With each higher level the OS must provide extra \nfeatures, many in the area of logging of activities. Needless to say, we don\u2019t want to \nload down the OS of a personal computer in a home with all the features necessary \nfor security on that military system. The lowest level is D, which has minimal secu-\nrity. A system with this level of security might be used by any user in an office or \nin a home. As an example of the increasing levels, the additional requirements (over \nthose required for C1) for a C2 rating are:\n \ufffd Access control works on per user basis. It must be possible to permit access to \nany selected subset of the user community. \n \ufffd Memory must be cleared after use. The OS must ensure that disk space and \nmemory allocated to a process does not contain data from previous operations.  \n \ufffd The OS must be capable of recording security-relevant events, including authen-\ntication and object access. The audit log must be protected from tampering and \nmust record the date, time, user, object, and event.  \n Most commercial OSs today can easily operate at the C2 level. OSs that operate at \nhigher levels are generally specially designed for that purpose. For government pur-\nposes, the security level of an OS must be established by an independent third-party \nauditing firm. Furthermore, the certification applies only to a specific release of the \nOS and a specific hardware configuration so generic certification by the manufacturers \nis not often done at these levels.  \nelm49810_ch16_359-384.indd   380\nelm49810_ch16_359-384.indd   380\n12/11/08   7:35:43 PM\n12/11/08   7:35:43 PM\n",
        "category": "Category"
    },
    {
        "id": "176",
        "title": "Title for Chunk 176",
        "content": "Confirming Pages\n \nChapter 16  Protection and Security  \n381\n 16.6 SUMMARY \n Since computer systems are now accessible by many \nusers and are more often connected to the Internet, \nit is necessary that the systems, the files therein, the \nrunning processes, and the communications between \nusers and between processes be protected from harm, \neither accidental or intentional. In this chapter we \ndiscussed several facets of protection and security as \nthey pertain to OSs. First, we gave an overview of \nsystem security problems. We classified some of the \nsecurity problems we see as a result of being con-\nnected to the Internet and described how an OS needs \nto deal with them, including mechanisms outside the \nOS. Then we moved on to discuss the protection \nservices OSs offer to users, primarily in the area of \nprivacy of files. We described the general designs of \nsuch services. The OS must also provide services for \nprocesses. Significant barriers are erected between \nrunning processes and the OS. We looked at some of \nthe services provided to processes that are communi-\ncating with one another.  Section 16.4  covered secu-\nrity about networks, most specifically the Internet. \nIt discussed encryption, authentication protocol, and \nmessage digests, and the related topics of network \nsecurity outside of the OSs. We covered problems of \nadministration of network and OS security.  \n In the next chapter we take a look at special con-\nsiderations we must use when using OSs to create \nsystems that are distributed across multiple systems. \n BIBLIOGRAPHY \n Akl, S. G., \u201cDigital Signatures: A Tutorial Survey,\u201d \n Computer, Vol. 16, No. 2, February 1983, pp. 15\u201324. \n Denning, D. E., \u201cProtecting Public Keys and Signature \nKeys,\u201d  IEEE Computer, Vol. 16, No. 2, February \n1983, pp. 27\u201335. \n Denning, D. E., \u201cDigital Signatures with RSA and Other \nPublic-Key Cryptosystems,\u201d  Communications of the \nACM, Vol. 27, No. 4, April 1984, pp. 388\u2013392. \n Dennis, J. B., and E. C. Van Horn, \u201cProgramming \nSemantics for Multiprogrammed Computations,\u201d \n Communications of the ACM, Vol. 9, No. 3, \nMarch 1966, pp. 143\u2013155. \n Farrow, R., \u201cSecurity Issues and Strategies for Users,\u201d \n UNIX World, April 1986, pp. 65\u201371. \n Farrow, R., \u201cSecurity for Superusers, or How to Break \nthe UNIX System,\u201d  UNIX World, May 1986, \npp. 65\u201370. \n Filipski, A., and J. Hanko, \u201cMaking Unix Secure,\u201d  Byte, \nApril 1986, pp. 113\u2013128. \n Grampp, F. T., and R. H. Morris, \u201cUNIX Operating \nSystem Security,\u201d  AT&T Bell Laboratories \nTechnical Journal, Vol. 63, No. 8, October 1984, \npp. 1649\u20131672. \n Hecht, M. S., A. Johri, R. Aditham, and T. J. Wei, \n\u201cExperience Adding C2 Security Features \nto UNIX,\u201d  USENIX Conference Proceedings, \nSan Francisco, June 20\u201324, 1988, pp. 133\u2013146. \n Kramer, S. M., \u201cRetaining SUID Programs in a Secure \nUNIX,\u201d  USENIX Conference Proceedings, \nSan Francisco, June 20\u201324, 1988, pp. 107\u2013118. \n Lamport, L., \u201cPassword Authentication with Insecure \nCommunication,\u201d  Communications of the ACM, \nVol. 24, No. 11, November 1981, pp. 770\u2013772. \n Lehmann, F., \u201cComputer Break-Ins,\u201d  Communications \nof the ACM, Vol. 30, No. 7, July 1987, pp. 584\u2013585. \n National Bureau of Standards, \u201cData Encryption \nStandard DES,\u201d NTIS  NBS-FIPS PUB 46, \nJanuary 1977. \n Needham, R. M., and M. D. Schoeder, \u201cUsing \nEncryption for Authentication in Large Networks \nof Computers,  Communications of the ACM, \nVol. 21, No. 12, 1978, pp. 993\u2013999. \n Organick, E. I.,  The Multics System: An Examination \nof Its Structure. Cambridge, MA: MIT Press, 1972. \n Reid, B., \u201cReflections on Some Recent Widespread \nComputer Break-Ins,\u201d  Communications of the ACM, \nVol. 30, No. 2, February 1987, pp. 103\u2013105. \n Rivest, R., and A. Shamir, \u201cHow to Expose an \nEavesdropper,\u201d  Communications of the ACM, \nVol. 27, No. 4, April 1984, pp. 393\u2013394. \n Rivest, R., A. Shamir, and L. Adleman, \u201cOn Digital \nSignatures and Public Key Cryptosystems,\u201d \n Communications of the ACM, Vol. 21, No. 2, \nFebruary 1978, pp. 120\u2013126. \nelm49810_ch16_359-384.indd   381\nelm49810_ch16_359-384.indd   381\n12/11/08   7:35:43 PM\n12/11/08   7:35:43 PM\n",
        "category": "Category"
    },
    {
        "id": "177",
        "title": "Title for Chunk 177",
        "content": "Confirming Pages\n382 \nPart 5 Networks, Distributed Systems, and Security\n Rushby, J. M., \u201cDesign and Verification of Secure \nSystems,\u201d  Proceedings of the 8th Symposium on \nOperating Systems Principles, Vol. 15, No. 5, \nDecember 1981, pp. 12\u201321. \n Rushby, J., and B. Randell, \u201cA Distributed Secure \nSystem,\u201d  Computer, Vol. 16, No. 7, July 1983, \npp. 55\u201367. \n Schell, R. R., \u201cA Security Kernel for a Multiprocessor \nMicrocomputer,\u201d  Computer, Vol. 16, No. 7, July \n1983, pp. 47\u201353. \n Silverman, J. M., \u201cReflections on the Verification of \nthe Security of an Operating System Kernel,\u201d \n Proceedings of the 9th Symposium on Operating \nSystems Principles, ACM, Vol. 17, No. 5, October \n1983, pp. 143\u2013154. \n Simmons, G. J., \u201cSymmetric and Asymmetric \nEncryption,\u201d  ACM Computing Surveys, Vol. 11, \nNo. 4, December 1979, pp. 305\u2013330. \n Spafford, E. H., \u201cThe Internet Worm Program: An \nAnalysis,\u201d  Purdue Technical Report CSD-TR-823, \nNovember 28, 1988. \n Wood, P., and S. Kochan,  UNIX System Security. Carmel, \nIN: Hayden Book Co., 1985.  \n WEB RESOURCES \n http://ciac.llnl.gov/ciac/index.html (U.S. Department of \nEnergy, Office of the Chief Information Officer\u2014\ncomputer incident advisory capability) \n http://www.cert.org (Carnegie Mellon University\u2019s \nComputer Emergency Response Team) \n http://freshmeat.net (Web\u2019s largest index of UNIX \nand cross-platform software) \n http://www.ietf.org (Internet Engineering Task Force, \nincluding all RFCs) \n http://www.linuxsecurity.com  \n http://www.netfilter.org (packet filtering framework \nfor Linux) \n http://www.networkcomputing.com (networking \nmagazine with online edition)  \n http://packetstormsecurity.org (nonprofit organization \nof security professionals dedicated to securing \nnetworks) \n http://www.redbooks.ibm.com (IBM publications \narchive) \n http://www.tasklist.org (software to list all processes \nrunning on a Windows system) \n http://tldp.org (Linux Documentation Project [LDP]) \n http://www.usenix.org/publications/ (USENIX, the \nAdvanced Computing Systems Association) \n http://en.wikipedia.org/wiki/Identd (daemon program \nfor providing the ident service) \n http://www.windowsecurity.com \n REVIEW QUESTIONS \n 16.1 Which is the larger problem, hackers or insiders? \nJustify your answer. \n 16.2 What characteristics of malware distinguish a virus \nprogram?  \n 16.3 What characteristics of malware distinguish a \nTrojan program?  \n \n16.4 What characteristics of malware distinguish a worm \nprogram?  \n 16.5 Briefly describe a buffer overflow. \n 16.6 What is the purpose of the sandbox model? \n 16.7 Authentication makes use of some special mecha-\nnism to verify the identity of an entity. Most often \nwe are concerned with verifying the identity of \na user. Which of the following did we  not say was \nsomething that could be used to verify the identity \nof a user?\n \na. Something you have \n \nb. Something you see \n \nc. Something you know \n \nd. Something you are \n \ne. All of the above can be used to verify a user\u2019s \nidentity.  \n \n16.8 Once a user (or other entity) is authenticated, the \nactions allowed by the user must be authorized. \nWe discussed two different mechanisms that are \noften used to support authorization. The first was an \naccess control list. Briefly describe what an ACL is.  \n 16.9 What is a capability list? \nelm49810_ch16_359-384.indd   382\nelm49810_ch16_359-384.indd   382\n12/11/08   7:35:43 PM\n12/11/08   7:35:43 PM\n",
        "category": "Category"
    },
    {
        "id": "178",
        "title": "Title for Chunk 178",
        "content": "Confirming Pages\n \nChapter 16  Protection and Security  \n383\n 16.10 Where should backup copies of data be stored? \n 16.11 What is meant by the phrase \u201cbrute force attack\u201d?  \n 16.12 How many key values are used in a symmetric \nkey encryption system? \n 16.13 True or false? In a asymmetric key encryption key \nsystem it is crucial for both of the key values to be \nkept secret. \n 16.14 If we are not particularly concerned about confi-\ndentiality but we want to ensure that a message \nthat is sent is not altered by any party, what sort \nof mechanism would we use? \n 16.15 A certificate authority signs a user\u2019s public key \nwith its own private key. How does a browser use \nthat to verify the user\u2019s public key? \n 16.16 What secure protocol is used on the Web for \nHTTPS connections? \n 16.17 What is a common mechanism for protecting a \nnetwork from an outside attack? \nelm49810_ch16_359-384.indd   383\nelm49810_ch16_359-384.indd   383\n12/11/08   7:35:44 PM\n12/11/08   7:35:44 PM\n",
        "category": "Category"
    },
    {
        "id": "179",
        "title": "Title for Chunk 179",
        "content": "elm49810_ch16_359-384.indd   384\nelm49810_ch16_359-384.indd   384\n12/11/08   7:35:44 PM\n12/11/08   7:35:44 PM\n",
        "category": "Category"
    },
    {
        "id": "180",
        "title": "Title for Chunk 180",
        "content": "Confirming Pages\n181\n Chapter \n Chapter  9  9 \n More Process \nManagement: Interprocess \nCommunication, \nSynchronization, \nand Deadlocks \nIn this chapter: \n \n9.1 Why Have Cooperating Processes? 182\n \n9.2 Interprocess Communication 184\n \n9.3 Synchronization 190\n \n9.4 Deadlocks 197\n \n9.5 Summary  206\n  I\nn this chapter we continue the in-depth discussion of processes and threads. We \ndiscuss techniques for designing applications that are divided into multiple parts \nin order to keep the system busier working on behalf of the application. When \nwe break applications into multiple parts, the parts will need to cooperate, and to do \nthat they will need to communicate with one another. Since we spent considerable \ntime explaining how and why an OS isolated processes, we now need to explain the \nmechanisms that have evolved to allow them to communicate. \n OSs devote a great deal of their resources to ensuring that processes are inde-\npendent of one another. More formally, an  independent process cannot affect or \nbe affected by the execution of another process. On the other hand, we sometimes \nneed for two or more processes to cooperate with one another. Again, formally, a \ncooperating process  is one that can affect or be affected by the execution of another \nprocess. When we try to develop systems we may need to allow for the system to \ninclude multiple cooperating processes. Sometimes we will need for parts of the pro-\ncess to run on different machines, and sometimes they will run on the same machine. \nelm49810_ch09_181-208.indd   181\nelm49810_ch09_181-208.indd   181\n12/6/08   5:54:59 PM\n12/6/08   5:54:59 PM\n",
        "category": "Category"
    },
    {
        "id": "181",
        "title": "Title for Chunk 181",
        "content": "Confirming Pages\n182 \nPart 3 CPU and Memory Management\nIn any case, the parts will need to do several things in order to cooperate successfully \nwith one another to do the job. They will certainly need to  communicate with one \nanother. For example, one process might be taking in sales orders. It may then pass \nthose orders to another process, which will enter a transaction to ship the merchan-\ndise. Processes may also need to  synchronize their actions so that they do not inter-\nfere with one another by trying to update the same piece of information at the same \ntime. As the processes run they may need to ask the OS to give them exclusive access \nto a resource for some time. It turns out that this can lead to a special kind of problem \ncalled a  deadlock that the OS will need to worry about. \n This chapter will talk mostly about separate processes, but much of the material \nalso applies to multiple threads. In particular, threads share memory and will have \nmany of the synchronization and deadlock issues addressed in this chapter. They will \ngenerally not use the message-passing mechanisms often used between processes. \n In Section 9.1, we discuss the motivating factors behind this idea\u2014why do we \nsometimes have to divide applications even though we might not necessarily desire \nto do so? Next, Section 9.2 describes various mechanisms used by cooperating pro-\ncesses to communicate among themselves. In Section 9.3, we explore the need for \nprocesses to synchronize their activities and discuss some mechanisms for doing so. \nIn Section 9.4, we discuss a potential problem called a deadlock that can arise when \nprocesses seek to have exclusive access to resources. We conclude with a chapter \nsummary in Section 9.5. \n 9.1 WHY HAVE COOPERATING PROCESSES? \n Before we get into the details of how processes can communicate, it makes sense \nto ask why we might want to divide our system into multiple processes. There are a \nnumber of reasons why we may want to develop systems where the application runs \nin several pieces: \n Performance. When we design a system we may have more work to be done \nthan can be done on one inexpensive processor. It may be more economical to put in \nseveral inexpensive processors and run some portion of the process on each machine \nthan it would be to buy a bigger system that could do the entire task itself. If the sys-\ntem will need to service a large number of users it might not be possible to service \nthem all with a single system. \n Scaling. When we first develop an application we do not necessarily know how \nbig the system load will get. What we think of as a small service might become an \novernight sensation and require that it serve many more users than we originally \nthought it would. A good example is the Google \u2122 search engine. Whatever the \ndreams of the originators of this service, it is very doubtful that they ever imagined \nthat by the year 2004 they would have 65,000 servers running the application. This \nreason is obviously closely related to the performance problem, but it is different. \n Purchased components. We may want our system to include some function \nsuch as a Web server. It is unlikely that we would find it economical to develop our \nown Web server. We would most likely use an existing Web server program and fit it \ninto our system somehow\u2014perhaps by writing parts of the system that dynamically \ncreate pages that the purchased server displays. \nelm49810_ch09_181-208.indd   182\nelm49810_ch09_181-208.indd   182\n12/6/08   5:55:02 PM\n12/6/08   5:55:02 PM\n",
        "category": "Category"
    },
    {
        "id": "182",
        "title": "Title for Chunk 182",
        "content": "Confirming Pages\n \nChapter 9  More Process Management: Interprocess Communication, Synchronization, and Deadlocks   \n183\n Third-party service. Our system might make use of a service that is provided \nby another organization. A typical example is to enter a credit card charge. Again, it \nis unlikely that we could develop a system to do this function as cheaply as buying \nthe service unless we have a very high volume of transactions to process. \n Components in multiple systems. We might be building a number of different \nsystems that do similar jobs. Rather than build similar parts of many systems and \nbe required to maintain them separately, we can build the common components to \nrun as a separate process and have the various systems feed transactions to the com-\nmon components. For example, these days a company selling directly to the public \nwill likely have a website that allows customers to place orders online. It might also \nhave retail counters in the stores, a telemarketing group that takes orders over the \ntelephone in response to infomercials run on TV, and a mail-order catalog group that \nenters orders as well. Each of these systems might accept orders in a different way \nand use the common services of other processes to first verify and later charge cus-\ntomer credit cards, to order shipping from the warehouse, to monitor inventory, and \nto place orders with suppliers when goods appear to be running low. These common \ncomponents may be run as separate processes. \n Reliability. When systems are built in one piece and are all on one computer, \nthen a significant failure in that computer will terminate the entire system. If systems \nare built in a modular fashion then there can be multiple instances of each module. \nReturning to the Google design, if one system out of 10,000 fails, then the sys-\ntem will continue to run. There might be a few users whose searches were already \nallocated to the failing server. They may have to click the \u201creload\u201d button, but will \nprobably be totally unaware that a server at the host site has been lost. In the case \nof Google, they have even split the servers among several different sites, so that a \nphysical disaster such as a fire or flood will not take out the entire system. \n Physical location of information. Even a small company will sometimes end \nup with multiple facilities. Often this situation arises because one company buys \nanother. Whatever the reason, we may end up with multiple warehouses, for exam-\nple, and for most transactions we will want to have an inventory system at the site. \nFor other purposes, we will want to have parts of the system at a central location. \nDue to volume discounts, for example, we will want a single centralized purchasing \nfunction. If we have designed the various warehouse inventory systems so that they \nfeed inventory requests to the purchasing system, then we can view this as a single \nsystem, parts of which are at various physical locations. \n Enable application. There are a very few applications that have such massive \ncomputational requirements that they literally could not be done on existing computer \nsystems. Sometimes this is partly a question of economics\u2014a big enough machine \ncould be built but the organization wanting to solve the problem could not afford it. \nSometimes we would only have to wait a few years. Roughly speaking, the power \nof available processors doubles every 18 months. With the continuous application of \nthis law we might have a big enough machine soon. An example of such a system is \nthat employed by SETI (Search for Extra-Terrestrial Intelligence). This is a system \nthat takes large volumes of data recorded by a large radio telescope and searches it \nfor patterns that might indicate an intelligent origin to the data. The amount of data \nis so massive that in order to get it processed by the machines available today they \ndivide it up into smaller data sets and distribute those data sets to various interested \nelm49810_ch09_181-208.indd   183\nelm49810_ch09_181-208.indd   183\n12/6/08   5:55:02 PM\n12/6/08   5:55:02 PM\n",
        "category": "Category"
    },
    {
        "id": "183",
        "title": "Title for Chunk 183",
        "content": "Confirming Pages\n184 \nPart 3 CPU and Memory Management\nusers who have volunteered to let the idle time on their computer system be used to \nprocess this data via the mechanism of a screen saver. Regardless of your opinion \nof the scientific merits of this endeavor, it was certainly one of the first systems to \nemploy this technique. When viewed as a single, loosely coupled system, it currently \nrepresents the world\u2019s single largest computer system. Without this \u201cdivide and con-\nquer\u201d approach, they literally could not have processed this data. \n 9.2 INTERPROCESS COMMUNICATION \n For one or more of these reasons, people have been building systems of multiple \ncooperating processes for some time now, and the number of such systems is grow-\ning rapidly, both in absolute numbers and as a percentage of new applications. Obvi-\nously, if we are going to have a system that is comprised of multiple processes, those \nprocesses will have to communicate to get the work done. However, we have spent \na great deal of time and effort making sure that two processes running on the same \nsystem can\u2019t interfere with one another. Therefore, we need to develop mechanisms \nto allow processes to communicate. As developers began to recognize this need, \nthose of them in different environments saw the problem in different terms. They \nalso had different tools to work with. IBM mainframe customers using SNA and \nSDLC saw things differently from PC users using Novell Netware, and they saw \nthings differently from UNIX or VAX users with XNS or DECNet or TCP/IP. As \na result, there are dozens of different mechanisms that exist for processes to com-\nmunicate with one another. There are two fairly different types of mechanisms for \nIPC. On the one hand, there are message passing mechanisms. They operate much \nas the term specifies\u2014one process sends a message to another process using some \nfacility of the OS. Message passing is generally done between processes. On the \nother hand, is the use of shared memory. With such a mechanism two or more tasks \nshare access to one block of memory. Sharing of memory space is implicit between \nthreads of a single process, but it can also be done among processes. Before discuss-\ning these classes of mechanisms we will first abstract the common features of all the \nmechanisms so that when you are faced with a different mechanism you will have \nan organized structure with which to identify the important characteristics. Then we \nlook at a few of the more common mechanisms.  \n 9.2.1 Attributes of communication mechanisms \n The services available for processes to use for communication can be characterized \nby several different attributes:\n Number of processes that can use a single channel at one time \n One-way or bidirectional connections \n Buffering strategy (none, 1, N, infinite) \n Connection oriented or connectionless \n Naming strategy (name, one way or two way, mailbox, port) \n Multicast, broadcast, unicast \nelm49810_ch09_181-208.indd   184\nelm49810_ch09_181-208.indd   184\n12/6/08   5:55:02 PM\n12/6/08   5:55:02 PM\n",
        "category": "Category"
    },
    {
        "id": "184",
        "title": "Title for Chunk 184",
        "content": "Confirming Pages\n \nChapter 9  More Process Management: Interprocess Communication, Synchronization, and Deadlocks   \n185\n Multiple or single connections possible \n Streaming or message oriented \n Heterogeneous or homogeneous only \n Synchronous or asynchronous \n Persistent or transient \n Number of processes supported. In most cases there are only two processes \ninvolved in a specific interprocess communication. But in some cases there can be \nmany processes involved in communicating among themselves at the same time. For \nexample, many processes might be able to simultaneously share a connection to a \nsingle process that would write records to a log file. \n One-way or bidirectional. While it might be somewhat unusual for cooperating \nprocesses to have communication that was only one way, it is not unusual to have com-\nmunication channels that are one way. What normally happens with one-way channels \nis that two channels may be set up between two processes, but the channels are going \nin opposite directions. This type of mechanism is usually found where the communi-\ncation is much heavier in one direction than in the other. For example, one process is \nsending transactions to a second process and the second process is only sending back \nacknowledgments. We might need many large buffers on the first channel but many \nfewer or much smaller buffers or lower bandwidth on the return channel. \n Buffering strategy. There are four different cases of handling the buffers in \na communication channel based on the number of buffers available: none, one, N, \nand infinite. The first case is where there is  no buffer to which both processes have \naccess. Both processes must be accessing the channel at the same time so that one \nprocess can send the message to the other process. The second case is that there \nis only  one buffer with both processes having shared access to it. In this case, the \nsending process will put a message in the buffer and then tell the OS it is available. \nThe OS will tell the receiving process that the message is there and it will take the \nmessage out of the buffer. It will then tell the OS that the sender can send another. \nThe case of one buffer might appear to be just one possible instance of the case of N \nbuffers, but in the case of one buffer we can use simple mechanisms to synchronize \nthe processes. The processes always know which buffer to use, and the processes \nonly need to coordinate whether the buffer is now available for the sender to insert \na message into it or not. In the case of  N buffers we have much more informa-\ntion to coordinate. The communication channel mechanism for each process must \nknow where the buffers are and which ones contain messages and which do not. We \ndiscuss these problems further in Section 9.3.9. The last case is where the channel \nmechanism has some external memory that it can use to expand the buffer space by \nessentially an infinite amount. An example might be a spooling system that uses a \ndisk file to hold a message stream until a printer is available on which to print it. For \npractical purposes the sending process can consider the buffer to be infinite. \n Connection oriented or connectionless. A communication channel can be \nconnection oriented or connectionless. Sometimes communicating processes need \nto establish a complex conversation. In this case they will be likely to establish a \nconnection that they will use for the duration of their interaction. A good analogy is \na telephone call where one person calls another. The terminology comes from a time \nelm49810_ch09_181-208.indd   185\nelm49810_ch09_181-208.indd   185\n12/6/08   5:55:02 PM\n12/6/08   5:55:02 PM\n",
        "category": "Category"
    },
    {
        "id": "185",
        "title": "Title for Chunk 185",
        "content": "Confirming Pages\n186 \nPart 3 CPU and Memory Management\nwhen connections were made between devices using an actual physical connection. \nToday the connection is likely to be a logical or virtual connection. Sometimes, \nhowever, one process simply has information to send and does not care what other \nprocesses might be listening. An example might be an application where a server in \na company is broadcasting stock purchase information so that clients can receive it \nif they want. An analogy might be to a radio broadcast. There might be millions of \nlisteners or none. \n Naming strategy. When two processes are going to communicate with one \nanother, they will need some mechanism to identify one another. This is called the \nnaming strategy. In the strictest case, both processes must explicitly name each other. \nThe name is most often the name of the executable file used to run the program, but \nnames can be associated with running processes in other ways\u2014in some systems the \nprocess id number might be used as a name. This specific naming mechanism has \nthe advantage of having the least margin for error, but also requires the most effort \nto maintain. It is generally only useful when the same developers are responsible \nfor both processes and there is only one sender and one receiver. In a somewhat \nlooser model, the message sender must specify the name of the receiving process, \nbut the receiver is willing to accept transmissions from any sending process. The \nthird model is that both processes agree on some other reference that they will both \nuse. Examples include mailbox numbers and TCP/IP ports. \n Another attribute of interprocess communication is whether the messages are \nsent as a  unicast,  a multicast, or a  broadcast. Unicast messages are sent only to the \nreceiver, so if many processes are cooperating, then many messages may need to be \nsent for all processes to receive the message. Unicast messages are private, however. \nBroadcast messages are sent so that every process (in a given environment) can hear \nthem. An example might be a time server that periodically sends clock update mes-\nsages so that any process can read them. Unfortunately, broadcast messages must \nbe received and processed by all processes, whether the process is interested in the \nmessage or not, so it may waste resources. Some messages might need to be received \nby all processes\u2014a system shutdown request, for example. Multicast messages are \nintended only for a group of receivers. Sometimes this is for security reasons, so \nthat membership in the group might be restricted. Sometimes multicast groups are \ncreated only to save resources for those processes not interested in the messages\u2014a \nstock ticker application might be a good example. \n Multiple or single connections possible. Most of the time it is sufficient to \nallow only one connection between two processes. Sometimes it is desirable to have \nseparate channels for data messages and control messages. FTP is an example of a \nstandard that uses two connections in this manner. There can also be multiple paral-\nlel data connections. An example of multiple connections is the mechanism used in \nsome Web browser/server connections using the HTTP version 1 protocol. In this \nprotocol a single channel could retrieve only one object from the server and then the \nserver would close the connection. In order to speed up the process, a browser could \nretrieve a main page and parse it to find the other elements needed to display the \npage. It then could open as many connections as there were objects to retrieve. (In \npractice the client usually opened only some limited number at one time in order to \nkeep from bogging down the server.) \nelm49810_ch09_181-208.indd   186\nelm49810_ch09_181-208.indd   186\n12/6/08   5:55:03 PM\n12/6/08   5:55:03 PM\n",
        "category": "Category"
    },
    {
        "id": "186",
        "title": "Title for Chunk 186",
        "content": "Confirming Pages\n \nChapter 9  More Process Management: Interprocess Communication, Synchronization, and Deadlocks   \n187\n Streaming or message oriented. For some applications it is important that the \ncommunication link supports the idea of discrete  messages. The sending application \nwill send a block of data and that same block will be presented to the receiving appli-\ncation in the same manner\u2014as a discrete message. The blocks may be of fixed or \nvariable length, depending on the implementation. Other applications do not identify \nblocks in the data. Instead, the communication is viewed as a  stream of data flowing \nfrom the sender to the receiver. As easy example is a telnet client. Each keystroke \nthat the user types on the keyboard is sent from the client to the server without regard \nto the content. Certain keystrokes may take priority over others (e.g., CTL/C), and \nthe protocol may bundle many keystrokes together for transmission in order to mini-\nmize transmission overhead, but generally the keystrokes are sent as a continuous \nflow of information. \n Heterogeneous or homogeneous only. Some communication systems assume \nthat the sender and receiver of the messages are operating on the same type of hard-\nware and the same OS. The strongest case is when the assumption is that the two \ncommunicating processes are running on the same machine. Other communication \nsystems do not make this assumption. In this case they may try to cope with a set of \nproblems that have to do with the representation of information. Different systems \nstore information in different formats. Often this is due to hardware considerations. \nOne example is the storage of integers. On Intel 80 X 86 series hardware the most \nsignificant byte (MSB) of the number is stored in a higher memory address. On most \nother hardware the MSB is in a lower memory address. (This is known as the \u201clittle \nendian/big endian\u201d problem, a reference to  Gulliver\u2019s Travels. ) If a system is send-\ning messages between platforms that may implement integers in different formats \nthen that system may want to solve that problem in a universal way. For example, a \nsubroutine called with Remote Procedure Calls (RPCs) may need to perform arith-\nmetic operations on the arguments, so the sender and receiver will need to solve this \nproblem in a way that is transparent to the applications. On the other hand, the FTP \nprotocol simply moves files. Any reformatting of the contents is not the concern of \nthe communication mechanism. However, FTP may need to consider the differences \nin file naming conventions. The name of a file on a sending system might not be a \nlegal name on the receiving system. Some examples of formatting questions concern \nnot the hardware but the language of the implementation. For example, strings may \nbe stored one way in C and another way in BASIC, so systems that have components \nwritten in different languages may have to convert data between these formats. (Of \ncourse, this can be true of a single program running on a single CPU as well as for \nmultiple processes.) One other problem that might be encountered is that a param-\neter to a message might be a memory address\u2014possibly a pointer to an error routine. \nObviously, if such a parameter were passed directly to a process running on another \nplatform it would be meaningless. If we are going to pass memory addresses as \nparameters we will have to invent some other mechanism for supporting them. \n Synchronous or asynchronous. When a program reads a record from a file in \nmost high-level languages the model that is normally used for this function is that \nwhen the next instruction is executed the read has been completed. This model of \nI/O is known as  synchronous I/O or  blocking I/O. If a process has other tasks to \nattend to while the reading is being done then it may choose to issue the read as an \nelm49810_ch09_181-208.indd   187\nelm49810_ch09_181-208.indd   187\n12/6/08   5:55:03 PM\n12/6/08   5:55:03 PM\n",
        "category": "Category"
    },
    {
        "id": "187",
        "title": "Title for Chunk 187",
        "content": "Confirming Pages\n188 \nPart 3 CPU and Memory Management\n asynchronous or  nonblocking read. In this case the read instruction will return to \nthe program immediately and the read will take place independently. Eventually \nthe program will want to find out if the read has finished. The means to do that \ndepend on the language and the OS. Communication channels are similar. A pro-\ncess might want to check a channel for messages but continue on if no messages \nare available. So with some communication mechanisms a receiving process can \nissue an asynchronous read of the channel, and if there is no information to read, \nthe OS will return from the call with an indication that no data was transferred, \nand the process will not wait. Similarly, an asynchronous write might be rejected if \nthere were no buffer space available to receive the message. \n Persistent or transient. In the simplest case both the sending and receiving \nprocesses must be running at the same time for them to exchange messages. If one of \nthe processes is unavailable then the system cannot function. This sort of mechanism \nis called  transient. In other systems the OS will retain messages that are intended \nfor a process that is not running now or deliver messages from processes that are no \nlonger running. Such communication services are said to be  persistent. \n 9.2.2 Examples of IPC systems \n In the simplest case, a sending process may need to pass only a minimum amount of \ninformation, a single bit, to indicate that some event has occurred. In this case they \ncan make use of the synchronization mechanisms described in the next section. Most \nof the time, however, processes need to send more information than a single bit, so \nthey will use more elaborate schemes to send entire messages. \n One widely used method of message exchange between processes is the use of \n pipes. A pipe is essentially a circular buffer (or queue) that one process will put data \ninto and the other will take data out of. The two processes can make use of system \ncalls to put and get the data. This mechanism lets the processes avoid having to worry \nabout synchronization issues. (We will discuss the nature of this problem shortly.) \nThe OS will watch for a full buffer or an empty buffer, but the calling routine needs \nto be aware that the call might not succeed. For example, if the buffer is full then a \nsending routine that tries to put data into the buffer will be blocked. Usually a receiv-\ning routine can call a nonblocking system routine to try to read data from the buffer. \nIf data is available then it will be returned. If no data is in the buffer then the call \nwill return immediately, but there will be a return code indication that no message \nwas read. Usually there is also a blocking type read as well. A receiver might use a \nblocking read if it had nothing else to do except wait for incoming information. Pipes \nfirst appeared in UNIX, and in UNIX and Linux the pipes are byte streams rather \nthan discrete messages and the pipes are one-way channels. In the Windows imple-\nmentation the pipes can be byte streams, but they can alternatively be used to send \nmessages, and the pipes are bidirectional. \n Another issue with pipes is the question of how they are set up in the first place. \nIn some cases the sending and receiving processes must name each other explicitly. \nThis is generally undesirable because it is more difficult to maintain than other meth-\nods. Alternatively, the receiver might not care who is sending but the sender must \nname the receiver explicitly. An application that is writing messages to a log file \nelm49810_ch09_181-208.indd   188\nelm49810_ch09_181-208.indd   188\n12/6/08   5:55:04 PM\n12/6/08   5:55:04 PM\n",
        "category": "Category"
    },
    {
        "id": "188",
        "title": "Title for Chunk 188",
        "content": "Confirming Pages\n \nChapter 9  More Process Management: Interprocess Communication, Synchronization, and Deadlocks   \n189\nmight offer this service to many clients at the same time. It will receive an indication \nof which client sent the message and can log that information as well. A final method \nis for the sender to provide some other reference rather than the name of the receiv-\ning process. This is sometimes called a  mailbox. In this case the sender is looking \nfor a service that can be provided by many different processes. It does not care which \nprocess is providing the service. An example of such a mechanism is  named pipes. \n The mechanism of  sockets has been in use for quite a while now, so one of the \nbenefits of it is that it has many compatible implementations\u2014they are available on \nevery OS. Sockets are designed to run over a standard networking layer. Most often \nthis layer is TCP or UDP over IP, but other implementations exist. The client (send-\ning) host names the server (receiving) host and also names a specific socket (some-\ntimes called a port) on the receiving host. These are only logical designations and \nnot references to hardware ports. In many cases, this socket will be a  well-known \nnumber. Well-known sockets (below 1024) are assigned by standards bodies for pro-\ntocols that are also standardized. A higher range of socket numbers is reserved for \napplications that are not standardized. The client will be assigned a socket number \nfor its use when it tries to connect to the server. Unlike the simpler one-way buffer-\ning mechanism used for pipes, sockets support a much more elaborate model. Once \nthe client and server have connected, the protocol they use is determined by the \napplication. Either the client or the server can send a message at any time. For some \napplications the application layer protocol is standardized, but new applications can \ndesign any sort of protocol that is needed. Applications can also use existing proto-\ncols for different purposes. For example, it is common for applications to support \nthe HTTP protocol because many firewalls are set to pass this protocol. The server \nnormally establishes a socket by making a series of OS calls and then waits for \nincoming connections to the socket. If the server is offering a complex service such \nas FTP, it is common for the server to start a separate thread to handle each client. \nIf the service is very simple, such as a quote-of-the-day service, then the server may \njust send a message and break the connection. \n Another advantage of the socket design is that the server and the client can be \nlocated on the same machine. This is especially handy when developing new appli-\ncations. It also means that the same program can serve both local and remote clients \nwithout any changes in either program. It is a very clean model without some of the \ncomplications of other mechanisms. Of course, it does mean that for local clients \na lot of work is being done that is not strictly necessary. If performance is an issue \nand the system will always run with the client and server on the same machine, then \nmore efficient mechanisms should be used. \n One kind of persistent communication system is called  message queuing.  Such \nsystems create named queues of messages. A process wishing to write messages to \nthe queue calls the OS with the message and the name of a queue to put the mes-\nsage in. A process wishing to read messages from the queue will call the OS with an \nempty buffer and the name of the queue. The processes may or may not be running \nat the same time. Other processes or system utilities are normally used to create \nand destroy the message queues. The queues are normally maintained in secondary \nstorage is order to ensure this persistence, so there is a large amount of overhead to \nusing them. \nelm49810_ch09_181-208.indd   189\nelm49810_ch09_181-208.indd   189\n12/6/08   5:55:05 PM\n12/6/08   5:55:05 PM\n",
        "category": "Category"
    },
    {
        "id": "189",
        "title": "Title for Chunk 189",
        "content": "Confirming Pages\n190 \nPart 3 CPU and Memory Management\n 9.2.3 Examples of shared memory systems \n In many OSs it is possible for two (or more) processes running on the same machine \nto ask the OS to allow them to share access to a block of memory, a technique known \nas  shared memory. Usually this is done by having one process call the OS and asking \nfor a segment of memory (of some specified length) to be allocated and given a name. \nOther processes wishing to share this memory will have to know the same name. \nThey will then give the OS the name and ask for access to the segment. The memory \naddress settings of both processes will be altered so that they can have access to the \nshared block of memory. The exact mechanism is discussed in Chapter 11. Some \napplications are very simple and will not need complex synchronization to make sure \nthat the two processes do not interfere with one another. Other systems may require \nmore elaborate synchronization mechanisms to control access to the data in the shared \nmemory block. This topic will be elaborated upon in the next section. You should \nrecall that while separate processes must use such an elaborate mechanism to share \nmemory, threads within a single process always share their memory by definition. \n A special case of shared memory is sometimes provided in the form of  memory \nmapped files. This is a slight modification of the shared memory technique. In this \ncase the initiating procedure calls the OS and gives it the name of a file on secondary \nstorage. The OS will locate the file and will allocate space in the calling process to \ncontain the entire file. However, the file will not immediately be loaded into mem-\nory. As parts of the shared file are accessed for the first time the hardware will signal \nthe OS and it will load the appropriate portion of the file into the memory and then \nresume running the process. This mechanism is described more fully in Chapter 11. \n 9.3 SYNCHRONIZATION \n 9.3.1 The problem \n Now that we have an understanding of why processes need to communicate and \nsome of the mechanisms they can use to do so, we need to turn our attention to a \nproblem that can occur when two processes want to share a piece of data in memory. \nConsider the following example where two processes, A and B, are using a buffer \nto communicate and are attempting to update a shared record counter, X, which ini-\ntially has the value 8. Process A has put a record into a buffer and is trying to incre-\nment the counter by adding 1 to X. Process B has taken a record out of the buffer, so \nit is trying to decrement the counter by subtracting 1 from X. So process A has an \ninstruction X  \ufffd X  \ufffd 1 and process B has an instruction X  \ufffd X - 1. After these two \ninstructions execute we would expect X to still contain the value 8. However, there \nis a small potential problem. \n The high-level language instructions we have shown are normally broken into \nthree separate machine instructions: a Load to a register, an Add or Subtract, and \na Store back into memory. Consider the execution shown in  Figure 9.1 . Process A \nloads the value of X into register A, so register A contains an 8. Process A is now \ninterrupted because its time slice has finished. The registers are saved in the PCB for \nprocess A. Now process B gets a time slice. It loads the value of X into register A, \nelm49810_ch09_181-208.indd   190\nelm49810_ch09_181-208.indd   190\n12/6/08   5:55:05 PM\n12/6/08   5:55:05 PM\n",
        "category": "Category"
    },
    {
        "id": "190",
        "title": "Title for Chunk 190",
        "content": "Confirming Pages\n \nChapter 9  More Process Management: Interprocess Communication, Synchronization, and Deadlocks   \n191\nso register A is not changed. Process B subtracts 1 from register A, yielding a 7, and \nstores it in the memory location for X, leaving X at a 7. It continues on. Eventually \nprocess A gets another time slice. The registers for process A are restored from its \nPCB, so register A now contains an 8 again. It adds 1 to Register A, giving a value \nof 9, which it stores in the memory location for X, leaving X at a 9. This result is not \nexactly what we were expecting. To make matters even worse, this problem is timing \ndependent. There is a very small window in which this problem will occur. Almost \nall the time these two processes will share this variable very nicely, assuming this \nwas the only modification they were making to the variable. This kind of problem \nis quite hard to debug because it is intermittent. It is called a  race condition. A race \ncondition, or  race hazard, is a defect in a design whereby the output of the system \nis dependent on the sequence or timing of other events. This problem can also occur \nin a multiprocessor system when process A is running on one CPU and process B is \nrunning on another CPU. Regardless of the cause of the problem, we need a solution. \nAlthough multiple CPU systems have been uncommon outside of high-end servers, \nthe focus of the current generation of CPU chips is to have multiple CPUs within a \nsingle chip. As a result, this sort of problem will become more common. \n 9.3.2 Atomic operations \n The trick we need is to make those operations  atomic. This word means that the oper-\nation we are doing is indivisible\u2014specifically, it cannot be interrupted by another \nprocess that wants to update the same information. One possible solution might be to \ncompile that instruction into a single uninterruptible instruction. For example, some \nPoint\nX\nProcess B\nProcess A\nStore Register A into X\nAdd 1 to Register A\nProcess A\nContinues\nProcess B\nContinues\nSubtract 1 from Register A\nRA=8\nRA=7\nStore Register A into X\nX=7\nLoad X into Register A\nX=8\nRA=8\nRA=9\nX=9\nLoad X into Register A\nFIGURE 9.1 \nTwo processes \nupdating a shared \nvariable.\nelm49810_ch09_181-208.indd   191\nelm49810_ch09_181-208.indd   191\n12/6/08   5:55:05 PM\n12/6/08   5:55:05 PM\n",
        "category": "Category"
    },
    {
        "id": "191",
        "title": "Title for Chunk 191",
        "content": "Confirming Pages\n192 \nPart 3 CPU and Memory Management\nmachines can add 1 to (or subtract 1 from) a variable in memory without loading the \nvariable into a register. However, when we are writing our program in a higher-level \nlanguage we want to not worry about such hardware details. We would like to be \nable to move our program to a different machine that perhaps didn\u2019t have such an \ninstruction. So we have to use a more general solution. \n 9.3.3 Locks and critical sections \n Sometimes our processes will be sharing a single variable and sometimes they will \nbe sharing a more elaborate structure. Sometimes we will be doing a single operation \nand sometimes we will be doing more complex operations. Sometimes we will have \nonly two processes trying to share a single resource and sometimes we will have many. \nSometimes we will be trying to share a resource for which there are multiple instances \nand sometimes there will only be one instance of the resource. The general technique we \nwill use is to use a special kind of variable called a  lock to control access to the shared \nvariable. A lock is also sometimes called a  mutex since it can be used to provide mutu-\nally exclusive access to the item the lock is protecting. When we look at a process that is \nusing a lock we can think of the program as having four parts, as seen in  Figure 9.2 .  \n A  critical section is a part of the process that is manipulating information that \nmay also be manipulated by another process. The  entry section is code that locks \nthe shared information\u2014it first ensures that no other process is currently in its criti-\ncal section and then locks the lock so that no other process sharing this information \ncan now enter its critical section. The  exit section  is code that releases the lock after \nthis process has finished with this critical section. The  remainder section  is the rest \nof the process. Note that this process can contain other critical sections and locks. \nThis description is merely a structured way of looking at the parts of a single locking \noperation. The effect of this structure is that we have made the operations we are per-\nforming on the shared information atomic. No other process that wants to manipu-\nlate this shared information can interrupt this critical section. This structure does not \nkeep process A from being interrupted. It does mean that if process A is interrupted, \nany other process that tries to enter its critical section (for this variable) will be made \nto wait until process A finishes its exit section. \n 9.3.4 Hardware locking instructions \n There are many ways that the entry and exit section can be coded. In a very simple \nembedded OS or in the kernel of an OS we may use special machine instructions to \nlock and unlock the locks. These instructions are themselves atomic instructions. \nThere are only a few common variants. One is a  Test and Set instruction. This \nMain() {\nentry section \n/* make sure the lock is free */\ncritical section\n/* manipulate the shared data */\nexit section \n/* show the lock is free */\nremainder section /* everything else */\n}\nFIGURE 9.2 \nThe parts of a \nprocess manipulating \nshared memory.\nelm49810_ch09_181-208.indd   192\nelm49810_ch09_181-208.indd   192\n12/6/08   5:55:06 PM\n12/6/08   5:55:06 PM\n",
        "category": "Category"
    },
    {
        "id": "192",
        "title": "Title for Chunk 192",
        "content": "Confirming Pages\n \nChapter 9  More Process Management: Interprocess Communication, Synchronization, and Deadlocks   \n193\ninstruction will set a variable in memory to a nonzero value (i.e., lock it) and will \nalso return a result that tells us whether the lock was already set before we executed \nthis instruction. If the lock was already set then we did not gain access to the lock, so \nwe just retry the operation:\n while (TestAndSet(MyLock)) ;  \nNote that the scope of the while statement is null (the ;), so this loop does nothing but \nwait until the lock is not set when the instruction is executed. This type of coding is \nsometimes called a  spin-lock or  busy-waiting. Another common atomic instruction \nis a  Swap instruction. It exchanges the values of two variables in a single step. This \ninstruction is slightly more powerful than the Test and Set instruction in the sense that it \ncan put any value into the lock variable. Other than that, the instructions are equivalent. \nAnother similar instruction is called  fetch-and-add. It fetches an integer used as a lock \nfrom memory and at the same time adds one to the value and writes it back to the same \nlocation. An XADD instruction that works this way has been used in the Intel proces-\nsors since the 80486 CPUs. The choice of which of these atomic instructions to imple-\nment is a function of hardware design issues. With the first two of these instructions the \nexit section of our process is merely to set the lock variable to false (zero). Storing a \nzero into a memory location is normally an atomic instruction on any hardware.  \n 9.3.5 Semaphores and waiting \n If a process actually contained that while loop that we showed with the Test and Set \ninstruction, it would be wasting CPU cycles while it was waiting. As a result, in most \ncases an application will not use these instructions to implement an entry section. \nInstead, it will issue OS system calls for both the entry and exit sections. Normally \nthe variable used in these calls is declared to be a  semaphore. Semaphores can be \nmore complex than the simple locks we have been describing. A lock is always a \nbinary condition but semaphores are often more general. So the simple semaphores \nare called  binary semaphores, and only support locking. \n While different OSs and languages use many different names for these routines, \ngenerally the system call for the entry section is simply:\n wait (MySemaphore)  \nand the call for the exit section is:\n signal (MySemaphore)  \nWhen we call the  wait routine, if the locked resource is not available, then instead \nof putting our process into a loop the OS will take our task out of run state and put \nit into wait state. The process will be waiting for the lock to be released. This will \nhappen when the task that currently has the lock falls through its exit section and \nexecutes a  signal system call on the lock we are waiting for. The OS will take our \ntask out of wait state and put it in ready state. At the same time, it will give our task \nthe lock so that no other task can get it. As was mentioned earlier, there can be any \nnumber of tasks waiting on the same lock, so the OS may need to have a queue for \nall the tasks waiting for each semaphore. \nelm49810_ch09_181-208.indd   193\nelm49810_ch09_181-208.indd   193\n12/6/08   5:55:06 PM\n12/6/08   5:55:06 PM\n",
        "category": "Category"
    },
    {
        "id": "193",
        "title": "Title for Chunk 193",
        "content": "Confirming Pages\n194 \nPart 3 CPU and Memory Management\n 9.3.6 Counting semaphores \n But in the more general case a count is associated with each semaphore, which is a \npositive integer. Such semaphores are sometimes called  counting semaphores. They \nare normally used to control access to a group of similar resources such as the records \nin a buffer. The count associated with a counting semaphore is initialized to the num-\nber of available resources. The code in the application for using counting semaphores \nis normally the same as for binary semaphores. When a process wants to access an \ninstance of the resource it calls the  wait routine as shown. If the count associated \nwith the semaphore is zero then no instances of the resource are available and the \nrequesting process is blocked. If the count is greater than zero then more instances of \nthe resource are available. The count will be decremented to show that an instance is \nin use. When the process calls the  signal routine the associated count will be incre-\nmented, and any waiting processes will be dispatched with the available resource. \n Counting semaphores can also be used to synchronize access to files where pro-\ncesses will do many reads and only a few writes. Many readers can be allowed at the \nsame time, but we may not want to allow readers to be active when a process is try-\ning to write to the file. So we can allow multiple readers with a counting semaphore \nand only allow a writer to access when the count of readers reaches zero. Once a \nwriter tries to access the lock we will not allow any more readers to get the lock until \nthe writer has gotten the lock and finished its work. \n 9.3.7 Synchronization and pipeline architectures \n When multiple CPUs are present in a single system and the CPUs have a pipeline \narchitecture it is possible for a CPU to execute instructions out of order. This can \ncause timing problems with synchronization instructions such as the test and set. As \na result, a mechanism is usually provided that allows an application (or the OS) to \nissue a command that forces the CPU to execute a particular sequence of instructions \nin the order they are in the program, thus avoiding the problem. \n 9.3.8 Synchronization in SMP systems \n We mentioned in earlier chapters that the trend is for computer systems to include \nmultiple CPUs, in particular multicore processors where multiple CPUs are incor-\nporated into a single integrated circuit. Such systems require OSs that can manage \nthe resources of the multiple CPUs. The preferred solution is known as  symmetric \nmultiprocessing, or  SMP. In this architecture the OS is designed so that it can run \non any of the CPUs. (An alternative architecture is known as asymmetric multipro-\ncessing where one CPU runs the OS and the others only run applications. This archi-\ntecture is seldom seen today.) \n The multiple execution streams of the OS running on separate CPUs can attempt \nto reference the same data at the same time. In order to avoid this an SMP OS will use \nlocks. We had said that user programs did not use spin locks since they would waste \nvaluable CPU cycles for an unknown amount of time. Within an OS, however, we pre-\nsumably know that we will hold a lock only for a very brief, predetermined amount of \ntime. Also, we can\u2019t very reasonably make an OS call to a  wait routine since we are \nelm49810_ch09_181-208.indd   194\nelm49810_ch09_181-208.indd   194\n12/6/08   5:55:07 PM\n12/6/08   5:55:07 PM\n",
        "category": "Category"
    },
    {
        "id": "194",
        "title": "Title for Chunk 194",
        "content": "Confirming Pages\n \nChapter 9  More Process Management: Interprocess Communication, Synchronization, and Deadlocks   \n195\nalready in the kernel! As a result, OS kernel code normally uses a hardware spin lock \nmechanism in spite of the waste of CPU cycles. \n This brings up an interesting hardware problem though. Suppose that one of the \nseveral processors wishes to write a value into memory. To protect that critical sec-\ntion it uses a lock. The semaphores are in the shared memory, and each CPU may \nalso have the value of the semaphore in its cache. You can see the problem\u2014now \nthere are many processors that are using those same atomic instructions, potentially \nat the same time. This requires that CPUs that share memory in SMPs be a little \nsmarter about sharing. One common way to do this is for every CPU to watch for \nmanipulation of shared memory by  snooping the memory bus. This is more work \nfor the CPU hardware, but it is worth the effort\u2014the potential for speedup by using \nmultiple CPUs is quite large. The cache hardware must also be smarter because each \nCPU might have a copy of the semaphore in its cache and if one CPU changes the \nvalue of the semaphore then all the other copies must be updated as well. These are \nvery important problems for CPU architects, and are very widely argued about. \n 9.3.9 Priority inversion \n Priority inversion describes a situation that can arise when a lower-priority task \nholds a shared resource that is required by a task running with a higher priority. This \ninversion causes blocking of the high-priority task until the resource is released. This \neffectively inverts the priorities of the two tasks. If some other medium priority task \nnot using the shared resource tries to run it will take precedence over both the low- \nand high-priority tasks. Priority inversion often does not cause great harm. The delay \nof the high-priority task goes unnoticed and eventually the low-priority task releases \nthe shared resource. However, priority inversion can cause serious problems. If the \nhigh-priority task is delayed long enough it might lead to triggering of a timer and \nthe resetting of the OS. The Mars Pathfinder mission had a priority inversion prob-\nlem that caused it to reset itself several times. At the very least priority inversion \ncan make a system seem unreasonably slow. Low-priority tasks usually have a low \npriority because it is not important for them to finish in any particular time frame so \nlong as their job gets done eventually. A high-priority task probably has strict time \nconstraints. It might be working with the user interface or on a soft real-time task. \nThus, priority inversion can lead to reduced system responsiveness. \n 9.3.10 A classical problem \n There is a problem that occurs quite often in OSs called the  producer\u2013consumer \nproblem or the  bounded-buffer problem. It is an example of a multiprocess syn-\nchronization problem. It concerns at least two processes, one of which is a producer \nof data and another of which is a consumer of the data, and they all share a common, \nfixed-size buffer. The job of a producer process is to continuously generate blocks of \ndata and put them into the buffer. At the same time, a consumer process is consuming \nthe data by taking it from the buffer a block at a time. But a producer should not try \nand add data to the buffer if it\u2019s full and a consumer should not try to remove data from \nan empty buffer. One solution to this problem is shown in the following procedures. It \nelm49810_ch09_181-208.indd   195\nelm49810_ch09_181-208.indd   195\n12/6/08   5:55:07 PM\n12/6/08   5:55:07 PM\n",
        "category": "Category"
    },
    {
        "id": "195",
        "title": "Title for Chunk 195",
        "content": "Confirming Pages\n196 \nPart 3 CPU and Memory Management\nworks for multiple consumers and multiple producers but we will discuss it as though \nthere were only one of each. \n The solution for the producer is to block if the buffer is full. Each time the con-\nsumer removes an item from the buffer, it signals the producer who starts to fill the \nbuffer again. In the same way, the consumer blocks if it finds the buffer is empty. \nEach time the producer puts data into the buffer, it signals the consumer. The counting \nsemaphore  full is the number of buffers that are currently full, the semaphore  empty \nis the number of empty buffers, and  mutex  is for establishing mutual exclusion.  \n semaphore mutex  \ufffd 1\nsemaphore full  \ufffd 0\nsemaphore empty  \ufffd BUFFER_SIZE\nprocedure producer() {\n while (true) {\n  item  \ufffd produceItem()\n  wait(empty)\n  wait(mutex)\n  putItemIntoBuffer(item)\n  signal(mutex)\n  signal(full)\n }\n}\nprocedure consumer() {\n while (true) {\n  wait(full)\n  wait(mutex)\n  item  \ufffd removeItemFromBuffer()\n  signal(mutex)\n  signal(empty)\n  consumeItem(item)\n }\n}\n 9.3.11 Monitors \n Although it does not look that difficult on the surface, the use of locks and sema-\nphores is a very error-prone part of programming. In order to make locking and \nunlocking more robust, some high-level languages have introduced a mechanism for \nexpressing synchronization requirements. This mechanism is known as a  monitor. \nMonitors are not OS constructs so much as they are a way to package OS constructs \nin a less error-prone way. A monitor is an item with built-in mutual exclusion and \nthread synchronization capabilities. These features are defined by programming lan-\nguages so that the compiler can generate the correct code to implement the moni-\ntor. Though they take different forms in different languages, there are some general \nthings we can say about monitors. \nelm49810_ch09_181-208.indd   196\nelm49810_ch09_181-208.indd   196\n12/6/08   5:55:07 PM\n12/6/08   5:55:07 PM\n",
        "category": "Category"
    },
    {
        "id": "196",
        "title": "Title for Chunk 196",
        "content": "Confirming Pages\n \nChapter 9  More Process Management: Interprocess Communication, Synchronization, and Deadlocks   \n197\n A monitor is associated with an item in the language such as a procedure or a \nclass. A mutex will be associated with the procedure. Only one thread of an associ-\nated process can be executing with the monitor at any given time. A monitor proce-\ndure tries to access the lock before doing anything else, and holds it until it either \nfinishes or waits for a condition. When a procedure finishes, it releases the lock so \nno deadlocks can take place. \n Monitors may also have  condition variables. These allow a thread to wait if \nconditions are not right for it to continue executing with the monitor. In this case the \nthread will be blocked and another thread will be given the lock and allowed to exe-\ncute. The other thread may change the state of the monitor. If conditions are now right \nfor the waiting thread to continue, the running thread can signal the waiting thread. \nThis will move the waiting thread back to the ready queue so that it can resume \nexecution with the monitor when it becomes free. The following code uses condition \nvariables to use a communication channel that can store only one message at a time: \n monitor channel {\n condition can_send\n condition can_receive\n char contents\n boolean full : = false\n function send (char message) {\n  while full then wait (can_receive)\n  contents : = message\n  full : = true\n  signal (can_send)\n }\n function receive () {\n  var char received\n  while not full then wait (can_send)\n  received : = contents\n  full := false\n  signal (can_receive)\n  return received\n }\n }\n 9.4 DEADLOCKS \n 9.4.1 What is a deadlock? \n A very simple case \n Suppose that we have two processes, A and B, which are attempting to share two \ndifferent resources, 1 and 2. Process A locks resource 1 and then locks resource 2. It \ndoes its work and then releases the resources. Process B locks resource 2 and then \nelm49810_ch09_181-208.indd   197\nelm49810_ch09_181-208.indd   197\n12/6/08   5:55:08 PM\n12/6/08   5:55:08 PM\n",
        "category": "Category"
    },
    {
        "id": "197",
        "title": "Title for Chunk 197",
        "content": "Confirming Pages\n198 \nPart 3 CPU and Memory Management\nlocks resource 1. It does its work and then releases the resources. These events are \nshown schematically in  Figure 9.3 . \n Now consider what happens if process A gets interrupted at Point X\u2014perhaps \nit has used up its time quantum and the operating system takes it out of the run state \nand puts it back in the ready queue. Process A has already locked resource 1. Now \nprocess B starts. It locks resource 2 and then tries to lock resource 1. Since process \nA is holding a lock on resource 1, the OS puts process B into the wait state and some \nother process is started. Eventually process A comes to the head of the ready queue \nand is restarted by the dispatcher. It runs briefly and tries to lock resource 2. Since \nprocess B is holding a lock on resource 2, process A is put into the wait state and \nthese two processes are now in a deadlock. Neither process will ever finish because \neach is holding a resource that the other is waiting for. \n This simple example easily shows two of the necessary conditions for a dead-\nlock to occur. The first is that there must be resources involved that are not shar-\nable. This is called  mutual exclusion. In the case of locks, this is clear from the \ndefinition\u2014only one process can hold a lock at any one time. In the case of some \nresources it is not as clear, as will be discussed later. The second condition necessary \nfor a deadlock is that it must be possible for a process to hold one resource while it \nwaits for another. This is called  hold-and-wait.  Again, in the case of locks we can \nsee that normally a process can get as many locks as it needs without releasing any \nthat it holds. \n Some more elaborate examples \n A favorite example in the computer science literature is the \u201cDining Philosophers\u201d \nproblem. In this problem, shown in  Figure 9.4 , there is a table at which there are three \nphilosophers who alternatively eat or think. After thinking for a while, a philosopher \nwill want to eat. The meal being served is rice, and it requires two chopsticks to eat. \nBetween each two philosophers is a chopstick. When it is time to eat, a philosopher \npicks up one chopstick on the left and one chopstick on the right and begins to eat. \nIt should be clear that this setting can easily lead to a deadlock. Suppose that more \nor less simultaneously, each philosopher decides to eat. Each reaches out to the left \nand picks up a chopstick. Each philosopher then gets interrupted and has to wait for \na while (as in the simple example). \nLock \nResource \n1\nLock \nResource \n1\nLock \nResource \n2\nLock \nResource \n2\nProcess A\nProcess B\nProcess A\nContinues\nProcess B\nContinues\nPoint \nX\nFIGURE 9.3 \nTwo processes \nsharing two \nresources.\nelm49810_ch09_181-208.indd   198\nelm49810_ch09_181-208.indd   198\n12/6/08   5:55:08 PM\n12/6/08   5:55:08 PM\n",
        "category": "Category"
    },
    {
        "id": "198",
        "title": "Title for Chunk 198",
        "content": "Confirming Pages\n \nChapter 9  More Process Management: Interprocess Communication, Synchronization, and Deadlocks   \n199\n When it resumes processing (trying to eat), it tries to pick up the chopstick to \nthe right, but finds that chopstick already in use, so it waits on the right chopstick. \nEventually we make it all around the table and each philosopher is holding one chop-\nstick and waiting for another. The difference between this example and the first is \nthat in this case there are more than two processes (philosophers) and more than \ntwo resources (chopsticks). Each process is holding one resource and is waiting for \nanother resource. This condition is known as  circular wait. It was present in the \nfirst example but the circle was harder to see because there were only two processes. \nEach process then had a resource that was needed by the other. As is seen in the \ndining philosophers problem, all that is needed is that there is some sequence of \nprocesses, each holding a resource wanted by another, and ultimately one process in \nthis sequence that is holding a resource wanted by the first process. There is a simple \nmethod of avoiding this situation, which we discuss later in the chapter. \n An often cited example of a deadlock in the real world is a gridlock in traffic \non city streets. For example,  Figure 9.5 shows a simple traffic gridlock. (To keep it \nsimple we have shown one-way streets.) In this case you see a number of different \nprocesses (cars), each wanting to use a resource that the car in front of it is already \nusing. In this case the resource is a position on the street. It is clear that there is \nmutual exclusion\u2014no two cars can be in the same position at the same time. There is \nalso circular wait\u2014it is obvious from the picture. Consider, however, the car identi-\nfied as A. Although this car is also waiting, it is not a part of the deadlock because no \nother car is waiting on the resource it holds. \n In many analyses of deadlocks a fourth condition is stated\u2014that preemption not \nbe allowed. Preemption would mean that we could take away from a process some \nresource that it is currently holding, thus breaking the deadlock. In our analysis, pre-\nemption is a solution to a deadlock. Adding a \u201ccondition\u201d of no preemption is merely \na way of saying that one possible solution to the deadlock problem is not used. It is not \nreally a necessary condition for a deadlock. We discuss this further later in the chapter.  \nFIGURE 9.4 \nThe \u201cDining \nPhilosophers\u201d \nproblem.\nelm49810_ch09_181-208.indd   199\nelm49810_ch09_181-208.indd   199\n12/6/08   5:55:09 PM\n12/6/08   5:55:09 PM\n",
        "category": "Category"
    },
    {
        "id": "199",
        "title": "Title for Chunk 199",
        "content": "Confirming Pages\n200 \nPart 3 CPU and Memory Management\n Resource-allocation graphs \n A tool often used to explain deadlocks is called a  resource-allocation graph. These \ngraphs show processes and resources and which processes are waiting for or hold-\ning instances of each resource. An example is shown in  Figure 9.6 . Each node in the \ngraph represents either a process (shown here as a triangle) or a resource (shown as \nan oval box). A directed edge is drawn from process B to resource 2 to show that B \nis waiting for 2, and from 1 to A to show that A holds 1. If there is a deadlock then \nthere will be a loop in the graph and it will be obvious from the diagram. In a com-\nputer system there is usually more than one instance of a resource. In this case it is \ntraditional to represent each instance of a resource in the graph as a single dot inside \nthe resource node. In such a case a loop in the diagram does not necessarily mean \nthat there is a deadlock because there may still be free instances of each resource \navailable. Unfortunately, OSs don\u2019t understand pictures, so this technique is not as \nuseful to them as it is to a human analyst. A programmer can simulate a graph, how-\never, and write a program to do a search with a graph in mind, but that is not quite \nthe same thing. \nA\nFIGURE 9.5 \nA deadlock in city \ntraffic.\nR-1\nP-A\nR-2\nP-B\nProcess A is\nholding\nResource 1\nProcess B is\nwaiting for\nResource 2\nFIGURE 9.6 \nA resource allocation \ngraph.\nelm49810_ch09_181-208.indd   200\nelm49810_ch09_181-208.indd   200\n12/6/08   5:55:10 PM\n12/6/08   5:55:10 PM\n",
        "category": "Category"
    },
    {
        "id": "200",
        "title": "Title for Chunk 200",
        "content": "Confirming Pages\n \nChapter 9  More Process Management: Interprocess Communication, Synchronization, and Deadlocks   \n201\n  9.4.2 What can we do about deadlocks? \n There are basically four approaches to solving the deadlock problem. First, we can \n prevent deadlocks from ever happening by making sure that one of the necessary \nconditions does not exist. Second, we can allow all three conditions to occur, but \n avoid deadlocks by making sure that we do not allocate resources in such a way that \nthey will ever happen. Third, we can allow deadlocks to happen,  detect that they \nhave happened, and perhaps do something about them. Finally, we can ignore them. \n 9.4.3 Prevention \n Preventing deadlocks would involve making sure that one or more of the three neces-\nsary conditions for deadlock cannot occur. We address these three conditions in turn. \n Mutual Exclusion \n In a computer system some resources are very clearly not sharable. If one process \nis printing the payroll checks on a printer it will not work well for another process \nto begin to print an email message on the same printer. (We can simulate simultane-\nous access to a printer by spooling the output. We discuss this further later in this \nsection.) Similarly, if one process is writing records to a tape drive it will not be \npractical for another process to start using the same tape drive. Other resources are \nclearly sharable. For example, a network interface card is very likely to be shared \nby several applications at the same time. A server might be running several different \nservices over the same network adapter\u2014perhaps a Web server, a file server, and \nan FTP server. Requests can come in randomly from other hosts in the network and \nresponses can be queued up by the server processes. One might argue that the mes-\nsages are not going out together\u2014that the line is not really being used \u201cat the same \ntime.\u201d However, the point is that no process will ever have to wait for the network to \nsend data. Assuming enough memory space is available for buffers, no process will \never enter a deadlock because it is waiting to send data to the network. (It may have \nto wait for a response, but that is not the same thing.) Similarly, access to files on a \ndisk drive is sharable at the software level. Two processes can have files open on a \nhard drive and can read from and write to those files on a single drive without wait-\ning for the other process to completely finish with its file processing. \n Some resources are less clear. Consider RAM, for example. One could argue \nthat RAM is sharable since many processes can be using parts of it at the same \ntime. However, processes generally are given exclusive access to blocks of RAM \nand are not allowed to access blocks allocated to other processes. So in that sense \nRAM is really not sharable. However, there are many instances where processes do \nshare memory, so memory is very difficult to categorize in this regard. With most \nOSs access to a single file may be sharable. If we have a spelling dictionary on a \ntimesharing system each user can be checking spelling on different documents at \nthe same time. However, if the system is an inventory system and we have several \nprocesses trying to allocate inventory to customers at the same time, the applications \nneed to lock the files (or at least parts of the files) so that we do not try to ship the \nlast widget to three different customers. So files are not intrinsically either sharable \nor nonsharable. It depends on the use being made of them. \nelm49810_ch09_181-208.indd   201\nelm49810_ch09_181-208.indd   201\n12/6/08   5:55:10 PM\n12/6/08   5:55:10 PM\n",
        "category": "Category"
    },
    {
        "id": "201",
        "title": "Title for Chunk 201",
        "content": "Confirming Pages\n202 \nPart 3 CPU and Memory Management\n Even with nonsharable devices like printers we can use some mechanisms to \nmake most uses of a printer a sharable event. The solution is to use spooling. Rather \nthan write data directly to the printer, the OS will take the data from the application \nand temporarily store it in a disk file. Later, when it knows that the printer is avail-\nable, has the right forms mounted, and so on, it can actually print the data on the \nprinter. Since we have removed the mutual exclusion involving printers, we have \nremoved them from the list of resources that can cause a deadlock. On the other \nhand, a deadlock of a sort can occur even with spooling. When an OS is spooling the \nprinter output for several applications it is temporarily writing the output to disk. It is \nentirely possible that the disk space allocated to the spooling fills up. This can once \nagain leave the system exposed to a possible deadlocked state. \n But the bottom line is that since some resources are intrinsically nonsharable, \nremoving mutual exclusion is not a generally applicable solution. \n Hold and wait \n There are two ways we can avoid the hold-and-wait condition necessary for a dead-\nlock to occur. We can require that a process must request all resources it will ever \nneed when it starts. For a few simple batch systems this might be possible, but for \nmost modern applications it is not feasible. There are simply too many combinations \nof possible events to make prediction of all requirements practical. Furthermore, in \nmany cases the 80/20 rule applies\u2014in 80 percent of the cases we will only need a \nfew resources. In only 20 percent of the cases will we need a big allotment of extra \nRAM. If we have to ask for the worst case in advance then most of the time we will \nbe tying up resources that we will not need. \n The second option is to require that any process that is asking for a resource \nmust first release all resources it is holding before it asks for any other resources. So, \nin our first example, when process B wants to ask for resource 1 it must first release \nresource 2 and then ask for resources 1 and 2 at the same time. This set of resources \ncan\u2019t be allocated because process A has resource 1, so process B will now wait, but \nit will no longer be holding resource 2. Process A will eventually get its next time \nslice and it will release resource 1 and attempt to allocate resources 1 and 2 at the \nsame time. Since it currently has the CPU it will be allowed to lock both resources \nand will continue. When it is finished with these two resources and releases both of \nthem, then process B will eventually be put into the ready state and will be granted \nboth resources and continue. Thus we have prevented a deadlock. However, if an \napplication was using a nonsharable resource, how could it release it? Furthermore, \nthis constant releasing and relocking is just too inefficient to use except in the most \ntrivial circumstances. So, as with mutual exclusion, eliminating hold and wait is gen-\nerally not a useful solution to the problem of deadlocks. \n Circular wait \n The last condition of a deadlock is a circular wait. There is a very simple method of \npreventing deadlock by not allowing this condition. The solution is to establish an \nordering of all the resources in a system. (There is no real significance to this order-\ning except that it works best if the ordering matches the order in which programs are \nelm49810_ch09_181-208.indd   202\nelm49810_ch09_181-208.indd   202\n12/6/08   5:55:11 PM\n12/6/08   5:55:11 PM\n",
        "category": "Category"
    },
    {
        "id": "202",
        "title": "Title for Chunk 202",
        "content": "Confirming Pages\n \nChapter 9  More Process Management: Interprocess Communication, Synchronization, and Deadlocks   \n203\nmost likely to lock the resource.) The next requirement is that all processes must lock \nresources in the same order. This will prevent the circular wait condition. Consider \nonce again the first example. If process A and process B both try to lock resource \n1 before they try to lock resource 2, then a deadlock between these two will never \narise. When the second process tries to lock resource 1 it will be forced to wait. This \nworks just as well if multiple processes and multiple resources are involved. \n Unfortunately, as a general-purpose solution for deadlock avoidance in OSs, \nresource ordering is not a practical solution. OS utility programs, third-party soft-\nware, and end user applications all would have to be written with some such standard \nin mind and no such standard exists. However, for a development team working on \na large system with multiple concurrently running subsystems, ordering of locks on \nresources is a useful technique to avoid creating deadlocks within the application \nsystem itself. So this is an important technique to be aware of, even if it is not a gen-\neral solution to the deadlock problem. \n 9.4.4 Avoidance \n So far all our examples of resources have shown a single instance of each resource. \nA simple lock can only have one user at a time, a printer can only have one user, and \nso on. With other resources there can be many instances of the resource. The most \nobvious example is RAM\u2014there are always many blocks of RAM to be allocated. \nSimilarly, we might have multiple tape drives on which a tape can be mounted. On \na large mainframe we may even have multiple identical printers and not really care \nwhich one we get to use. In studying the avoidance mechanisms, we consider the \nmore general case where resources can have multiple instances. \n There are two mechanisms for deadlock avoidance. Each of these mechanisms \nrequires that before a process runs it must provide the OS with a maximum number \nof instances of each resource that it will ask for under any circumstances. It might \nsay that it will only need 543 KB of RAM, one printer, and three tape drives. There \nare then two ways the OS can use this number. The first is to use the numbers to \ndecide whether to run the job at all. When the OS is going to start a job it can look \nat the resources it has available right now and see if it can satisfy the maximum \ndemand that the application might ask for. It might have the printer and three tape \ndrives it can allocate to the program, but only 506 KB of RAM. If the OS can\u2019t \nensure that it will be able to grant the maximum number of all the resources that \nthe job might request, then it does not run the job. In this way the OS will  avoid \nputting itself into a situation where a deadlock can occur. This is certainly safe but \nis not a very optimum solution since the job might often run without asking for the \nworst case of its resources. This is equivalent to requiring that the process ask for all \nresources in advance. \n The second solution is harder, but more nearly optimum. In this case the OS \nwill start the job without checking the maximum resource allocations, but when the \nprogram asks for any resource the OS will determine whether it knows it will be able \nto grant that request and still be able to finish all the other jobs it has running. If the \nsystem can\u2019t safely grant the request that the process has made then it will put that \nprocess into a wait state. A state where the OS knows it can finish running all the \nelm49810_ch09_181-208.indd   203\nelm49810_ch09_181-208.indd   203\n12/6/08   5:55:11 PM\n12/6/08   5:55:11 PM\n",
        "category": "Category"
    },
    {
        "id": "203",
        "title": "Title for Chunk 203",
        "content": "Confirming Pages\n204 \nPart 3 CPU and Memory Management\ncurrently running jobs even if all the jobs request the maximum amount of all \nresources they have said they might use is known as a  safe state. \n In the example shown in  Figure 9.7 , the OS is monitoring four resources, \nA\u2013D. For these resources it currently has unallocated (Available) 1, 5, 2, and 0 \ninstances, respectively. We show these lists of resource counts without commas \nfor simplicity. There are five processes, 0\u20134. When these processes started running \nthey each gave a maximum number of instances of each of the four resources they \nmight ask for. These are listed in the column titled Max. That is, process 1 said that \nat a maximum it would need 1 instance of resource A, 7 of B, 5 of C, and no Ds. \nEach process is currently holding some number of instances of each resource, as \nlisted in the column titled Alloc. As we can see, process 2 currently has allocated \n1 A, 3 Bs, 5 Cs, and 4 Ds. The OS can determine that process 1 could not ask for \nany more As because it is already allocated as many as it said it would ever need. \nIf it asked for more we could terminate the job. It could ask for 7 Bs and 5 Cs but \nno Ds. These are shown in the column titled Need. The OS can check to see if it \nwill be possible to finish this set of jobs without a deadlock occurring. We notice \nthat process 1 will be not be able to finish because it can ask for 7 more Bs and \nwe only have 5. But process 0 will be able to finish since it can\u2019t ask for anything \nmore. When it finishes we will recover the resources allocated to the process\u2014in \nthis case 0 0 1 2. This will leave us with 1 5 3 2. This is shown in the column titled \nWork. Now process 1 still can\u2019t finish, but process 2 can finish because its need \nis less than our working resources. When it finishes we will recover its resources, \ngiving us 2 8 8 6. Now process 1 can finish, giving us 3 8 8 6. Similarly, process 3 \nand 4 can also finish. Since we know that all the processes can finish we know that \nthe system is in a safe state. \n So in order to avoid deadlocks the OS must check each request by a process for \na resource allocation to make sure that if it grants the request the system will still \nbe in a safe state. Note that an unsafe state does not mean that we have a deadlock \nor that we will definitely have a deadlock. It only means that we  might eventually \nhave a deadlock. By never allowing the system to enter an unsafe state we will avoid \ndeadlocks. However, we will once again be using the system in a suboptimum man-\nner because we may be making processes wait when they could have successfully \nrun without a deadlock. The algorithm we just informally described is known as the \nBanker\u2019s Algorithm. It was used in an OS known as THE Operating System. How-\never, for many systems it is impossible to know in advance what every process will \nrequest, so deadlock avoidance is not used in current OSs. \nFor resources (A, B, C, D):   Available: 1 5 2 0\nNeed\nMax\nAlloc\nProc\nP0 can finish\nenough of every thing\nP1 can't finish\nnot enough Bs\n0      0 0 1 2     0 0 1 2\n0 0 0 0\n1      1 0 0 0     1 7 5 0\n0 7 5 0\n2      1 3 5 4     2 3 5 6\n1 0 0 2\n3      0 6 3 2     0 6 5 2\n0 0 2 0\n4      0 0 1 4     0 6 5 6\n0 6 4 2\nWork\n1 5 2 0\n1 5 3 2\n2 8 8 6\n3 8 8 6\n. . .\nFIGURE 9.7 \nShowing a safe state.\nelm49810_ch09_181-208.indd   204\nelm49810_ch09_181-208.indd   204\n12/6/08   5:55:11 PM\n12/6/08   5:55:11 PM\n",
        "category": "Category"
    },
    {
        "id": "204",
        "title": "Title for Chunk 204",
        "content": "Confirming Pages\n \nChapter 9  More Process Management: Interprocess Communication, Synchronization, and Deadlocks   \n205\n 9.4.5 Detection \n Our next approach to the deadlock problem is simply to let deadlocks happen, when \na deadlock happens, discover that it happened, and then try to recover from the \ndeadlock. The main advantage of this approach is that it is optimum in the sense \nthat it lets all processes try to run and never makes processes wait just to avoid a \npossible deadlock. \n If we were actually concerned about detecting resource allocation conflicts with \nmultiple instances of each resource we could utilize an algorithm similar to the Bank-\ner\u2019s Algorithm. Instead of maximum resources yet requested, we would be looking \nat the resources currently requested but not yet allocated. If we were not able to find \na \u201csafe state\u201d then we would know that the processes that were unable to finish were \ninvolved in a deadlock. However, no real OS today incorporates such an algorithm. \nInstead, they leave it up to the applications to worry about deadlocks since these are \nthe sorts of deadlocks that are actually encountered. The OS provides an API call that \nallows the application to examine the list of all waiting tasks. The application can \nthen examine all the waits to see if there is a loop in them. This examination is actu-\nally done by a debugger program that is running a user application. If the debugger \nfinds a loop then the programmers can examine the data and fix the problem.  \n 9.4.6 Preemption and other real-world solutions \n Some resources are used in such a way that once a process starts using them the pro-\ncess needs to finish what it is doing before we can use the resource. Good examples \nare writing a file to a tape drive or to a printer (without spooling). Other resources are \ndifferent\u2014RAM, for example. If two processes are running and each demands more \nRAM than the system can supply, we can temporarily suspend one of the processes, \nsave all the information it currently has in RAM to secondary storage, and let the \nsecond process have all the RAM. When the second process finishes we restore the \nfirst process into RAM, give it the extra RAM it wanted, and let it continue. This \ntechnique is known as  preemption. In  Figure 9.5 , we could apply preemption by \nhaving a police officer ask the driver of the car in the lower left corner of the figure \nto back it up, preempting its position on the street. \n The next question is then which job(s) should be preempted. The best choice is \nusually the one that has the minimum cost\u2014the one with the smallest current RAM \nuse that is large enough to satisfy the current request, for example. If preempting the \nlargest process does not free enough resources for the remaining jobs to finish, then \nthe preemption may need to be repeated with the next smaller process. \n If all the processes involved in a deadlock are waiting on resources that can-\nnot be preempted, we may have no choice but to abort some or all of the processes. \nAs unusual as it may seem, the normal choice is to abort all the processes in the \ndeadlock. Deadlocks are usually a rare event\u2014so rare that it is probably not worth \nspending the time to develop more complex algorithms. Plus, the available data on \nwhich to develop such algorithms is sparse. A better choice would be to successively \nabort the lowest cost processes until the deadlock disappears. The deadlock detection \nalgorithm should be run after each attempt. \nelm49810_ch09_181-208.indd   205\nelm49810_ch09_181-208.indd   205\n12/6/08   5:55:12 PM\n12/6/08   5:55:12 PM\n",
        "category": "Category"
    },
    {
        "id": "205",
        "title": "Title for Chunk 205",
        "content": "Confirming Pages\n206 \nPart 3 CPU and Memory Management\n As was mentioned, the most often used solution is to ignore the problem. \nUnfortunately, the deadlocked processes may consume some large amount of \nresources. Probably other processes will eventually begin to stop and wait because \nof the deadlocks held by the originally deadlocked processes. Eventually, the sys-\ntem may stop running any processes. Hopefully, the system operator will notice \nthis problem and will begin to solve it, probably by aborting jobs until the system \nresumes operation. \n In the future it seems likely that OSs will incorporate more mechanisms for \ncoping with deadlocks. Although the algorithms for detection do require some CPU \nand memory resources, deadlocks are very mysterious to users\u2014the system they are \nusing just appears to hang and they have no idea what to do to fix it or to avoid it in \nthe future. Computer hardware continues to get more powerful and RAM less expen-\nsive. Deadlock detection is being implemented for debuggers and we surmise that \nthey will find their way into the kernel as a background function in the future. \n 9.5 SUMMARY \n In this chapter, we discussed the nature of systems \nthat are comprised of multiple cooperating pro-\ncesses. We started this chapter with an examination \nof the reasons why systems are often built this way, \na trend that seems to be increasing. We looked at \nthe mechanisms that processes use to communicate \nwith one another. We then studied the problems that \narise when each of two processes is trying to access \ndata that the other process is (or may be) accessing \nat the same time. We described some tools that have \nbeen developed to allow processes to synchronize \ntheir activities so that these issues can be avoided. \nFinally, we discussed another class of problems \ncalled deadlocks that can arise when multiple pro-\ncesses use the synchronization mechanisms to lock \nresources. We described four theoretical mecha-\nnisms for keeping deadlocks from bringing our \nsystems to a halt. \n In the next chapter we cover management of \nprimary system memory. \n BIBLIOGRAPHY \n Ben-Ari, M.,  Principles of Concurrent Programming. \nEnglewood Cliffs, NJ: Prentice Hall, 1982. \n Bernstein, A. J., \u201cOutput Guards and Nondeterminism \nin Communicating Sequential Processes,\u201d  ACM \nTransactions on Programming Languages and \nSystems, Vol. 2, No. 2, 1980, pp. 234\u2013238. \n Brinch Hansen, P., \u201cStructured Multiprogramming,\u201d \n Communications of the ACM, Vol. 15, No. 7, July \n1972, pp. 574\u2013578. \n Brinch Hansen, P.,  Operating Systems Principles. \nEnglewood Cliffs, NJ: Prentice Hall, 1973. \n Coffman, E. G., Jr., M. J. Elphick, and A. Shoshani, \n\u201cSystem Deadlocks,\u201d  Computing Surveys, Vol. 3, \nNo. 2, June 1971, pp. 67\u201378. \n Courtois, P. J., F. Heymans, and D. L. Parnas, \n\u201cConcurrent Control with Readers and Writers,\u201d \n Communications of the ACM, Vol. 14, No. 10, \nOctober 1971, pp. 667\u2013668. \n Dijkstra, E. W., \u201cCo-operating Sequential Processes,\u201d in \nF. Genuys (Ed.),  Programming Languages. London: \nAcademic Press, 1965, pp. 43\u2013112. \n Dijkstra, E. W.  EWD 126: The Multiprogramming System \nfor the EL X8 THE (manuscript), 14 June 1965. \n Dijkstra, E. W., \u201cSolution of a Problem in Concurrent \nProgramming Control,\u201d  Communications of the \nACM, Vol. 8, No. 5, September 1965, p. 569. \nelm49810_ch09_181-208.indd   206\nelm49810_ch09_181-208.indd   206\n12/6/08   5:55:12 PM\n12/6/08   5:55:12 PM\n",
        "category": "Category"
    },
    {
        "id": "206",
        "title": "Title for Chunk 206",
        "content": "Confirming Pages\n \nChapter 9  More Process Management: Interprocess Communication, Synchronization, and Deadlocks   \n207\n Dijkstra, E. W., \u201cHierarchical Ordering of Sequential \nProcesses,\u201d  Acta Informatica, Vol. 1, 1971, \npp. 115\u2013138. \n Eisenberg, M. A., and M. R. McGuire, \u201cFurther \nComments on Dijkstra\u2019s Concurrent Programming \nControl Problem,\u201d  Communications of the ACM,  \nVol. 15, No. 11, November 1972, p. 999.  \n Habermann, A. N., \u201cPrevention of System Deadlocks,\u201d \n Communications of the ACM, Vol. 12, No. 7, July \n1969, pp. 373\u2013377, 385. \n Havender, J. W., \u201cAvoiding Deadlock in Multitasking \nSystems,\u201d  IBM Systems Journal, Vol. 7, No. 2, 1968, \npp. 74\u201384. \n Hoare, C. A. R., \u201cTowards a Theory of Parallel \nProgramming,\u201d in C. A. R. Hoare (Ed.),  Operating \nSystems Techniques.  New York: Academic Press, \n1972, pp. 61\u201371. \n Holt, R. C., \u201cSome Deadlock Properties of Computer \nSystems,\u201d  ACM Computing Surveys, Vol. 4, No. 3, \nSeptember 1972, pp. 179\u2013196. \n Howard, J. H., \u201cMixed Solutions for the Deadlock \nProblem,\u201d  Communications of the ACM, Vol. 16, \nNo. 7, July 1973, pp. 427\u2013430. \n Isloor, S. S., and T. A. Marsland, \u201cThe Deadlock Problem: \nAn Overview,\u201d  IEEE Computer, Vol. 13, No. 9, \nSeptember 1980, pp. 58\u201378. \n Kessels, J. L. W., \u201cAn Alternative to Event Queues for \nSynchronization in Monitors,\u201d  Communications of \nthe ACM, Vol. 20, No. 7, July 1977, pp. 500\u2013503. \n Knuth, D., \u201cAdditional Comments on a Problem in \nConcurrent Programming Control,\u201d  Communications \nof the ACM, Vol. 9, No. 5, May 1966, pp. 321\u2013322. \n Lamport, L., \u201cA New Solution to Dijkstra\u2019s Concurrent \nProgramming Problem,\u201d  Communications of the \nACM, Vol. 17, No. 8, August 1974, pp. 453\u2013455. \n Lamport, L., \u201cSynchronization of Independent Processes,\u201d \n Acta Informatica, Vol. 7, No. 1, 1976, pp. 15\u201334. \n Lamport, L., \u201cConcurrent Reading and Writing,\u201d \n Communications of the ACM, Vol. 20, No. 11, \nNovember 1977, pp. 806\u2013811. \n Lamport, L., \u201cThe Mutual Exclusion Problem: Part I\u2014A \nTheory of Interprocess Communication,\u201d  Journal of \nthe ACM, Vol. 33, No. 2, 1986, pp. 313\u2013326. \n Lamport, L., \u201cThe Mutual Exclusion Problem: Part II\u2014\nStatement and Solutions,\u201d  Journal of the ACM, \nVol. 33, No. 2, 1986, pp. 327\u2013348. \n Lampson, B. W., and D. D. Redell, \u201cExperience with \nProcesses and Monitors in MESA,\u201d  Communications \nof the ACM, Vol. 23, No. 2, February 1980, \npp. 105\u2013117. \n Levine, G. N., \u201cDefining Deadlock,\u201d  Operating Systems \nReview, Vol. 37, No. 1, pp. 54\u201364. \n Newton, G., \u201cDeadlock Prevention, Detection, and \nResolution: An Annotated Bibliography,\u201d  ACM \nOperating Systems Review, Vol. 13, No. 2, April \n1979, pp. 33\u201344. \n Patil, S. S., \u201cLimitations and Capabilities of Dijkstra\u2019s \nSemaphore Primitives for Coordination among \nProcesses,\u201d M.I.T. Project MAC Computation \nStructures Group Memo 57, February 1971. \n Peterson, G. L., \u201cMyths About the Mutual Exclusion \nProblem,\u201d  Information Processing Letters, Vol. 12, \nNo. 3, June 1981, pp. 115\u2013116. \n Raynal, M.,  Algorithms for Mutual Exclusion.  Cambridge, \nMA: MIT Press, 1986. \n Zobel, D., \u201cThe Deadlock Problem: A Classifying \nBibliography,\u201d  Operating Systems Review, Vol. 17, \nNo. 4, October 1983, pp. 6\u201316. \n WEB RESOURCES \n http://boinc.berkeley.edu (SETI and BOINC) \n http://research.microsoft.com/~mbj/Mars_Pathfinder/\nMars_Pathfinder.html  \nhttp://www.softpedia.com/get/Others/Home-Education/\nDeadlock-Avoidance-Simulation.shtml\nhttp://webscripts.softpedia.com/script/\nDevelopment-Scripts-js/Complete-applications/\nBanker-s-Algorithm-Demonstration-15119.html\nelm49810_ch09_181-208.indd   207\nelm49810_ch09_181-208.indd   207\n12/6/08   5:55:13 PM\n12/6/08   5:55:13 PM\n",
        "category": "Category"
    },
    {
        "id": "207",
        "title": "Title for Chunk 207",
        "content": "Confirming Pages\n208 \nPart 3 CPU and Memory Management\n REVIEW QUESTIONS \n \n9.1 We listed eight reasons why it is sometimes desir-\nable to have a system separated into different pro-\ncesses, sometimes running on different machines. \nFor each of these reasons, give a different exam-\nple than was given in the text.\n a. Performance - \n b. Scaling - \n c. Purchased components - \n d. Third-party service - \n e. Components of multiple systems - \n f. Reliability - \n g. Physical location of information -  \n h. Enable application -  \n \n9.2 For each attribute of interprocess communication \nmechanisms there were various alternatives for \nthat attribute. Discuss some good and bad points \nfor the alternatives for the following attributes:\n a. Multiple or single connections possible - \n b. Naming strategy - \n c. Connection oriented or connectionless - \n d. Persistent or transient - \n e. Number of processes -  \n \n9.3 True or false? Pipes are an example of a blocking \ncommunication mechanism. \n \n9.4 True or false? Sockets are an example of a persis-\ntent communication mechanism. \n \n9.5 What is the big problem with shared memory IPC \nmechanisms? \n \n9.6 Why are synchronization problems so difficult to \ndebug? \n \n9.7 What is the special feature of all the hard-\nware locking instructions that we discussed for \nsynchronization? \n \n9.8 Why do applications not use spin-locks? What do \nthey do instead? \n \n9.9 What are the normal names of the locking and \nunlocking system calls?\n a. Lock and unlock \n b. Set and clear \n c. Wait and signal \n d. Enter and exit \n e. None of the above \n 9.10 There are special semaphores called counting sema-\nphores. What kinds of things are they used for?  \n 9.11 True or false? When running on SMP systems, \napplications must take special precautions to \nmake sure that the values of any locks are seen by \nall CPUs. \n 9.12 Briefly describe the concept of priority inversion. \n 9.13 What caused the development of monitors in \nhigh-level languages? \n 9.14 There are three conditions for a deadlock. What \nare they? \n 9.15 We said that for a deadlock to happen there had \nto be a sequence of processes, each holding a \nresource and waiting on another resource that \nwas held by another process, with the last pro-\ncess waiting on a resource held by the first pro-\ncess. How many processes does it take to create a \ndeadlock? \n 9.16 Some devices are not sharable, but we have found \na way to make a virtual device that allows us to \npretend that we are sharing them. What is that \nmechanism? \n 9.17 Ordering of locks on resources can eliminate cir-\ncular waits and thus eliminate deadlocks. When is \nthis technique applicable and when is it not? \n 9.18 We discussed two different types of avoidance. In \ngeneral, what\u2019s wrong with avoidance? \n 9.19 The algorithms for deadlock detection are well \nknown and not too hard to write. So why do we \nnot use them more often? \n 9.20 What is the case where preemption is easy to do \nand works well? \n Problems possibly requiring further reading: \n 9.21 Modern OSs use several different kinds of sema-\nphores for different purposes. Pick a modern OS \nand name some of the different types of semaphores \nthey support with a brief explanation of each.  \n 9.22 There are several classic problems involved in syn-\nchronization. We described two. What were they \nand what other classic problems can you find?  \nelm49810_ch09_181-208.indd   208\nelm49810_ch09_181-208.indd   208\n12/6/08   5:55:13 PM\n12/6/08   5:55:13 PM\n",
        "category": "Category"
    },
    {
        "id": "208",
        "title": "Title for Chunk 208",
        "content": "Confirming Pages\n67\n Chapter \n Chapter  4  4 \n A Single-User Multitasking \nOperating System  \nIn this chapter: \n \n4.1  Introduction: A Simple Multitasking System 69\n \n4.2  The Palm OS Environment and System Layout 71\n \n4.3  Process Scheduling 73\n \n4.4  Memory Management 75\n \n4.5  File Support 80\n \n4.6  Basic Input and Output 82\n \n4.7  Display Management 82\n \n4.8  Event-Driven Programs 84\n \n4.9  Summary 86\n I\nn this chapter we discuss a more complex class of operating systems than the one \ndiscussed in Chapter 3, and one that is considerably more modern. We look at the \nPalm Operating System\u2122 1 developed by Palm, Inc. The CP/M system, which was \ncovered in the previous chapter, originally supported only one program (or process) \nat a time. Toward the end of its major period of use it was extended to include func-\ntions such as background printing. In contrast, the Palm OS was designed from the \noutset to support the execution of several processes at the same time. \n We start this chapter in Section 4.1 with an overview of Palm OS and some \nbackground about the underpinnings of the kernel. There are several other OSs in \n1 The OS functions described in this chapter cover releases of the Palm OS prior to release 5. Release 5 \nis a different OS and supports a different CPU. We feel that there will continue to be a class of devices \nand corresponding OSs that will function at approximately the level described, so we have not changed \nthe material to correspond to the later versions. The functions covered in this chapter are probably more \nrepresentative of the functions that students will find in similar low-end OSs for some time to come. For \nexample, as nanotechnology evolves, it is quite likely that such machines will often contain computer \nsystems that will require an OS and there will be no secondary storage. Furthermore, it currently seems \nlikely that rotating data storage devices may soon be a thing of the past, and that most new computers \nwill have vast amounts of primary storage and some removable tertiary storage but no secondary storage. \nThus, all OSs might function like this OS at some point. \nelm49810_ch04_067-088.indd   67\nelm49810_ch04_067-088.indd   67\n12/10/08   5:55:40 PM\n12/10/08   5:55:40 PM\n",
        "category": "Category"
    },
    {
        "id": "209",
        "title": "Title for Chunk 209",
        "content": "Confirming Pages\n68 \nPart 2 Building Operating Systems Incrementally: A Breadth-Oriented Spiral Approach\nthis class, most notably EPOC by Symbian\u2122 and scaled-down versions of Linux \nand Windows NT. The latter is called the Windows Mobile (formerly the Pocket PC) \nOS. At the end of the chapter we look at these other OSs and also some more recent \ndevelopments in this highly dynamic field. The Palm OS was developed for small \nhandheld devices called  personal digital assistants ( PDA s) or  personal informa-\ntion managers ( PIM s) that are typically used by a single user to keep track of per-\nsonal schedules, contacts, and to-do lists or to access email or the World Wide Web \nwhile on the move. These OSs are now used in cellular phones that have much of the \nsame functionality as a PDA. The Palm OS usually runs only a few applications at a \ntime, and can concurrently run some OS processes in parallel with the small number \nof applications. Thus, it supports a limited number of concurrently executing tasks. \nIt provides more features than the single-tasking type of OS described in Chapter 3. \nIt also serves to illustrate a modern version of a simple OS. \n In Section 4.2 we discuss some unusual hardware characteristics of the hand-\nheld computers that use the Palm OS. These special characteristics force the choices \nof some of the decisions made in the Palm OS design. In the CP/M world we saw \nat the very end the introduction of multiple programs in memory at the same time, \nproviding such functions as pop-up windows and background printing. The Palm OS \nhas much more complex multiprogramming, so in Section 4.3 we discuss the sched-\nuling of application processes and OS tasks in the Palm OS. \n When multiple programs are running in a system at the same time, memory \nmanagement becomes more complex. A program can no longer assume that it can \nuse all the memory there is. The OS must take on the responsibility of allocating sec-\ntions of memory to applications as they ask for it. It must therefore track the memory \nused by each application and recover it when the application ends. Therefore, Sec-\ntion 4.4 moves on to discuss memory management. Section 4.5 covers the organiza-\ntion of files in the Palm OS, and Section 4.6 covers the basic I/O functions that the \nPalm OS provides. \n Early PDAs were text based to a large extent, though many had special icons or \nsmall portions of the screen that had graphics capabilities. Now such devices always \nhave graphics-oriented displays. CP/M was a text-based OS, so in this chapter we \nalso introduce some simple characteristics of a graphical user interface, or GUI. All \nmodern OSs include support for a GUI, though they are not always intrinsic to the \nOS itself. Programs on a CP/M system assumed that they were in total control of \nthe system, so they were designed to interact in a certain way. Programs that work \nin a GUI have to cope with events that occur asynchronously to the main flow of \nthe program. So this chapter also introduces event-oriented programming. Section \n4.7 describes the display subsystem and Section 4.8 first discusses event-oriented \nprogramming and then describes the design of a typical Palm OS application. We \nconclude with a chapter summary in Section 4.9. \n Later in the book we cover a few more advanced features of the Palm OS and \nsimilar systems. Chapter 20 discusses several interesting subsystems in the Palm \nOS and explains the nature of the cross-development systems needed to develop \nprograms for such a limited environment. It also covers some of the developments in \nlater releases of the Palm OS. \nelm49810_ch04_067-088.indd   68\nelm49810_ch04_067-088.indd   68\n12/10/08   5:55:43 PM\n12/10/08   5:55:43 PM\n",
        "category": "Category"
    },
    {
        "id": "210",
        "title": "Title for Chunk 210",
        "content": "Rev. Confirming Pages\n \nChapter 4 A Single-User Multitasking Operating System \n69\n 4.1 INTRODUCTION: A SIMPLE MULTITASKING SYSTEM \n The Palm OS was developed by Palm, Inc. for use with their small handheld comput-\ners. A typical unit is shown in  Figure 4.1 . This platform has become very popular. \nSeveral hardware manufacturers have produced devices that conform to this tech-\nnology, including Handspring, Sony, and IBM. The same OS is also used in several \ncellular telephones, including the Treo and the Samsung 500. The environment in \nwhich Palm OS runs has several characteristics that are unusual compared to most \ngeneral-purpose computers or PCs. These characteristics forced some unusual deci-\nsions to be made when developing the OS. However, these characteristics are typical \nin many systems that will be seen more and more in the future, so that far from being \na distraction, these characteristics will actually be quite important to current and \nfuture OS architects. These characteristics also limit the design goals of the OS so \nthat it is only a little more complex than the single-process OSs covered in Chapter \n3. They are summarized in  Table 4.1 . \n  The first of these unusual characteristics arises from the fact that these handheld \ncomputers are grown-up versions of the PDAs that preceded them. They are designed \nto give top priority to servicing the interface with the user\u2014so much so that the OS \nis actually built on top of a real-time kernel that Palm, Inc. licensed from another \nvendor. 2 For example, this real-time kernel allows the system to support the use of a \nstylus to \u201cwrite\u201d on a small section of the liquid crystal display (LCD) screen. The \nscreen is touch sensitive, and touching the screen (preferably with the stylus) will \ncause an interrupt that will give the coordinates of the touched screen location to a \n2 That system is the AMX\u2122 Multitasking Executive from KADAK Products Limited. \nScreen\nCalculator\nSearch\nMenu\nContacts\nCalendar\nTo Do\nNote Pad\nGraffiti Area\nNavigation Buttons\nFIGURE 4.1 \nA Palm Pilot.\nelm49810_ch04_067-088.indd   69\nelm49810_ch04_067-088.indd   69\n12/22/08   12:57:44 PM\n12/22/08   12:57:44 PM\n",
        "category": "Category"
    },
    {
        "id": "211",
        "title": "Title for Chunk 211",
        "content": "Rev. Confirming Pages\n70 \nPart 2 Building Operating Systems Incrementally: A Breadth-Oriented Spiral Approach\nroutine that will track the movement of the stylus across the screen. The OS attempts \nto read and interpret the handwriting in real time\u2014this is known in the Palm OS as \n Graffiti input. 3 While the OS is handling this real-time task, it also allows a few \napplications to be running on the machine at the same time. Having multiple applica-\ntions as well as the real-time kernel running concurrently necessitates a  multitask-\ning or  multiprogramming system design. \n The Palm OS is designed for supporting applications such as the following:\n \ufffd Reading email \n \ufffd Keeping track of contacts in an address book \n \ufffd Keeping records of expenses \n \ufffd Enhancing to-do lists with alarm reminders \n \ufffd Playing simple games such as Sudoku \n \ufffd Accessing information through the WWW \nIt is not intended to support multiple users at a time or to be a Web server. Accord-\ningly, the real-time and multitasking characteristics of the OS are not exposed to the \napplication programmer through the application programming interfaces (APIs). \n Another unusual aspect of these systems is that in general there is no secondary \nstorage\u2014all of system memory is primary storage (electronic main memory). The \nlimited memory and CPU performance in these handheld systems lead to special \ndesigns for memory management and some special treatment for basic input and \noutput operations. Some of these devices come with plug-in capability. This allows \nvarious types of  cards or  modules to be attached to the device. These cards can \nbe memory cards preloaded with specific applications, global positioning systems \n(GPS) navigational devices, digital cameras, or even hard disks. The basic hardware, \nhowever, has no secondary storage, so the design of the OS must reflect this. Support \nfor secondary storage has been grafted onto the main system design, as we discuss \nin more detail later. \n The Palm OS supports a GUI to display output to the user. There are special \nconsiderations for programming this interface because of its small screen size. In \nparticular, there is usually only a single window (form) visible on the screen at any \npoint. There may be smaller dialog or alert boxes that are displayed in front of that \nsingle window. Finally, these systems support several mechanisms for accepting \n3 In 2003 PalmSource, Inc. lost a suit over the use of the original Graffiti software. The software now \nused is known as Graffiti 2. We use the simpler term as a generic name for the function. \nTABLE 4.1 Unusual Characteristics of the Palm OS\nReal-time OS tasks but non-real-time applications\nAll solid state memory\nLow power to conserve batteries\nSingle-window GUI\nMultiple text input options\nExpansion through plug-ins\nelm49810_ch04_067-088.indd   70\nelm49810_ch04_067-088.indd   70\n12/22/08   12:57:45 PM\n12/22/08   12:57:45 PM\n",
        "category": "Category"
    },
    {
        "id": "212",
        "title": "Title for Chunk 212",
        "content": "Rev. Confirming Pages\n \nChapter 4 A Single-User Multitasking Operating System \n71\nuser text input but they try to hide the differences between these mechanisms from \nthe applications.  \n 4.2 THE PALM OS ENVIRONMENT AND SYSTEM LAYOUT \n There are several characteristics of Palm devices that had to be taken into consider-\nation when designing the Palm OS. These were:\n \ufffd Basic memory is volatile RAM \n \ufffd Typically no secondary storage \n \ufffd Small screen size \n \ufffd Keyboard is not standard \n \ufffd CPU is slow to reduce battery drain \n 4.2.1 Basic memory is volatile RAM \n There are several unusual characteristics about the handheld computers that the \nPalm OS is designed to support. First, the devices are battery powered, and the \ndesign of the hardware and the OS reflect this. If the system is unused for a few min-\nutes it will put itself into a  sleep mode that uses very little power. The CPU is still \nrunning so the OS can sense when the user presses buttons, but it is running very \nslowly and in a small loop where it is waiting for interrupts. Power to the memory \nis actually  never turned off. Even when the CPU and the OS are shut down the \nmemory is still powered on. The hardware has a small current flow to maintain the \ncontents of memory. (It is also possible to add memory modules to the system that \ncontain read-only memory [ROM] or programmable read-only memory [PROM], \nsometimes called flash memory, but the basic design assumes that all main memory \nis volatile.)  \n 4.2.2 No secondary storage \n The second unusual characteristic about these handheld systems is that in the \noriginal design they do not have any secondary storage\u2014no disk, CD, DVD, or \ntape drives. All data and programs are kept in a single address space. Some of this \nmemory is ROM on modules (cards) that can be removed from the computer. This \nallows programs and databases to be loaded onto these modules and inserted into \nthe machines as desired. Whether on a removable card or built in to the machine, all \nof memory is visible all the time so that all programs and all databases are always \ndirectly accessible. Some vendors of Palm OS\u2013compatible hardware have added \na separate class of memory that is accessed through I/O commands just as a sec-\nondary storage device is. This memory is not part of the main address space and \nthus requires special OS commands to access it. This class of memory is removable \nand is intended to be used to move information from one system to another. It is \ndesigned to emulate a disk drive so that it is physically compatible with other hard-\nware systems as well.  \nelm49810_ch04_067-088.indd   71\nelm49810_ch04_067-088.indd   71\n12/22/08   12:57:45 PM\n12/22/08   12:57:45 PM\n",
        "category": "Category"
    },
    {
        "id": "213",
        "title": "Title for Chunk 213",
        "content": "Confirming Pages\n72 \nPart 2 Building Operating Systems Incrementally: A Breadth-Oriented Spiral Approach\n 4.2.3 Small screen size \n The next feature is the nature of the LCD that presents the GUI to the user. Its system \nfunction is similar to CRT (cathode ray tube) or LCD screens used in other current \nsystems, such as PCs utilizing OSs with GUI implementations. The fundamental dif-\nference is the size of the screen. Since these devices are literally designed to fit in a \nuser\u2019s hand, the screen display is limited. With most other GUIs there can be multiple \nwindows open on the screen at the same time. Often these windows overlap such that \nparts of some windows are hidden by other windows that are \u201cin front\u201d of them. It is \nusually possible to \u201cmaximize\u201d one window so that it fills (almost) the whole screen. \n In contrast to other GUIs, an application window in the Palm OS will fill the \nwhole screen. The application may still use pull-down menus and dialog boxes but \nthere will usually be no other application windows partially hidden behind the win-\ndow of the running application. \n 4.2.4 No keyboard \n One final interesting aspect of PDA handheld systems is that they initially did not \nhave a keyboard. There are some attachable keyboards available, and some later \nmodels do have an actual keyboard, but this is not the way the system is normally \nassumed to obtain user input. The usual mode of input is through Graffiti input, as \ndiscussed in Section 4.1. This is generally acceptable, as most applications for PDAs \ndo not expect large amounts of input. \n Figure 4.2  shows an overall layout of the Palm OS. Immediately above the hard-\nware is a software layer known as the hardware abstraction layer (HAL). Its  function \nHardware\nHardware Abstraction Layer\nKernel\nSystem Services\nSerial Manager\nResource Manager\nSound Manager\nModem Manager\nFeature Manager\nEvent Manager\nGraffiti Manager\nSystem Libraries (TCP/IP, Float Math)\nApplication Libraries\nApplication\nFIGURE 4.2 \nPalm OS \narchitecture.\nelm49810_ch04_067-088.indd   72\nelm49810_ch04_067-088.indd   72\n12/10/08   5:55:45 PM\n12/10/08   5:55:45 PM\n",
        "category": "Category"
    },
    {
        "id": "214",
        "title": "Title for Chunk 214",
        "content": "Confirming Pages\n \nChapter 4 A Single-User Multitasking Operating System \n73\nis to isolate the rest of the software from the specifics of the hardware devices. This \nallows the developers of the OS kernel to build an OS that can easily be moved to \nanother hardware platform. The kernel of the OS lies on top of the HAL. Many ser-\nvices provided by the OS are not part of the kernel, but lie above it. On top of the \nSystem Services area (which is always there) would come optional system library \nroutines; on top of that would come application library routines, and, finally, the \napplications themselves. \n 4.3 PROCESS SCHEDULING \n In the Palm OS multitasking environment, one needs to distinguish between \nOS processes and application processes. In this section, we discuss some pro-\ncesses of each type, and describe how the Palm OS handles and schedules these \nprocesses.  \n 4.3.1 Processing Graffiti input\u2014A real-time OS task \n As was mentioned in the first chapter, there are many tasks that can best be done \nin the OS. There are several reasons for putting functions in the OS. Often it is \nbecause they are used by many applications. Putting the function in the OS simpli-\nfies development for the application programmers, guarantees that all applications \nwill function similarly, and decreases the likelihood of having bugs in that part of the \napplications. The prime example of such a task in the Palm OS is the Graffiti input \nfunction. The display of the Palm OS systems is an LCD panel that is touch sensi-\ntive. Users generally input data into the Palm by drawing characters on this screen. \nThis is such a specialized task that it is done by the OS. Two OS tasks are involved: \n stylus tracking and  character recognition. \n In order to track the path of a stylus across the face of the Graffiti area of the \nLCD screen, the CPU must rapidly and repeatedly check the current location of \nthe stylus. This tracking is a real-time task because the system needs to be able to \nguarantee that it can check the position of the stylus frequently and quickly enough \nto track the movement of the stylus. This task is further complicated because the \nCPUs in these devices are running more slowly than those in PCs or workstations. \nThe tracking task will recognize when the stylus changes direction and will divide \nthe path into small vectors, which it will pass to the character recognition task. \nOnce the position vectors of the stylus are analyzed and discovered, then the char-\nacter can be recognized. Again, this is done by the OS. Every application developer \ndoes not want to have to write a handwriting recognizer. Indeed, this is one of the \nadvances in PDA technology that the Palm OS brought to the market. This is a \ntask that can be approached more leisurely than the tracking of the stylus. As the \ncharacters are recognized, the recognition task will give them to the application, \nwhich must display them back to the user in appropriate places on the LCD screen \nso that the user will get feedback about the characters input\u2014just as with keyboard \ninput on a PC.  \nelm49810_ch04_067-088.indd   73\nelm49810_ch04_067-088.indd   73\n12/10/08   5:55:46 PM\n12/10/08   5:55:46 PM\n",
        "category": "Category"
    },
    {
        "id": "215",
        "title": "Title for Chunk 215",
        "content": "Confirming Pages\n74 \nPart 2 Building Operating Systems Incrementally: A Breadth-Oriented Spiral Approach\n 4.3.2 Application processes\u2014One focus at a time \n In most systems a user can be running several applications at the same time. In the \nPalm OS only one user application will be visibly running at a time. Most Palm appli-\ncations, however, do not have an \u201cexit\u201d function that the user can invoke. When the \nuser selects a new application, any application that was running will be hidden from the \nuser by the OS. So in the Palm OS, only one application will be running at a time that \nis in  focus \u2014that is, in control of the  screen window, accepting and displaying input. \nHowever, other applications may run at times but do not have the focus. One example \nof such activity is a text search function. If the user does a text search, the Palm OS will \nsequentially call every application that has indicated to the OS that it will provide a text \nsearch function for its own database files. Each application will be asked to search its \ndatabase for the search string that the user has input. These applications, however, will \nnot gain control of the screen, and will only report their results to the OS. \n Another example of a task that is running but does not have the focus of the \nscreen is found in the  Sync application. This application synchronizes database files \non the handheld unit with those on a PC. The PC is running a corresponding syn-\nchronization program and the two systems communicate using some type of serial \ncommunication link. This connection might be an infrared or Bluetooth\u2122 link or \na USB cable. While this application will normally have the focus, there is no user \ninput while the synchronization is running. However, the user might want to stop the \nsynchronization before it finishes. One way to make this happen would be for the \nsync application to be in a loop, sending a block of data and then checking the screen \nfor a stylus tap. However, this would slow the serial communication and would delay \nthe response to the tap. Instead, the Palm Sync application uses two tasks: a real-time \ntask to respond to screen taps via an interrupt and a synchronization application that \ncan devote all its time to the communication task. \n 4.3.3 Typical user applications \n Most Palm OS applications primarily involve a database and GUI interface and are \ndesigned for organizing information. Typical applications include to-do lists, address \nand contact information, appointment calendars, and various alarms. As such, they \ndo not directly involve real-time tasks. As was previously described, the OS uses \nreal-time tasks for stylus input. The applications themselves merely input and dis-\nplay information about things such as the user\u2019s appointments. Normal user applica-\ntions, therefore, do not need to start extra tasks, as does the Sync system application. \nThe main part of each application is a loop called the  event loop. The OS \u201claunches\u201d \nthe application. The application checks to see if this is the first time it has been run. \nIf so, it will initialize any databases it maintains. It then enters the loop in which it \nwaits for events. Most events are activities such as the recognition of a character by \nthe Graffiti input or the selection of an item in a menu list. \n There are a few unusual system events such as a notification to all applications \nthat the system is about to enter sleep mode. Another frequent type of event is the \n\u201cappStopEvent.\u201d As was mentioned before, when the user selects another application \nto run, that application will become the active application and the OS will force the \nelm49810_ch04_067-088.indd   74\nelm49810_ch04_067-088.indd   74\n12/10/08   5:55:46 PM\n12/10/08   5:55:46 PM\n",
        "category": "Category"
    },
    {
        "id": "216",
        "title": "Title for Chunk 216",
        "content": "Rev. Confirming Pages\n \nChapter 4 A Single-User Multitasking Operating System \n75\ncurrently running application to stop. In a different environment another OS would \nnot want to stop an application merely because it did not have the focus. Too much I/O \nand CPU processing would be required to restart the application if the user switched \nback to it. On Palm handheld systems, however, there is no need to do such tasks as \nallocate memory to the program, read the executable module from a disk drive, and \nopen its files, since both the program and the files are already in main memory at all \ntimes. If the user reselects an application that has been stopped, all the application \ndoes is realize that its files are already initialized and go into its loop of checking the \nqueue of events that it needs to process. For a typical application that is merely wait-\ning for the user to select some action from a menu or via the GUI, stopping may not \nmean much. But a game where a user is playing against the computer probably will \npause its actions if the user switches to another application, for example. \n 4.3.4 Will the real scheduler please stand up? \n As far as the actual process scheduler used by the Palm OS, it is a preemptive mul-\ntitasking scheduler. This means that it is prepared to run many tasks, shifting among \nthem as needed in order to service the needs of the system. Different types of tasks \nhave various priorities and the OS scheduler will dynamically determine which task \nis the most important and will interrupt a less important task to run a more important \none. Interrupting one task to run another is called  preemption. The CPU is being \ntaken away from the less important task so the more important task can run first. \nVarious types of OS CPU schedulers will be discussed in more detail in Chapter 9. \n 4.4 MEMORY MANAGEMENT \n Because there are many processes in a Palm system that are sharing the primary \nmemory, the OS must provide lots of memory management functions. The first job \nis to see that the various processes don\u2019t access any locations outside their assigned \nmemory. It must also keep track of memory that is not currently in use. \n 4.4.1 Memory fundamentals \n Memory access in the Palm system uses 32-bit addresses, allowing for a 4 GB total \naddress space. The actual physical memory is on one or more cards and the view of \nmemory that the application sees reflects this. Each card has a minimum 256 MB \nportion of the logical address space. The cards are normally replaceable so the \namount of memory in a system can be upgraded. While initial hardware designs sup-\nported only one memory card, newer systems allow for more. Memory cards may \ncontain three different types of memory:\n \ufffd  Read-only memory ( ROM ) \n \ufffd  Programmable read-only memory ( PROM; also called  flash memory ) or \n nonvolatile RAM ( NVRAM ) \n \ufffd Random access memory (RAM) \nelm49810_ch04_067-088.indd   75\nelm49810_ch04_067-088.indd   75\n12/22/08   12:57:46 PM\n12/22/08   12:57:46 PM\n",
        "category": "Category"
    },
    {
        "id": "217",
        "title": "Title for Chunk 217",
        "content": "Confirming Pages\n76 \nPart 2 Building Operating Systems Incrementally: A Breadth-Oriented Spiral Approach\nAll cards contain at least some RAM; the presence of the other two types of mem-\nory on a card depends on the card. The OS and the entire initial set of applications \nwere initially contained in ROM but are now usually in PROM so that they can be \nupgraded. Additional applications can also be installed in the PROM or RAM. \n Logically, the RAM is divided into two sections: (1) one section of the RAM \nis treated as being volatile and is called  dynamic RAM and (2) the other section of \nRAM is treated as being  nonvolatile 4 ( NVRAM ) and is called  storage RAM. \n If there is PROM on the card it is always considered to be storage RAM since \nit really is nonvolatile. The dynamic RAM is used like conventional RAM as it is \nin most computer systems. The contents of the entire RAM are preserved when the \nsystem is  turned off (i.e., turned to low-power sleep mode). However, when the sys-\ntem is  turned on (or  booted ) the contents of the dynamic part of the RAM are reset \nby the OS. The storage portion of the RAM is used in the same way a disk drive is \nused in most systems\u2014to contain  persistent data that is intended for retention for \na long time (i.e., files or databases). Storage RAM can also contain extensions (and \npresumably fixes) to the OS as well as additional applications. \n Since the cards are replaceable, there needs to be a mechanism for preserving \nthe data contained in the storage RAM. The method is to use the Sync application \nto synchronize the contents of the storage RAM with a PC, replace the memory \ncard, and then resynchronize the Palm with the PC. When used this way the PC is \na backup device for the memory card contents. Alternatively, we can consider the \nPalm to be a  mobile device that  caches copies of part of the user\u2019s files and data-\nbases that normally reside on the PC. \n 4.4.2 Allocating memory \n Memory is managed by the Palm OS as a  heap 5 \u2014that is to say that pieces of the \nmemory are allocated and tracked by the OS and accessed within the heap as the \napplication program runs and finally is released by the programs and returned to \nthe available pool of memory by the OS. Those pieces are known in the Palm OS as \nmemory  chunks. There are a minimum of three heaps, one for each type of memory: \nROM, dynamic RAM, and storage RAM. In newer versions of the Palm OS some \nof these blocks of memory may be broken into more than one heap. Within each \nheap, the OS allocates chunks of memory when an application makes a request. The \nchunks can be of any nonzero size up to slightly less than 64 KB in increments of \n2 bytes. Memory chunks can be returned to the OS in any order and can be made \nsmaller or larger through OS service calls. \n Memory chunks are randomly allocated and freed and they may change size. \nIf they are made larger then they may have to move to another place in the heap. \nUltimately this process will lead to a condition known as  external  fragmentation. \nThis term describes a condition where there are free chunks available for use and the \ntotal amount of free memory is sufficient to satisfy a new request but the largest free \n4 Nonvolatile memory does not lose its contents in case of power failure. \n5 A heap is a structure in which memory is allocated as needed in no particular sequence or order. \nelm49810_ch04_067-088.indd   76\nelm49810_ch04_067-088.indd   76\n12/10/08   5:55:46 PM\n12/10/08   5:55:46 PM\n",
        "category": "Category"
    },
    {
        "id": "218",
        "title": "Title for Chunk 218",
        "content": "Confirming Pages\n \nChapter 4 A Single-User Multitasking Operating System \n77\nchunk is too small to satisfy the request, so the memory request cannot be directly \nsatisfied. This is illustrated in  Figure 4.3 . \n When this happens, the OS will attempt to move the currently used chunks so \nthat the free space is contiguous. This kind of reorganization of fragmented space is \nknown as  compaction. There is a potential problem with this memory reorganiza-\ntion: an application has been allocated these chunks of memory and has pointers to \nthem. If the OS is going to move the data then the application must still be able to \naccess the data. \n To allow for this moving of chunks in memory, the occupied chunks are accessed \nin a controlled manner. First, the data are accessed indirectly by the code rather than \nbeing accessed directly. That way the OS can move the data in the heap and the pro-\ncess will still be able to access it through the pointer. Each chunk in a heap is pointed \nto by an entry in a table called the master pointer table ( MPT ). The MPT is itself a \nchunk of RAM at the start of the heap. When a chunk is allocated, the application is \nnot given a direct pointer to the chunk. Instead, it is returned a master chunk pointer \n( MCP ). This pointer is actually the offset in the MPT of the pointer to that chunk, as \nillustrated in  Figure 4.4 . \n The second aspect of the controlled access to memory is that an application \nmust  lock a chunk prior to using it. When the application wants to use the data \nin a chunk of memory it calls the OS to lock the MCP of that chunk. The OS will \nmaintain a count of the locks for each chunk and will increase the lock count for that \nchunk by 1 (the maximum is 16) and return to the application the current physical \naddress of the chunk. The application can now access the chunk as it needs to. The \napplication unlocks the chunk when it is finished using it and the OS will decrement \nAlthough there are 96 bytes of \nfree space in this heap we can\u2019t \nallocate a chunk any larger than \n16 bytes because the free space \nis fragmented.\nHEAP Space\nunused 16-byte chunk\nchunk for variable D\nunused 16-byte chunk\nchunk for variable C\nunused 16-byte chunk\nchunk for variable E\nunused 16-byte chunk\nchunk for variable B\nunused 16-byte chunk\nchunk for variable A\nunused 16-byte chunk\nFIGURE 4.3 \nExternal \nfragmentation.\nelm49810_ch04_067-088.indd   77\nelm49810_ch04_067-088.indd   77\n12/10/08   5:55:47 PM\n12/10/08   5:55:47 PM\n",
        "category": "Category"
    },
    {
        "id": "219",
        "title": "Title for Chunk 219",
        "content": "Confirming Pages\n78 \nPart 2 Building Operating Systems Incrementally: A Breadth-Oriented Spiral Approach\nthe lock count. When the OS needs to do compaction it will not move chunks that \nare locked by an application, as the lock means that the application is currently using \nthe data. \n Each MPT that controls one specific heap segment also contains a pointer to a \npossible next MPT. If the first MPT fills up, then a second MPT will be allocated \nfrom the heap and the first MPT will point to the second.  Figures 4.5  and  4.6  illus-\ntrate these concepts. 6 \n 4.4.3 Nonmoveable chunks \n Some memory chunks cannot be moved\u2014for example, program code. Nonmoveable \nchunks are allocated from the high order end of the heap (higher memory addresses) \nwhile moveable chunks are allocated from the front (lower memory addresses). Non-\nmoveable chunks do not need an entry in the MPT since the only purpose of the \nMPT is to allow chunks to be moved during compaction. For consistency, even ROM \nis accessed through a chunk table. This allows an application to be debugged in \nRAM and then be moved to ROM without any changes. Since the code in the ROM \nis nonmoveable by definition, there will be no MCPs in the MPT for the heap in \nthe ROM. \n6 This mechanism looks quite complex, and it  is complex. However, it is typical of the memory access \ncontrol mechanisms used in many OSs today, so it is worth looking at it in detail. \n0\nHEAP Space\n5\nThe application \nprogram\u2019s \u201cPointer\u201d\nfor variable A is  \nactually the offset of  \nthe MPT entry for \nvariable A.\n1\n2\n3\n4\n5\nMPT entry for variable A\n6\n\u2026\nOffset in MPT\nrest of MPT (& heap)\n\u2026\nChunk for variable A\n\u2026\nFIGURE 4.4 \nMaster pointer table.\nelm49810_ch04_067-088.indd   78\nelm49810_ch04_067-088.indd   78\n12/10/08   5:55:48 PM\n12/10/08   5:55:48 PM\n",
        "category": "Category"
    },
    {
        "id": "220",
        "title": "Title for Chunk 220",
        "content": "Confirming Pages\n \nChapter 4 A Single-User Multitasking Operating System \n79\n 4.4.4 Free space tracking \n When the heap is initially created by the OS, the storage management software will \ncreate the empty MPT. As was mentioned, moveable chunks are allocated from the \nfront of the heap and nonmoveable chunks are allocated from the end. The area \nbetween the two is considered to be free memory. When applications have chunks \nHEAP Space before\nGarbage collection\nThe memory \nmanager moves\nchunks that are not \ncurrently locked to\ncombine unused \nchunks into larger\nchunks. Chunk B\nwas not moved\nbecause it was\nlocked.\nHEAP Space after\nGarbage collection\nchunk for variable E\nchunk for variable D\nchunk for variable A\nchunk for variable C\nunused 48-byte chunk\nchunk for variable B\nunused 48-byte chunk\nunused 16-byte chunk\nchunk for variable D\nunused 16-byte chunk\nchunk for variable C\nunused 16-byte chunk\nchunk for variable E\nunused 16-byte chunk\nchunk for variable B\nunused 16-byte chunk\nchunk for variable A\nunused 16-byte chunk\nFIGURE 4.5 \nGarbage collection.\nFirst MPT\nchunk for variable D\nunused 16-byte chunk\nSecond MPT\nchunk for variable A\nunused 16-byte chunk\nHEAP Space\n...\n...\nFIGURE 4.6 \nMPT chaining.\nelm49810_ch04_067-088.indd   79\nelm49810_ch04_067-088.indd   79\n12/10/08   5:55:48 PM\n12/10/08   5:55:48 PM\n",
        "category": "Category"
    },
    {
        "id": "221",
        "title": "Title for Chunk 221",
        "content": "Confirming Pages\n80 \nPart 2 Building Operating Systems Incrementally: A Breadth-Oriented Spiral Approach\nthat are no longer needed they call the OS to free the chunk. The freed chunks are \nmarked as being free and will be allocated again to any application if needed. If a \nrequest for a smaller amount of memory is made, a larger chunk will be split into two \npieces, one allocated to the data and one marked free (unused). This fragments the \nheap. But how does the OS decide which of the free chunks to divide? Does it pick \nthe smallest one that will fit? Does it pick the first one it finds that is big enough? \nThese strategies, respectively called \u201cfirst fit\u201d and \u201cbest fit,\u201d as well as other strate-\ngies are discussed further in Chapter 10. \n 4.5 FILE SUPPORT \n In a more traditional OS the file system will call the OS to read individual file records \nfrom secondary storage into main memory. The application will operate on the data \nin main memory, and if needed, the application will write the data back to secondary \nstorage, again by calling the OS. In the Palm design there normally is no secondary \nstorage. All data is kept in the storage portion of main memory, either flash memory \nor RAM. Since most programmers are strongly oriented to the concepts of files and \nrecords, this orientation is maintained in the Palm OS. The storage RAM is used as \na kind of secondary storage. As was mentioned earlier, the contents of storage RAM \nare never erased, even when the system is turned \u201coff.\u201d \n 4.5.1 Databases and records \n Data are saved in  records. For example, a record might correspond to the contact \ninformation for one contact in an address book. Each record is saved in a memory \nchunk. The chunks are aggregated into collections called  databases. (These data-\nbases are what are called \u201cfiles\u201d in most OSs. They are not what we normally mean \nwhen we use the word \u201cdatabase,\u201d a system that automatically indexes data, among \nother things.) Each database has a  header. This header contains some basic informa-\ntion about the database and a list of records in the database. This list is actually a list \nof unique IDs for the records. If the initial chunk that contains the list of record IDs \nbecomes full, then another header chunk will be allocated and the first header will \npoint to the second. The IDs are only unique within the address space of a single \nmemory card, so all the records for a given database have to reside within a single \nmemory card. While the record ID is simply an integer with no relation to the data, \nit is also possible to create a key field in each database record that can be searched \nfor by a program. \n On some (non-Palm) systems with limited data storage the data can be com-\npressed to save space. Because the CPU power in the Palm OS platforms is also \nmodest, the information is not usually stored in compressed form. When secondary \nstorage is on a rotating memory such as a disk there is a time lapse (latency) between \nthe time when an application asks for a record and the time when the hardware can \naccess the data. That time can normally be traded against the time required to do the \ncompression and decompression. Since there normally is no rotating memory in the \nelm49810_ch04_067-088.indd   80\nelm49810_ch04_067-088.indd   80\n12/10/08   5:55:48 PM\n12/10/08   5:55:48 PM\n",
        "category": "Category"
    },
    {
        "id": "222",
        "title": "Title for Chunk 222",
        "content": "Confirming Pages\n \nChapter 4 A Single-User Multitasking Operating System \n81\nPalm OS platform there is no time to be gained, so any time used for compression \nwould be visible to the user. As a result, compression is not normally used with the \nPalm OS. \n 4.5.2 Resource objects \n In a GUI there are elements that appear on the screen such as buttons, text boxes, \nslider controls, and so on. The Palm OS defines the various elements of a GUI inter-\nface as  objects called  resources. These resources are not objects in the traditional \nsense; instead, they are merely  data structures. Each resource has a specific structure \nso that the OS can handle it in certain default ways. For example, if an application \nwants to display a confirmation alert for a record deletion it merely defines the alert \nand calls the OS to display it.  Figure 4.7  shows such an alert box. When the alert is \ndisplayed, the OS does all the work of saving the window under which the alert will \nbe displayed and updating the window on the form so that the user sees the alert. \nAfter the user confirms the alert the OS will restore the saved window to the form \nand tell the application which button on the alert box the user selected. The applica-\ntion can always override the default action and cause some special action to happen. \nThe resources are saved in chunks just as with database records and are tagged by the \nOS so that it knows what kind of resource each object represents. \n 4.5.3 Secondary storage \n We mentioned that there typically was no secondary storage on the Palm OS plat-\nform. From the standpoint of most applications that is true. However, other develop-\nments in the area of small handheld devices have led to a requirement for a more \ngeneral storage mechanism. As of Palm OS release 4.0, support is included for a dif-\nferent category of memory device. These devices are assumed to have an organiza-\ntion that is more typical of common secondary storage devices. One popular model \ncomes initialized with a file system that mimics that found on a DOS disk drive. The \nintended use of these modules is that they would be written to by another device, \nsuch as a PC, and then inserted into the Palm OS hardware device for later access. \nA user can store many files on a PC and load individual files onto memory modules \nthat can later be inserted in a Palm system for access. In order that the PC need not \nhave special software to access regular Palm memory modules, a file organization \nthat is already supported by many OSs was used. Because of the ubiquitous nature of \nthe Microsoft OSs, virtually all OSs today support those file formats for removable \nsecondary storage devices. \nAppointment Delete\nDo you really want to\ndelete this appointment?\n?\nOK\nCANCEL\nFIGURE 4.7 \nAn Alert box form.\nelm49810_ch04_067-088.indd   81\nelm49810_ch04_067-088.indd   81\n12/10/08   5:55:49 PM\n12/10/08   5:55:49 PM\n",
        "category": "Category"
    },
    {
        "id": "223",
        "title": "Title for Chunk 223",
        "content": "Confirming Pages\n82 \nPart 2 Building Operating Systems Incrementally: A Breadth-Oriented Spiral Approach\n 4.6 BASIC INPUT AND OUTPUT   \n 4.6.1 Hiding hardware details \n The Palm OS was designed so that to a programmer the system looked like a con-\nventional computer system as much as possible. A good example of this is in the \nhandling of user input. It is normal for an OS to hide many of the details of user \nkeyboard input. Generally there are at least two levels of abstraction:\n 1. Some programs want to see every keystroke. A good example would be a screen-\noriented text editor like the UNIX text editor program vi. Such application pro-\ngrams interpret every keystroke so that they can implement very powerful editing \ncommands with only a few keystrokes. This is known as a  raw interface.  \n 2. A second level of abstraction is available for applications that only want to read \nan entire line of input. The OS will provide various editing operations of the line \nas the user enters it. These might include character or string insertion or dele-\ntion, duplication of the previous line, backspace and strikeover, and so on. The \nprogram only sees completed input lines. This is known as a  cooked interface. \n Programmers used to writing in C will know the cooked keyboard interface is exposed \nas the function  stdin (standard input). C libraries also usually provide a cooked style \nof interface for printer output called  stdout (standard output) and a similar output \ninterface for reporting errors called  stderr (standard error). Originally, these output \nstreams were designed to be directed to a hardcopy printer, but later implementations \nusually directed the stdout to the terminal screen instead of a real printer. The Palm \nOS is similar. It provides all three of these interfaces. The unusual thing about the \nhandheld hardware, of course, is that it normally has no keyboard. This point serves \nto reinforce the utility of these abstractions. The user may be using the stylus to select \ncharacter icons from a display on the handheld screen that looks like a keyboard or to \nwrite free form characters in the Graffiti area. The OS hides all those details and allows \na program written in C to use stdin, ignore those hidden details, and accept an entire \nline of input without worrying about the details of how it was actually entered. When \nan actual keyboard is attached to a handheld unit it will allow the user to enter com-\nmands through the keys and the application program will never know the difference.  \n 4.7 DISPLAY MANAGEMENT \n 4.7.1 The hardware \n The standard display is a touch-sensitive LCD panel with a resolution of 160  \ufffd 160 \n pixels (picture elements or dots). A high-resolution display may have up to 480  \ufffd 320 \npixels. The original models were only black on white but later models could display \na four-level grayscale. Newer models are capable of displaying color with 2, 4, 64, \n256, or 65 K colors. As with early PCs, the screen is refreshed directly from memory \nrather than being a device that must be written to with I/O instructions. As the actual \ndisplays vary, it is strongly recommended that applications access the display by \nusing standard system calls and leave the hardware details to the OS. This is a typical \nelm49810_ch04_067-088.indd   82\nelm49810_ch04_067-088.indd   82\n12/10/08   5:55:49 PM\n12/10/08   5:55:49 PM\n",
        "category": "Category"
    },
    {
        "id": "224",
        "title": "Title for Chunk 224",
        "content": "Confirming Pages\n \nChapter 4 A Single-User Multitasking Operating System \n83\nabstraction that an OS makes so that applications do not have to deal with hardware \ndetails and are thus more portable. \n 4.7.2 Top-level GUI elements \n The Palm OS has a GUI that is based on the concept of  forms. These forms are similar \nto what is called a window in other GUI OSs, but they normally fill the entire screen. \nA form is typically a view of some portion of an application\u2019s data. For example, an \naddress book application might have one form to view the list of addressees, another \nfor editing a single address, and so on. The OS also supports an element called a \nwindow, but in this case the term  window refers to an object that can be operated on \nby the system\u2019s drawing features. There may be windows that are not forms. These \nare used to create dialog boxes, for example. All forms are windows. In most cases \nthe application will not draw directly on the windows. All manipulation will be done \nas a result of the definition of  GUI elements \u2014such as buttons or menus\u2014or as a \nresult of system calls made by the application. For example, the OS knows how to \ndraw a button and how to handle a tap on the button by the user. The application only \nneeds to define the label on the button, tell the OS where to place the button on the \nform, and what numeric code to provide the application when the user touches the \nscreen over the button. This is presented to the application as an event. The applica-\ntion will only use the low-level drawing facilities if it wants to provide animation, \nfor example, or if it wants to define its own additional GUI elements that the OS \ndoes not provide. These application-specific GUI elements are known in the Palm \nOS as  gadgets or  objects. (In other OSs they are often called widgets.) They are not \n\u201cobjects\u201d as that term is used in programming. They are merely date structures that \nmay have certain subroutines associated with events such as the completion of a field \nor the \u201ctapping\u201d of a button on a form on the screen. \n 4.7.3 Special form types \n There are two special types of forms that do not fill the entire screen. The first of \nthese is an  alert box. A typical alert box might be a confirmation of a record dele-\ntion as was shown in  Figure 4.7 . The alert box is displayed by an application. The \napplication requires that this box holds the focus until the user acknowledges the \nbox. This is called a  modal form. In some cases there is a single button the user must \ntouch to acknowledge the box. In the case shown in  Figure 4.7  there are two but-\ntons and the user selects one of them by touching them with the stylus. Then the OS \nremoves the box from the screen. The other special thing about this form is that the \napplication does not have to create the form specifically\u2014it merely fills in a struc-\nture that defines the text that appears in the box and on the buttons and asks the OS to \ncreate the box. The OS will handle all the events such as the taps on the buttons. \n The second type of special form is a  progress dialog. This form is similar to \nthe alert box but is more dynamic. It is intended for use when an application is \ndoing some lengthy processing such as a file transfer. There is a separate call that the \napplication can make that will change the text that is currently being displayed. This \nis normally an indicator about the progress of the application. If the application is \nsending a 100 KB, file and has sent 50 KB, it might draw a bar that is 50% colored. \nelm49810_ch04_067-088.indd   83\nelm49810_ch04_067-088.indd   83\n12/10/08   5:55:49 PM\n12/10/08   5:55:49 PM\n",
        "category": "Category"
    },
    {
        "id": "225",
        "title": "Title for Chunk 225",
        "content": "Confirming Pages\n84 \nPart 2 Building Operating Systems Incrementally: A Breadth-Oriented Spiral Approach\nThis gives the user an indication of the time left to finish the operation. There is nor-\nmally a button that the user can press, for example, to cancel the operation. Watching \nfor a click on this button is one of the real-time tasks that the OS can do for an appli-\ncation without interrupting the application flow and still provide a timely response \nto the button. This relieves the application from having to check for the button click \nin its processing loop. \n 4.7.4 Lower-level GUI controls \n The Palm OS GUI controls are not traditional objects. Having no methods or proper-\nties, they are merely data structures. For a given type of control there are various OS \ncalls that can be made that will cause them to be displayed. When the user touches one \nof the controls on the screen there will be an  event generated that will be passed to the \napplication. The application will receive the event and execute the appropriate code. \n Table 4.2  shows the controls that the Palm OS supports and some examples or \nother details about the control. \n 4.8 EVENT-DRIVEN PROGRAMS \n Under the Palm OS, most applications are written to be interactive. They do not gen-\nerally process batches of data like a payroll application on a mainframe or respond to \ncomplete individual requests like a server. Instead, they focus on the user\u2019s  immediate \ninteractive inputs. These applications are therefore organized in a special way. When \na Palm application runs it first initializes its files (if any) and then goes into a loop in \nwhich it checks for events that are being given to it by the OS. An example is shown \nin  Figure 4.8 . \nTABLE 4.2 Palm OS Controls\nSystem-Defined Controls\nControl\nDetails\nButton\nInvokes a function (e.g., \u201cDisplay\u201d)\nPush button\n\u201cRadio buttons\u201d\nSelector trigger\nOpens a specialized dialog box (e.g., for date input)\nIncrement arrow\nVaries a value in an associated control\nCheckbox\nTrue/false\u2013On/off\nPop-up list\nInvoked by a pop-up trigger\nPop-up trigger\nOpens pop-up list (downward pointing triangle \u25bc)\nList\nA pull-down list (e.g., in a menu)\nMenu\nAccess less frequently used functions\nText box\nBasic data entry box\nScroll bar\nWhen the data overflows the display area of a form\nelm49810_ch04_067-088.indd   84\nelm49810_ch04_067-088.indd   84\n12/10/08   5:55:50 PM\n12/10/08   5:55:50 PM\n",
        "category": "Category"
    },
    {
        "id": "226",
        "title": "Title for Chunk 226",
        "content": "Confirming Pages\n \nChapter 4 A Single-User Multitasking Operating System \n85\n If there are no events for it to process then it tells the OS that it wants to WAIT \nfor more events. When another event occurs the OS will pass the information to the \napplication as a return from one of the calls to check for various classes of events. \nThe user has started the application for some specific task\u2014perhaps to look up a \nphone number in the contact file. Until the user gives the program a specific task \nthe program does not have anything to do so it merely waits. The user will use the \nmenus and other controls in the form to tell the application what to do. Perhaps \na name is being keyed into a text box. As each character is keyed the applica-\ntion will get an event signal and will update the display to reflect the name that is \nbeing keyed. \n For many of the controls defined in a form, the application is able to specify \nactions to be taken such that the OS can do much of the work without the involve-\nment of the application. For example, the OS knows how to automatically increment \na value in a control with an increment arrow. For other buttons the application may \nneed to do special processing. Each control that the application defines may result in \nevent codes being passed to the application when that control is touched. Consider, \nfor example, the confirmation dialog shown in  Figure 4.7 . When this control is dis-\nplayed and the user touches one of the buttons, the application will be sent an event. \nThe value sent to the application will identify which control the event was from and \nwhich button was tapped. \n Because the operation of the touch screen is asynchronous with the application \n(i.e., screen events can happen at any time while the program is running), several \nevents can happen faster than the application can process them. The OS therefore has \nto maintain a queue of the events that have happened but that have not been given to \nthe application yet. This queue is maintained in priority order so that more important \nevents can be processed first by the application. \n A few such events are system-related events. For example, events are sent to the \napplication when the power is being turned off (i.e., the system is going into the low-\npower sleep mode). In this case the application will suspend any other operations \nsuch as communication to another system. \nstatic void EventLoop(void)\n{\nUInt16 error;\n  EventType event;\n  do\n        {\nEvtGetEvent(&event, evtWaitForever);\nPreprocessEvent(&event);\nif(! SysHandleEvent (&event))\n            if(! MenuHandleEvent(NULL,&event,&error))\n               if(! ApplicationHandleEvent(&event))\n                   FrmDispatchEvent(&event);\n        #ifEMULATION_LEVEL != EMULATION_NONE\n            ECApptDBValidate (ApptDB);\n        #endif\n        }\nwhile (event.eType != appStopEvent);\n}\nFIGURE 4.8 \nAn event-driven \nprogram main \nloop.\nelm49810_ch04_067-088.indd   85\nelm49810_ch04_067-088.indd   85\n12/10/08   5:55:50 PM\n12/10/08   5:55:50 PM\n",
        "category": "Category"
    },
    {
        "id": "227",
        "title": "Title for Chunk 227",
        "content": "Confirming Pages\n86 \nPart 2 Building Operating Systems Incrementally: A Breadth-Oriented Spiral Approach\n 4.9 SUMMARY \n In this chapter, we discussed the features and concepts \nof a simple modern OS\u2014the Palm Operating Sys-\ntem\u2122 developed by Palm, Inc. This OS was devel-\noped for small handheld devices. Although this is a \nsingle-user system, it can concurrently run some OS \nprocesses and a small number of applications. Thus, \nit supports a limited number of concurrently execut-\ning tasks, making it a simple multitasking system. \n We started this chapter with an overview of the \nPalm OS and discussed some of the unusual hard-\nware characteristics of the handheld computers \nthat use the Palm OS. These special characteristics \nforce the choices of some of the decisions made in \nthe Palm OS design. Then we discussed the nature \nof multitasking and how an OS works to schedule \napplication processes and OS tasks. We then dis-\ncussed memory management, and the different types \nof memory storage supported by the OS. Because the \nPalm platform does not normally have a hard disk, it \nuses a part of memory called storage RAM to keep \npersistent data. When power is turned off and the \nsystem is in sleep mode, storage RAM maintains its \ncontents. We discussed how memory is divided into \nchunks, and how the OS locates different chunks in \nmemory tables and uses compaction to manage the \nfree memory. \n Then came an overview of the organization of \nfiles in the Palm OS, followed by coverage of the \nbasic I/O functions that the Palm OS provides. These \ninclude the Graffiti input system that allows users to \ninput freehand text. We next described the display \nsubsystem and simple GUI programming, followed \nby a brief discussion of event-oriented programming, \na paradigm used in most Palm applications. Next, we \ndescribed the design of a typical Palm OS application. \n In the next chapter we move on to an OS more \ncomplex than the Palm OS. It generally handles mul-\ntiple programs running concurrently at the applica-\ntion level. It is correspondingly more complex and \ncontains more system overhead. \n BIBLIOGRAPHY \n AMX/FS File System User\u2019s Guide. Vancouver, BC, \nCanada: KADAK Products Ltd., 1995. \n AMX User\u2019s Guide. Vancouver, BC, Canada: KADAK \nProducts Ltd., 1996. \n Exploring Palm OS: Palm OS File Formats, Document \nNumber 3120-002. Sunnyvale, CA: PalmSource, \nInc., 2004. \n Exploring Palm OS: System Management, Document \nNumber 3110-002. Sunnyvale, CA: PalmSource, \nInc., 2004. \n Palm OS\u00ae Programmer\u2019s API Reference, Document \nNumber 3003-004. Sunnyvale, CA: Palm, \nInc., 2001. \n Palm OS Programmer\u2019s Companion, Volume 1, \nDocument Number 3120-002. Sunnyvale, CA: \nPalm, Inc., 2001.  \n Palm OS Programmer\u2019s Companion, Volume 2, \nCommunications, Document Number 3005-002. \nSunnyvale, CA: Palm, Inc., 2001. \n Rhodes, N., & J. McKeehan,  Palm Programming: \nThe Developer\u2019s Guide, 1st ed., Sebastopol, CA: \nO\u2019Reilly & Associates, Inc., 2000. \n SONY Cli\u00e9, Personal Entertainment Organizer. Sony \nCorporation, 2001.  \n WEB RESOURCES \n http://www.accessdevnet.com (ACCESS Linux Platform \nDevelopment Suite) \n http://www.freewarepalm.com (free Palm software) \n http://oasis.palm.com/dev/palmos40-docs/\nmemory%20architecture.html \n http://www.palm.com (Palm home page) \n http://www.pocketgear.com/en_US/html/index.jsp \n(software for mobile devices) \n http://en.wikipedia.org/wiki/Graffiti_2 (article on Graffiti 2) \nelm49810_ch04_067-088.indd   86\nelm49810_ch04_067-088.indd   86\n12/10/08   5:55:51 PM\n12/10/08   5:55:51 PM\n",
        "category": "Category"
    },
    {
        "id": "228",
        "title": "Title for Chunk 228",
        "content": "Confirming Pages\n \nChapter 4 A Single-User Multitasking Operating System \n87\n REVIEW QUESTIONS \n \n4.1 Since the Palm processor can only have one pro-\ngram on the display at a time, why does the sys-\ntem need a multiprocessing OS? \n \n4.2 Outside of a slow processor and fairly small \nmemories compared to modern systems, what is \nthe most unusual part of the basic hardware design \nthat the OS is based on? \n \n4.3 Is the Palm OS a microkernel or a monolithic \nkernel? \n \n4.4 What does the Palm OS use a real-time kernel for?  \n \n4.5 What is the basic logic flow of most applications? \n \n4.6 Why is memory allocated to a process accessed \nindirectly through the MPT? \n \n4.7 How does the OS track free memory? \n \n4.8 As is typical in much of information system tech-\nnology, the developers of the Palm OS overloaded \na perfectly good term with a different meaning. \nWhat does the Palm OS documentation mean \nwhen it refers to a \u201cdatabase?\u201d \n \n4.9 Considering that the Palm platforms do not have \nmuch memory, why do they typically not use \ncompression on the databases? \n 4.10 The Palm OS gives the programmer several \nabstractions for I/O so that the application pro-\ngrammer did not have to worry about the hard-\nware details. What were some of the abstractions \nthat were mentioned? \n 4.11 True or false? The screens are memory mapped \nrather than handled by I/O instructions so most \napplications directly move data to the screen area \nin memory. \n 4.12 Briefly describe event-driven programming. \n 4.13 How does an application programmer draw the \nforms that he wants to display on the screen? \nelm49810_ch04_067-088.indd   87\nelm49810_ch04_067-088.indd   87\n12/10/08   5:55:51 PM\n12/10/08   5:55:51 PM\n",
        "category": "Category"
    },
    {
        "id": "229",
        "title": "Title for Chunk 229",
        "content": "elm49810_ch04_067-088.indd   88\nelm49810_ch04_067-088.indd   88\n12/10/08   5:55:52 PM\n12/10/08   5:55:52 PM\n",
        "category": "Category"
    },
    {
        "id": "230",
        "title": "Title for Chunk 230",
        "content": "483\n In this appendix: \n \nA.1 Typical Computer System Components 484\n \nA.2 The Processor or Central Processing Unit 485\n \nA.3 The Memory Unit and Computer Storage Hierarchies 496\n \nA.4 Input and Output 502\n \nA.5 The Network 504\n \nA.6 A More Detailed Picture 507\n \nA.7 Summary  507\n In this appendix, we give an overview of computer architecture concepts, with an \nemphasis on those concepts that are particularly relevant to OSs. Some readers will \nhave already completed a course in computer organization or computer architecture, \nand hence will be familiar with these concepts. In this case, the appendix can pro-\nvide a review of this material. For those who have not had a previous course in this \ntopic, this appendix might be covered in detail, because the discussions of many OS \nconcepts are based on the underlying computer architecture. The concepts presented \nhere are needed throughout the presentation of OS concepts. \n We start by giving a description of the major components of a typical computer \nsystem in Section A.1, and a discussion of the functions performed by each com-\nponent. In Section A.2 we discuss the central processing unit and control concepts. \nSection A.3 outlines the ideas of memory and storage hierarchy, and Section A.4 \ndescribes the basic concepts of input/output systems. Section A.5 briefly discusses \nthe role and characteristics of networks in modern computing. We then give a more \ndetailed picture of typical computer system components in Section A.6. Finally, \n Section A.7 provides a summary. \n Overview of Computer System \nand Architecture Concepts \n",
        "category": "Category"
    },
    {
        "id": "231",
        "title": "Title for Chunk 231",
        "content": "484 \nAppendix Overview of Computer System and Architecture Concepts\n A.1 TYPICAL COMPUTER SYSTEM COMPONENTS \n Computer systems vary widely, based on their functionality and expected use. They \ninclude the following types of systems:\n Personal desktop and notebook computers that are typically utilized by a \nsingle user at a time. \n Large  server  computers that provide services to hundreds or thousands \nof users each day. These include Internet  Web servers  that store Web \ndocuments,  database servers that store large databases,  file servers that \nstore and manage files for a network of computers, and application servers \nthat run some specific application that provides a remotely accessed \nservice.  \n Embedded computer systems, which are used in automobiles, aircraft, \ntelephones, calculators, appliances, media players, game consoles, computer \nnetwork units, and many other such devices. As CPU chips have become \ncheaper and cheaper we see them in more and more places. In the future we \nwill see them in places that might be hard to imagine today. \n Mobile wearable devices, cell phones, and PDAs (personal digital assistants) \nthat are used for keeping appointment calendars, email, phone directories, \nand other information. Today these units are becoming hard to distinguish \nfrom personal computers as they become more and more powerful. \n Hence, it is difficult to decide what a typical computer system would look like. How-\never, it is traditionally accepted that most computer systems have three major com-\nponents, as illustrated in  Figure A.1 . These are the processor or central processing \nunit, the memory unit, and the input/output units. 1 In addition to the three major \ncomponents, network devices connect computer systems together and allow sharing \nof information and programs. Let us briefly describe the main functionality of each \nof these units. \n The  central processing unit (or  CPU ) is the circuitry that performs the com-\nputation and control logic required by a computer system. The  memory  is the com-\nponent that stores both the data required by a computation and the actual commands \nthat perform the computation. Memory is often organized into several levels, lead-\ning to a  storage hierarchy of different types of storage devices, as we describe in \nSection A.3. The class of  input/output (or  I/O ) units include two broad subclasses \nof devices based on their major functionality: input and output. Some devices can \nalso be used for both input and output.  Input devices  are used to load data and pro-\ngram instructions into the memory unit from devices such as CD-ROMs or disks. \nThey are also used to process input commands from a user through devices such \nas a keyboard or pointing device (e.g., a mouse or touchpad).  Output devices are \nused to display data and information to the user through devices such as printers or \n1 At a more detailed level, the CPU is sometimes separated into two components: the control unit and the \ndata path unit, as we discuss in the next section. Similarly, the input/output unit is sometimes separated \ninto input devices and output devices. \n",
        "category": "Category"
    },
    {
        "id": "232",
        "title": "Title for Chunk 232",
        "content": " \nAppendix Overview of Computer System and Architecture Concepts \n485\nvideo monitors, and to store data and programs on secondary storage devices such \nas  various types of disks. Devices such as hard disk drives and CD-RW drives are \nused for  both input and output, and hence are classified as  input/output devices. \nNetwork devices can be considered as input/output devices but they are so special \nthat they are best regarded as being something separate. \n Disk devices in general (hard disk, floppy disk, CD, etc.) are considered as I/O \ndevices if we consider a low-level hardware view of the computer system. If we take \na more conceptual view of the roles they play, which is to store data and programs, \nthen they can also be considered as part of the storage hierarchy of the computer \nsystem, as we discuss in Section A.3. \n Another crucial component in many modern computer systems is the  network, \nwhich is the hardware and software that allows the millions of computers and network \ndevices in existence to communicate with one another. Networks can be formed from \nphone lines, fiber optic and other types of cables, satellites, wireless hubs, infrared \ndevices, and other components. At the individual machine level, though, it is some-\ntimes useful to consider the network as another type of input/output device, because \nits main functionality is to transfer data (such as files, text, pictures, commands, etc.) \nfrom one machine (as output) to another machine (as input). For computer users, the \nInternet is the most visible example of a network. \n The following three sections discuss each of the three main computer system \ncomponents\u2014processor, memory, and input/output\u2014in more detail. The network is \ndiscussed in Section A.5. \n A.2 THE PROCESSOR OR CENTRAL PROCESSING UNIT \n As was said before, the central processing unit, or CPU, is the hardware circuitry \nthat performs the various arithmetic and logical operations. Each processor will \nhave a particular  instruction set that defines the operations that can be performed \nby the processor. These typically include integer arithmetic operations, comparison \n FIGURE A.1    \nSimpli\ufb01 ed diagram of \nthe major computer \nsystem components.  \nSystem Buses (transfer data, addresses, control\ncommands)\nCPU\nMain Memory\nInput and Output\nDevices\nVideo\nDisplay\nKeyboard\nHard\nDisk\nNetwork\nConnection\n",
        "category": "Category"
    },
    {
        "id": "233",
        "title": "Title for Chunk 233",
        "content": "Confirming Pages\n486 \nAppendix Overview of Computer System and Architecture Concepts\no perations, transfer operations, control operations, and so on. A processor usually \nhas a set of  registers that hold the operations that are being executed as well as some \nof the data values or  operands needed by these operations.    2 Other operands can be \naccessed directly from memory locations, depending on the design of the instruction \nset. We further elaborate on the use of registers and the types of operands later in this \nsection. \n Instruction sets can vary widely. Some processors are designed based on the \n RISC (reduced instruction set computer) philosophy, where only a few basic instruc-\ntion types are directly implemented in hardware. These instructions are usually \nsimilar to one another in their design. One of the advantages of RISC is to reduce \nhardware complexity by having a limited set of instruction types and hence increase \nthe speed of execution of the instructions. The most common RISC microprocessors \nare the HP Alpha series (no longer being manufactured, but historically significant), \nARM-embedded processors, MIPS, the PIC microcontroller family, the Apple/IBM/\nMotorola PowerPC and related designs, and the Sun Microsystems SPARC family. \n Other processors have a much larger instruction set implemented directly in \nhardware, with a variety of instruction types included in the instruction set. This \napproach is known as  CISC (complex instruction set computer). A RISC proces-\nsor typically has between 30 and 100 different instructions with a fixed instruction \nformat of 32 bits. A CISC processor typically has between 120 and 400 different \ninstructions. Examples of CISC processors are the IBM System/360, DEC VAX, \nDEC PDP-11, the Motorola 68000 family, and Intel x86 architecture\u2013based proces-\nsors and compatible CPUs. \n Most of today\u2019s processors are not completely RISC or completely CISC. The \ntwo are really design philosophies that have evolved toward each other so much that \nthere is no longer a clear distinction between the approaches to increasing perfor-\nmance and efficiency. Chips that use various RISC instruction sets have added more \ninstructions and complexity so that now they are as complex as their CISC counter-\nparts and the debate is mostly among marketing departments. \n A.2.1 Instruction set architecture: The machine language \n The instruction set architecture defines the  machine language of the processor, \nwhich is the set of commands that the processor can directly execute. Each instruc-\ntion is coded as a sequence of bits (a  bit string ) that can be decoded and executed \nby the processor. Instructions are stored in memory, and are typically executed in \nsequential order, except when a specific  transfer of control is specified by some \ntypes of instructions. The instruction bit string is divided into several parts called \n fields. Although instruction formats can vary widely, some of the typical fields are \nthe following: \n The  opcode (operation code) field specifies the particular operation to be \nexecuted. \n2 The registers that store data values can also be considered, at least conceptually, to be the top level of \nthe storage hierarchy (see Section A.3), since they hold data and provide the fastest access time when \naccessed by the executing instructions. Physically they are part of the processor chip. \nelm49810_app_483-510.indd   486\nelm49810_app_483-510.indd   486\n12/29/08   3:08:53 PM\n12/29/08   3:08:53 PM\n",
        "category": "Category"
    },
    {
        "id": "234",
        "title": "Title for Chunk 234",
        "content": "Confirming Pages\n \nAppendix Overview of Computer System and Architecture Concepts \n487\n A  modifier field is sometimes used to distinguish among different operations \nthat have the same opcode and format\u2014for example, integer addition and \nsubtraction. \n The  operand fields specify the data values or addresses that are needed by \neach particular operation. Addresses can be either memory addresses or \nregister addresses. \n There are many different types of operands, and the way to interpret the \nmeaning of each type of operand is called the  addressing mode. We can \ndistinguish between two main types of operands. The first type supplies \na  data value or the  address of a data value needed by the operation. \nThe second type provides the  address of an instruction, and is used for \nchanging the sequence of instruction execution by a  branch or  jump \noperation. \n The most common addressing modes for  data operands are the following:\n Register addressing: The operand specifies a register location where the data \nthat is needed or produced by the operation is stored. \n Immediate addressing: The operand is a direct data value contained in one of \nthe fields of the instruction bit string itself. \n Base register addressing: The operand is stored in a memory location. The \naddress of the memory location is calculated by adding the contents of a \n base register (which contains the address of a reference memory location) \nand a  displacement or  offset. The displacement can be a direct value in the \ninstruction itself, or it could be the value in another register, called an  index \nregister. \n Indirect addressing: The memory address of the data to be used as an operand \nis stored in a register or in another memory location. This is called  indirect \naddressing because instead of pointing to the data to be used in an operation \nthe instruction points to the address of the data, either in memory or in \na register, and that address must first be accessed to get the actual data \naddress needed. \n The most common addressing modes for  instruction address operands are the \nfollowing:\n PC-relative addressing: The memory address of the instruction is calculated \nby adding an offset to the contents of the  PC (program counter)  register, \nwhich holds the address of the next instruction to be executed. As in base \nregister addressing, the offset can be a direct value in the instruction itself, \nor it could be the value in an index register. \n Indirect addressing: The memory address of the instruction is stored in a \nregister or in another memory location. As with indirect data addressing, \ninstead of pointing to the address to be transferred to, the instruction \npoints to the address of the address, either in memory or in a register, \nand that address must first be accessed to get the actual transfer address \nneeded.  \nelm49810_app_483-510.indd   487\nelm49810_app_483-510.indd   487\n12/29/08   3:08:53 PM\n12/29/08   3:08:53 PM\n",
        "category": "Category"
    },
    {
        "id": "235",
        "title": "Title for Chunk 235",
        "content": "Confirming Pages\n488 \nAppendix Overview of Computer System and Architecture Concepts\nInput data value\nRegister A\nInput data value\nRegister B\nResult output data value (sum of input data values)\nRegister C\nRegister C\nOpcode\nRegister A\nInstruction Register\nRegister\nAddress\nRegister\nAddress\nRegister\nAddress\nRegister B\n FIGURE A.2(a)  \nRegister addressing \nfor add operation.\n FIGURE A.2  \n Illustrating some \naddressing modes \nand instruction \nformats. \nFigure A.2(a) illustrates an add operation which places the result of adding the \ncontents of registers A and B into register C. Here the values to be added must first \nbe loaded into registers A and B by previous instructions.\nInstruction Register\nInput data value\nRegister A\nResult output data value (sum of input data values)\nRegister C\nImmediate Operand Value\nOpcode\nRegister A\nRegister\nAddress\nRegister\nAddress\nInput\nDataValue\nRegister C\n FIGURE A.2(b)  \nRegister and \nimmediate \naddressing for add \noperation.\nFigure A.2(b) shows an add operation where one of the operands is an immedi-\nate value stored in the instruction itself. This operation places the result of adding the \ncontents of register A and the immediate operand value into register C.\n Some of these addressing modes are illustrated in  Figure A.2 . \n The type of operation determines how to interpret the operands\u2014whether \nas memory addresses or instruction addresses or direct data values or in some \nother way. RISC processors typically have a limited number of addressing modes, \nwhereas CISC processors typically have a much larger variety of addressing \nmodes. \n We now illustrate some simple instruction formats and their addressing modes \nin  Figure A.2 . \nelm49810_app_483-510.indd   488\nelm49810_app_483-510.indd   488\n12/29/08   3:08:54 PM\n12/29/08   3:08:54 PM\n",
        "category": "Category"
    },
    {
        "id": "236",
        "title": "Title for Chunk 236",
        "content": "Confirming Pages\n \nAppendix Overview of Computer System and Architecture Concepts \n489\nNext instruction to be executed\nMemory Location\nInput reference memory address location\nBase Register\nOpcode\nInstruction Register\nRegister\nAddress\nBase Register\nOffset\nData Value\nImmediate Operand Value\nAddress of\nmemory\nlocation\n+\nFIGURE A.2(d) \nImmediate relative \naddress for jump \noperation.\nFigure A.2(d) shows an unconditional jump operation, which transfers control \nto an instruction other than the next instruction. It calculates the memory address \nof the next instruction based on a base register and an immediate value. The next \ninstruction to be executed is in the memory address calculated by adding the base \nregister contents to the immediate index value stored in the instruction itself.\nInput offset value\nIndex Register\nResult output data value (loaded from memory location)\nRegister A\nData value to be loaded into Register A\nMemory Location\nInput reference memory address location\nBase Register\nOpcode\nRegister A\nInstruction Register\nRegister\nAddress\nRegister\nAddress\nBase Register\nRegister\nAddress\nIndex Register\n+\nAddress \nof \nmemory location\nFIGURE A.2(c) \nBase and index \nregisters for load \noperation.\nFigure A.2(c) illustrates a load operation that places a value from memory \ninto register A. This instruction uses base register addressing mode to calculate the \nmemory address. The values in the base and index registers are added, and their \nresult is used as the memory address whose contents are loaded into the result reg-\nister A.\nelm49810_app_483-510.indd   489\nelm49810_app_483-510.indd   489\n12/29/08   3:08:54 PM\n12/29/08   3:08:54 PM\n",
        "category": "Category"
    },
    {
        "id": "237",
        "title": "Title for Chunk 237",
        "content": "Confirming Pages\n490 \nAppendix Overview of Computer System and Architecture Concepts\nNext instruction to be executed (if branch)\nAddress of next instruction (if no branch)\nOpcode\nInstruction \nRegister\nProgram\nCounter (PC)\nMemory Location\nInput data value\nRegister B\nInput data value\nRegister A\nRegister\nAddress\nRegister A\nRegister B\nOffset\nData Value\nImmediate Operand Value\nAddress \nof \nmemory location\n+\nYes (branch)\nNo (no branch)\n=?\nFIGURE A.2(e) \nProgram counter \nindexed addressing \nfor conditional \nbranch.\nFigure A.2(e) shows a conditional branch-on-equal operation. The instruction \nfirst compares the values in registers A and B. If the values are equal, it transfers \ncontrol to the instruction whose address is calculated by adding the contents of the \nprogram counter register (the next instruction address) to the immediate value in the \ninstruction. Such an instruction can be used to control looping, for example.\nIn addition to different addressing modes\u2014which determine how to  interpret \nan operand location and value\u2014many processors have two execution modes. \nUser mode is used when a user or application program is executing. Supervisory \n(or privileged) mode is used when an OS kernel routine is executing. A special \nregister in the processor determines which execution mode is being used. When \nin user mode, certain safeguards are incorporated during instruction execution. \nFor example, memory protection is enabled in user mode to prohibit the pro-\ngram from accessing memory locations outside of the part of memory allocated \nto the user program. Certain privileged instructions are allowed to execute only \nwhen the system is in supervisory mode\u2014for example, instructions that control \nI/O devices.\n A.2.2 Components of a CPU \n Figure A.3  is a simplified diagram that shows the typical components of a CPU. \nThe  integer ALU  (arithmetic and logic unit) and the  floating point unit  include the \nhardware circuitry that performs instruction set operations. Most regular i nstructions \nare handled by the integer ALU, whereas floating-point arithmetic instructions are \nelm49810_app_483-510.indd   490\nelm49810_app_483-510.indd   490\n12/29/08   3:08:55 PM\n12/29/08   3:08:55 PM\n",
        "category": "Category"
    },
    {
        "id": "238",
        "title": "Title for Chunk 238",
        "content": "Confirming Pages\n \nAppendix Overview of Computer System and Architecture Concepts \n491\nhandled by the floating point unit, since such operations require more complex, \nhighly specialized circuitry. The  control unit usually includes the processor regis-\nters, as well as circuitry for controlling the sequencing of instruction execution, the \ninterpretation of instruction codes and operands, and the execution of instructions \nusing the ALU or floating point unit circuitry. \n The  processor cache shown in  Figure A.3  is a memory component that is part \nof the processor chip, and holds instructions and data from main memory that are \nbeing used by the processor. (There may be other cache memories outside the CPU \nchip itself.) The cache is connected to main memory via a separate  memory bus. The \nmain memory is also connected to a main  system bus. The control unit is connected \nto the I/O devices through the system bus as well. Another component is a  DMA \n(direct memory access) controller. It allows for transfer of data directly from I/O \ndevices to memory. We discuss the idea of caching in some detail in Section A.3.2 \nand covered DMA in Chapter 14. \n A.2.3 Programs: Source, object, and executable \n An  assembly language is an alternate form of the machine language instructions \nthat is easier to read (and write) by humans. In assembly language, each possible \nopcode is given a  mnemonic name \u2014a symbolic name to identify the instruction. \nThe operands are shown as numbers or are also given names to identify program \nvariables that are mapped to a memory address or register. A program that is writ-\nten in a high-level programming language such as C++ (called the  source code ) \nis converted into a program in machine language (called the  object code ) by the \nprogramming language  compiler. Such an object code program is then linked \nwith other needed object code programs from program libraries and other pro-\ngram modules, creating an  executable code program file. This is usually stored on \ndisk as a binary file, and hence is sometimes called the  program binary (or  bin ) \nfile. The executable code is loaded into memory when needed, and the program \ninstructions are executed in the desired sequence by the processor. \nInteger\nALU\nCPU\nFloating\nPoint\nUnit\nProcessor\nCache\nI/O\nControllers\nControl\nUnit\nSystem\nBus\nMain Memory\nDMA\nController\nFIGURE A.3 \nSimpli\ufb01 ed diagram \nof typical CPU \ncomponents.\nelm49810_app_483-510.indd   491\nelm49810_app_483-510.indd   491\n12/29/08   3:08:55 PM\n12/29/08   3:08:55 PM\n",
        "category": "Category"
    },
    {
        "id": "239",
        "title": "Title for Chunk 239",
        "content": "Confirming Pages\n492 \nAppendix Overview of Computer System and Architecture Concepts\n Good programming language compilers should take advantage of the machine \ninstruction set available when creating the object code. Hence, programmers who \nwrite compilers must study the instruction set architecture of each machine in detail \nin order to fully utilize its capabilities. \n A.2.4 Processor registers, data path, and control \n There are several types of registers that are part of the CPU. They are used by the \nprocessor circuitry in various ways. Some processors use  general-purpose registers, \nwhere the same physical register may be used in many or all of the ways discussed \nbelow. In other processor designs some or all of the registers are  special-purpose \nregisters and can only be utilized for specific functions. The following are the most \ncommon uses of registers: \n Instruction registers: These registers are used to hold the instructions that \nare being executed. They are directly connected to the control circuitry that \ninterprets the opcode and operands when executing an instruction. \n Program counter: Also known as the  instruction counter, this register holds \nthe address of the next instruction to be executed. It is initialized to the \naddress of the first program instruction when the program is loaded into \nmemory and is to start execution. The length of the current instruction is \nnormally added to this register as the instruction is executed in order to \nfetch the next sequential instruction. Of course, branching or subroutine \ncalls or other transfer of control may alter that sequence. \n Data registers: These registers hold operands. Some data registers may be \ndedicated to hold operands of a certain data type; for example, a floating-\npoint register could only hold a floating-point operand. Small CPUs may \nhave only one main data register, typically called an  accumulator. In some \nsuch cases there will be an additional register used for larger operands or \nremainders of division operations and generically called an  accumulator \nextension register. \n Address registers: These hold values of main memory addresses where \noperands or instructions are stored. They may hold absolute memory \naddresses, or relative memory addresses (offsets) that are added to a value in \na  base register to calculate an absolute address. Registers that hold relative \naddresses are called  index registers. \n Interrupt registers: These hold information about interrupt events that may \nhave occurred, as we discuss shortly. \n Program status registers: These hold control information needed by the \nCPU. Different machines may have any number of status registers and the \ncontents vary wildly. Examples of the sort of control information that they \nhold include the following:\n \ufffd Results of the last comparison operation (i.e., a > b, a = b or a < b) \n \ufffd Processor status (i.e., whether it is in user or supervisory mode) \n \ufffd Error status such as arithmetic overflow, divide by zero, etc. \nelm49810_app_483-510.indd   492\nelm49810_app_483-510.indd   492\n12/29/08   3:08:56 PM\n12/29/08   3:08:56 PM\n",
        "category": "Category"
    },
    {
        "id": "240",
        "title": "Title for Chunk 240",
        "content": "Confirming Pages\n \nAppendix Overview of Computer System and Architecture Concepts \n493\n Clock: The clock register is actually a timer that counts down to zero and causes \nan interrupt. This is known as a  clock or  timer interrupt, and can be set \nby the OS for various reasons. For example, in a multiuser system, the OS \ntypically gives control to a user program for a limited amount of time known \nas the  time quantum.  By setting a timer interrupt, the OS can interrupt the \nuser program if it is still running at the end of the time quantum and check \nto see if other programs are waiting to run on the processor. This interrupt \nmay also be used to compute the actual date and time. A CPU usually has a \nprivileged instruction that can only be executed by the OS to load a value into \nthe clock register so that a user program cannot override the OS clock value.  \n Some registers can be set by user programs, and hence are known as  user- visible \nregisters. These usually include data, address, and instruction registers. Other reg-\nisters can only be set by the processor or the OS kernel, such as status and interrupt \nregisters. RISC processors typically have a large number of general-purpose regis-\nters because of their uniform instruction set design, whereas CISC processors often \nhave both general-purpose and special-purpose registers. Some types of register use \nmay require special-purpose registers; for example, interrupt registers, program sta-\ntus registers, and instruction registers. \n The circuitry to identify the particular instruction (from the opcode) and to exe-\ncute the instruction using the operands is connected to the instruction register. Since \ninstruction execution involves the transfer of information (opcode, operands, etc.) \nfrom registers and memory through the hardware circuitry, it is sometimes referred \nto as the  data path component of the processor. On the other hand, the circuitry that \ncontrols the fetching of the next instruction and handling of other events such as \ninterrupts (see below) is referred to as the  control component of the processor. \n A.2.5 System timing \n Another important component within each processor is the  system clock.  The opera-\ntion of most logic circuits proceeds in synchronized steps. At the electronic level this \nis known as a system clock. (This should not be confused with the CPU register that \nis used by the OS for timing.) A system  clock cycle is the fixed shortest time interval \nduring which a processor action can occur. The speed of a processor is determined by \nhow many cycles per second are generated by the system clock. A one-Gigacycle pro-\ncessor will have one billion clock cycles per second. The processor technology and the \ninstruction set design are major factors that determine overall processor speed, because \nsimple instructions take fewer clock cycles to complete than do complex instructions. \nThat is considered one advantage of RISC machines, since the RISC instructions typi-\ncally execute in a smaller number of clock cycles than will CISC instructions. \n A.2.6 Instruction execution cycle and pipelining \n It is customary to divide a typical instruction execution cycle into the following five \nphases: \n Instruction Fetch: The instruction is fetched from memory into an instruction \nregister. \nelm49810_app_483-510.indd   493\nelm49810_app_483-510.indd   493\n12/29/08   3:08:57 PM\n12/29/08   3:08:57 PM\n",
        "category": "Category"
    },
    {
        "id": "241",
        "title": "Title for Chunk 241",
        "content": "Confirming Pages\n494 \nAppendix Overview of Computer System and Architecture Concepts\n Decode: The opcode is decoded and the input operand locations are \ndetermined. \n Data Fetch: The operands are fetched from memory if necessary. \n Execute: The operation is executed. \n Write-back: The operation output results are stored in the appropriate \nlocations. \n Note that the instruction or the operands may be in a cache memory instead of the \nprimary memory. For many simple instructions, each phase typically takes one clock \ncycle, although this may differ depending on the CPU, the type of instruction, and the \naddressing modes for the operands. A simple instruction would thus take five clock \ncycles from start to finish. In order to speed up program execution, most modern \nprocessors employ a strategy called  pipelining, where successive instructions over-\nlap their execution phases. For example, while one instruction is in its write-back \nphase, the next instruction would be in its execute phase, the following one in its data \nfetch phase, and so forth. This would work as long as all instructions are executed in \nsequential order so that their order of execution is known in advance by the processor. \nA speedup of instruction processing by a factor of five would be realized in this case. \n A pipelining processor would have to include provisions for instructions that \nchange the order of execution, such as  branch and  jump instructions. A jump will \nterminate one execution pipeline and start another at a different instruction loca-\ntion. Instructions that have gone through some steps of their execution cycle may \nhave to be cancelled (undone) if a branch is determined after their execution cycle \nis started. It is also sometimes necessary to delay the pipeline if an instruction needs \nas its input an operand that is being produced by the previous instruction. Hence, the \nspeedup actually achieved by pipelining must be estimated by averaging the speedup \nachieved by many different programs. \n A.2.7 Interrupts \n An important functionality included in the processor is the  interrupt. This is par-\nticularly relevant to OSs, which use interrupts in various ways, as we see throughout \nthis book. An interrupt is usually an  asynchronous event, which is an event that can \noccur at any time, and is hence not synchronized with the system clock and with \nprocessor instruction execution cycle. The interrupt signals to the processor that it \nneeds to handle a high-priority event. The processor hardware typically includes one \nor more  interrupt registers, which are set by the interrupting event. \n Whenever an instruction finishes executing, the control circuitry automati-\ncally checks to see whether any event has placed a value in an interrupt register. \nHence, interrupts cannot be serviced  during instruction execution \u2014only between \ninstructions. 3 If so, the  processor state \u2014which includes the contents of the pro-\ngram counter and any registers that will be used during interrupt processing\u2014is \nsaved into memory and a jump to execute the program code that handles interrupts is \n 3 When pipelining is used, interrupts may be checked whenever an instruction completes its execution \ncycle. Provisions for undoing partially executed subsequent instructions by the processor would be needed. \nelm49810_app_483-510.indd   494\nelm49810_app_483-510.indd   494\n12/29/08   3:08:57 PM\n12/29/08   3:08:57 PM\n",
        "category": "Category"
    },
    {
        "id": "242",
        "title": "Title for Chunk 242",
        "content": "Confirming Pages\n \nAppendix Overview of Computer System and Architecture Concepts \n495\np erformed. Once the interrupt handler is done, the system will normally restore the \nprocessor state and resume processing the user program from the point at which it \nwas interrupted. The OS may switch to run another program if the interrupt caused \nthe current program to be terminated or suspended. \n While processing an interrupt, it is usually the case that lower priority or less \nimportant interrupts are disabled until interrupt handling is completed. The OS does \nthis by setting an  interrupt disable (or  interrupt mask ) register. Depending on the \nvalue in that register the system will not check for interrupts for lower priority inter-\nrupt levels. Hence, the OS can set this register before starting interrupt processing, \nand reset it back after completing the interrupt processing. \n We can categorize the events that cause interrupts into hardware events and soft-\nware events. In general, hardware interrupts are asynchronous and software inter-\nrupts are synchronous. Typical of the  hardware events that can cause interrupts are \nthe following: \n Some I/O user action has occurred, such as mouse movement or mouse \nbutton click or keyboard input. The interrupt handler would retrieve the \ninformation about the I/O action, such as mouse coordinates or which \ncharacter was input from the keyboard. \n A disk I/O transfer was completed. The interrupt handler would check to see if \nother disk I/O operations were pending, and if so initiate the next disk I/O \ntransfer to or from main memory. \n A clock timer interrupt has occurred, which allows the OS to allocate the CPU \nto another program. \n The  software events that can cause interrupts may be further categorized into  traps, \nwhich occur when a program error or violation happens, and  system calls, which \noccur when a program requests services from the OS. (For historical reasons a sys-\ntem call interrupt is sometimes called a trap\u2014somewhat confusing.) Some events \nthat cause traps are the following: \n A memory protection violation, for example, a program executing in user mode \ntries to access an area of memory outside of its allowed memory space. \n An instruction protection violation, for example, a program executing in user \nmode attempts to execute an instruction reserved for supervisor mode. \n An instruction error such as division by zero. \n An arithmetic error such as a floating point overflow. \n We discuss in detail how these events and other events that cause interrupts are han-\ndled by the OS throughout this book. \n A.2.8 Microprogramming \n In some computers complex instructions are implemented as sequences of basic \ninstructions, often using the concept of  microprogramming. A microprogram \nis a sequence of basic operations that implement a more complex operation. This \nsequence is stored in a special microprogram memory in the processor, so that it \nelm49810_app_483-510.indd   495\nelm49810_app_483-510.indd   495\n12/29/08   3:08:58 PM\n12/29/08   3:08:58 PM\n",
        "category": "Category"
    },
    {
        "id": "243",
        "title": "Title for Chunk 243",
        "content": "496 \nAppendix Overview of Computer System and Architecture Concepts\ncan be invoked when the complex instruction is to be executed. The microprograms \nare sometimes referred to as  firmware. Some CPU architectures, usually CISC, use \nmicroprogramming while others do not. \n A.2.9 Processor chip \n Historically the CPU was built out of discrete components such as relays, tubes, tran-\nsistors, or simple integrated circuits. In modern systems the whole processor is typi-\ncally implemented as a single integrated circuit (chip). The  processor chip includes \nthe CPU, clock, registers, cache memory, and perhaps other circuitry depending on \nthe particular processor design. \n A.2.10 Multicore chips \n In the last few years the manufacturers of CPU integrated circuits have concluded \nthat the demand for ever faster CPUs is slacking off somewhat. They have begun \nto use the extra space on the chips to provide multiple CPUs in the package. There \nare various alternative designs regarding placement of cache memories, etc. We talk \nabout these caches in the next section. Although this would appear to be a fairly \ntrivial change, we see in the chapters on memory that it is not at all trivial for the OS. \nAt the present time chips with four CPU cores are fairly common. Predictions call \nfor up to 128 cores in the next few years. \n It is difficult to write a program that can effectively use multiple CPUs at the \nsame time. But most users have many programs running at the same time and having \nmultiple CPUs to run them on will mean that they will all run faster. Furthermore, \nmost users use only a few programs, and they are ones that have been highly devel-\noped and are prepared to use the multiple CPUs. Such programs include most of the \nprograms we use the most\u2014word processors, spreadsheets, browsers, and so on. \n A.3 THE MEMORY UNIT AND STORAGE HIERARCHIES \n A.3.1 Storage units: Bits, bytes, and words \n The memory unit is the hardware that stores the program instructions and oper-\nands that are needed by the processor. The basic physical storage unit is a single \n bit, which stores a binary zero (0) or one (1) value. In modern systems, bits are \ngrouped into  bytes (8 bits), and bytes are grouped into  words (typically 4 bytes \nor 8 bytes, though CPUs designed for embedded systems may have 1- or 2-byte \nwords). Normally, the basic unit that will be transferred between the memory unit \nand the processor is a word. Typically there will be instructions that will allow load-\ning or storing of a single byte or half word. In most systems each byte has a unique \n memory address. Given a particular memory address, the memory circuitry can \nlocate that particular byte in memory. The word containing this byte can then be \ntransferred to or from the processor. Memory bytes or words can also be transferred \nto or from input/output devices. In many cases, blocks of multiple words are trans-\nferred directly. \n",
        "category": "Category"
    },
    {
        "id": "244",
        "title": "Title for Chunk 244",
        "content": "Confirming Pages\n \nAppendix Overview of Computer System and Architecture Concepts \n497\n The word size is usually the standard size for processor registers. A 32-bit pro-\ncessor thus will have standard data items of 32 bits, or 4 bytes. On the other hand, \n16-bit processors would have 16-bit data formats as many older PC processors had. \nSome processors have a 64-bit \u201cdouble word\u201d data size. At one time this was mostly \nfound in large mainframe computers. Most processors currently are of the 32-bit \nvariety, but today\u2019s PCs are switching to a 64-bit format. The size of many operands \nis also one word size (4 bytes), although some operands can be a single byte or 2 \nbytes or 8 bytes. The particular opcode will determine the type and size of each \noperand. \n As the basic data word size has increased from 16 to 64 bits, the instruction \nformats have also increased in size, mainly so that larger memory addresses can be \nused. Instructions in CISC machines tend to be variable length since it takes only \na few bits to specify a register but many to specify a memory address. Depending \non the addressing mode, instructions specify anywhere from none to three memory \naddresses, so the instruction lengths will vary accordingly. \n A.3.2 A storage hierarchy \n Most current systems have several levels of storage, often referred to as the  storage \nhierarchy. This is illustrated in  Figure A.4 . The traditional view of a storage hier-\narchy has three levels: primary, secondary, and tertiary storage. We discuss each of \nthese next. \n Primary storage consists of main memory and usually one or more cache memo-\nries. Even the processor registers are sometimes considered to be part of the main \nmemory storage hierarchy. Hence, within primary storage, there can be several lev-\nels. If we consider the processor  registers to be part of the memory hierarchy, they \nwould be at the top level. At the next level is a high-speed low-capacity  cache mem-\nory, which is usually included as part of the processor chip itself. There may be addi-\ntional cache memories outside of the main CPU chip, each slower but larger than the \nprevious level. At a still lower level, a lower-speed but higher-capacity  main mem-\nory is included on one or more separate chips. The cache memory typically uses a \nFIGURE A.4 \nA storage hierarchy.\nRegisters\nCache Memory (first and second level)\nMain Memory\nPrimary\nStorage\nHard Disk\nFlash Memory\nSeconday\nStorage\nRemovable Floppy and Zip Disks\nCD-ROMs and DVDs\nMagnetic Tapes\nTertiary\nStorage\nelm49810_app_483-510.indd   497\nelm49810_app_483-510.indd   497\n12/29/08   3:08:59 PM\n12/29/08   3:08:59 PM\n",
        "category": "Category"
    },
    {
        "id": "245",
        "title": "Title for Chunk 245",
        "content": "Confirming Pages\n498 \nAppendix Overview of Computer System and Architecture Concepts\nh ardware technology known as SRAM (static random access memory), whereas the \nmain memory typically uses DRAM (dynamic random access memory) technology. \nSRAM technology is faster but more expensive than DRAM per unit of storage. 4  \n Processor registers are faster to read or write than cache memory or main mem-\nory locations. For example, a register-to-register copy may take a single clock cycle \nin a RISC processor, whereas a register-to-cache transfer may take two clock cycles, \nand a register-to-memory transfer might take three or four clock cycles. \n The cache memory is often divided into two parts: the  data cache (for storing \noperands) and the  instruction cache (for storing instructions). In some cases there \nare distinct cache parts for applications in user mode and the kernel in supervisor \nmode. Transfer of bytes between the cache and processor is several times faster than \nthat between the main memory and the cache. Hence, the goal is to keep in the cache \nthe data and instructions currently being used. This job is the responsibility of the \ncache management circuitry in the processor, but program design can affect the abil-\nity of the hardware to cache the needed instructions and data. \n Memory capacity is usually measured in Kilobytes (KB or 1,024 bytes), Mega-\nbytes (MB or 1,048,576 bytes), Gigabytes (GB or 1,073,741,824 bytes), and even \nTerabytes (TB or 1,099,511,627,776 bytes). Since cache is more expensive than main \nmemory it has a much smaller capacity. Many processors have two caches: a level-1 \nor  L1 cache on the processor chip and an external level-2 or  L2 cache outside the \nprocessor. A few processors have a third  L3 cache that is also outside the CPU. The \nhigher-level caches are faster than the lower-level caches but are more expensive and \nhold less information. \n The  memory bus is the hardware component that handles the transfer of data \nbetween main memory (on the memory chip) and cache memory (on the processor \nchip). Cache memory sizes often are in the 64-KB to several Megabyte range, whereas \nmain memory capacity is typically in the 32-MB to 4-GB range. These numbers con-\ntinue to grow rapidly, though. \n A.3.3 Secondary storage: Hard disk \n The next level in the storage hierarchy is typically a  magnetic disk hard-drive stor-\nage component or simply  hard disk, which is slower than main memory but has a \nmuch higher capacity and lower cost per Megabyte. Hard disk capacity typically \nranges between 10-GB to 1-TB or higher, but again these numbers continue to grow \nrapidly. A hard disk is a part of most standalone computer systems, but is often not \nincluded in embedded systems that are used in various devices such as PDAs, music \nplayers, telephones, cars, home appliances, and so on. Traditionally, the registers, \ncache memories, and main memory together are referred to as  primary storage, \nwhereas the hard disk is referred to as  secondary storage. Every system must have \na primary storage component. \n An important distinction between primary and secondary storage is called  stor-\nage volatility. In a  volatile memory,  memory content is lost when electric power \n 4 Memory, processor, and disk technologies are always changing, so newer technologies may come in \nuse at any time. We will not discuss further how different types of memories are actually built at the \nhardware level, since this is not directly relevant to our presentation. \nelm49810_app_483-510.indd   498\nelm49810_app_483-510.indd   498\n12/29/08   3:08:59 PM\n12/29/08   3:08:59 PM\n",
        "category": "Category"
    },
    {
        "id": "246",
        "title": "Title for Chunk 246",
        "content": "Confirming Pages\n \nAppendix Overview of Computer System and Architecture Concepts \n499\nis turned off. In  nonvolatile memory, content is not lost when power is turned off. \nMost main memory systems are volatile, whereas most secondary storage systems \nare nonvolatile. Hence, the disk also serves as a backup storage medium in case of \nsystem crashes due to power failure. 5  \n At the hardware level, transfer of data between primary and secondary storage \ninvolves an I/O device controller, which we discuss in Section A.4. Device control-\nlers often have a storage component to hold data being transferred between the disks \nand main memory. This storage component is called the  disk cache or  controller \ncache. \n This cache is needed because the controller typically has its own processor and \nclock that are not synchronized with the clock of the CPU. Once the CPU initiates a \ntransfer operation, it leaves the actual control of the transfer to the I/O controller\u2014\nwhile the CPU continues with program execution. Hence, main memory is being \naccessed by both the CPU and the device controllers. Because requests to access \nmemory by the CPU are given higher priority, memory access by the controller may \nbe delayed. The controller cache prevents the loss of data because of such delays \nby acting as a buffer storage when transferring data from disks and other second-\nary storage devices to main memory. Controller caches also exist in I/O controllers \nfor some types of tertiary storage devices such as floppy disks and CDs, which we \ndescribe next. This type of data transfer between an I/O controller and main memory \nmay make use of DMA technology (direct memory access), which we discussed in \nChapter 14. \n A.3.4 Tertiary and offline storage: Removable discs and tapes \n Additional levels of the storage hierarchy exist in many computer systems, such as \nvarious types of magnetic tape storage for backup, sometimes referred to as tertiary \nstorage or offline storage. In addition, various types of rotating memories (floppy \ndisk, CD-ROM, CD-RW, DVD, etc.)  6 are used as storage media to hold informa-\ntion. The information stored on removable media is generally either too large to fit \non secondary storage or is not usually needed frequently or immediately, so it is not \npermanently kept on the hard disk. So this data is not usually available within the \ncomputer system as is the case with cache memory, main memory, and hard disk, \nwhich are referred to as  online storage because they are available as soon as the \ncomputer system is turned on. \n Removable media units can be automated so that the drive can select from among \nmany individual media that are inserted into the drive. Examples include automated \ntape libraries or optical disc jukeboxes. In this case they are properly referred to as \n tertiary storage. Removable media storage units that are not automated are usually \ncalled  offline storage, because the storage media (floppy disk, DVD, CD-ROM, tape) \nmust be manually loaded before the data on the media can be accessed. Tertiary and \noffline storage devices can also be viewed as input/output devices (see Section A.4). \n 5 Historically, main memories were not necessarily volatile. Magnetic core primary memory in particular \nwould retain its contents even with the power turned off. \n 6 CD-ROM stands for compact disc-read only memory; CD-RW stands for compact disc-read write; and \nDVD stands for digital video disc. \nelm49810_app_483-510.indd   499\nelm49810_app_483-510.indd   499\n12/29/08   3:09:00 PM\n12/29/08   3:09:00 PM\n",
        "category": "Category"
    },
    {
        "id": "247",
        "title": "Title for Chunk 247",
        "content": "Confirming Pages\n500 \nAppendix Overview of Computer System and Architecture Concepts\n A.3.5 Managing the storage hierarchy \n Transfer between the various levels of the storage hierarchy is usually done in units \nof multiple bytes or  blocks of bytes. The block size between main memory and cache \nmemory is typically in the range of 16 bytes (four words) to 256 bytes (64 words), \nwhereas the block size between hard disk and main memory is typically in the 4-KB \nto 16-KB range or even higher. The main reason for transferring blocks instead of \nsingle bytes or single words is to improve performance by reducing overall transfer \ntime. Especially with tapes there is a large overhead to start and stop the tape move-\nment. So transferring larger blocks with each read or write is much more efficient \nthan transferring smaller blocks. Similarly, positioning a tape or disk to access the \nneeded information is quite slow. Transferring more data at one time means that \nfewer such positioning operations are needed. \n Performance is also improved by taking advantage of the  locality principle, \nwhich states that programs tend to access a small portion of their instructions and \noperands in any short time interval. This locality characteristic has been shown to \nexist in most programs, and has two components: \n Temporal locality: This characteristic states that a program that accesses \ncertain memory addresses may soon access them again. An example is that \ninstructions within a loop may be accessed repeatedly within a short period \nof time. \n Spatial locality: This characteristic states that if a program accesses certain \nmemory addresses, it may soon access other words that are stored nearby. \nFor example, instructions are typically stored and accessed sequentially. \nAnother example is that a program may process operands (data) that are \nstored consecutively\u2014for example, accessing consecutive array elements or \nsequentially scanning through a block of text that is being edited. \n If multiple words that are stored in spatial proximity in a block are loaded into cache \nmemory, then access to subsequent words when needed will be quite fast since they \nwill already be in the cache. These are known as  cache hits. On the other hand, if \nthese subsequent words are never accessed, the cost of loading them into the cache \nwill be wasted. When instructions or operands are referenced that are not in cache \nmemory, the system will try to locate them in main memory and transfer them to the \ncache. These are known as a  cache misses. \n If the words that caused a cache miss are not in main memory, they have to be \nlocated on hard disk and transferred to main memory, and the needed part is then \ntransferred to cache. Hence, it is necessary to find an appropriate block size that \nreduces the access cost per unit of storage. Generally, the cost of transferring  n con-\nsecutive bytes or words between one level and the next in a single transfer is much \nlower than transferring them using multiple transfers. This is particularly true for \ntransfer between hard disk and main memory, and is also true to a lesser extent for \ntransfer between main memory and cache memory. As we will see, a major part of \nthe memory management component of an OS is to attempt to optimize these types \nof transfers. In general, the OS handles transfers between hard disk and primary \nmemory, and the CPU hardware handles memory-to-cache transfers. \nelm49810_app_483-510.indd   500\nelm49810_app_483-510.indd   500\n12/29/08   3:09:01 PM\n12/29/08   3:09:01 PM\n",
        "category": "Category"
    },
    {
        "id": "248",
        "title": "Title for Chunk 248",
        "content": "Confirming Pages\n \nAppendix Overview of Computer System and Architecture Concepts \n501\n A.3.6 Memory protection \n Another aspect of main memory that is particularly relevant to OSs is the memory \nprotection component. When an executing program references a memory location, \nthe OS needs to make sure that this location is part of the  address space for that \nprogram. It should not allow an application program to make references to memory \nlocations that are being used by other programs or by the OS itself. This protects the \nOS and other user programs and data from being corrupted by an erroneous or mali-\ncious program. \n One technique for memory protection is to use a pair of registers, the  base reg-\nister and  limit register. This is illustrated in  Figure A.5 . Before a program starts \nexecution, the OS sets those registers to delimit the addresses in memory that contain \nthe program address space. Setting the contents of the base and limit registers are \nprivileged instructions that can only be used when the CPU is in supervisory mode \nin the OS kernel. Once the OS sets the execution mode to user mode and transfers \ncontrol to the user program, the base and limit registers cannot be changed. Any \nreference to memory locations outside this range causes a hardware interrupt that \nindicates an invalid memory reference. The OS will reset the base and limit registers \nwhenever it transfers execution to another program. \n In many modern systems a more complex scheme is used. Memory is divided \ninto equal-sized  memory pages. Typical memory page sizes range from 512 bytes to \n4 KB. This technique uses  page tables, which are data structures that refer to the par-\nticular memory pages that can be accessed by the executing user program. Only those \nmemory locations referenced through the page table are accessible to the program. \nThe page table is implemented through hardware support in the processor itself. The \ncommands to load the contents of the page table would be privileged instructions that \ncan only be executed by the OS in supervisory mode in the kernel. We discussed this \nand other memory protection techniques in detail in Chapters 10 and 11. \nFIGURE A.5 \nA memory protection \nmechanism using \nbase and limit \nregisters.\nUnused space\nOperating system\nmemory address space\nUnused space\nUnused space\nProgram 1 address space\nProgram 2 address space\n(executing program)\nProgram 3 address space\nLimit Register\nBase Register\nelm49810_app_483-510.indd   501\nelm49810_app_483-510.indd   501\n12/29/08   3:09:01 PM\n12/29/08   3:09:01 PM\n",
        "category": "Category"
    },
    {
        "id": "249",
        "title": "Title for Chunk 249",
        "content": "502 \nAppendix Overview of Computer System and Architecture Concepts\n A.4 INPUT AND OUTPUT\n The input and output systems are the components that connect the main memory and \nthe processor to other devices. These are sometimes called  I/O devices or  periph-\neral devices. \n A.4.1 Types of I/O devices \n I/O devices can be divided into four broad categories: user interface devices, storage \ndevices, network devices, and devices that the computer is controlling. \n User interface I/O devices: These are employed for user interaction with \nthe computer system. Devices for direct interaction between a user and a \nsystem include keyboards, pointing devices (such as mouse, trackball, touch \nscreen, or pad), joysticks, microphones (voice or sound input), other similar \ncomponents for  input, and video monitors, speakers (voice or sound output), \nand the like for  output. Other I/O devices allow indirect interaction, such \nas digital cameras and scanners for video or image input, and printers and \nplotters for hard copy or film output. \n Storage I/O devices: These are used for  storing information and hence are \nconsidered as both input/output devices and as part of the storage hierarchy. \nThey include magnetic disks (hard or floppy), optical discs/DVD, magnetic \ntape, flash memory chips, and so on. \n Network I/O devices: These are devices that connect a computer system to \na network, and include analog telephone modems, DSL (digital subscriber \nline) connections, cable modems, and wired cables. In addition, wireless \nconnections such as infrared or Bluetooth are becoming quite common. \nThey may use a wireless network card installed in a computer or device to \nconnect to a wireless hub, which in turn connects to the network, or they \nmay connect devices directly to a computer. \n Controlled devices: Computers are often used to control noncomputing \ndevices. Examples include motors, heating and air conditioning, light \ndisplays, and so on. Embedded computer systems also fit into this category. \n As we can see, there are a wide variety of I/O devices, and new devices are fre-\nquently being introduced. To deal with this proliferation of I/O devices, efforts \nwere undertaken to standardize single interfaces that can be used with different \ntypes of I/O devices. One such standard is the USB (Universal Serial Bus) 2.0 \nstandard, which allows I/O transmission rates of 480 million bps (bits per second), \nand is hence suitable for connecting everything from keyboards to digital video \ncameras or external disk hard drives. Another standard is IEEE 1394, which also \nallows transmission rates of up to 400 million bps and is used for the same sorts of \ndevices. This interface is also known by two proprietary names, FireWire \u2122 from \nApple and i.Link \u2122 from Sony. FireWire is somewhat more efficient than USB for \nhigher-speed devices and is commonly used for video cameras. It has also been \n",
        "category": "Category"
    },
    {
        "id": "250",
        "title": "Title for Chunk 250",
        "content": "Confirming Pages\n \nAppendix Overview of Computer System and Architecture Concepts \n503\nselected as the standard connection interface for audio/visual component commu-\nnication and control. \n A.4.2 Device controllers and device drivers \n A  device controller is a component that interfaces an I/O device to the computer \nprocessor and memory. Device controllers frequently contain their own processor, \nwhich has a specialized instruction set that is used by device manufacturers to write \nprograms that control the I/O devices. A device controller will also have a  command \nset, which is the set of commands that the OS can send to the controller across one of \nthe system buses to control the I/O device. These commands are generally restricted \nto being used only by OS  device drivers, and are usually not accessible to applica-\ntion or systems programmers. Many device controllers also have a memory compo-\nnent known as controller cache (see Section A.3.3). \n Standard device controllers such as USB and FireWire can be used to connect to \nany type of I/O device that supports the standard. On the other hand, some special-\nized device controllers\u2014such as disk controllers or graphics video controllers\u2014can \nonly connect to a single type of I/O device for which it was designed.  7 The controller \nhandles the interfacing with the I/O device and may use its memory to either buffer \nor cache the data as it is being transferred from or to the computer primary memory. \nThe command set of the controller will include commands that initiate input or out-\nput operations. For example, a hard disk controller would have commands to initi-\nate a read-block command for a particular disk block address, while providing the \naddress of the computer memory buffer that will hold the block.  Figure A.6  is a \nsimplified diagram to illustrate these concepts. \n At the computer side, the OS typically handles all interactions with the device \ncontrollers. As was mentioned, the parts of the OS that interact with the device con-\ntrollers and handle I/O are called the  device drivers. Each device driver will be \nprogrammed to handle the low-level hardware commands and details of a particular \ndevice controller. The device driver will present an abstract and uniform view of the \ndevice to the rest of the OS. \n 7 In some cases, a controller is limited further to a subset of a certain type of device; for example, an \nATA controller only works with ATA disk drives rather than all types of disk drives. Sometimes the \ncontroller will only work with devices from a single manufacturer or even only with a specific model. \nDevice\nDevice Controller\nData and Addresses\nMemory\nData\nAddresses\nDevice Controller\nDevice\nCPU\nFIGURE A.6 \nHow I/O devices \nconnect to memory \nand the CPU through \ndevice controllers.\nelm49810_app_483-510.indd   503\nelm49810_app_483-510.indd   503\n12/29/08   3:09:02 PM\n12/29/08   3:09:02 PM\n",
        "category": "Category"
    },
    {
        "id": "251",
        "title": "Title for Chunk 251",
        "content": "504 \nAppendix Overview of Computer System and Architecture Concepts\n A.4.3 Other categorizations of I/O devices and connections \n There are other ways to categorize I/O devices. One categorization is to divide them \ninto groups based on the type of connection to the computer. I/O devices are typi-\ncally connected to the memory and CPU at the hardware connection level using \neither serial or parallel physical connections (usually cables). A  serial connection \ntransfers bits serially over a single wire, whereas a  parallel connection typically \ntransfers 8 bits (or more) at a time in parallel over multiple wires. Interfaces to sim-\nple I/O devices such as keyboard, mouse, or modem typically use serial connections, \nwhereas higher-speed devices such as some hard disk SCSI (small computer system \ninterface) connections use parallel cables. USB and FireWire controllers use serial \ncables, but the cables are high grade and shielded, and this permits the high data \ntransfer speeds of these controllers. \n Another higher-level categorization of I/O devices is into  block devices that \ntransfer multiple bytes at a time versus  character devices that transfer single \nc haracters or bytes. Disks are a good example of block devices, whereas a keyboard \nis an example of a character device. \n A third categorization is whether the connection is wired through a cable or \nwireless. Wireless connections are being used increasingly to connect portable com-\nputers to the network or to output devices such as printers. \n A.5 THE NETWORK \n Many computers are connected to some kind of network. At an abstract level, one \nmay consider a network connection to be similar to the way that a computer\u2019s CPU \nand memory can be connected to I/O devices. However, the network allows the com-\nputer to be connected to other computers, as well as other devices connected to the \nnetwork. This connectivity allows users to access functions and information on other \ncomputers and to use devices that their own computer does not have. It also allows \nfor exchange of information among processes running on different computers. \n A.5.1 Client-server versus peer-to-peer versus multitier models \n One common way to look at network interaction is through the  client\u2013server model. \nHere, one computer\u2014typically where the user is located\u2014is called the  client. The \nclient can access one or more  server computers to access information or other func-\ntions that the server provides. Servers might include any of the following: \n \ufffd database servers that contain large amounts of information \n \ufffd Web servers that allow the client to access documents on the Internet \n \ufffd printer servers that allow the user to print on various printers \n \ufffd file servers that manage user files \n \ufffd email servers for storing and forwarding email \n \ufffd servers that support application such as word processing or spreadsheets \n Another model for network interaction is the  peer-to-peer model in which the com-\nputers are considered to be equals. For example, the computers could be cooperating \n",
        "category": "Category"
    },
    {
        "id": "252",
        "title": "Title for Chunk 252",
        "content": "Confirming Pages\n \nAppendix Overview of Computer System and Architecture Concepts \n505\ntoward solving a large computing problem that has been designed to run in a distrib-\nuted manner over multiple computers on the network. \n As distributed systems have evolved it has become necessary to have more com-\nplex models than these. Large applications are frequently designed in  multiple tiers. \nIn a typical three-tier design there will be a front-end that is responsible for the user \ninterface, a middle tier that contains the main logic for the application\u2014often called \nthe business rules\u2014and a database tier that is responsible for all the data storage for \nthe application. In Chapter 17 we discussed the reasons why these more complex \narchitectures have evolved. These models are discussed in greater length in Chapter 15 \non networking and Chapters 7 and 17 on distributed processing systems. \n A.5.2 Network controllers, routers, and name servers \n Similar to the manner in which a computer interacts with a device controller that con-\ntrols an I/O device, the CPU and memory connect to a network through a  network \ninterface controller, or  NIC. At the hardware level there are various types of net-\nwork connections of varying speed, and new technologies for connections are being \nintroduced all the time. Some of the common hardware devices and technologies that \nconnect computers to a network are modems, Ethernet, DSL, cable modems, and \nseveral wireless techniques. \n At the Physical level, it is useful to distinguish between two types of connections \nused to build a network: wired and wireless. Hardware for wired networks includes \ncables or optical fibers of different types, network gateways, routers, switches, hubs, \nand other similar components. Wireless network components include satellites, base \nstations for wireless connections, wireless hubs, infrared and Bluetooth ports, and \nso on. \n The network can route a message from its source to its destination through the \nuse of  bridges,  switching devices, or  routers. To manage the complexity it is com-\nmon to divide a network within an organization into subnetworks, each connecting \na small number of computers via a local area network (LAN). These subnetworks \nare connected to one another through local routers, which then connect to a regional \nrouter, which then connects to the rest of the global network through one or more \nadditional Internet routers. \n In the case of the Internet, every computer on the network has a numeric IP \n(Internet protocol) address (such as 192.168.2.1), which uniquely identifies that \ncomputer, and allows the network to route messages addressed to that IP address. \nC omputers also have unique names, such as ourserver.example.com. Specialized \nservers called  domain name servers (DNS) have databases that can find a com-\nputer\u2019s numeric IP address when given its name. The other specialized comput-\ners that connect the network, namely the routers and switching devices, can then \nfind a path through the network to deliver a message to the destination computer \nbased on the numeric IP address or the  media access control ( MAC ) address of \nthe destination. These devices use specific network protocols at various levels to \nphysically deliver the message.  Figure A.7  shows a simplified diagram to illustrate \nthese concepts. The techniques for doing this routing and switching are covered in \nChapter 15.  \nelm49810_app_483-510.indd   505\nelm49810_app_483-510.indd   505\n12/29/08   3:09:03 PM\n12/29/08   3:09:03 PM\n",
        "category": "Category"
    },
    {
        "id": "253",
        "title": "Title for Chunk 253",
        "content": "Confirming Pages\n506 \nAppendix Overview of Computer System and Architecture Concepts\n A.5.3 Types of networks \n We conclude this brief introduction to networks with a traditional characterization of \nthe types of networks. 8 \n Local area networks ( LAN s) are networks that normally connect computers \nwithin a limited geographical area, say a group of offices or one building or a num-\nber of adjacent buildings within an organization. These networks are primarily built \nof cables that run through and between the buildings, possibly with switches or rout-\ners connecting, say, the various networks on each floor or in each cluster of adjacent \noffices. Increasingly, wireless access points are being used that allow the connection \nof a computer with a wireless network card to the local area network. \n Wide area networks ( WAN s), on the other hand, generally refer to networks \nthat connect computers over a large geographical area. These use phone lines, fiber \noptic cables, satellites, and other connections to connect the thousands of local area \nnetworks to one another, and hence to allow global connectivity of computers. \n Mobile networks are made up of thousands of telecommunications towers and \ncontrol systems that operate as fixed base stations, which are then connected to local \nor wide area networks. Mobile devices such as cellular phones or handheld comput-\ners or PDAs can connect to a nearby base station, which connects it to the rest of the \nnetwork, and to other parts of the global network. \n 8 The technical distinction between a LAN and a WAN is somewhat different. See Chapter 15 for details. \nEmail Server\nShared\nPrinter\nLAN\nLAN\nLAN\nDNS\nWAN\nInternet\nRouter\nRouter\nRouter\nFile Server\nClient\nClient\nClient\nWeb\nServer\nFIGURE A.7 \nHow a network \nconnects various \ncomputers.\nelm49810_app_483-510.indd   506\nelm49810_app_483-510.indd   506\n12/29/08   3:09:04 PM\n12/29/08   3:09:04 PM\n",
        "category": "Category"
    },
    {
        "id": "254",
        "title": "Title for Chunk 254",
        "content": " \nAppendix Overview of Computer System and Architecture Concepts \n507\n A.7 SUMMARY \n In this appendix, we gave an overview of the basic \ncomponents of a computer system. We started with \na simple overview and a diagram of typical com-\nputer system components, and concluded with a \nmore detailed\u2014though still simplified\u2014diagram. In \nbetween, we devoted one section to each of the main \ncomponents of modern-day computers: the processor \nor CPU, memory and storage hierarchy, I/O devices, \nand the network. From the discussion, it should be \nclear that there is overlap between these categories. \nFor example, hard disks can be considered as both \nan I/O device or as part of the storage hierarchy, \nand the network interface to a computer can also be \nabstracted to look like I/O devices. However, the tra-\nditional division is useful for structuring our discus-\nsion and presentation of computer systems and OSs. \nFIGURE A.8 A diagram to illustrate a computer system in some additional detail.\nSerial Port\nController\nATA Disk\nController\nUSB\nController\nSCSI\nController\nParallel\nPort\nController\nPrinter\nMouse\nHard Disk\nTape\nCD-ROM/DVD\nGPS\nHard Disk\nVideo Camera\nSystem Buses (transfers data, addresses, control commands)\nCPU\nand\nLevel 1 Cache\nGraphics\nController\nNetwork\nController\nVideo\nMonitor\nDisplay\nNetwork\nLevel 2 Cache\nKeyboard\nController\nKeyboard\nMain\nMemory\n A.6 A MORE DETAILED PICTURE \n We conclude this appendix with  Figure A.8 , which presents a more detailed p icture \nto illustrate how various system components that we discussed throughout this \nappendix are connected to one another. \n",
        "category": "Category"
    },
    {
        "id": "255",
        "title": "Title for Chunk 255",
        "content": "508 \nAppendix Overview of Computer System and Architecture Concepts\n BIBLIOGRAPHY \n Belady, L. A., R. P. Parmelee, and C. A. Scalzi, \u201cThe IBM \nHistory of Memory Management Technology,\u201d  IBM \nJournal of Research and Development, Vol. 25, \nNo. 5, September 1981, pp. 491\u2013503. \n Brown, G. E., et al., \u201cOperating System Enhancement \nthrough Firmware,\u201d  SIGMICRO Newsletter, Vol. 8, \nSeptember 1977, pp. 119\u2013133. \n Bucci, G., G. Neri, and F. Baldassarri, \u201cMP80: A \nMicroprogrammed CPU with a Microcoded \nOperating System Kernel,\u201d  Computer, October 1981, \npp. 81\u201390. \n Chow, F., S. Correll, M. Himelstein, E. Killian, and \nL. Weber, \u201cHow Many Addressing Modes Are \nEnough?\u201d  Proceedings of the Second International \nConference on Architectural Support for \nProgramming Languages and Operating Systems, \nPalo Alto, CA, October 5\u20138, 1987, pp. 117\u2013122. \n Davidson, S., and B. D. Shriver, \u201cAn Overview of \nFirmware Engineering,\u201d  Computer, May 1978, \npp. 21\u201331. \n DeRosa, J., R. Glackemeyer, and T. Knight, \u201cDesign \nand Implementation of the VAX 8600 Pipeline,\u201d \n Computer, Vol. 18, No. 5, May 1985, pp. 38\u201350. \n Elmer-DeWitt, P., and L. Mondi, \u201cHardware, Software, \nVaporware,\u201d  Time, February 3, 1986, p. 51. \n Fenner, J. N., J. A. Schmidt, H. A. Halabi, and \nD. P. Agrawal, \u201cMASCO: The Design of a \nMicroprogrammed Processor,\u201d  Computer, Vol. 18, \nNo. 3, March 1985, pp. 41\u201353. \n Foley, J. D., \u201cInterfaces for Advanced Computing,\u201d \n Scientific American, Vol. 257, No. 4, October 1987, \npp. 126\u2013135. \n Foster, C. C., and T. Iberall,  Computer Architecture, \n3rd ed., New York: Van Nostrand Reinhold, 1985. \n Fox, E. R., K. J. Kiefer, R. F. Vangen, and S. P. Whalen, \n\u201cReduced Instruction Set Architecture for a GaAs \nMicroprocessor System,\u201d  Computer, Vol. 19, Issue \n10, October 1986, pp. 71\u201381. \n Hunt, J. G., \u201cInterrupts,\u201d  Software\u2014Practice and \nExperience, Vol. 10, No. 7, July 1980, pp. 523\u2013530. \n Leonard, T. E., ed.,  VAX Architecture Reference Manual. \nBedford, MA: Digital Press, 1987. \n Lilja, D. J., \u201cReducing the Branch Penalty in Pipelined \nProcessors,\u201d  Computer, Vol. 21, No. 7, July 1988, \npp. 47\u201353. \n Mallach, E. G., \u201cEmulator Architecture,\u201d  Computer, \nVol. 8, August 1975, pp. 24\u201332. \n Patterson, D. A., \u201cReduced Instruction Set Computers,\u201d \n Communications of the ACM, Vol. 28, No. 1, January \n1985, pp. 8\u201321. \n Patterson, D., and J. Hennessy,  Computer Organization \nand Design, 3rd ed., San Francisco, CA: Morgan \nKaufmann, 2004. \n Patterson, D. A., and R. S. Piepho, \u201cAssessing RISCs in \nHigh- Level Language Support,\u201d  IEEE Micro, Vol. 2, \nNo. 4, November 1982, pp. 9\u201319. \n Patton, C. P., \u201cMicroprocessors: Architecture and \nApplications,\u201d  IEEE Computer, Vol. 18, No. 6, June \n1985, pp. 29\u201340. \n Pohm, A. V., and T. A. Smay, \u201cComputer Memory \nSystems,\u201d  Computer, October 1981, pp. 93\u2013110. \n Rauscher, T. G., and P. N. Adams, \u201cMicroprogramming: \nA Tutorial and Survey of Recent Developments,\u201d \n IEEE Transactions on Computers, Vol. C-29, No. 1, \nJanuary 1980, pp. 2\u201320. \n Smith, A. J.; \u201cCache Memories,\u201d  ACM Computing \nSurveys, Vol. 14, No. 3, September 1982, \npp. 473\u2013530. \n  WEB RESOURCES \n http://books.elsevier.com/companions/1558606041/ \n(Hennessy and Patterson) \n http://en.wikipedia.org/wiki/Cache  \n REVIEW QUESTIONS \n \nA.1 What are the two major classes of CPU design? \n \nA.2 What is the importance of the instruction set archi-\ntecture to a discussion of the design and develop-\nment of OSs? \n \nA.3 Why is a system hardware timer important to \nan OS? \n \nA.4 What is the purpose of an interrupt? \n \nA.5 What is the significance of multicore CPU chips? \n",
        "category": "Category"
    },
    {
        "id": "256",
        "title": "Title for Chunk 256",
        "content": "Confirming Pages\n \nAppendix Overview of Computer System and Architecture Concepts \n509\n \nA.6 True or false? Primary storage in computers is \nalways made up of electronic memory circuits. \n \nA.7 It is hard to overemphasize the importance of \ncaching to the performance of an OS.\n a. What is the purpose of a cache? \n b. What theory underlies its function? \n \nA.8 In theory we could make the cache between sec-\nondary storage and primary storage as big as the \nsecondary storage. This would have the advantage \nof having much smaller latency. Why do we not \ndo this? \n \nA.9 What is the purpose of memory protection? \n A.10  What is the purpose of having device controllers? \n A.11 In order to help us discuss and understand large \ncomplex topics such as I/O devices, we can view \nthe subject as a space with many dimensions. We \nfirst discussed a broad division of I/O devices \naccording to the purpose of the device. What were \nthe three broad purposes that were discussed? \nGive some examples of each class. \n A.12 We also divided the I/O device space into those \ninterfaces that were general-purpose interfaces \nand those that were for specific device types. Give \nsome examples of each class. \n A.13 DMA controllers cause many fewer interrupts per \nblock transferred to or from a device than do con-\ntrollers, which do not use DMA. Other than obvi-\nously freeing up the CPU to do other things, why \ndo we need controllers that use DMA? \n A.14 What is the function of a device driver and how do \nwe configure OSs with the correct drivers? \n A.15 What facility is used to translate computer names \nsuch as  omega.example.com  to IP addresses for \nuse in the Internet?  \nelm49810_app_483-510.indd   509\nelm49810_app_483-510.indd   509\n12/29/08   3:09:05 PM\n12/29/08   3:09:05 PM\n",
        "category": "Category"
    },
    {
        "id": "257",
        "title": "Title for Chunk 257",
        "content": "Confirming Pages\nelm49810_app_483-510.indd   510\nelm49810_app_483-510.indd   510\n12/29/08   3:09:06 PM\n12/29/08   3:09:06 PM\n",
        "category": "Category"
    },
    {
        "id": "258",
        "title": "Title for Chunk 258",
        "content": "Confirming Pages\n225\n Advanced Memory \nManagement \nIn this chapter: \n 11.1 Why Do We Need Hardware Help? 225\n 11.2 Paging 226\n 11.3 Segmentation 233\n 11.4 Segmentation with Paging 236\n 11.5 Demand Paging 238\n 11.6 Special Memory Management Topics 248\n 11.7 Summary  252 \n  T\nhis chapter continues the discussion of memory management techniques. In \nparticular, it covers the more advanced techniques used in modern systems. \nThe first section discusses the issues that arise from the mechanisms covered \nin the last chapter and why the newer techniques were developed. \n Section 11.2 describes the action of paging hardware and how it further sepa-\nrates the logical and physical addressing spaces. Section 11.3 discusses an alter-\nnative hardware mechanism known as segmentation and Section 11.4 shows how \npaging and segmentation can be used together. In Section 11.5 we move on to the \nsubject of demand paging\u2014bringing pages into memory only when they are to be \naccessed\u2014and some of the problems that arise with this technique. Section 11.6 \nthen covers a few special advanced memory techniques and Section 11.7 summa-\nrizes the chapter. \n11.1 WHY DO WE NEED HARDWARE HELP? \n Multiprocessing with contiguous memory allocation causes external fragmentation, \nwasting memory and CPU resources when we are not able to run programs even \nthough sufficient RAM is available to run them. In the last chapter we saw that we \ncan mitigate this problem somewhat, but the solution requires running compaction \nroutines, an unproductive use of the CPU and memory. In order to do away with \n 11 \n Chapter  11 \n Chapter \nelm49810_ch11_225-254.indd   225\nelm49810_ch11_225-254.indd   225\n12/8/08   5:00:30 PM\n12/8/08   5:00:30 PM\n",
        "category": "Category"
    },
    {
        "id": "259",
        "title": "Title for Chunk 259",
        "content": "Confirming Pages\n226 \nPart 3 CPU and Memory Management\nthis problem we need to further separate the memory address space that a program \nsees (the logical address) from the address space used by the hardware (the physical \naddress) in such a way that all the parts of a program do not have to be in contiguous \nmemory. Making this separation requires hardware assistance. There are several dif-\nferent approaches to this problem and these approaches are covered in the following \nsections.   \n 11.2 PAGING \n Earlier we discussed the idea of the separation of the logical addressing space from \nthe physical addressing space. We changed the memory management unit (MMU) \nto make this work. Instead of using the base register to check an address we used it \nto relocate an address. This allowed us to put any program anywhere in memory\u2014\ndynamic relocation. However, we found that allowing variable-sized programs to \ncome and go in memory caused us to have external fragmentation of the memory \nand to spend valuable CPU time doing compaction. Unfortunately, compaction is not \n\u201cuseful work\u201d in the sense that it is not anything the user is trying to do. It is merely \na task that the OS does to make things work better in an overall sense. Eventually \nanother solution was developed\u2014we divide the memory into fixed-size blocks and \ninstead of allocating to an application the entire space it needs in one large segment, \nwe allocate enough of the smaller blocks to give the program what it needs. How-\never, the blocks we allocate do not need to be contiguous\u2014they can be anywhere in \nmemory because we ask the MMU to dynamically relocate each block separately. \nThis technique is known as  paging. This means that we have to make our memory \nmanagement unit a lot more complex. \n We will divide our physical address space into blocks of uniform size, which \nwe call  frames. We will conceptually divide the logical addressing space into \nblocks called  pages, which are the same size as the frames. Commonly these \nblocks are 512 bytes to 8 KB long. For byte addressable machines the number of \nbytes in a block is always a power of 2. Today a common page size is 4 KB, but \nthe increasing size of RAM and hard drives means that in the future we are more \nlikely to see larger page sizes.  Figure 11.1  shows the process of relocating each \naddress reference.  \n We see that the CPU generates a memory address. In general, the program ignores \nthe fact that the memory is handled in separate pages, so these addresses are regarded \nas just a binary number in the range of the logical address space. This address might \nbe the address of the next sequential instruction, a jump to a subroutine, a reference \nto a data item or to the stack. The purpose of the reference does not matter. As before, \nwe call this the logical address. However, the MMU will regard the address as being \ncomposed of two parts, shown here as the  page number, p and the  displacement, \n d. The displacement is the address of the specific byte within the frame. If our frame \nsize is 4 KB then our displacement field is the exact size needed to address every byte \nin a frame, or 12 bits. When we relocate a logical address to a physical address we \nwill still be addressing the same displacement in the frame as we were in the page. \nSo we will not change the displacement part of the logical address. The rest of the \nelm49810_ch11_225-254.indd   226\nelm49810_ch11_225-254.indd   226\n12/8/08   5:00:34 PM\n12/8/08   5:00:34 PM\n",
        "category": "Category"
    },
    {
        "id": "260",
        "title": "Title for Chunk 260",
        "content": "Confirming Pages\n \nChapter 11  Advanced Memory Management  \n227\nlogical address is the page number. What we need to relocate is the page, so we will \nlook in a  page table of relocation addresses for the frames. We will have a register \nthat holds the memory address of the page table for the running process. This register \nis called the  page table address register. The memory control unit will add the page \nnumber from the logical address generated by the process running in the CPU to the \nvalue in the page table address register. The value stored in that location of the page \ntable will be the relocation address of the particular  frame we are trying to access. In \nthis case it is shown as the value  f. The value of  f is combined with the displacement \nwe already had to address the particular byte in physical memory.  \n Figure 11.2  shows a more complete page table. We are ignoring the displace-\nment portion of the address and considering only how the pages map to the frames. \nHere we see the logical address space for a process that is running. It is divided into \npages that are labeled A\u2013H. The third page is labeled C, for example. If the CPU gen-\nerates a reference to this page, then the memory management unit will translate this \naddress by looking in the third entry in the page table for the process. Here we see \nCPU\nPage Table\nAddress Register\np\np\nd\nf\nf\nd\nPage Table\nper Process\nLogical\nAddress\nPhysical\nAddress\nMemory\nFIGURE 11.1 \nPaged memory \naccess.\nLogical\nAddress\nSpace\nPage Table\nper Process\nPhysical\nAddress\nSpace\nA\nB\nC\nD\nE\nF\nG\nH\n3\n5\n7\n1\n4\n2\n6\n8\nD\nF\nA\nE\nB\nG\nC\nH\nFIGURE 11.2 \nMapping logical \naddresses to \nphysical addresses.\nelm49810_ch11_225-254.indd   227\nelm49810_ch11_225-254.indd   227\n12/8/08   5:00:34 PM\n12/8/08   5:00:34 PM\n",
        "category": "Category"
    },
    {
        "id": "261",
        "title": "Title for Chunk 261",
        "content": "Confirming Pages\n228 \nPart 3 CPU and Memory Management\nthat this entry contains the number of frame 7. So the memory management unit will \nlook into frame 7 to find the information we are accessing. Of course, in a real sys-\ntem the frames would be spread out and mixed in with frames from other processes. \n 11.2.1 Dual memory accesses required \n As we have described this mechanism, however, we have a problem. For each refer-\nence to memory we have to make a second reference to memory to find the page \ntable entry to use as the relocation factor for this page. This will make our process \nrun at half speed when accessing memory, an obviously unacceptable penalty. As \nwith many other things in computer systems, our solution is for the memory man-\nagement unit to cache the last few relocation factors so we can use them again \nwithout having to look them up in memory. This caching is done with a special \nkind of hardware device called a  translation lookaside buffer, or TLB. The TLB \nis a type of circuit that goes by several names. It is sometimes called a content \naddressable memory (CAM) or associative memory. The essence of this circuitry \nis that when it tries to check to see if it has a page number in it, all the entries \nare searched in parallel. This means that the entries in the TLB do not have to be \nkept in any order since they are all compared at the same time. If the page we are \ntrying to access has been accessed lately then it will be in the TLB and it will be \nreturned very quickly\u2014maybe 100 times faster than if we had to access the page \ntable in main memory. The TLB is obviously a complex circuit. As a result, they are \ntypically rather small. On current machines they are rarely over about 1,000 entries \nand usually much fewer. However, that is normally enough for most processes to \nfind the information in the cache most of the time. The use of a TLB is shown in \n Figure 11.3 .  \nCPU\np\np\np\nd\nTLB\nf\nf\nf\nd\nPage Table\nin RAM\nLogical\nAddress\nPhysical\nAddress\nMemory\nFIGURE 11.3 \nThe translation \nlookaside buffer.\nelm49810_ch11_225-254.indd   228\nelm49810_ch11_225-254.indd   228\n12/8/08   5:00:34 PM\n12/8/08   5:00:34 PM\n",
        "category": "Category"
    },
    {
        "id": "262",
        "title": "Title for Chunk 262",
        "content": "Confirming Pages\n \nChapter 11  Advanced Memory Management  \n229\n 11.2.2 Effective memory access times \n There is a formula by which we can estimate the impact of the TLB on the execution \nspeed of the computer. We will calculate the  effective access time, or EAT. The for-\nmulas use the speed of a TLB lookup, which we will call  E and the speed of a main \nmemory reference, which we will call  M. Some percent of the time we will find the \npage number we are referencing in the TLB. We will call this percentage  A. This per-\ncentage is often called the  hit ratio. Obviously, the percentage that we will not find \nthe referenced page in the TLB (a  TLB miss ) will be 1-A. For example, if we get a \nhit 80% of the time then we are going to get a miss 20% of the time. When we find \nthe page number in the TLB, then the memory reference will take E  \ufffd M time \ufffd E to \nsearch the TLB and M to make the normal memory reference. When we do not find \nthe page number in the TLB, then the total memory reference will take 2 *  M\u2014two \nmemory references, one to get the frame number out of the page table and one for the \nnormal memory reference. The EAT will then be: \nEAT\nA (E\nM)\n(1\nA) (2\nM)\n\ufffd\n\ufffd\n\ufffd\n\ufffd\n\u2217\n.\n For example, suppose our TLB lookup time (E) was 5 nanoseconds, our memory \naccess time (M) was 100 nanoseconds, and our hit ratio (A) was 80%. Then the \neffective memory access time would be .8(100  \ufffd 5)  \ufffd (1 \ufffd .8)  * (2 *  100), or 124 \nnanoseconds. This is a slowdown of 25%. \n Depending on the hardware design, the TLB lookup may take place while the \nfirst memory reference is being started. If the TLB lookup is not successful, then the \nmain memory reference will continue. In this case, the formula just given applies. \nBut other hardware may not start the main memory reference until the TLB lookup \nhas failed. In this case, the equation for EAT becomes: \nEAT\nA (E\nM)\n(1\nA) (E\n2\nM)\n\ufffd\n\ufffd\n\ufffd\n\ufffd\n\ufffd\n\u2217\n.\n The larger we make the TLB the higher the hit ratio will be. For example, using the \nsame numbers as before but with a hit ratio of 90%, the EAT will be .9(100  \ufffd 5)  \ufffd \n(1 \ufffd .9) *   (2 *   100), or 114.5 nanoseconds. This is a slowdown of less than 15%. \nUnfortunately, this is a hardware design decision, not a software question or even a \ndecision the purchaser of the system can make. Unlike RAM, for example, TLBs are \ngenerally not upgradeable, being an integral part of the memory management unit \nitself and normally embedded in the CPU chip. \n Note that each process has the same logical addressing space\u2014it starts at 0 and \ngoes up to the size of the program. On most systems the TLB hardware does not \nconcern itself with which process is running. As a process runs, the TLB will fill \nup with frame numbers that correspond to the page numbers of the running process. \nWhen we switch to another process the OS must tell the hardware to forget all the \ncurrent frame numbers since the new process will have different frame numbers that \nwill need to be mapped to the same page numbers that the previous process had used. \nTherefore, after we do a context switch to the new process, for the first few mem-\nory references we will not get any TLB hits, so our process will run at half speed \non memory reference instructions. This is one reason why we don\u2019t want to switch \nelm49810_ch11_225-254.indd   229\nelm49810_ch11_225-254.indd   229\n12/8/08   5:00:35 PM\n12/8/08   5:00:35 PM\n",
        "category": "Category"
    },
    {
        "id": "263",
        "title": "Title for Chunk 263",
        "content": "Confirming Pages\n230 \nPart 3 CPU and Memory Management\nprocesses any more often than we have to and why switching threads is faster than \nswitching processes. A few hardware designs do have  address space identifiers, or \n ASIDs, stored in the cache with the frame numbers. These designs do not require \nthat the TLB be flushed. They will still get many TLB misses and will therefore run \nmore slowly for a short time until the TLB is repopulated. This sort of TLB is very \nuseful with CPUs that are running multiple processes in parallel. \n 11.2.3 Memory access control \n When we were accessing main memory with one relocation register for the entire \nprogram we also had a limit register that prohibited a process from accessing out-\nside the memory area assigned to it. With paging hardware we will need a similar \nmechanism. There is no problem with the individual pages themselves since they are \nnormally of a fixed size. However, we will need some mechanism for limiting the \naccess to the page table. There are basically two approaches to this problem. Both \ndepend on the hardware, so the decision is not up to the OS designer, but we will \ndiscuss them so that you will be aware of them. The first approach is to use a fixed \npage table size. In this case, we will need a  valid bit in each page table word to indi-\ncate whether a page table address is valid. So, for example, if we had a fixed page \ntable size of 10 entries and the process only took three pages in the logical address \nspace, we would fill in the first three entries with the addresses of the corresponding \nmemory page numbers and set the valid bit \u201con\u201d for those three entries. For the rest \nof the entries in that page table we would set the valid bit to \u201coff\u201d because they do \nnot hold a reference to a valid page. When the memory management unit accessed \nany entry in the page table it would generate a memory addressing error if the entry \nhad a valid bit that was set to off. \n The other approach to memory address control is to use a page table with a \nvariable size. In this case, we will have a  page table length register. With a single \nrelocation register we had a length register that specified the length of the process in \nmain memory. A page table length register will work just as it sounds like it would. It \nholds the address of the largest valid page number for a process. If an address gener-\nated by the CPU when the process is running contains a page number bigger than the \nnumber in the page table length register, then the hardware will generate an address-\ning error interrupt because the process has generated a reference to a page that is not \nin the logical address space of the process. These days most systems use a valid bit \nfor reasons that we will see later. \n Page access protection \n In addition to limiting memory addressing, paging allows the OS to restrict the kinds \nof access that may be made to the various pages. The hardware can be set up to \nallow only read access to a page, for example, or only execute access. In order to \nmake effective use of this the compilers (and assemblers) must be able to force the \nlinker to place portions of the executable file on a page boundary. In this way, the \ndata portions of the module can be marked as read\u2013write but not execute. Similarly, \nthe program code can be marked as execute only. There are some problems with this \nelm49810_ch11_225-254.indd   230\nelm49810_ch11_225-254.indd   230\n12/8/08   5:00:35 PM\n12/8/08   5:00:35 PM\n",
        "category": "Category"
    },
    {
        "id": "264",
        "title": "Title for Chunk 264",
        "content": "Confirming Pages\n \nChapter 11  Advanced Memory Management  \n231\nsort of mechanism that need to be addressed. For example, it might appear that the \nstack should not allow execution of items on the stack. But it is common for Java \nvirtual machines to compile Java program byte codes into instructions on the stack \nand execute them there. \n 11.2.4 Large page tables \n In modern machines with modern OSs and modern compilers the programs are get-\nting very large. This means that the page tables are also very large. Also, it turns out \nthat in many cases the page tables are sparse, meaning that they may have large parts \nof the table that are in the logical address space but do not point to a valid frame. \nLater, we discuss some of the reasons why this happens. In any case, it became \nincreasingly difficult to manage the memory allocated to the page tables themselves. \nSeveral different approaches were taken to deal with these large, sparse tables. \n The first technique was to make a  multilevel page table.  Figure 11.4  shows a \ntwo-level page table\u2014essentially we page the page table. As with the single-level \ntables we have been discussing, the MMU will consider the logical address gener-\nated by the CPU as being made up of several parts\u2014in this case, three. As before, \nwe have the page displacement, which will be carried over and used as the frame \ndisplacement. Now we view the page number as being made up of two parts, here \nshown as p1 and p2. P1 will be used by the hardware to access into the top-level page \ntable, just as before. However, the number stored in this entry will not be a frame \nnumber, but another memory address, that of a second-level page table. The remain-\ning bits of the page number, here shown as p2, will be used to access within the \nselected second-level page table. This entry will be the frame number for the page \nnumber represented in the original address by p1 and p2 together. This frame number \nCPU\nPage Table\nAddress Register\np2\nf\nf\nd\nFirst-Level\nPage Table\nLogical\nAddress\nPhysical\nAddress\nMemory\np1\nSecond-Level\nPage Table\np1\np2\nd\nFIGURE 11.4 \nA two-level page \ntable.\nelm49810_ch11_225-254.indd   231\nelm49810_ch11_225-254.indd   231\n12/8/08   5:00:35 PM\n12/8/08   5:00:35 PM\n",
        "category": "Category"
    },
    {
        "id": "265",
        "title": "Title for Chunk 265",
        "content": "Confirming Pages\n232 \nPart 3 CPU and Memory Management\nwill be used with the original displacement to access the desired memory location in \nphysical memory. The DEC VAX systems used a two-level paging architecture. \n Two-level page tables turned out to be such a useful technique that the process \nhas been extended. Modern processors normally have three- or four-level page table \narchitectures. Note that this could potentially really cause problems with our EAT. \nIn the worst case, with a four-level page table we can take five memory accesses to \nreach a single byte in memory because each of the page table references may not be \nin the TLB. Thus our equation for the EAT becomes something like: \nEAT\nA (E\nM)\n(1\nA) (5\nM)\n\ufffd\n\ufffd\n\ufffd\n\ufffd\n\u2217\n.\n Fortunately, most of the time our TLB will hold those final physical memory refer-\nences and on the average we will pay a performance penalty only slightly greater \nthan with a single-level page table. \n It is worth noting that this technique has the effect of creating a  virtual page \ntable. Since the address spaces are so large, the page table is generally very sparse\u2014\nthere are large parts of it that are not really used. In such cases those portions of the \nlower-level page tables do not need to be allocated and filled in until they are actu-\nally needed. This can save considerable table space and the resources necessary to \naccess it. \n 11.2.5 Inverted page table \n A slightly different approach to the problem of external memory was to turn the \nproblem around. The idea was to map the physical frames into the logical pages.  Fig-\nure 11.5  shows an inverted page table approach to process page mapping. The table \nis kept in order by the physical frame number. The table itself is searched to find a \nreference. Since there is only one table, the page numbers from the various processes \nCPU\np\nd\ni\ni\np\np\nf\nd\nLogical\nAddress\nProcess ID\nSearch\nPhysical\nAddress\nMemory\nf\nf\ni\nFIGURE 11.5 \nInverted page table.\nelm49810_ch11_225-254.indd   232\nelm49810_ch11_225-254.indd   232\n12/8/08   5:00:35 PM\n12/8/08   5:00:35 PM\n",
        "category": "Category"
    },
    {
        "id": "266",
        "title": "Title for Chunk 266",
        "content": "Confirming Pages\n \nChapter 11  Advanced Memory Management  \n233\nare not sufficient to specify the mapping. For instance, every process will have a \npage number 0. A process identifier must therefore be stored with the page number. \nThe time to search an inverted page table will often be slower than for a normal page \ntable. The OS can speed up this search by using a hash function to access the table. \nThis method will require a chaining scheme to resolve collisions since some pro-\ncesses may have page number/process ID combinations that hash to the same value. \nSo even more than with a normal page table, we rely heavily on the TLB lookup to \nresolve most of our lookups. Inverted page tables take much less RAM than normal \npage tables. \n 11.2.6 Page tables with multiple page sizes \n In later systems it has become common to have more than one page table size. In the \nIntel Pentium architecture, for example, the normal page size is 4096 bytes, but there \nis another possible page size of 4 MB. The reason for this is so that the kernel of \nthe OS can be mapped in the page table with the process without taking up so much \nRAM in the page table. Most of the kernel pages will be the same in every process; \nthey will never move around and cause fragmentation and they will always be there, \nso there is no need to divide them into small pages as there is with processes that \nare of unknown size and duration. In addition, as we will see shortly, in the applica-\ntion part of the logical space of a process the pages will sometimes not even be in \nmemory. This is usually not the case with the kernel, though some OSs page portions \nof the kernel. Therefore, having only one or a few pages to map the kernel through \nis a big advantage since it can be set up and manipulated more easily and only takes \none TLB entry to map the entire kernel. \n In some of the later UltraSPARC \u00ae processors the software can select multiple \npage sizes for different parts of the application. We will see in the section on seg-\nmentation with paging how this works. \n 11.2.7 A historical footnote \n While modern systems normally use these techniques in the context of running mul-\ntiple processes concurrently, historically there were a few systems that used paging \nwhile only running a single process. Programs could refer to portions of the program \nthat were not yet in memory much as if they were calling overlays, as discussed \nin the last chapter. This had the advantage of allowing the running process to be \nmuch larger than the physical memory. In the era of smaller memories this was a big \nadvantage, but it is not utilized much in current systems. Modern OSs use demand \npaging, discussed in a later section. \n 11.3 SEGMENTATION \n At about the same time that paging was being devised, a different track of develop-\nment evolved that was designed mostly to help solve the same problems that paging \naddressed, but a few others besides. This technique is called  segmentation. It arose \nelm49810_ch11_225-254.indd   233\nelm49810_ch11_225-254.indd   233\n12/8/08   5:00:36 PM\n12/8/08   5:00:36 PM\n",
        "category": "Category"
    },
    {
        "id": "267",
        "title": "Title for Chunk 267",
        "content": "Confirming Pages\n234 \nPart 3 CPU and Memory Management\nout of the observation that we can consider a program as being made up of several \ndistinct parts. We usually have a main routine and we often have subroutines and \nfunctions that are recognized by the compiler as being separate items. Sometimes we \neven compile the subroutines and functions separately and put them into libraries. \nWe have areas where we keep the stack, static data items, constant information, file \nbuffers, communication buffers, and so on. Each of these areas can be created and \ncontrolled separately.  Figure 11.6  shows a collection of segments of a program that \nmake up a process after being loaded into primary memory. \n Each of these parts can be considered to be separate from the other parts and \ncan have a separate logical addressing space. For example, since there is a sepa-\nrate addressing space for the data, we would consider that the first data item was \nat address 0 in the data segment address space. We now need for the hardware to \nrelocate all references to addresses in each segment in the same way it relocated ref-\nerences to the entire process with a relocation register. So we will use a mechanism \nthat is much like a page table, with a couple of small differences.  Figure 11.7  shows \na sample segment table. We will still consider the logical address to be broken into \ntwo parts, but they will be a  segment number ( s ) and a  displacement ( d ). With pag-\ning we had quite a few pages of a fairly small size so the displacement was a small \nnumber of bits and the page number was much larger. With segmentation we have a \nrelatively small number of segments, each of which can be fairly large by itself, so \nthe segment number will usually be a smaller number of bits and the displacement \nwithin the segment will be a larger size. In addition, while the entries in a page table \ncontained a frame number, the entries in the segment table will contain memory \naddresses. The programmer does not normally exert any overt control over the seg-\nmentation. The compilers will generate separate segments for the major portions of \nthe module being compiled\u2014the program code, the stack, the heap, global variables, \nand so on\u2014and place symbolic references to them in the object modules. The linker \nwill assign actual segment numbers to be used when combining the object modules \ninto the executable binary program and for the OS to use when dynamically loading \nlibrary modules. \nCode\nSegment\nOriginal Program\nMain Memory\nSubroutine A\nSubroutine B\nData \nSegment\nStack \nSegment\nHeap \nSegment\nHeap \nSegment\nStack\nSegment\nCode\nSegment\nData \nSegment\nLanguage\nLibrary\nFIGURE 11.6 \nSegmenting \na process.\nelm49810_ch11_225-254.indd   234\nelm49810_ch11_225-254.indd   234\n12/8/08   5:00:36 PM\n12/8/08   5:00:36 PM\n",
        "category": "Category"
    },
    {
        "id": "268",
        "title": "Title for Chunk 268",
        "content": "Confirming Pages\n \nChapter 11  Advanced Memory Management  \n235\n In  Figure 11.7  we see a memory reference to the segment containing Subroutine \nA. The hardware will use the segment table entry specified by the number in the seg-\nment part of the address. It will take the segment table address pointer found in that \nentry of the segment table and it will add it to the displacement part of the logical \naddress. The paging hardware simply replaced the page number with a frame num-\nber. This worked because frames and pages were always the same size so they were \nalso always located on block boundaries. Since segments are of variable size they \ncan also be located anywhere, so we will use the segment table pointer  plus the dis-\nplacement to get the physical memory address. Note that use of segmentation causes \nan extra memory reference for each access, just as it did with paging. So systems \nwith segmentation will also use a TLB to speed up access. \n Since segments can be anywhere and are not all the same size, this is not an opti-\nmum solution to avoid external fragmentation. We will still have to keep track of mem-\nory holes. We will still not allocate tiny pieces of memory. Instead, we will have some \nminimum granularity\u2014perhaps 1024 bytes. We will therefore have some internal frag-\nmentation. But now the range of sizes of the holes will be smaller than the range we had \nto consider when keeping track of entire processes because we are breaking each pro-\ncess up into (potentially many) segments. Therefore, we will have less of a problem with \nexternal fragmentation than we did with memory management for entire processes. \n Since the segments are of variable size, we must provide a way for the system to \ncheck the addresses so that we can make sure the process is not addressing outside \nthe limits of the segment. The limit for each segment is stored in the segment table \nalong with the pointer to the segment. Since the segments have different purposes we \ncan also increase the protection we are providing to the system by limiting the kinds \nof accesses we make to the various segments, much as we discussed with paging. \nIt is common to have a set of bit flags with each segment that controls the kinds of \naccess we can make. For example, a segment of data constants can be marked as read \nonly. The program pages can be marked as execute only. Stacks and data pages will \nallow read and write but not execute. \nCPU\nMemory\nPhysical\nAddress\nLogical\nAddress\nData\nSegment\nCode\nSegment\nStack\nSegment\nSubroutine A\nSubroutine B\nSubroutine A\nstack\ncode\ndata\nSubroutine B\ns\nd\ns\nFIGURE 11.7 \nSegment table \nand segments \nin main memory.\nelm49810_ch11_225-254.indd   235\nelm49810_ch11_225-254.indd   235\n12/8/08   5:00:36 PM\n12/8/08   5:00:36 PM\n",
        "category": "Category"
    },
    {
        "id": "269",
        "title": "Title for Chunk 269",
        "content": "Confirming Pages\n236 \nPart 3 CPU and Memory Management\n In some OSs it is possible for processes to share segments. For example, we \nmight have several users running a program editor at the same time. We could cre-\nate a process per user and map the code segments in their respective segment tables \nso that they all pointed to the same parts of physical memory. If we had common \nruntime libraries for standard languages, we could also map segments to point to the \nsame physical memory segments, even for different programs. Managing the seg-\nment numbers across multiple processes can be quite a chore for the OS. \n Programmers who are writing in high-level languages will not normally be aware \nthat segmentation is being used by an OS until their program generates a segmenta-\ntion fault, most often by overflowing the segment used for the stack. The compilers \nand the linker will generally take care of assigning the segment numbers for the vari-\nous pieces by calling OS routines that manage the segment numbers. Programmers \nworking in fairly low-level languages will need to be aware of segmentation and how \nthe OS is using it and they can control the segmentation if need be. The Windows \nNT family does not use segmentation because it is not needed on many hardware \ndesigns and not available on others and using it would make the software less por-\ntable. Linux uses segmentation only in a limited way, which we discuss in the next \nsection. Most UNIX-derivative OSs use segmentation with paging, also discussed in \nthe next section. \n 11.4 SEGMENTATION WITH PAGING \n There is a fundamental difference between paging and segmentation. Paging is trans-\nparent to the running process. An application program that was created to run in an \nOS where the process is mapped into a single large partition could run unchanged on \na system that used a paged memory architecture. Segmentation, on the other hand, \nrequires that programs somehow be structured so that they are divided into logi-\ncal parts with different address spaces. An interesting aspect of this is that with the \nproper hardware design we can run a segmented program architecture in combina-\ntion with a paged memory architecture. In the documentation for various OSs the \nsegments may be known as  regions or  memory areas. The segmentation works as \nwe have described it, but the address that is generated is not used as a physical mem-\nory address. Instead, it is now treated as a logical address and run through a paging \nmechanism. This allows us to have both the fine control over the types of references \nas with segmentation and the fixed page sizes of paging, which result in no external \nfragmentation. \n There are two generally different ways that segmentation and paging can be \ncombined. The first design originated with the Multics project.  1 In this design we \nwill have a page table for each segment of a process rather than a single page table \nfor the process. This design is shown in  Figure 11.8 . First, the segment portion of \nthe address is looked up in a segment table. This lookup returns a pointer to a page \ntable that maps the page numbers within the segment to frame numbers in physical \nmemory. \n1 http://www.multicians.org/fjcc1.html \nelm49810_ch11_225-254.indd   236\nelm49810_ch11_225-254.indd   236\n12/8/08   5:00:37 PM\n12/8/08   5:00:37 PM\n",
        "category": "Category"
    },
    {
        "id": "270",
        "title": "Title for Chunk 270",
        "content": "Confirming Pages\n \nChapter 11  Advanced Memory Management  \n237\n The second design is used in more modern systems. In this design there is still \na segment table, but instead of pointing to separate page tables for each segment, \nthe addresses in the segment table lie within a linear address space, which is then \nmapped into the physical memory in the same manner that a paged system works. \nThis design is seen in  Figure 11.9 . In this case a segment table entry describes a por-\ntion of the linear address space, which can be viewed as the page table for the seg-\nment. But as far as the hardware is concerned, it is just a part of a single-page table. \nCPU\ns\ns\np\np\nd\ndata\ncode\nstack\nSubr. A\nSubr. B\nPage Table\nper Segment\nSegment Table\nper Process\nf\nLogical\nAddress\nPhysical\nAddress\nMemory\nFIGURE 11.8 \nSegmentation \nwith paging.\nCPU\ns\np\nd\nPage Table\nper Process\nSegment Table\nper Process\nf\nLogical\nAddress\nPhysical\nAddress\nMemory\np\ns\nd\nf\ndata\ncode\nstack\nSubr. A\nSubr. B\nFIGURE 11.9 \nSegmentation \nwith linear \naddressing.\nelm49810_ch11_225-254.indd   237\nelm49810_ch11_225-254.indd   237\n12/8/08   5:00:37 PM\n12/8/08   5:00:37 PM\n",
        "category": "Category"
    },
    {
        "id": "271",
        "title": "Title for Chunk 271",
        "content": "Confirming Pages\n238 \nPart 3 CPU and Memory Management\n Most modern OSs use this latter mechanism in one form or another, but they \nlimit the use of the segments. Linux, for example, uses the segments only for the \nkernel, except for one segment that it uses for the running process. The segments \nare used to restrict addressing and control access. So, for example, two segments are \nused to map the same kernel address space. One is used for the execution of the pro-\ngram, so it is set to allow execution but not reading or writing. The other is used for \naccess to data, so it allows reading and writing but not execution. Another is used for \naccessing a runtime stack. This allows the hardware mechanism to check for stack \noverflow efficiently and dynamically. \n 11.5 DEMAND PAGING \n So far we have assumed that when a program is brought into memory that the entire \nprogram is brought in and a frame of physical memory is allocated for every page \nin the logical addressing space. However, it was eventually realized that this was not \nnecessary. As programs run they do not really access addresses randomly through-\nout their logical address space. The instructions in the code segment are accessed \nsequentially to a large extent, so for about a thousand instructions we might be \naccessing a single page in the code portion of the logical address space. Or the \nprogram may go into a loop, sometimes for quite a while, and stay in a single code \npage. To be sure, we will frequently call library routines, which may in turn call \nother library routines. The program steps through an array or scans through a string \nor searches through an incoming message. When we divide the execution of a pro-\ngram into small time slots and look at the pages accessed by the memory references \nin that time slot we will normally find that only a few pages are accessed by the \nprocess in any given time slot. This phenomenon is quite important in OS design. It \nis called  locality of reference. We use the same idea in caching and in many of our \nother OS algorithms. \n The trick that was developed to take advantage of this phenomenon is called \n demand paging. The idea is that we slightly modify the meaning of the valid bit \nin the page table. The hardware associated with the use of the bit will not change. \nAll the bit indicates is that there is no frame allocated for this page. In our previous \ndesign this meant that this page was outside the logical address space for the pro-\ngram. Now it may still indicate that, but it may only indicate that no physical frame \nis currently mapped to this page. When we load the first page we will set its valid bit \nto true to indicate that it is in memory. We will mark the valid bit of every other page \nto show that that page is not in memory. Then we will start the program running. In \ntheory, we could begin the execution of a program without bringing in to physical \nmemory  any pages. The OS could simply branch to the process in memory and let \nthe page fault mechanism bring in even the first page of the program. This is known \nas  lazy loading.  Even if we load the first page of the program, it will soon reference \ndata in another page that is not yet in memory.  Figure 11.10  shows an example of \nsuch a page table. This reference will fetch the page table entry and the setting of \nthe valid bit will cause a \u201cmemory addressing error\u201d interrupt. The memory manage-\nment subsystem will look at the reference to see if the reference is to a page that \nelm49810_ch11_225-254.indd   238\nelm49810_ch11_225-254.indd   238\n12/8/08   5:00:37 PM\n12/8/08   5:00:37 PM\n",
        "category": "Category"
    },
    {
        "id": "272",
        "title": "Title for Chunk 272",
        "content": "Confirming Pages\n \nChapter 11  Advanced Memory Management  \n239\nreally is in the logical address space of the program, but that has not been brought \ninto memory yet. If the reference is to a page that is not really in the logical address \nspace of the process, then the program has made an error and an addressing excep-\ntion is raised, most likely aborting the process. \n If the address that caused a fault is in the logical address space of the process, \nthen the page simply is not currently mapped into physical memory, either because it \nhas never been brought in or because it has been taken out. This condition is known as \na  page fault. The memory management subsystem will now request a read of the page \nfrom secondary storage and the OS will put the program into wait state until it has \nfinished. Once the block has been read in, the OS will update the page table to point \nto the new frame, mark the entry valid, and restart the process that generated the page \nfault at the instruction that caused the fault. Note that this mechanism is still transpar-\nent to the application. In other words, the application programmer does not normally \nneed to be aware that this process is going on, much less do anything about it. \n In some cases this would allow us to run programs that were so large they would \nnot fit into memory at all. The \u201c80/20 rule\u201d usually holds\u201480% of a program is \nwritten to take care of things that only happen 20% of the time. In many cases, there-\nfore, much of that 80% of the program will never be loaded into memory. As an extra \nbenefit, this will allow our programs to start faster, because if a page is never refer-\nenced we never load it into memory at all. As well, in an environment where we are \ntrying to run many programs, perhaps for many users, with a given amount of physi-\ncal memory, on the average we will be able to run more programs at the same time. \n 11.5.1 EAT with demand paging \n You may recall that when we first looked at the paging mechanism we saw how \nthe use of a page table by itself would double the effective access time of memory. \nThis necessitated the introduction of the TLB to cache the frame numbers for the \npage references in the working set. Now consider what happens when we access a \npage that is not in memory. Our effective access time will have four components, as \nshown in  Table 11.1.  (The speeds shown are simply approximate relative speeds, not \nspecific expected values.) \nA\n2\n1\n0\n0\n7\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\nB\nC\nD\nE\nEnd of\nLogical\nSpace\nLogical\nAddress\nSpace\nPage Table\nin RAM\nPhysical\nAddress\nSpace\nValid bit\n1\n2\n3\n4\n5\n6\n7\n8\n1\n2\n3\n4\n5\n6\n7\n8\nA\nC\nFIGURE 11.10 \nA page table \nshowing pages not \nin physical memory.\nelm49810_ch11_225-254.indd   239\nelm49810_ch11_225-254.indd   239\n12/8/08   5:00:37 PM\n12/8/08   5:00:37 PM\n",
        "category": "Category"
    },
    {
        "id": "273",
        "title": "Title for Chunk 273",
        "content": "Confirming Pages\n240 \nPart 3 CPU and Memory Management\n As the table shows, the disk I/O vastly overwhelms the memory speeds. This \ndomination will lead to several mechanisms that may seem at first to be overly \ncomplex that are developed merely to avoid doing a single-disk I/O for demand \npaging.  \n 11.5.2 The working set and page replacement \n So far we have assumed that there are enough pages free in memory to bring in any \npage we need when a process references it. Unfortunately, we normally will soon run \nout of free pages. At that point we need to get rid of some pages that are in memory. \nFrequently this will not cause us any problem at all. As a program runs it will be \nreferencing some set of pages\u2014a page in the main process, perhaps a few pages of \nlibrary routines, buffers for the input and the output, doubtless a few pages of data. \nThis group of pages that a process is referencing in a short period is called the  work-\ning set. We typically measure the working set over some fixed interval known as a \n sliding window. \n For example, suppose a process had a logical address space containing seven \npages identified as 1 through 7, and had the sequence of references to those pages \nas follows:\n 1 2 1 5 7 1 6 3 7 1 6 4 2 7 \n We will track the working set by looking at the last four references. As this sequence \nof references unfolds the working set will change, as seen in  Table 11.2 .   As the pro-\ncess runs, the working set typically changes from time to time. It is normal to find \nthat a process will have in memory several pages that it is no longer referencing. In \nthe table we can see that page 5 is no longer referenced after step 4, so we could get \nrid of it. What we would like to be able to do is to identify those pages and remove \nthem from memory when we no longer need them. (Removing pages that we think \nmay not be needed anymore is called  page replacement. ) Unfortunately, we can\u2019t \nreally do that. Just because we have not referenced a page in a while does not mean \nthat the very next instruction won\u2019t reference that page. In the table we saw that page \n2 was not referenced between steps 2 and 13, so we no longer saw it as being in the \nworking set since we were only looking at a four-step window. Fortunately, remov-\ning a page from memory that is needed later doesn\u2019t break anything. It is just not \nquite as efficient. The next reference to the page will cause a page fault and the page \nwill be fetched again. \nTABLE 11.1 Demand Paging Effective Address Time\nComponent\nRelative Speed\nTLB lookup\n1 nanosecond\nMemory access\n100 nanoseconds\nDisk write (dirty page)\n20 milliseconds\nDisk read\n20 milliseconds\nelm49810_ch11_225-254.indd   240\nelm49810_ch11_225-254.indd   240\n12/8/08   5:00:37 PM\n12/8/08   5:00:37 PM\n",
        "category": "Category"
    },
    {
        "id": "274",
        "title": "Title for Chunk 274",
        "content": "Confirming Pages\n \nChapter 11  Advanced Memory Management  \n241\n There is a very simple page replacement strategy,  first in, first out, or  FIFO. \nThe OS keeps a queue of the page numbers as they are brought in for each process \nand simply ejects the oldest one. This algorithm is a low-overhead algorithm, which \nrequires little overhead from the OS. While FIFO is cheap and easy to understand \nand implement, it performs poorly and erratically so it is rarely used today. This \nalgorithm experiences Belady\u2019s anomaly. It was used in the VAX/VMS OS. \n Theoretically, there is a  optimal page replacement algorithm (also known as \nOPT). It would work as follows: when a page needs to be replaced, the OS replaces \nthe page whose next use will be the furthest in the future. For example, a page that is \nnot going to be used until 200 milliseconds from now will be chosen over a page that \nis going to be used in 10 milliseconds. This algorithm can\u2019t be used in general because \nit is impossible to know how long it will be before a page is going to be used except in \nvery limited circumstances. If it were implementable it would be the best we could do, \nso it is worth discussing. Assuming that we had only three free frames to work with, if \nwe used this algorithm with the reference string shown previously, we would generate \nnine page faults, including the page faults required to bring in the first three pages. \n There are several other mechanisms we can use to select a page to replace. One \npossibility is to try to figure out which page has not been referenced for the longest \ntime. As is commonly said, this page is the  least recently used (LRU) page. We \nwill make the assumption that this page is the most likely not to be used again, and \nwe will take it out of memory. If we tried to actually save the time of the last refer-\nence to every page, we would end up making at least one extra memory reference \nfor every real memory reference. So real OSs do not implement an LRU algorithm. \nHowever, with the help of some hardware features we can identify pages that have \nnot been used for some time. The simplest of the algorithms that use this feature is \nTABLE 11.2 Tracking a Working Set\nEvent Number\nWorking Set\n1\n1\n2\n1 2\n3\n1 2\n4\n1 2 5\n5\n1 2 5 7\n6\n1 2 5 7\n7\n1 5 6 7\n8\n1 3 6 7\n9\n1 3 6 7\n10\n1 3 6 7\n11\n1 3 6 7\n12\n1 4 6 7\n13\n1 2 4 6\n14\n2 4 6 7\nelm49810_ch11_225-254.indd   241\nelm49810_ch11_225-254.indd   241\n12/8/08   5:00:38 PM\n12/8/08   5:00:38 PM\n",
        "category": "Category"
    },
    {
        "id": "275",
        "title": "Title for Chunk 275",
        "content": "Confirming Pages\n242 \nPart 3 CPU and Memory Management\nknown as the  clock algorithm. 2 At a fairly low cost (in terms of additional memory \nreferences) the hardware can ensure that a bit in a page table entry is set when a page \nis referenced. This bit is often called a  page reference bit, or sometimes an  access \nbit or  use bit. (See  Figure 11.11 .) When a page is referenced (via the page table), the \nhardware will check this bit. If it is already set, then nothing needs to happen. If it is \nnot yet set, it will be turned on, perhaps costing one extra memory cycle. Occasion-\nally, the OS can clear these bits for the pages that are currently in memory. We clear \nthe bits for all the pages in a page table and we let the process run for a while. The \nhardware will set the bits on for all the pages that are referenced. When we need to \nfind a page to take out of RAM we will search through the table and find a page with \na valid bit set on and a reference bit that is cleared. This page will be a good candi-\ndate for replacement. \n We can also enhance this mechanism a little bit. For each page we can keep a \nbyte or more of information about the past history of the setting of this bit, called \n(somewhat misleadingly) a  reference count. This mechanism is sometimes known \nas  aging. When we periodically clear the reference bits, we first shift the reference \ncount right one bit and shift the latest value of the page reference bit into the high-\norder position of the reference count. If a page was referenced in the last cycle, this \ncount will therefore have a high value. As refresh cycles go by in which this page \nis not referenced, the shift operation will effectively keep dividing the count by two \neach time, so the number will get smaller and smaller.  Figure 11.12  shows a refer-\nence count for a page. In the last two refresh cycles the bit shifted into the high-order \nposition was a zero, so this number is getting smaller each time. When we need to \nreplace a page we pick the page with the smallest reference count. This gives us a \nmuch better idea of the recent history of the usage of a page than a single bit that \nshows only that it has or has not been referenced in the last time interval. \n 11.5.3 Dirty pages \n When part of a program is loaded into a page and we replace it with something else, \nwe don\u2019t need to save it anywhere because we can go back to the original program \nand get the page if it is referenced again. This is one of many reasons why programs \nare not supposed to ever modify themselves while they are running. However, if a \npage contains data and some of the contents of the page have been changed since the \npage was brought into memory, then we can\u2019t just replace the page\u2014we must save \n2 This unfortunate term has no reference to the system clock. It refers to the idea that when the OS \nreaches the end of the page reference list it simply starts over, much as a clock sweeps past 12 and goes \nback to 1. \nPage reference bit\nValid bit\n1\n0\nFIGURE 11.11 \nThe page reference \nand valid bits.\nelm49810_ch11_225-254.indd   242\nelm49810_ch11_225-254.indd   242\n12/8/08   5:00:38 PM\n12/8/08   5:00:38 PM\n",
        "category": "Category"
    },
    {
        "id": "276",
        "title": "Title for Chunk 276",
        "content": "Confirming Pages\n \nChapter 11  Advanced Memory Management  \n243\nthe data currently in the page in case it is referenced again. We refer to pages that \nhave been modified as  dirty pages. We will write those dirty pages out to secondary \nstorage in a special place. This place is variously called a  swap file or a  backing \nstore. This swap file therefore acts as an extension of the primary memory of the \nsystem. This is the origin of the term  virtual memory. The swap file can be many \ntimes larger than the primary memory. In some OSs this file is literally a file in the \nnormal file space and in others it is in a special block of disk space that lies outside \nthe regular file system. In either case it is accessed in such a special way by the OS \nthat accesses to it do not go through the normal file system interface, but use raw \nmode I/O routines. With some OSs there is only one such file. With others it is pos-\nsible to place separate swap files on separate drives to increase performance. \n 11.5.4 More page replacement algorithms \n Modern OSs use a variety of algorithms to try to optimize page replacement.  One such \nalgorithm is called the  second chance algorithm. It is a modification of the clock \nalgorithm, which looks through the page table in the manner that we first described, \nlooking for a page that has not been referenced. However, as it checks each page, \nif it finds the reference bit set, then it clears it. In this way it updates the reference \nbits to reflect a later time than the latest reference refresh cycle. As it moves through \nthe page table, if it does not find any pages that are free on the first pass, then it will \nfind some on the second pass. In some OSs this searching for pages is done by a \nbackground process rather than by the page replacement process. If the free memory \nspace in the system is very low, then the OS will run the background process more \noften and for a longer time than if there is plenty of memory available. It will run less \noften and for a shorter time if the free memory is not an immediate cause for concern. \n Background operations are chores that are done when there are no high-priority pro-\ncesses in the ready state. Instructions that are executed in a background task are thus \nnot executed at the expense of any user process, so they are more or less free. \n It is worth noting that replacing a dirty page is twice as expensive as replacing \na read-only page or a clean page. This is because the OS must make two accesses \nto the disk and the disk is roughly 1\u201310,000 times slower than the primary memory. \nTherefore, we can afford to burn lots of CPU cycles trying to figure out which is the \n\u201cbest\u201d page to replace given what is known at the time. One way we can see such \nan expenditure of processing resources to save I/O is to enhance the second chance \nPage reference bit\nReference count\nShift right every time\nthe reference bit is cleared\nValid bit\n1\n0\n0\n0\n1\n1\n1\n1\n1\n1\nFIGURE 11.12 \nA page table entry \nand associated \nreference count.\nelm49810_ch11_225-254.indd   243\nelm49810_ch11_225-254.indd   243\n12/8/08   5:00:38 PM\n12/8/08   5:00:38 PM\n",
        "category": "Category"
    },
    {
        "id": "277",
        "title": "Title for Chunk 277",
        "content": "Confirming Pages\n244 \nPart 3 CPU and Memory Management\nalgorithm by using the dirty bit in conjunction with the reference bit. This algorithm \nis sometimes known as the  enhanced second chance algorithm and sometimes as \nthe  not recently used (NRU) or  not used recently (NUR) algorithm. In this case \nwe will divide the pages into four classes according to the settings of these two bits: \n(1) clean and unreferenced, (2) dirty but unreferenced (the referenced bit has been \ncleared since the page was modified), (3) clean but referenced, and (4) dirty and \nreferenced. We first look through the page table for entries in the first class to find \na page that is unreferenced and clean. We can use this page immediately. If we do \nnot find a page in this class then we look through the table again for class two, and \nso forth. By the fourth pass we are assured to find a page, but we usually will have \nfound a better one before then. \n One question that arises in demand paging systems is how to choose the process \nthe OS should take a replacement page from. There are two possibilities. Either the \nOS can select the page only from the process that caused the fault ( local replace-\nment ) or it can select the page from any process ( global replacement ). We would \nlike for programmers to write programs that use the fewest resources. If a program-\nmer writes a program that generates fewer page faults, then his programs should run \nfaster. With local replacement a poorly performing program will hurt itself the most. \nWith global replacement a poorly written program can hurt other processes by hav-\ning too large a working space and therefore generating too many page faults. As a \nresult, a program that is well designed and generates fewer page faults can be penal-\nized by another, less well designed program that generates many page faults. Hav-\ning a background process that runs the second chance algorithm to identify suspect \npages works well with global replacement. UNIX and related systems generally use \nglobal replacement and the Windows NT family uses local replacement. \n Page replacement algorithms are an area where much research is ongoing because \nof the very dynamic nature of both RAM and hard disks. As the sizes, speeds, and \ncosts are changing, the tradeoffs change and different algorithms become useful. \n 11.5.5 How many pages for each process? \n When an OS is being designed with demand paging, we are not going to let pro-\ngrams grow indefinitely in RAM. For one thing, as we saw in the discussion on the \nworking set concept, eventually there will be pages in memory that the program \nwill not reference again. There will be others that it will not need for some time, \nbut that we could profitably let another process use for now, reloading them again \nwhen we need them. So the question arises of how many pages each process should \nbe allowed to use. Different schemes are commonly used to set this limit. To begin \nwith, there is some minimum set below which we don\u2019t want a program to fall. For \nexample, a common type of instruction on some machines is a memory-to-memory \noperation. In this case, the instruction itself may span across a page boundary so \nthat we need two pages just to access the instruction. Both the source and the target \noperands may also span a page boundary, so that on this type of machine there is an \nabsolute lower limit of six pages for a single process. Even in this situation a pro-\ngram will likely have a working set that is larger than that. But what is a reasonable \nupper limit? \nelm49810_ch11_225-254.indd   244\nelm49810_ch11_225-254.indd   244\n12/8/08   5:00:39 PM\n12/8/08   5:00:39 PM\n",
        "category": "Category"
    },
    {
        "id": "278",
        "title": "Title for Chunk 278",
        "content": "Confirming Pages\n \nChapter 11  Advanced Memory Management  \n245\n We could study running programs on a prototype system and set some arbitrary \nlimit. But, if there are not enough processes running to fill up all of the available \nmemory with pages, then we will produce page faults when we don\u2019t need to. So \nsetting an arbitrary limit is not a good idea. We can make the system a little more \ndynamic by simply dividing the number of available pages by the number of pro-\ncesses that are running. This mechanism is known as  equal allocation. But this is \nnot usually reasonable either. If one of the processes was a GUI calculator and the \nother was a Web server, then we would probably reasonably infer that the Web server \nwould use extra pages to more benefit. One simple method of guessing which pro-\ngrams could use more pages is to compare the sizes of the programs. The Web server \nprogram on the disk might be 100 times larger than the calculator program, so it \nwould be reasonable to allocate 100 times as many pages to the Web server as to the \ncalculator. This mechanism is known as  proportional allocation.  But it is still not a \nperfect solution. Consider a word processor that can open either a small memo file \nor an entire book. Clearly, opening an entire book would probably effectively utilize \nmore pages than opening a small memo file. What we would like to do is have a \nmechanism that allocates pages to a process in proportion to its use of the pages. \n 11.5.6 Automatic page limit balancing \n Most modern operating systems use just such a mechanism. Most of these mecha-\nnisms are variations on the  page fault frequency (PFF) algorithm. They depend \non the idea that the page fault rate of a process is a good indicator of whether it has \nthe right number of pages. If it has too few pages, then the page fault rate will go up \nrapidly. If a process is not generating any page faults, then it may also have pages in \nRAM that it doesn\u2019t need. This mechanism sets an upper and lower limit on the page \nfault rate.  Figure 11.13  shows this mechanism at work. If the page fault rate of a \nprocess falls below the lower limit, then the OS will subtract one from the maximum \nframe count for that process. If the page fault rate exceeds the upper limit, then the \nOS will add one to the count. This mechanism will tend to keep all the processes in \nthe system running at a similar page fault rate and will allocate only as many frames \nto a process as it needs to stay in this range. \n 11.5.7 Thrashing \n Assume for a moment that we have set a hard upper limit on how many pages a process \ncan use\u2014let\u2019s call that limit  N. Suppose further that the design of this process is such \nthat it has reached a phase in its execution where its working set is more than the  N page \nlimit. Finally, assume that we are using only local page replacement so that when the \nprocess creates a page fault we will replace one of the pages that this process already \nhas mapped. This process will constantly be creating new page faults and will spend \nmost of its time waiting on the disk I/O. As a consequence it is going to get little real \nwork done and the system will see an excessive amount of disk I/O. This phenomenon \nis called  thrashing. In this case a single process is thrashing. Thrashing does not depend \non those restrictions we imagined here. If the sum of the working sets of all the running \nprocesses is greater than the real main memory, then the whole system is going to spend \nelm49810_ch11_225-254.indd   245\nelm49810_ch11_225-254.indd   245\n12/8/08   5:00:39 PM\n12/8/08   5:00:39 PM\n",
        "category": "Category"
    },
    {
        "id": "279",
        "title": "Title for Chunk 279",
        "content": "Confirming Pages\n246 \nPart 3 CPU and Memory Management\nmore time replacing pages than it will spend running processes and we will say that the \nsystem is thrashing. When it happens it can be difficult to stop because the very act of \nexecuting operations to stop some processes that might not be essential will itself cause \nmore code to be brought into memory and may actually make the situation worse.  \n 11.5.8 Page locking \n Primary memory is commonly used as a buffer for input and output operations. If \na buffer page has an I/O operation pending, then it is probably not currently being \nchanged by the application, so it might end up being selected by the paging mecha-\nnism for reuse\u2014clearly with disastrous results. In order to prevent such an unfortu-\nnate event, an OS that is doing demand paging must allow an application (usually \na device driver) to  lock a page so that the paging mechanism will not select it. The \nfollowing calls from the POSIX specification are typical for these functions:\n int  mlock  (const void  \n* addr, size_t len)  \nThis routine asks the OS to lock a range of pages from the logical address space of \nthe calling process. The range of pages to be locked starts at address  addr and is \n len bytes long. Only whole pages can be locked, so the range actually includes any \npages that contain any part of the specified address range. If the function returns suc-\ncessfully then each of the pages is bound to a physical frame and is marked to stay \nthat way. This means that a call to this function may cause page-ins if some of the \npages in the range are not currently resident and the function will block to wait for \nthem. If the function succeeds, the return value is zero. Otherwise, it is \ufffd1 and the \nglobal  errno variable is set accordingly.\n int  munlock  (const void  \n* addr, size_t len)  \nMax.\nFrames\nallocated\n0\n0\nPage fault frequency\nMax.\nAbove page fault\nrate maximum\u2014add\nframes\nPage fault\nrate\nBelow page fault rate\nminimum\u2014remove frames\nFIGURE 11.13 \nAutomatic page limit \nbalancing.\nelm49810_ch11_225-254.indd   246\nelm49810_ch11_225-254.indd   246\n12/8/08   5:00:39 PM\n12/8/08   5:00:39 PM\n",
        "category": "Category"
    },
    {
        "id": "280",
        "title": "Title for Chunk 280",
        "content": "Confirming Pages\n \nChapter 11  Advanced Memory Management  \n247\nThe munlock routine asks the OS to unlock a range of pages of the calling process. \nIt is the inverse of mlock. \n 11.5.9 Clean page mechanisms \n As was mentioned, it is important to use a page for replacement that is clean rather \nthan a dirty page so that the dirty page does not have to be written to the swap file. \nIn addition, because the disk is 1\u201310,000 times slower than main memory, we can \nspend many instructions trying to avoid one disk I/O operation. Alternatively, we \ncan try to do some of the disk operations in the background rather than when we are \nwaiting for a page to be loaded. \n We can lessen the impact of the use of a dirty page by keeping available for use \na pool of free frames that are clean. When the page replacement algorithm selects a \ndirty page as the victim for replacement, the OS can use one of the clean frames from \nthe pool. Then in the background the contents of the dirty page can be written out to \nthe disk. When it is clean then the frame can be placed in the pool. \n Another task that can be done in the background is to clean pages that are dirty. \nA background task can look for pages that have not been referenced lately (and thus \nare likely candidates for replacement) but that are dirty. A background write opera-\ntion can be started for those pages so that when they are selected for replacement \nthey will be clean. Of course, the page may become dirty again while the process \nruns, but we are doing this work in the background at the lowest priority so we are \nnot wasting I/O or CPU cycles that could be spent doing something else. \n 11.5.10 Program design and page fault rates \n In general, we say that virtual memory and demand paging are transparent to an \napplication program, However, there are a few observations about how program \ndesign can affect the rate of page faults. Consider, for example, searching a large \ntable. Assume that the table is large enough that it covers many pages and that it is to \nbe searched many times for different items. With a binary search we will hit the mid-\ndle page every time we start a search. Then we will likely hit one of two other pages, \neither in the first half or the second half. These three pages at least will probably stay \nin memory most of the time so we will rarely get a page fault on these pages. With \na hash table search, however, almost every lookup will cause a different page to be \nread in since the basic intent of hash tables is to randomly address the entire table in \nhopes of hitting the desired entry with the first reference. So very large hash tables \ndo not work well with virtual memory systems. \n Next, consider a portion of a program that does a matrix multiplication: 3\n for(i \ufffd 0;i<500;i \ufffd \ufffd )\n      for(j \ufffd 0;j<500;j \ufffd \ufffd )\n            for(k \ufffd 0;k<500;k \ufffd \ufffd )\n                  x[i][j] \ufffd x[i][j] \ufffd y[i][k]*z[k][j];\n3 Patterson, David A. and John L. Hennessy,  Computer Organization and Design: The Hardware/\nSoftware Interface, Morgan Kaufmann, 2004, p. 617. \nelm49810_ch11_225-254.indd   247\nelm49810_ch11_225-254.indd   247\n12/8/08   5:00:39 PM\n12/8/08   5:00:39 PM\n",
        "category": "Category"
    },
    {
        "id": "281",
        "title": "Title for Chunk 281",
        "content": "Confirming Pages\n248 \nPart 3 CPU and Memory Management\n When this code was run with arrays of double precision floating point numbers on a \nSilicon Graphics system with a MIPS R4000 processor and a 1 MB cache, the run-\nning time was 77.2 seconds. \n We can make a small change to vary the order of the loops so that the innermost \nloop is stepping through the memory in the same page like this: \n for(k \ufffd 0;k<500;k \ufffd \ufffd )\n      for(j \ufffd 0;j<500;j \ufffd \ufffd )\n            for(i \ufffd 0;i<500;i \ufffd \ufffd )\n                  x[i][j] \ufffd x[i][j] \ufffd y[i][k]*z[k][j];  \nThe problem with the first example is that the array is stored in memory so that \nadjacent row elements (the first subscript) are contiguous. Since the variable that is \ncontrolling the innermost loop is not the row subscript, then each reference will be \nto a different page. When we change the loops as in the second example, then each \niteration is referencing the same page and the runtime decreases to 44.2 seconds due \nto the lower number of page faults. \n So it is true that in general the action of virtual memory and demand paging \nare transparent to applications in the sense that the programmer does not have to \npay a great deal of attention to the mechanism\u2014this code will work correctly in \neither format. But as we have just seen, this doesn\u2019t mean that they have no effect \nin every case.  \n 11.6 SPECIAL MEMORY MANAGEMENT TOPICS \n 11.6.1 Sharing memory among processes \n Both segmentation and paging allow for portions of memory to be shared between \nprocesses. This can result in large savings in memory. For example, on a mainframe \nsupporting many users it might be common for many users to be running a word pro-\ncessing program at the same time. With paging the page tables for many processes \ncan both point to the same frames in memory so that only one copy of the program \ncode is actually resident. Similarly, with segmentation the segment tables for many \nprocesses can point to the same physical memory segment. While this can be handy, \nit can also cause problems. If the portions of memory that are being shared are data \nsegments, then the individual processes will be changing some of the pages. This \nmay or may not be desired. Several processes might be using shared memory to \ncommunicate among themselves. In this case, we would want each process to see all \nthe changes to the pages, so they should be looking at the same frames in physical \nmemory. But consider the case where one process forks itself. Initially, it would be \nideal to share the entire physical address space between the two processes. But as \nthey run, changes made by one process should not be seen by the other process. In \norder to allow this to happen, an OS can use a mechanism known as  copy on write. \nInitially, the two processes will be mapped to the same physical frames. But the page \n(or segment) tables will be set as read only. If either process tries to write to a shared \nportion of the memory, then an interrupt will occur. When this happens the memory \nelm49810_ch11_225-254.indd   248\nelm49810_ch11_225-254.indd   248\n12/8/08   5:00:40 PM\n12/8/08   5:00:40 PM\n",
        "category": "Category"
    },
    {
        "id": "282",
        "title": "Title for Chunk 282",
        "content": "Confirming Pages\n \nChapter 11  Advanced Memory Management  \n249\nmanagement subsystem will make a separate copy of the shared portion for each \nprocess and remove the write protection flag from the table, allowing each process to \nsee only its own version of the data. \n Solaris supports access to a shared memory block (Solaris calls it a segment) \nusing the shmget() routine. One process creates a shared block with the first call. The \nblock is described by a control structure with a unique ID that points to an area of \nphysical memory. The identifier of the block is called the shmid. \n Here is the call used to access a shared memory block in Solaris:\n int shmget (key_t key, size_t size, int shmflg);  \n The key argument is either of type key_t or is IPC_PRIVATE. It is the numeric key \nto be assigned to the returned shared memory block. The size argument is the size \nin bytes of the requested block. The shmflg argument specifies the starting access \npermissions and creation control flags. \n If the call succeeds, it returns an ID to identify the shared memory block. This \ncall can also be used to get the ID of an existing shared block by another process. \nThe following code illustrates shmget():\n key_t key;           /* key to be passed to shmget()               */\nint shmflg;          /* shmflg to be passed to shmget()     */\nint shmid;           /* return value from shmget()                          */\nint size;            /* size to be passed to shmget()           */\nshm_id  \ufffd shmget(IPC_PRIVATE, size, shmflg);\nif (shm_id<0) {\n     printf(\u201cshmget error\\n\u201d);\n     exit(1);\n}\n Server and clients can be created with a fork call or can be unrelated. For a child \nprocess, if a shared memory block is requested and attached prior to forking the \nchild, then the server may want to use IPC_PRIVATE since the child has a copy of \nthe server\u2019s address space, which includes the attached shared block. However, if the \nserver and clients are separate processes, using IPC_PRIVATE is not a good idea \nsince the clients will not know the key. \n 11.6.2 Memory mapped files \n Most modern OSs allow a special mode of memory sharing referred to as  memory \nmapped files. In this mode a process will ask the OS to open a file and associate all \nor part of the data in the file with a region of the logical address space of the process. \nThen the process can refer to the information in that space as an array or through \nmemory pointers. There are two main advantages of such a system. The first is that \nthe process does not have to use I/O statements to access the data\u2014the demand pag-\ning system takes care of accessing the right data from the file. The second advantage \nis that two or more processes can ask the OS for access to the same file at the same \ntime. The same memory frames will be mapped into the logical address spaces of \nelm49810_ch11_225-254.indd   249\nelm49810_ch11_225-254.indd   249\n12/8/08   5:00:40 PM\n12/8/08   5:00:40 PM\n",
        "category": "Category"
    },
    {
        "id": "283",
        "title": "Title for Chunk 283",
        "content": "Confirming Pages\n250 \nPart 3 CPU and Memory Management\nboth processes, allowing them to share access to the memory. This mechanism there-\nfore provides a simple mechanism for sharing data between two processes. Of course, \nthe processes may need to use synchronization techniques to avoid interfering with \none another. In addition, if the real purpose of the \u201cshared file\u201d is to provide a shared \nmemory region between two or more processes, the shared file does not actually need \nto reside on the file system as a file. \n As an example, here is how memory mapped objects (including files) can be \ncreated under the Windows Win32 libraries: \n HANDLE WINAPI CreateFileMapping(\n  _in HANDLE hFile,\n  _in_opt LPSECURITY_ATTRIBUTES lpAttributes,\n  __in DWORD flProtect,\n  __in DWORD dwMaximumSizeHigh,\n  __in DWORD dwMaximumSizeLow,\n  _in_opt LPCTSTR lpName\n);\n The meanings of some of the parameters are:\n \ufffd hFile\u2014A handle to the file from which to create a mapping object. If hFile is \n\ufffd1, the call must also give a size for the object in the dwMaximumSizeHigh \nand dwMaximumSizeLow parameters and a temporary file is created in the sys-\ntem paging file instead of mapping to a file system file. \n \ufffd A pointer to a security descriptor structure for the object that contains access \ncontrol lists (ACL) and other security information. \n \ufffd flProtect\u2014Protection to be applied to the object\n \n\ufffd PAGE_READONLY \n \n\ufffd PAGE_READWRITE \n \n\ufffd PAGE_WRITECOPY (copy on write) \n \n\ufffd PAGE_EXECUTE_READ \n \n\ufffd PAGE_EXECUTE_READWRITE \n \n\ufffd PAGE_EXECUTE_WRITECOPY \n \n\ufffd Etc. \n \ufffd dwMaximumSizeHigh\u2014High-order DWORD of max size of the object. \n \ufffd dwMaximumSizeLow\u2014Low-order DWORD of max size of the object. \n \ufffd lpName\u2014The name of the file to be mapped. \n 11.6.3 Windows XP prefetch files \n Various OSs have developed some interesting tricks to optimize the use of demand \npaging. One interesting technique used in Windows XP is designed to speed up the \nloading and initialization of programs. The idea is that when a program is loading \nit will go through the same sequence of instructions each time. Therefore, it will \ngenerate the same sequence of page faults. Furthermore, it will tend to generate \nthese faults in clusters. For example, as the code executes it will pass through a \ncontiguous sequence of pages in the code. As it does so it will be generating other \nelm49810_ch11_225-254.indd   250\nelm49810_ch11_225-254.indd   250\n12/8/08   5:00:40 PM\n12/8/08   5:00:40 PM\n",
        "category": "Category"
    },
    {
        "id": "284",
        "title": "Title for Chunk 284",
        "content": "Confirming Pages\n \nChapter 11  Advanced Memory Management  \n251\npage faults as it calls subroutines and references data in other pages. As a result, \nthe disk drive gets a workout seeking back and forth to fetch these pages in random \norder. XP (and sometimes other OSs as well) uses a better technique. The first time \na program starts, the OS will keep track of all the page faults it makes in the first \nfew minutes. It will record those page faults in a file called a  prefetch file. Later, \nin the background it will sort that file so that subsequently when the program is \nlaunched the OS can fetch all the code pages that will be used as the program ini-\ntializes. It can fetch all the needed pages of the main program in a few large read \noperations. Then it will move to another place on the disk to fetch all the subrou-\ntine code, then move to another place to fetch those data pages that will be used, \nand so forth. This technique will save a lot of page fault interrupts. It will also save \na lot of disk head movement and rotational delays as larger chunks of disk storage \nare read in single operations.  \n 11.6.4 Symbian memory management \n The Symbian OS was created for use in cell phones. This OS has a unique way of \nutilizing the paging hardware found in modern CPUs. The problem they faced was \nthis: In a cell phone it is presumed that there is no secondary storage\u2014no disk drive. \nAs was discussed in Chapter 4 on the Palm OS, all the programs that are stored in \nthe phone are always in primary memory. Therefore, primary memory is even more \nscarce than in most systems, especially given the need to maintain a low power bud-\nget in cell phones. But the processor architecture used in the phone includes paging \nhardware since most system environments do include secondary storage. In most \nOSs there are three functions that the memory management hardware is supposed to \nperform: (1) dynamic relocation of the program, (2) restriction of addressing to the \nspace reserved for a given program, and (3) allowing for random dynamic loading \nof any page from secondary storage into primary storage. In the Symbian OS the \ndynamic loading function is not needed. In addition, storing a page table for each \nprogram would take up valuable RAM. So the problem faced by the Symbian devel-\nopers was how to use the hardware most efficiently to do the two jobs that remained. \nThe solution adopted by the Symbian OS developers was to use a single-page table \nfor all the processes in the system. \n The single-page table is modified when a context change is needed and a pro-\ngram is about to be put into run state.  Figure 11.14  shows how this change is made. \nIn  Figure 11.14a  we see the page table when process B is running. The page table \nhas a normal mapping for the frames of both process A and process B and for their \nrespective thread data pages. But there is also a reserved section of the page table \nthat always points to the frames for the process that is currently executing. When it \nis time to make a context switch and start executing process A, the OS will copy the \npage table entries for process A into the page table entries reserved for the running \nprocess. This is shown in  Figure 11.14b  where we see that the page table has been \nchanged to run process A. The result is that pointers to the frames of the running pro-\ncess always appear in two places in the page table, once where it actually resides and \nonce where the running process appears. This allows the paging hardware to support \nelm49810_ch11_225-254.indd   251\nelm49810_ch11_225-254.indd   251\n12/8/08   5:00:40 PM\n12/8/08   5:00:40 PM\n",
        "category": "Category"
    },
    {
        "id": "285",
        "title": "Title for Chunk 285",
        "content": "Confirming Pages\n252 \nPart 3 CPU and Memory Management\nthe dynamic relocation function needed to simplify code generation and still restrict \nprogram access to its own memory areas without consuming extra RAM for a page \ntable per process. \nLogical\nPhysical\nThread A2 Data\nThread A1 Data\nProcess A\nThread B1 Data\nProcess B\nThread B1 Data\nProcess B\n(a) Process B is running\n(b) Process A is running\n29\n21\n9\n43\n17\n43\n17\nLogical\nPhysical\nThread A2 Data\nThread A1 Data\nProcess A\nThread B1 Data\nProcess B\nThread A2 Data\nThread A1 Data\nProcess A\n29\n21\n9\n43\n17\n21\n29\n9\nThe running process is\nalways mapped here.\nFIGURE 11.14 \nSymbian memory \npage table.\n 11.7 SUMMARY \n In this chapter we discussed the designs of memory \nmanagement through paging and segmentation sys-\ntems and their hardware requirements as well as a \ncombination of segmentation and paging. We then \ndiscussed demand paging memory management. \nWe examined the effect of demand paging and some \nproblems that arose in its implementation. Through-\nout this discussion we also focused on the hardware \nrequired to support these OS techniques. We ended \nwith a section that covered some subtopics related \nto advanced memory management. \n BIBLIOGRAPHY \n Belady, L. A., \u201cA Study of Replacement Algorithms for \nVirtual Storage Computers,\u201d  IBM Systems Journal, \nVol. 5, No. 2, 1966, pp. 78\u2013101. \n Belady, L. A., and C. J. Kuehner, \u201cDynamic Space \nSharing in Computer Systems,\u201d  Communications of \nthe ACM, Vol. 12, No. 5, May 1969, pp. 282\u2013288. \n Carr, R. W., and J. L. Hennessy, \u201cWSClock\u2014A \nSimple and Effective Algorithm for Virtual \nMemory Management,\u201d  Proceedings of the Eighth \nSymposium on Operating Systems Principles, \nVol. 15, No. 5, December 1981, pp. 87\u201395. \n Denning, P. J., \u201cThe Working Set Model for Program \nBehavior,\u201d  Communications of the ACM, Vol. 11, \nNo. 5, May 1968, pp. 323\u2013333. \n Denning, P. J., \u201cVirtual Memory,\u201d  ACM Computing \nSurveys, Vol. 2, No. 3, September 1970, pp. 153\u2013189.  \n Denning, P. J., \u201cWorking Sets Past and Present,\u201d  IEEE \nTransactions on Software Engineering, Vol. SE-6, \nNo. 1, January 1980, pp. 64\u201384. \n Mattson, R. L., J. Gecsie, D. R. Slutz, and I. L. Traiger, \n\u201cEvaluation Techniques for Storage Hierarchies,\u201d  IBM \nSystems Journal, Vol. 9, No. 2, 1970, pp. 78\u2013117.  \nelm49810_ch11_225-254.indd   252\nelm49810_ch11_225-254.indd   252\n12/8/08   5:00:41 PM\n12/8/08   5:00:41 PM\n",
        "category": "Category"
    },
    {
        "id": "286",
        "title": "Title for Chunk 286",
        "content": "Confirming Pages\n \nChapter 11  Advanced Memory Management  \n253\n Prieve, B. G., and R. S. Fabry, \u201cVMIN\u2014An Optimal \nVariable Space Page Replacement Algorithm,\u201d \n Communications of the ACM, Vol. 19, No. 5, May \n1976, pp. 295\u2013297. \n Stephenson, C. J., \u201cFast Fits: New Methods for \nDynamic Storage Allocation,\u201d  Proceedings of \nthe Ninth Symposium on Operating Systems \nPrinciples, ACM, Vol. 17, No. 5, October 1983, \npp. 30\u201332.  \n The bibliography for this chapter overlaps considerably \nwith the previous chapter.  \n WEB RESOURCE \n http://www.symbian.com (Symbian OS) \n REVIEW QUESTIONS \n 11.1 What hardware development solved the problem \nof external fragmentation? \n 11.2 While the paging hardware is translating a logical \npage address to a physical frame address, what \nhappens to the displacement part of the address?  \n 11.3 When we first looked at translating memory refer-\nences through a table that was also in memory, \nwhat was the effect on the effective access time of \nmemory? What did we do about it? \n 11.4 Using page tables, we need some way to know \nwhere the end of the logical address space is in \nthe table. We discussed two different techniques \nfor doing this. What mechanisms did the two \ntechniques use? Under what circumstance is one \ntechnique preferred over another? \n 11.5 Eventually, page tables started to grow very big \nand sparse. What technique was employed to \nsolve this problem? \n 11.6 An alternative to paging is segmentation. Briefly \ndescribe this technique. \n 11.7 What is the basic idea behind demand paging? \n 11.8 When running demand paging, how does the OS \nknow a page is needed by a process? \n 11.9 What is the \u201cworking set\u201d of a process? \n 11.10 Why do we worry about page replacement algo-\nrithms so much? \n 11.11 Why do we prefer not to replace dirty pages when \na page fault occurs? \n 11.12 When an OS is selecting a page to replace in \na demand paging system, what is the differ-\nence between local replacement and global \nreplacement? \n 11.13 What is the minimum number of pages that a pro-\ncess needs to run? \n 11.14 If a process frequently starts thrashing, what \nshould the architect of the process do to improve \nthe situation? \n 11.15 What kind of background operations can an OS \ndo to improve demand paging performance? \n 11.16 Hash tables are very poor performing structures \nas far as demand paging goes. We mentioned that \nbinary lookups were probably pretty good. What \nother basic system structure gives very good \ndemand paging performance? \n 11.17 What is the purpose of a prefetch file in Windows \nXP? \n 11.18 How are memory mapped files used by multiple \nprocesses? \n 11.19 The Symbian OS uses the paging memory hard-\nware in a very special way. Why is that? \nelm49810_ch11_225-254.indd   253\nelm49810_ch11_225-254.indd   253\n12/8/08   5:00:41 PM\n12/8/08   5:00:41 PM\n",
        "category": "Category"
    },
    {
        "id": "287",
        "title": "Title for Chunk 287",
        "content": "elm49810_ch11_225-254.indd   254\nelm49810_ch11_225-254.indd   254\n12/8/08   5:00:41 PM\n12/8/08   5:00:41 PM\n",
        "category": "Category"
    },
    {
        "id": "288",
        "title": "Title for Chunk 288",
        "content": "Confirming Pages\n255\nIn this part:\nChapter 12: File Systems\u2014Basics 257\nChapter 13: File Systems\u2014Examples and More Features 283\nChapter 14: Disk Scheduling and Input/Output Management 297\n N\not all operating systems have file systems, but any of those devices we would \nnormally think of as a computer certainly would have one. Indeed, many of \nthe devices that we might not think of as a computer may have file systems as \nwell, including many gaming systems, cell phones, music players, and personal digi-\ntal assistants. This part of the text covers those aspects of an OS that are concerned \nwith the management of secondary storage and the file systems found thereon.\nChapter 12 discusses the layout of typical hard drives and explains the basic \nconcerns that a file system has. The topics covered here start with the concepts of \ndirectories and how they are laid out in modern file systems. Then the chapter dis-\ncusses the concept of file access methods, including sequential, random, and indexed \naccess. Next, it covers the tracking of free space within a file system and the layout \n(allocation) of the files themselves.\nChapter 13 first covers several modern file systems as case studies to show how \nthe individual mechanisms discussed in Chapter 12 are used in real OSs. It then cov-\ners advanced file system features often found in modern OSs but not so fundamen-\ntal to the normal application. These topics include virtual file systems/redirection, \nmemory mapped files, file system utilities, and log-based file systems.\nChapter 14 moves to a lower level that is normally isolated from the file system. \nIt discusses the entire input/output management subsection present in any OS. It \ndiscusses various classes of I/O devices, including those used for secondary storage. \nThis chapter is included in this part of the text since secondary storage management \nis such a dominant use of the I/O subsystem. Other aspects of I/O are treated sepa-\nrately in the chapters on networking, for example.\nA Depth-Oriented Presentation \nof OS Concepts: File Systems \nand Input/Output\nPart\nPart 4\nelm49810_ch12_255-282 New.indd   255\nelm49810_ch12_255-282 New.indd   255\n12/10/08   9:41:24 PM\n12/10/08   9:41:24 PM\n",
        "category": "Category"
    },
    {
        "id": "289",
        "title": "Title for Chunk 289",
        "content": "Confirming Pages\n256\nelm49810_ch12_255-282 New.indd   256\nelm49810_ch12_255-282 New.indd   256\n12/10/08   9:41:25 PM\n12/10/08   9:41:25 PM\n",
        "category": "Category"
    },
    {
        "id": "290",
        "title": "Title for Chunk 290",
        "content": "Confirming Pages\n113\n Chapter \n Chapter \n A Multiple-User Operating \nSystem \n In this chapter: \n \n6.1 Introduction 113\n \n6.2 The Multiuser OS Environment 121\n \n6.3 Processes and Threads 123\n \n6.4 Summary  125\n I\nn this chapter, we discuss an operating system that is still more capable than the \nMac OS discussed in the previous chapter, at least as far as the versions of the \nMac OS prior to OS X. This is the Linux\u2122 Operating System. The intent of this \nchapter is not to discuss the Linux OS in all aspects, but rather to focus on those \npoints where the multiuser requirement of the OS lead to the inclusion of some addi-\ntional features. We return to Linux in Chapter 19 in a more complete case study that \nexamines the decisions made about the individual mechanisms for supporting the \nmajor system modules. \n We start this chapter in Section 6.1 with an overview of Linux and some back-\nground about its history. In Section 6.2 we discuss the nature of a multiuser OS and \nhow this design decision impacts the features of an OS. Next is Section 6.3 where we \ndiscuss the scheduling of processes and tasks in Linux. We have seen some of these \nfeatures in other OSs, but Linux is the first OS we have studied that started out with \na full implementation of all the concepts of both processes and threads. We conclude \nwith a chapter summary in Section 6.4. \n6.1 INTRODUCTION \n The design of Linux is based on UNIX, an earlier OS that was originally developed \nprimarily for supporting several users at remote terminals, usually display screens \nand keyboards with a serial data cable. These terminals were connected to a central-\nized computer system, perhaps even over a modem and phone line. UNIX was origi-\nnally created to give a large computer development environment feeling to a much \nless expensive mini-computer. (It was also developed as something of a hobby for its \n 6  6 \nelm49810_ch06_113-126.indd   113\nelm49810_ch06_113-126.indd   113\n12/10/08   5:56:43 PM\n12/10/08   5:56:43 PM\n",
        "category": "Category"
    },
    {
        "id": "291",
        "title": "Title for Chunk 291",
        "content": "Rev. Confirming Pages\n114 \nPart 2 Building Operating Systems Incrementally: A Breadth-Oriented Spiral Approach\ntwo creators, who have won very prestigious computing awards for the concept of \nUNIX.) There are also versions of Linux that are intended for many other situations. \nAmong these would be systems designed to:\n \ufffd support a single user at the console of a personal computer \n \ufffd act as servers for various remotely accessed functions such as file, print, and \ndirectory services \n \ufffd serve as platforms for other higher-level services such as database management \nsystems, Hypertext Transport Protocol (HTTP, or Web) servers, and File Trans-\nfer Protocol (ftp) servers \n \ufffd act as routers in networks \n \ufffd control real-time systems, and \n \ufffd be embedded in equipment where there is no direct human user. \n 6.1.1 The history of a multiuser OS \n Linux was inspired by UNIX\u2122, so it makes sense to discuss briefly the origins of \nUNIX before addressing Linux. In 1969, Ken Thompson of Bell Laboratories began \nexperimenting on creating a multiuser, multitasking operating system using a cast-\noff PDP-7 mini-computer. He teamed up with Dennis Ritchie and they and the other \nmembers of their small research group produced the first versions of UNIX, then \ncalled Unics as a dig at the Multics project on which they had both worked. (Multics \nwas a giant project with over a hundred people working on it whereas a handful of \nprogrammers created UNIX.) Early versions of UNIX were written in assembly lan-\nguage, but the third version was written in a programming language called C, which \nwas crafted by Ritchie expressly as a programming language for writing operating \nsystems. C was designed as a fairly low-level, simple language that allows the pro-\ngrammer to ignore many hardware details in most cases, but still write programs in \nsuch a way that the compiler can take advantage of special hardware features. UNIX \nwas a proprietary product of AT&T, the parent company of Bell Labs, where it was \ndeveloped. AT&T made very reasonable charges for licenses to UNIX for academic \nuse. UNIX version 6 (around 1976) was free for universities and version 7 cost \n$100. This included all the source code, freely modifiable. However, government \nlabs and commercial entities had to pay $21,000. This was not an unreasonable price \nat the time for an operating system for a machine that cost hundreds of thousands \nor millions of dollars. And for universities the academic license was an irresistible \ndeal since they had eager students who could port it to other machines or \u201cimprove\u201d \nit as they saw fit. This was especially true of the utility programs that are typically \ndistributed with an OS\u2014such things as text editors, for example. \n The allure of UNIX, a simple, consistent, small (it ran in a few kilobytes of \nmemory and the source code was only several thousand lines of mostly C), and yet \nvery flexible OS was compelling. Several companies and research groups wrote \nUNIX \u201cwork-a-likes,\u201d they worked like UNIX with the same OS system calls and \nOS utilities, but the source code was completely rewritten (to avoid AT&T property, \nand avoid needing to license anything from AT&T). \n In 1991, Linus Torvalds, a University of Helsinki (Finland) computer science \nstudent, was familiar with UNIX from his classwork and was looking for a UNIX-like \nelm49810_ch06_113-126.indd   114\nelm49810_ch06_113-126.indd   114\n12/22/08   1:03:05 PM\n12/22/08   1:03:05 PM\n",
        "category": "Category"
    },
    {
        "id": "292",
        "title": "Title for Chunk 292",
        "content": "Confirming Pages\n \nChapter 6  A Multiple-User Operating System  \n115\nOS to use at home. One of the few free options (it came with a textbook) was MINIX, \na limited UNIX-like system written by Andrew Tanenbaum for educational purposes. \nThere were other free OSs that were UNIX-like, but most weren\u2019t mature or stable yet, \nor required higher-end hardware than most users had at home. While Torvalds used \nMINIX, he felt that there were many features missing, so he decided to rewrite MINIX. \nHe initially kept the file system design but later replaced it with his own. MINIX ran \non a very basic 8088 CPU and floppy disks, allowing it to run on very inexpensive \nhardware systems. But it did not take advantage of the power of newer processors and \nhard disks. Torvalds used an Intel 386-based PC and started to add features and eventu-\nally wrote a new OS, initially using the C compiler on MINIX to do the development. \nBefore long, Linux had become a \u201creal\u201d OS. The resulting Linux kernel contains no \nUNIX or MINIX code. Rather, it is a complete rewrite based on UNIX interfaces and \nutilities. Linux is actually only the kernel of an OS. It is built with, and uses a lot of, \nthe GNU (GNU\u2019s Not UNIX\u2122) software produced by members of the Free Software \nFoundation in Cambridge, Massachusetts, for the utilities and applications that must \ncome with a complete OS. Indeed, the bulk of the OS outside the kernel is also part \nof the GNU project. So, one of the more interesting, important features of the Linux \nsystem is that it is not proprietary to a single company. All of the OSs that we have \ndiscussed to this point are (or were) owned by a company. They consider the source \ncode to be a trade secret and generally do not release it to the public. Linux and the \nGNU software are \u201copen source\u201d projects.  1 The source code is available for free, and \nusers are encouraged to correct bugs and to enhance the code. There is a wide-ranging \ndebate as to whether the proprietary process produces better, more robust OSs than \nthe open source process or vice versa. \n Although it is accurate to say that Linux provides a free version of an OS that \nsupports UNIX operations, this is not as clear or useful a statement as it might appear \nto be on the surface. For one thing, (in part because of the almost free price for the \nsource code for UNIX to universities), the history of UNIX development has been \nreplete with variants. Many programmers who were porting it to another environ-\nment could not resist the temptation to \u201cimprove\u201d something or to add some favor-\nite feature. Not until the late 1980s was a fairly standard UNIX API created by an \nindependent IEEE committee. This standard is known as POSIX. Unfortunately the \nIEEE charged substantial fees for access to this standard, with the result that the \ndevelopers of the free variants of UNIX-like OSs were usually not able to afford to \nhave their products certified by the IEEE as being POSIX compliant. Later work \nhas produced another specification that is more accessible to small companies or to \nunpaid developers, the  Single UNIX Specification ( SUS ). \n When Linux was first made available, a would-be Linux user needed to be some-\nthing of a UNIX expert, knowing what libraries and executables were needed to suc-\ncessfully get Linux to boot and run as well as the details concerning configuration and \nplacement of some of the files in the system. Many potential users just wanted the sys-\ntem to use for their work, hobbies, or research and were not interested in working on \nthe kernel or in becoming an expert on building the system from scratch. Linux source \n1 There are many variations on the concept of \u201copen source\u201d licenses. The adherents of the various \nversions are generally adamant about the variations. We are using the term in a loose, generic sense. \nelm49810_ch06_113-126.indd   115\nelm49810_ch06_113-126.indd   115\n12/10/08   5:56:47 PM\n12/10/08   5:56:47 PM\n",
        "category": "Category"
    },
    {
        "id": "293",
        "title": "Title for Chunk 293",
        "content": "Confirming Pages\n116 \nPart 2 Building Operating Systems Incrementally: A Breadth-Oriented Spiral Approach\ncode is free, and at the same time, anyone can make a copy of the system and sell the \ncopy. As a result, individuals, universities, and companies began creating  distribu-\ntions of Linux. A Linux distribution usually includes compiled versions of the Linux \nkernel and GNU system libraries and utility programs. Many distributions provide an \ninstall procedure like that provided with other OSs that will customize the OS for a \ngiven machine. The distributions were originally just a convenience, but today they \nhave become the usual installation method even for UNIX or Linux gurus because \nof the savings in time and the decreased probability of overlooking some small but \nimportant detail in building the system from the source. Now, most distributions of \nLinux are certified as compliant with SUS. There are many different distributions of \nLinux designed for special purposes, such as booting from a device other than a hard \ndrive, using Linux as a server, or supporting different languages as the default. \n The management of a Linux system is an interesting topic in itself. One of the \nkey features of Linux is the numbering of the various releases. The major  release \nnumber is the first integer. The preliminary versions that Torvalds first released were \nrelease 0. The current release is 2. The next part of the number is odd for develop-\nment releases (sometimes called \u201chacker\u201d releases) and even for production releases \n(sometimes called \u201cuser\u201d releases). So, for example, the current production release \nof Linux is 2.6 and the current development release is 2.7. Another integer is added \nto distinguish various patch levels. \n Linux has really outgrown its very humble beginnings. It started as an OS kernel \nthat was only available on single processor Intel 386 CPUs (or better) systems. Now \nit is available on almost every hardware platform available, including, in many cases, \nplatforms where the hardware vendor also offers a proprietary OS, sometimes even a \nversion of UNIX. (Naturally, some of the implementations are better than others.) For \nexample, IBM has adopted Linux with considerable enthusiasm. They have ported it \nto all four of their E-series systems lines. This strategy takes advantage of the porta-\nbility of applications using Linux. IBM now makes a greater portion of their income \nfrom writing, installing, and supporting applications than they do from selling hard-\nware or OSs. They quite likely often found themselves in the position of creating an \napplication on one of their four hardware product lines and then having to port the \napplication to other platforms for other customers. With Linux and Java\u2122 they can \ncreate applications one time and easily move them to other platforms, including all \nthe installation and support procedures using Linux packages, scripts, and so on.  \n 6.1.2 Basic organization of Linux \n Linux uses a  monolithic  kernel. This means that the entire kernel is loaded into a single \nprogram that contains all the modules of the OS. Every module has direct access to any \nfunction, object, or data structure in the kernel. This means that monolithic OSs are often \nfaster than microkernel OSs. The risks in this approach are several. First, all the OS code \nruns in supervisor mode so that any bug can theoretically cause more drastic problems. \nAlso, porting to new architectures is harder because the machine-specific portions are \nnot necessarily as well isolated. In addition, if the designers are not careful, the source \ncode can quickly become very complex because it is not absolutely essential to have \nclean, well-defined interfaces between the various modules as it is with a microkernel. \nelm49810_ch06_113-126.indd   116\nelm49810_ch06_113-126.indd   116\n12/10/08   5:56:47 PM\n12/10/08   5:56:47 PM\n",
        "category": "Category"
    },
    {
        "id": "294",
        "title": "Title for Chunk 294",
        "content": "Confirming Pages\n \nChapter 6  A Multiple-User Operating System  \n117\nAlso, adding support for new devices is more difficult with a monolithic kernel. Often \nit requires compiling the new driver and relinking and reloading the kernel. This obvi-\nously means that the OS has to be stopped and restarted\u2014something not appreciated in \na multiuser system or a server offering many network services or serving many users or \nboth. But modern Linux versions have overcome many of these problems, as we will see \nshortly. The organization of the Linux kernel is shown in  Figure 6.1 .  \n As was discussed earlier, another type of organization   for   an OS is to be built on a \n microkernel. Such an organization is shown in  Figure 6.2 . Again, this means that the \ncode in the kernel has been minimized to include only that part of the code that abso-\nlutely must be in the kernel in order to execute privileged instructions. These portions \ntypically include process management, basic memory management, and interprocess \ncommunication. The remainder of the functions that we normally think of as being \npart of the resident OS may be run in user mode. This organization has some benefits \nand some costs. It is easier to produce a kernel that is robust, and it is easier to port it \nto a new platform. The major cost of this organization is that it often introduces more \noverhead\u2014the interrupt handling and context switching often make the OS run slower \nthan a monolithic kernel. MINIX was designed and created as a microkernel system.  \n 6.1.3 Dynamically loadable modules \n Linux was initially envisioned to be a small, simple project. For this reason it did not \nseem to be important to go to the trouble of creating a microkernel OS. At one time in \nthe early development of Linux, Tanenbaum actually sent an email to Linus Torvalds \nthat dismissed Linux as being \u201cobsolete\u201d because of the monolithic kernel approach. \nAt that time, many in the computing science community viewed the microkernel \nI/O \nSystems\nSupport\nLayers\nProcess \nManagement\nDevice \nDrivers\nDevices\nProcess Scheduler and \nHardware-Specific Code\nCPU\nMemory \nManager\nRAM\nMemory \nManagement\nApplication \nPrograms\nKernel\nFIGURE 6.1 The Linux system architecture.\nelm49810_ch06_113-126.indd   117\nelm49810_ch06_113-126.indd   117\n12/10/08   5:56:47 PM\n12/10/08   5:56:47 PM\n",
        "category": "Category"
    },
    {
        "id": "295",
        "title": "Title for Chunk 295",
        "content": "Confirming Pages\n118 \nPart 2 Building Operating Systems Incrementally: A Breadth-Oriented Spiral Approach\napproach as a preferred approach for the reasons previously listed. As Linux became a \nviable OS alternative, Torvalds and the Linux community came up with an interesting \napproach to modify or augment a purely monolithic kernel. The key idea was intro-\nduced in version 2.0 of Linux. This version supports  dynamically loadable modules, \nor  DLMs. This concept allows the basic kernel to contain a minimum amount of func-\ntionality and be embellished by modules that can be loaded (and unloaded) after the \nsystem has started running. Many of the functions that are basic to Linux are devel-\noped as DLMs because they may not be needed in every installation. These include \nsuch functions as file systems, specific device drivers, SCSI high-level drivers (disk, \ntape, CD-ROM), network drivers, line printer drivers, and serial (tty) drivers. \n In order to support DLMs, the core kernel has to have well-defined interfaces. \nThis removes one of the significant objections to the monolithic approach. When a \nmodule is loaded it calls an OS function to \u201cregister\u201d itself with the kernel. The exact \nfunction to be called depends on the type of module being loaded. An illustrative set \nof such calls is listed in  Table 6.1 . \n One of the interesting effects about the DLM interface is that it allows software \ndevelopers to create enhancements to the Linux system for which they do not want \nto provide the source code (which is necessary to be in accordance with the various \nopen source licenses). This allows Linux to remain an open source project but still \nincorporate functions that are kept as proprietary by the developers. \nI/O \nSystems\nProcess \nManagement\nDevice \nDrivers\nProcess \nScheduler\nMemory \nManager\nHardware- \nSpecific Code\nKernel\nDevice\nCPU\nRAM\nMemory \nManagement\nApplication \nPrograms\nFIGURE 6.2 \nA microkernel system \narchitecture.\nelm49810_ch06_113-126.indd   118\nelm49810_ch06_113-126.indd   118\n12/10/08   5:56:48 PM\n12/10/08   5:56:48 PM\n",
        "category": "Category"
    },
    {
        "id": "296",
        "title": "Title for Chunk 296",
        "content": "Confirming Pages\n \nChapter 6  A Multiple-User Operating System  \n119\n Another point about DLMs is that they need to be linked with the core kernel \nfunctions and data structures. (That is, they need to be findable by the kernel and \nthey need to be able to access parts of the kernel in return.) This is accomplished \nby having a  symbol table loaded as part of the kernel. This table is called  ksym. \nAny function or data structure that is to be exposed in the kernel will need to have a \ndefinition in this symbol table. A module being loaded will call a function that will \nsearch the symbol table and resolve any references in the module being loaded. This \nmay sound as if it would slow down the system, but modules are generally loaded \nonce and then remain a part of the system. Even if they are added and removed \nrepeatedly, such as for a removable USB device, perhaps it is usually at intervals that \nare long compared to the CPU speed. \n It is also likely that a module that is being loaded by the kernel will want to expose \nits own functions and data structures. A simple function, EXPORT_SYMBOL, allows \nthe loading module to add entries to the symbol table.  \n 6.1.4 Interrupt handlers \n As was previously mentioned, device management in Linux is interrupt driven. Hard-\nware interrupts are a mechanism by which the hardware can notify the OS of asynchro-\nnous events. A primary example would be the arrival of a packet at a network adapter. \nWhen the adapter has received a packet it will generate an interrupt so that the OS can \nstop what it is doing and take care of this packet that has just arrived. Sometimes the \namount of processing required to take care of the packet can be quite lengthy. In addi-\ntion, the complete processing of the packet may be much less important than what else \nthe system was doing at the time. However, there is a minimum amount of work that \ndoes need to be done by the kernel immediately. At the very least the OS will prob-\nably need to assign a new buffer for any additional packet that might arrive. While this \nwork is being done it is typical that either all interrupt levels are disabled or that the \ncurrent interrupt level and any lower priority level interrupts are disabled. Naturally it \nTABLE 6.1 Dynamic Module Registration Functions\nPurpose\nDynamic Registration Function\nModules\ninit-module\nSymbol tables\nregister_symtab\nConsole drivers\ntty_register_driver\nTransport protocols\ninet_add_protocol\nNetwork protocols\ndev_add_pack\nLink protocols\nregister_netdev\nSerial interfaces\nregister_serial\nFile systems\nregister_filesystem\nBinary formats\nregister_binfmt\nBlock devices\nregister_blkdev\nCharacter devices\nregister_chrdev\nelm49810_ch06_113-126.indd   119\nelm49810_ch06_113-126.indd   119\n12/10/08   5:56:48 PM\n12/10/08   5:56:48 PM\n",
        "category": "Category"
    },
    {
        "id": "297",
        "title": "Title for Chunk 297",
        "content": "Confirming Pages\n120 \nPart 2 Building Operating Systems Incrementally: A Breadth-Oriented Spiral Approach\nis not a good idea to leave the interrupts disabled for very long or some external events \nwill be missed. Therefore, an interrupt handler in Linux followed a well-known, popu-\nlar  top-half  and  bottom-half organization. The top-half consisted of those things that \nneeded to happen immediately and the bottom-half were those things that could be \ndone at a more leisurely pace. The top-half would record sufficient information so that \nthe bottom-half could finish the work later. In later releases of Linux the structure of \na bottom-half was redesigned and given a new name\u2014a  tasklet. The primary reason \nfor the redesign is that tasklets can run on more than one processor in an environment \nwith multiple CPUs, whereas bottom-halves could only be run by one CPU at a time. \nExisting bottom-halves were mostly redesigned to conform to this change.  \n 6.1.5 File system directory tree \n Linux, like UNIX, has a strong orientation around the file system. Many things \nappear in the file system tree that are not files at all. This is shown in  Figure 6.3 . The \nroot of the directory tree is shown at the top level. Neither the proc nor the dev direc-\ntories are actually directories. Rather, they represent the running processes and the \nhardware (or virtual) devices on the system. References to these names will cause \nthe Linux OS to invoke other functions that will return appropriate information about \nthese elements when they are accessed. These are discussed further in Chapter 19. \nThe other interesting directories that can be seen in  Figure 6.3  are the subdirectories \nunder the /home directory. These are directories for individual users. When a user \nlogs on to the Linux system the OS will set the current working directory to be the \nhome directory for that user. \nhome\nmnt\nproc\nusr\nhda\nsda\nalice\nbob\nbin\nlib\nboot\ndev\nbin\netc\nlib\nroot\ntmp\nvar\nl\nFIGURE 6.3 A partial Linux directory tree.\nelm49810_ch06_113-126.indd   120\nelm49810_ch06_113-126.indd   120\n12/10/08   5:56:49 PM\n12/10/08   5:56:49 PM\n",
        "category": "Category"
    },
    {
        "id": "298",
        "title": "Title for Chunk 298",
        "content": "Confirming Pages\n \nChapter 6  A Multiple-User Operating System  \n121\n 6.2 THE MULTIUSER OS ENVIRONMENT \n Since Linux is modeled after UNIX and UNIX is a multiuser system, Linux is a \nmultiuser system. Assuming that there are multiple users on the system introduces \nfrom the start a problem that we have not had to worry about too much until now\u2014\ninformation security. When only one person can use a computer, the OS typically \ndoes not need to concern itself with the right of the user to access any files on the \ncomputer. It is assumed that any user of that computer can access any file and that \nfile security is provided by limiting access to the machine or by using utility pro-\ngrams, external to the OS, to safeguard files by encrypting them. Multiple users on \nthe system at the same time require that the OS provides a facility to protect each \nuser\u2019s files from all other users. This will mean that the OS will need to know who \nthe user is. This, of course, means that the user will need to log on to the computer \nwith a user ID (identifier) and a password. Of course, sometimes users will want to \nshare files, so the OS will need mechanisms to allow some files to be shared. All \nmultiuser systems also function as servers and may have multiple users logged on \nremotely. These OSs therefore also have security features, which are discussed in \na later chapter. Of course, as we saw with the Mac OS, as computers are added to \na network, even single-user systems will need to provide mechanisms for protect-\ning various assets, so user logon and such is now a common feature in most OSs if \nonly for network access. The server version of the Linux OS allows multiple users \nto access files and other resources on the system remotely. This was not the main \nthrust of this OS, but the ability to run many services and many user applications at \nthe same time meant that it also had to provide support for such advanced features \nas multiprogramming and multithreading. Supporting multiple users does not intro-\nduce any new requirements in this area, but Linux does take a different approach to \nthis subject, especially considering its UNIX origins.  \n 6.2.1 File permissions \n Linux supports the same model of file protection and sharing that other UNIX-like \nsystems support. With respect to any particular file, Linux regards all users as being \na member of one of three sets. The first set has only one member. This set is the file \nowner. Initially when a file is created the owner is the person who created the file. \nThe second set is one that is predefined by the system administrator, or  sysadmin \nas that person is commonly called. This set is normally a bunch of users that share \nsome  common interest in a set of files. Perhaps it is a project team that is working to \ndevelop the documentation for a new product or is using the same source code and \nwishes to share it among the team members. The sysadmin designates a new group \nby name and assigns users to be members of the group. The third set is \u201ceverybody.\u201d \nIn this case, it refers to every user who is not a member of one of the other two sets. \nFor members of each set, three types of access can be allowed for a specific file: \nreading, writing, and executing. \n The file owner can set the permissions on a file by using a utility called \n chmod. This typically obscure Linux command stands for \u201cchange mode.\u201d This \nelm49810_ch06_113-126.indd   121\nelm49810_ch06_113-126.indd   121\n12/10/08   5:56:49 PM\n12/10/08   5:56:49 PM\n",
        "category": "Category"
    },
    {
        "id": "299",
        "title": "Title for Chunk 299",
        "content": "Confirming Pages\n122 \nPart 2 Building Operating Systems Incrementally: A Breadth-Oriented Spiral Approach\nutility takes two arguments, a file name and a \u201cmode\u201d that specifies the changes \nto be made to the file  mode. Traditionally, this mode is a three-digit number. \nThe digits of the number are limited to octal digits\u2014that is, they can range from \n0 to 7. Each octal digit can be considered to be three bits. These three bits are used \nto allow the various operations\u2014read, write, and execute, respectively\u2014and the \nthree digits relate to one of the three sets\u2014owner, group, and everybody, respec-\ntively. The ls command, which lists the contents of a directory, can list these \nmode settings for a file or directory. Consider the following entry printed by the \nls command:\n -rwxr-x--x gil develop spellcheck  \nThis entry describes an executable file named \u201cspellcheck.\u201d The first part of the line \nis the settings of the permissions. The leading \u201c-\u201d has other uses. The initial mode \nof \u201crwx\u201d applies to the owner of the file, in this case \u201cgil.\u201d The group for the file is \n\u201cdevelop\u201d and its mode is \u201cr-x\u201d and the mode for everyone else is \u201c--x.\u201d This means \nthat user gil has all rights to the file, even the right to modify or remove it. The other \nmembers of the group \u201cdevelop\u201d can read it and execute it (if it is an executable \nscript or program) but not write it, and everyone else can only execute it. The chmod \ncommand to set these permissions would be:\n chmod 751 spellcheck  \nThe 7 corresponds to binary 111, all rights on, and the 5 corresponds to 101, or read \nand execute only. \n If we wanted to allow the group \u201cdevelop\u201d to modify this file we would have \nused another command, chgrp, for \u201cchange group.\u201d We would enter:\n chgrp develop spellcheck  \nThe rather cryptic chmod command use has been enhanced in Linux and other cur-\nrent UNIX-like systems to support more symbolic arguments. For example, the \ncommand\n chmod g \ufffd w spellcheck  \nwould add the write permission to the permissions for the group assigned to the file.  \n 6.2.2 File control blocks \n Since there are multiple processes running for multiple users, two or more users \nmight be working with some of the same files. But they might be processing in dif-\nferent parts of the file. As we see in  Figure 6.4 , the structures are in two pieces to \nsupport this use with a minimum duplication of information. As we can see, there is \na  systemwide open file table. It is in the kernel and it contains metadata about the \nfile that is the same for all users\u2014where is the first block, how long is it, and so on. \nEach process has a  per-process open file table as well. Each entry contains an index \ninto the systemwide open file table and information about the use of the file by this \nprocess such as the current pointer. \nelm49810_ch06_113-126.indd   122\nelm49810_ch06_113-126.indd   122\n12/10/08   5:56:49 PM\n12/10/08   5:56:49 PM\n",
        "category": "Category"
    },
    {
        "id": "300",
        "title": "Title for Chunk 300",
        "content": "Confirming Pages\n \nChapter 6  A Multiple-User Operating System  \n123\n 6.3 PROCESSES AND THREADS \n 6.3.1 Linux tasks \n We have not yet fully discussed the idea of threads. This is just as well, since Linux \ndoes not distinguish between processes and threads, but it is common for writers to \nuse those terms when writing about Linux because they are otherwise in common use. \nLinux documentation uses the term  tasks. Under UNIX, when a process (called the \nparent process) wants to start another process (called the child process), it first issues \nthe system call \u201cfork.\u201d This will create the child process as a copy of the parent pro-\ncess. (We will see later that there are ways the system can make this happen without \nactually copying all of the program.) With Linux, however, the corresponding system \ncall is  clone. Like all OSs, Linux maintains several different segments of memory \nfor every process. These will be described in more detail later. The clone system call \nspecifies a set of flags that tells the OS which of these segments are to be shared \nbetween the parent process and the child process. The flags are shown in  Table 6.2 . \n   In order to support programs written for other UNIX systems, Linux must also \nsupport the standard UNIX calls for forking a process. Unfortunately, the clone func-\ntion provided by Linux does not provide identical functionality. Several data struc-\ntures used for supporting tasks are not automatically shared between the parent and \nProcess \nA\nProcess \nB\nRecord \nRecord\nIndex W \nIndex X\nCount \nCount \nCount\nInode Data W \nInode Data X\nInode Data Y\nRecord\nRecord\nIndex X \nIndex Y \nSystemwide\nOpen File Table\nPer-Process \nOpen File Table\n. . .\n. . .\n. . .\n. . .\n. . .\n. . .\nFIGURE 6.4 \nLinux file control \nblocks.\nTABLE 6.2 Linux Clone Call Flags\nCLONE_VM\nShare memory\nCLONE_FILES\nShare file descriptors\nCLONE_SIGHAND\nShare signal handlers\nCLONE_VFORK\nAllow child to signal parent on exit\nCLONE_PID\nShare PID\nCLONE_FS\nShare the file system\nelm49810_ch06_113-126.indd   123\nelm49810_ch06_113-126.indd   123\n12/10/08   5:56:50 PM\n12/10/08   5:56:50 PM\n",
        "category": "Category"
    },
    {
        "id": "301",
        "title": "Title for Chunk 301",
        "content": "Confirming Pages\n124 \nPart 2 Building Operating Systems Incrementally: A Breadth-Oriented Spiral Approach\nchild tasks by the clone system call, including access rights. Libraries that intend to \nsupport POSIX compliance must then provide this service themselves. \n 6.3.2 Preemptive multitasking \n When a single user is running multiple programs, only one of those programs will be \ninteractive. In this case there will be no problem if that application takes more than \na fair share of the CPU time because the user will not care if other programs pause \nnow and again while some lengthy processing takes place in the interactive program. \nBut in a multiuser system a program running for one user should not be able to seize \nthe CPU and run indefinitely. Accordingly, as with the later versions of the Mac OS, \nLinux is a preemptive multitasking system. This means that when the OS starts run-\nning a process it will set a timer so that the OS will be interrupted if the process runs \ntoo long without making a blocking system call. If the timer expires then the running \nprocess will be put back into the queue of processes that are ready to run (i.e., the CPU \nis preempted from that process). This prevents a single process from getting control \nof the CPU and keeping any other process from running. This may be due to a bug in \nthe application that has caused it to go into an endless loop. Often, the process just has \na lot of work to do. Note that the resources consumed by the preemption itself are not \nbeing used to do actually useful work\u2014it is not something that is being done on behalf \nof any user process. However, it gives a smoother overall response to the user, and is \ngenerally perceived to be better, even though it is slightly less efficient than not pre-\nempting would be. In general, all modern OSs use preemption, except for some parts \nof hard real-time OSs. We discuss these questions more thoroughly in Chapter 8.  \n 6.3.3 Symmetric multiprocessing \n Multiprocessing systems are those that run multiple CPUs in a single system. This \narchitecture has been common on systems where not enough CPU power was avail-\nable to run the entire processing load. Given the alternative of adding a complete \nsecond system, which often had to be synchronized with the first system, multipro-\ncessing is a capable and less expensive option. One reason it is less expensive is that \na single system can share many expensive hardware components such as power sup-\nplies, primary and secondary storage, and the main system bus. \n Figure 6.5  shows the architecture of a typical multiprocessor system. This is \na simplified diagram\u2014for example, modern systems have several different buses. \nNote that the main memory and I/O architecture are shared among all the CPUs. On \na single CPU system we can only be executing one program at any given instant. \nOn a system with multiple CPUs there can literally be two or more processes (or \nthreads) running at the same time. \n Beginning around 2004, integrated circuit design engineers decided that it would \nbe more cost effective to embed multiple CPUs in one chip rather than to continue \nto make each individual CPU faster and faster. These circuits are known as tightly \ncoupled multiprocessors, chip-level multiprocessors (CMP), or multicore processors \n(MCP). They are even more tightly coupled than the previously available MP sys-\ntems, which incorporated multiple individual CPU chips. MCP circuits often share \na single L2 cache, for example. This means that most systems as large as a personal \nelm49810_ch06_113-126.indd   124\nelm49810_ch06_113-126.indd   124\n12/10/08   5:56:51 PM\n12/10/08   5:56:51 PM\n",
        "category": "Category"
    },
    {
        "id": "302",
        "title": "Title for Chunk 302",
        "content": "Confirming Pages\n \nChapter 6  A Multiple-User Operating System  \n125\ncomputer will be multiprocessor systems, though single CPU systems will still be \ncommon in embedded systems for the foreseeable future. \n There are two different approaches that an OS can take to supporting multiple \nCPUs. The first approach is called  asymmetric multiprocessing.  In this approach \nthe OS runs on only one designated CPU. The other CPUs run only applications. \nThis design has the advantage that the OS itself can ignore some of the complications \ninvolved in having the same process run on two CPUs at the same time. Although \nsimple, this approach is not commonly used because of performance bottlenecks \ndue to running the OS only on one processor. Instead, most modern OSs support \nmultiple CPUs with a different approach,  symmetric multiprocessing ( SMP ). In \nthis approach the OS is treated like every other process in that it can be running on \nany CPU. A running program obviously will be modifying its state (data). It is easy \nto see that having two (or more) CPUs running the same code that is modifying the \nsame data has to be thought about very carefully. Multiple instances of the OS run-\nning on different CPUs must be prevented from changing the same data structure at \nthe same time. We look at this topic more closely in Chapter 9. Because the individ-\nual CPUs may each be caching the same data, the hardware must do a lot of work to \nensure that all the caches contain the same information. The techniques involved in \nthis synchronization have so much overhead that most current systems will not scale \nup beyond a fairly small number of processors\u2014say, 64 or so. \n Since the 2.0 release Linux has supported SMP. \nMain System Bus\nCPU 4\nLocal Cache\nCPU 3\nLocal Cache\nCPU 2\nLocal Cache\nCPU 1\nLocal Cache\nMain\nMemory\nI/O \nControllers\n. . .\nFIGURE 6.5 \nA simplified \nmultiprocessor \nsystem architecture.\n 6.4 SUMMARY \n In this chapter, we discussed the features and con-\ncepts of a multiuser OS, Linux. This chapter is fairly \nbrief because it only addresses the additional features \nfound in Linux because it is a multiuser OS. Chapter \n19 is a more traditional case study of the Linux OS \nmodules. \n We started this chapter with an overview of \nLinux and a bit of the history of its evolution. We then \nmoved to a brief discussion of the characteristics of a \nmultiuser OS. Next, we discussed the support of files \nin Linux. We then gave an overview of the scheduling \nof processes and tasks in Linux. \n In the next chapter of the book we discuss \nan example of distributed OSs\u2014one that runs on \nmultiple systems at the same time and attempts to \nmake the many systems appear to the user as a single \nenvironment. The subsequent chapters begin an in-\ndepth look at the various components of OSs. \nelm49810_ch06_113-126.indd   125\nelm49810_ch06_113-126.indd   125\n12/10/08   5:56:51 PM\n12/10/08   5:56:51 PM\n",
        "category": "Category"
    },
    {
        "id": "303",
        "title": "Title for Chunk 303",
        "content": "Confirming Pages\n126 \nPart 2 Building Operating Systems Incrementally: A Breadth-Oriented Spiral Approach\n BIBLIOGRAPHY  \n Beck, M., et al.,  Linux Kernel Programming, 3rd ed. \nReading, MA: Addison-Wesley, 2002.\n Bovet, D. P., and M. Cesate,  Understanding the Linux \nKernel, 2nd ed. Sebastopol, CA: O\u2019Reilly & \nAssociates, Inc., 2003. \n Gorman, M.,  Understanding the Linux Virtual Memory \nManager. Upper Saddle River, NJ: Prentice Hall, \n2004. \n Love, R.  Linux Kernel Development. Indianapolis, IN: \nSams Publishing, 2004. \n Stevens, R.,  Advanced Programming in the UNIX \nEnvironment. Boston: Addison-Wesley, 1992. \n Stevens, R.,  Unix Network Programming. Upper Saddle \nRiver, NJ: Prentice Hall, 1990. \n Yaghmour, K.,  Building Embedded Systems. Sebastopol, \nCA: O\u2019Reilly & Associates, Inc., 2003.  \n WEB RESOURCES  \n http://www.linux.org (the home of Linux kernel \ndevelopment) \n http://www.kernel.org (a repository of historic kernel \nsources) \n http://www.tldp.org (the Linux Documentation \nProject) \n REVIEW QUESTIONS \n \n6.1 Why is a \u201cdistribution\u201d important in Linux?  \n \n6.2 Why is SUS important to Linux?  \n \n6.3 Why would a large organization probably not want \nto use release 2.7 as a standard installation for all \nof their Linux systems? \n \n6.4 True or false? Linux is only the kernel of an OS \nand relies on other groups to provide the needed \nutility programs to make it a usable OS. \n \n6.5 True or false? Linux is a microkernel OS. \n \n6.6 Modern OSs are used in a wide variety of environ-\nments. There are an incredible variety of devices \nand controllers that have been interfaced to Linux \nand a wide assortment of different file systems, \ndisk schedulers, and so on, most of which are not \nneeded on any given installation. How does an OS \nlike Linux avoid becoming overloaded with mod-\nules that are not needed in most situations? \n \n6.7 Why are interrupt handlers in Linux divided into a \ntop half and a bottom half? \n \n6.8 Describe briefly how the Linux clone mecha-\nnism differs from traditional UNIX processes and \nthreads. \n \n6.9 True or false? Linux is a nonpreemptive multitask-\ning OS. \nelm49810_ch06_113-126.indd   126\nelm49810_ch06_113-126.indd   126\n12/10/08   5:56:53 PM\n12/10/08   5:56:53 PM\n",
        "category": "Category"
    },
    {
        "id": "304",
        "title": "Title for Chunk 304",
        "content": "Confirming Pages\n283\n Chapter \n Chapter  13 \n 13 \n File Systems\u2014Examples \nand More Features \n In this chapter: \n 13.1 Introduction 283 \n 13.2 Case Studies 284 \n 13.3 Mounting 288 \n 13.4 Multiple File Systems and Redirection 290 \n 13.5 Memory Mapped Files 292 \n 13.6 File System Utilities 293 \n 13.7 Log-Based File Systems 294 \n 13.8 Summary 295  \n 13.1 INTRODUCTION \n In Chapter 12 we introduced the concept of file systems and how they fit in an OS. We covered \nmany possible alternative mechanisms for storing the files and tracking free space. Designers \nof real file systems have to make choices about the mechanisms they will include. We will \nsee that modern OSs use all of the techniques we have described, but none of them uses these \ntechniques in exactly the ways we have described. \n In Section 13.2 we take a look at several case studies of how modern OS file \nsystems have been designed. We then discuss several other topics related to file sys-\ntems and file processing. This begins in Section 13.3, where we address the concept \nof mounting a file system and making the information therein available to the appli-\ncations. We continue with special topics in Section 13.4 on the reasons behind virtual \nfile systems and related concepts and in Section 13.5 on the purpose of memory \nmapped files. OSs typically provide a number of utility programs to make standard \nmanipulations of file system information. Section 13.6 addresses some of these \nutility programs. Section 13.7 discusses the important concept of transactional or \nlog-based file system techniques, which make for more reliable file systems. We \nconclude with a chapter summary in Section 13.8. \nelm49810_ch13_283-296.indd   283\nelm49810_ch13_283-296.indd   283\n12/11/08   6:43:48 PM\n12/11/08   6:43:48 PM\n",
        "category": "Category"
    },
    {
        "id": "305",
        "title": "Title for Chunk 305",
        "content": "Confirming Pages\n284 \nPart 4 A Depth-Oriented Presentation of OS Concepts: File Systems and Input/Output\n 13.2 CASE STUDIES \n Often, real OSs use some combination of the basic techniques described in Chapter 12. \nWe have already mentioned, for example, that some OSs allow both contiguous file allo-\ncation and chained file allocation. In the following sections we look a little more closely \nat some modern file systems and how they are implemented.  \n 13.2.1 FAT \n The first file system we look at more closely is a modification of a linked system. \nInstead of having each data block contain the pointer to the next data block, those \npointers will be stored in a separate table. This system was used in the original \nMicrosoft DOS and is known by the name given to the area used to store this table, \nthe  file allocation table, or  FAT. In this case the FAT is not kept in the area that \nwould be used for data storage. It is in a separate area of the disk just after the \nboot block. This table will contain space for one disk pointer for each block in the \ndata area. If a block is not allocated to a file, then this pointer will be zero. If this \nblock is a part of a file, then this pointer will normally contain the pointer to the \nnext block in the file. If this block is the last one in the file, then it will contain a \nspecial pointer value that indicates that it is the end of the list.  Figure 13.1  shows \nhow a FAT might look with two files in it. We have indicated the end of file mark \nas FFFFFFFF. \n There are some very interesting things to notice about the FAT mechanism. First, \nthere is no separate mechanism to keep track of free space. The free space blocks \nhave a zero pointer in the FAT. Second, it is very easy to allocate contiguous space \nfor a file. Just as with a bitmap free space mechanism, all that is necessary to find a \ncontiguous group of free blocks is to scan the FAT and find a contiguous string of \nzero pointers. It is also easy to allocate single sectors to support allocation of single \nblocks for chained file access. \n The original FAT file system design was created for floppy disk drives, so the \npointers were quite small. It later came to be called the FAT12 file system. It was \nused on early small hard disks, but the disks quickly grew so large that even allocat-\ning large blocks instead of individual sectors could not cover the entire space. So \na new file system was designed that was much like FAT12 but used bigger point-\ners. This system was called the FAT16 file system. This was a fairly reasonable \nsize to base a file system design around because the computers of that era had a \n16-bit word size. This size was still fairly limiting and the FAT16 design was later \nreplaced by the FAT32 system. A summary of these three file systems is given in \n Table 13.1 . \n 13.2.2 NTFS \n NTFS is the native file system for the Windows NT family. It is a variation on a \ntwo-level indexed structure. NTFS uses a  master file table ( MFT ) to store all the \nmetadata about files and directories. In the MFT it creates a  file record for each file \nand a  folder record for each folder, even for the MFT itself. These records are 1 KB \nelm49810_ch13_283-296.indd   284\nelm49810_ch13_283-296.indd   284\n12/11/08   6:43:51 PM\n12/11/08   6:43:51 PM\n",
        "category": "Category"
    },
    {
        "id": "306",
        "title": "Title for Chunk 306",
        "content": "Confirming Pages\n \nChapter 13 File Systems\u2014Examples and More Features \n285\nBlock Number\n0\n6\n12\n18\n24\n30\n36\nFile M\nFile A\nUnused\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n1\n2\n3\nFFFFFFFF\n0\n0\n0\n0\n14\n0\n0\n0\n0\n0\n15\n16\n28\n0\n0\n0\n24\n0\n0\n0\n26\n27\n25\nFFFFFFFF\n20\n0\nDirectory\nName\n8\n27\n0\n3\n...\n...\nStart\nEnd\nFile A\nFile M\nFile C\nFIGURE 13.1 A file in a FAT file system.\nTABLE 13.1 Comparison of Various FAT File Systems\nAttribute\nFAT12\nFAT16\nFAT32\nUsed for\nFloppies and \nvery small hard \ndrives\nSmall to midsize \nhard drives\nMedium to very \nlarge hard drives\nSize of each FAT \nentry\n12 bits\n16 bits\n28 bits\nMaximum number \nof clusters\n4,096\n65,526\n> 260,000,000\nBlock size used\n0.5 KB to 4 KB\n2 KB to 32 KB\n4 KB to 32 KB\nMaximum volume \nsize in bytes\n16,736,256\n2,147,133,200\nAbout 241\nelm49810_ch13_283-296.indd   285\nelm49810_ch13_283-296.indd   285\n12/11/08   6:43:52 PM\n12/11/08   6:43:52 PM\n",
        "category": "Category"
    },
    {
        "id": "307",
        "title": "Title for Chunk 307",
        "content": "Rev. Confirming Pages\n286 \nPart 4 A Depth-Oriented Presentation of OS Concepts: File Systems and Input/Output\neach 1 and they include all the attributes of the file. NT considers the data in a file or \na directory to be one of the attributes for the file. If all of the attributes fit in the MFT \nrecord, then no separate space is allocated. This means that a small file or directory \n(about 900 bytes) will be stored entirely within the MFT record.  Figure 13.2  shows \nan MFT record for a small file or folder. If the data attribute does not fit into the \nMFT record, then one or more blocks will be allocated to hold the data and an index \nto the blocks will be built in the MFT record. Each file typically has only one MFT \nfile record. However, if a file has many attributes or is very fragmented it might need \nmore than one record. In this case the first record for the file, called the base file \nrecord, stores the location of the other file records required by the file. \n Folder (or directory) records contain index information. Small folder records \nreside entirely within the MFT structure, while large directories are organized into \nB-tree structures with pointers to external clusters that contain directory entries that \ncannot be contained within the MFT structure. The benefit of B-tree structures is \nevident when NTFS holds files in a very large folder. The B-tree structure groups \nsimilar file names into a block so that it need search only the group that contains the \nfile. This will minimize the disk accesses needed to find a file.   Some other points \nabout NTFS:\n \ufffd It uses a bitmap to track free space. \n \ufffd It supports variable block (cluster) sizes in the later releases. \n \ufffd It supports compression of the entire file system, directories, subtrees, or \nindividual files. \n \ufffd It supports file encryption of the entire file system, directories, subtrees, or \nindividual files. \n \ufffd It supports software RAID 1 and RAID 5 (see Chapter 14, Section 14.6). \n \ufffd It maintains a separate map of bad clusters that it will not use. \n \ufffd It will not write to disk (large) portions of a file that contain only binary zeroes \n(nulls). \n \ufffd It is a transactional (log-based) file system (see Section 13.7). \n 13.2.3 UNIX and Linux \n UNIX and many UNIX derivatives such as Linux support many different file sys-\ntems, but the ext file system is fairly standard. It uses a version of a multilevel index \nscheme to hold the metadata about a file. This data is stored in a table on the disk \ncalled an  inode. Each entry in a UNIX directory contains only the name of the item, \nand a numerical reference to the location of the item. The reference is called an \n i-number or  inode number, and is an index to a table known as the  i-list. Details \n 1 The details of the NTFS system are actually proprietary. The figures used here are generally accepted, \nbut might not always be exactly right. \nStandard\nInformation\nFile or\nDirectory Name\nData or Index\nUnused\nSpace\nFIGURE 13.2 \nNTFS MFT record for \nsmall file or directory.\nelm49810_ch13_283-296.indd   286\nelm49810_ch13_283-296.indd   286\n12/22/08   1:07:49 PM\n12/22/08   1:07:49 PM\n",
        "category": "Category"
    },
    {
        "id": "308",
        "title": "Title for Chunk 308",
        "content": "Confirming Pages\n \nChapter 13 File Systems\u2014Examples and More Features \n287\nof the i-list location and format and the contents of the inodes depend somewhat on \nthe specific variant and version of UNIX, but typical inode information is shown in \n Table 13.2 . Of interest here is what is and what is not in the inode. One thing that \nis not in the inode is the file name. UNIX allows files to have aliases, meaning that \nmore than one directory entry can point to the same file. Among other things, there \nis no requirement that different references to the file use the same name. Therefore, \nthe file name is stored in the directory and the directory entry points to the inode \nfor all other metadata about the file. One of the entries in the inode is the number of \ndirectory entries that point to this file. When a directory entry is deleted for a file, \nthe count of the references will be decremented, but the file itself will not be deleted \nuntil the reference count goes to zero. \n The UNIX file system inode structure is a hybrid variation of an indexed struc-\nture. There are a number of pointers that point directly to data blocks. That number \nvaries, but is typically 10\u201313. The inode is brought into primary memory when the \nfile is opened, so if the file is fairly small, then the pointers to the first few blocks \nare already available. If the file is large enough that it requires more blocks than can \nbe pointed to by these direct pointers, then the next pointer is a pointer to a single \nindex block. If the system is using 4 KB blocks, then this block might contain 1,024 \npointers to additional blocks. If all of this space is used up, then the next entry is to a \ndouble index block. This index block will contain pointers not to data blocks, but to \nother index blocks. So this index block will address 1,024 index blocks, which will \naltogether address over 1 million data blocks. If that is not enough, the next entry \nin the inode is a pointer to a triple index block structure. Using the 4 KB blocks \ndescribed, this structure can address over 4 Terabytes of file space. \nTABLE 13.2 Typical UNIX inode Contents\nFile type\nAccess permissions\u2014read, write, etc.\nCount of directories that reference the file\nOwner\nGroup (owner)\nDate and time created\nDate and time last accessed\nDate and time last modified\nSize\nData block pointer 1\nData block pointer 2\n. . .\nData block pointer 10 (sometimes 13)\nSingle index block pointer\nDouble index block pointer\nTriple index block pointer\nelm49810_ch13_283-296.indd   287\nelm49810_ch13_283-296.indd   287\n12/11/08   6:43:52 PM\n12/11/08   6:43:52 PM\n",
        "category": "Category"
    },
    {
        "id": "309",
        "title": "Title for Chunk 309",
        "content": "Confirming Pages\n288 \nPart 4 A Depth-Oriented Presentation of OS Concepts: File Systems and Input/Output\n When a UNIX file system is initialized, the i-list is built to be a size appropriate \nfor the size of the disk partition and the block size used. A number of empty inodes \nwill be created and distributed evenly across the partition. As blocks are allocated to \na file they will be selected from those available that are close to the inode. This pro-\ncess helps to keep all the blocks allocated to a file near each other. As long as other \nprocesses are not accessing too many other files on other parts of the drive, this will \nhave the effect of minimizing the seek time required to access the file. \n 13.3 MOUNTING \n Sometimes we have to deal with computer science terms that have multiple mean-\nings, known as overloading. One such term is  mounting. Actually, the two meanings \nfor this term are related, but at first glance they appear to refer to different opera-\ntions. The first meaning concerns what must be done when a disk drive partition con-\ntaining a file system is going to be accessed by the OS. The second meaning refers to \na process used to give a user a means of specifying files on a remote directory.  \n 13.3.1 Local file system mounting \n Before an OS can allow a user to access a particular file system, it will need to do \ncertain things. The metadata that describes the partition must be read, some part of \nthe free space mechanism must be read into RAM\u2014perhaps some blocks preallo-\ncated, the directory that represents the root of the directory tree must be read in, and \nso on. This process is called mounting. When the OS is installed there will be some \npartitions that it is told to access, and normally those partitions will be mounted \nwhenever the OS is booted. These partitions are normally the ones that are on local \nhard drives. There are differences between OSs, however, with respect to remov-\nable media, OSs treat them in one of three ways: (1) implicit mount when the media \nis inserted in the drive, (2) implicit mount when the media is first accessed, or (3) \nexplicit mount command must be given. \n UNIX and most of its variants have traditionally used the last mechanism. Until \nthe user gives a specific mount command the removable medium cannot be accessed. \nSince floppy disks formatted for MS-DOS were so pervasive, this actually had a good \nside effect since it allowed the user to specify which file system format a floppy disk \ncontained: UNIX, MS-DOS, or Mac. Later versions of Linux and UNIX have begun \nexperimenting with implicit mounting when the media is inserted. The term used \nfor this is  automounting. MS-DOS and the Windows products have always used \nimplicit mounting when an attempt is first made to access the media. Historically the \nMac OS automatically mounted a removable media whenever it was inserted into the \ndrive. Since Mac OS X is based on UNIX, it now mounts as UNIX does. \n A different situation exists in the area of CDs. Fairly early in the days of CD \ndevelopment a large number of vendors convened and decided on a common for-\nmat for data and audio CDs. This format ultimately was designated an international \nstandard, ISO-9660. This common format means that there is no reason to postpone \nthe mounting as was done with UNIX, so CDs are normally mounted immediately \nelm49810_ch13_283-296.indd   288\nelm49810_ch13_283-296.indd   288\n12/11/08   6:43:53 PM\n12/11/08   6:43:53 PM\n",
        "category": "Category"
    },
    {
        "id": "310",
        "title": "Title for Chunk 310",
        "content": "Confirming Pages\n \nChapter 13 File Systems\u2014Examples and More Features \n289\non insertion. This allows the OS to detect the format of the CD (i.e., audio, data, or \nmixed) and to have a default option to execute when such a CD is inserted. This \nmeans that if a user so chooses, inserting an audio CD will launch a CD audio player \napplication of the user\u2019s choice to play the CD. Similarly, a data CD can contain \ninstructions on what is to be done with the CD on common OSs. Many will auto-\nmatically run a script file that depends on the OS to start the software on the CD. \n 13.3.2 Mounting remote file systems \n A similar process must also take place when an OS is requested to provide access to a \nfile system on a remote computer, but the details are vastly different. The remote file \nsystem might be an entire file system that is made available to users, but more likely \nit is some portion of a file system rather than the whole thing. A large difficulty that \nmust be overcome is that the platform that the remote file system is running on may \nbe entirely different from the local file system. Data representation may be different, \nfile naming conventions may be different, directory structures may be different, and \nso forth. In order to overcome these differences we have to have well-established rules \nabout how the information is to be presented and the protocols to be used for exchang-\ning the information. In most cases the rules and protocols are de facto rules that are \nestablished by one platform vendor to allow their systems to interoperate. Other ven-\ndors will create packages to access these systems from other platforms. Sometimes \nthese rules become open standards, as with  network file system ( NFS; see Section \n13.4.2), and sometimes they are reverse engineered by other vendors. Whatever the \ncase, the remote system will do the accessing of the directories but the information \nmust be mapped into the context of the client OS. For example, if the client is a Win-\ndows system, then the metaphor of the remote file system is that of a \u201cdrive letter.\u201d \nInitially, these letters were used in DOS to indicate real drives on a system. Remote \nfile systems use the same convention, assigning any drive letter that is not used for a \nlocal resource. In contrast, UNIX sees all file systems as a tree structure, including \npseudo-directories like proc and dev. So mapping a remote file system in UNIX-like \nsystems simply involves adding (or replacing) a directory node in the file system tree \nstructure with a node that identifies itself as pointing to a remote resource. \n From a programmer\u2019s point of view, remote mounting of file systems is a pow-\nerful tool. Generally speaking, the program is not aware of any difference between \na local file and a remote file. Without making any modifications to programs at all \nthey are capable of operating over a network. Unfortunately, this is not always a wise \nthing to do. Consider the case of a database software program accessing a database \nfile that is remotely mounted across a network. When searching the indexes for data, \nthe database program will end up reading and writing large amounts of data across \nthe network. In a fast LAN with light traffic the performance might be acceptable, \nbut if the connection is a WAN or there is considerable network traffic, then it might \nnot be a good idea. In this case it would be far better to run the database program on \nthe remote machine and send SQL commands across the network, getting back only \nthe final answers. Even better would be to use commands previously stored on the \nremote server. Of course, it is not always possible to anticipate all queries so they can \nbe stored in advance on the server. Sometimes ad hoc queries are necessary. \nelm49810_ch13_283-296.indd   289\nelm49810_ch13_283-296.indd   289\n12/11/08   6:43:53 PM\n12/11/08   6:43:53 PM\n",
        "category": "Category"
    },
    {
        "id": "311",
        "title": "Title for Chunk 311",
        "content": "Confirming Pages\n290 \nPart 4 A Depth-Oriented Presentation of OS Concepts: File Systems and Input/Output\n Letting a node in a file system become a reference to a remote file system causes \na slight problem. Path names now become more difficult to parse. Without these \nremote reference nodes in the file system tree, parsing a path name was fairly simple. \nGiven a path like /fred/work/expenses, as the OS parsed down the string, each \u201c/\u201d \nrepresented a move to another directory in the local file system. But with nodes \npossibly representing remote file systems in the tree, the file system must check at \neach level to see whether the node was a local directory or a remote file system and \nperform the appropriate lookup. \n Another problem with remote mounting is that two different clients may mount \na given remote directory at different points in their local file system. In Windows \nsystems two users might assign the same remote file system to a different drive letter. \nIn UNIX-like systems they might mount the same remote file system at a different \nlogical node in their local file system. Then if a process on one user\u2019s machine passed \na path name to a process on the other user\u2019s machine the second machine would not \nbe able to find the file because the path is different. Administrators can mitigate this \nproblem by defining standardized mounting scripts that run at user login time and \nprovide more consistent path naming for all users for commonly accessed resources. \n 13.4 MULTIPLE FILE SYSTEMS AND REDIRECTION \n As in many other instances, an OS will present to the API an abstraction of a file. \nThe program should not be aware of what the file system is like. There are likely to \nbe performance differences if the wrong file system is used for an application, but \nthe coding of the application should not be affected. That is really a system engi-\nneering issue. If the application is designed for accessing a file randomly and the \nfile system supports random access, then the application should be unaware of any \nother differences. In most systems it will be necessary for the OS to support several \ndifferent file systems. If for no other reason, it is necessary because different file \nsystems are best suited for different media. For CDs there is normally only ISO-9660 \nto consider, although a few very early CDs were created in proprietary formats. For \nfloppy disks it is almost a given that the OS will need to be able to read and write \nFAT12 floppy formatted disks derived from MS-DOS. But Mac and UNIX formats \nare widely used as well. Even with hard drives it will sometimes be desirable to \nsupport a format other than the native format of the OS. This often happens when a \nsystem is upgraded to a new OS or a new version of the same OS. Even if the OS is \nthe same, the new version may have a new wonderful file system that comes with \nit. When the upgrade is first performed, however, the file system will still be the old \nformat. Usually a separate step is then needed to convert the old file system format \nto the new format. Not infrequently a system needs to contain two different OSs and \nbe booted into different ones depending on the current need. Today it is even becom-\ning common to see a virtual OS running two different client OSs at the same time \nand supporting different file systems on different drives. It may still be desirable to \naccess all of the file systems on the disc drives regardless of the OS currently in use. \nFor all of these reasons OSs will need to support a number of different file system \nformats. \nelm49810_ch13_283-296.indd   290\nelm49810_ch13_283-296.indd   290\n12/11/08   6:43:53 PM\n12/11/08   6:43:53 PM\n",
        "category": "Category"
    },
    {
        "id": "312",
        "title": "Title for Chunk 312",
        "content": "Confirming Pages\n \nChapter 13 File Systems\u2014Examples and More Features \n291\n 13.4.1 Virtual file systems \n UNIX developers created a mechanism exactly for the purpose of transparently sup-\nporting multiple file systems on the same system at the same time. It is called the \n virtual file system, or  VFS. VFS was a separate layer added to UNIX on top of the \nfile system module. Actually, it was loaded in a system with multiple file system \nmodules supporting different file systems. VFS supported the same API as the exist-\ning file systems so that applications would not have to change.  Figure 13.3  shows \nthe interface between applications and the file system both before (a) and after (b) \nVFS was introduced. When a request was passed to the VFS layer it would examine \nthe request by looking at the nodes in the file system tree and determine which file \nsystem module was the correct module for this file system. It would then pass the \nrequest to that module. When the file system module was finished with the request \nit would return control to the VFS module, which would then return control to the \napplication that had called it. \n 13.4.2 Network file system \n VFS was also used to redirect file system requests to remotely mounted drives using \nthe NFS protocol developed by Sun Microsystems. This process was alluded to \nunder the topic of remote mounting earlier.  Figure 13.4  shows how this mechanism \nworks. The client system is shown on the top of the figure. The application makes \nfile requests through the standard file API. The VFS system realizes that this is a \nrequest for access to an NFS file that is being served on another system. That system \nis the NFS server shown at the bottom of the figure. The VFS layer on the client \nmachine therefore sends the request to the NFS client system. It uses a remote pro-\ncedure call mechanism to solve the problems of heterogeneous OS environments. \nThis is discussed further in Chapter 17. The client system sends the request across \nthe network to the NFS daemon that is running in the NFS server system. The NFS \ndaemon takes the request and sends it to the VFS layer on the server system. The file \nApplication\nFile API\nFile System\nFile System A\nFile System B\nFile System C\nApplication\nFile API\nFile API\nVirtual File System\n(a) Before VFS\n(b) After VFS\nFIGURE 13.3 \nIntroducing the VFS \nlayer.\nelm49810_ch13_283-296.indd   291\nelm49810_ch13_283-296.indd   291\n12/11/08   6:43:53 PM\n12/11/08   6:43:53 PM\n",
        "category": "Category"
    },
    {
        "id": "313",
        "title": "Title for Chunk 313",
        "content": "Confirming Pages\n292 \nPart 4 A Depth-Oriented Presentation of OS Concepts: File Systems and Input/Output\nis accessed as requested as though the client were local, and the data are sent back to \nthe application running on the client system. \n The requests made by the application are redirected by the NFS client software \nto the system running the NFS server, so we say that the model being used is a  redi-\nrector. This is a common technique, being used in other OSs as well. NFS is nearly \ncompletely transparent to a client application. But before the files can be accessed by \nthe client application, the directories on the NFS server must be mounted so that the \napplication can find the file. This step is not transparent, because the user (or the appli-\ncation) must designate the server. In UNIX-derivative OSs this is done with a mount \ncommand. The mount command will specify the name of the remote system and a \ndirectory on that system as well as a local directory. The remote directory will thereaf-\nter appear to be a part of the directory tree in the local file system and to all operations \nof any applications it will be transparent that these files are actually remote. \n 13.5 MEMORY MAPPED FILES \n An alternative file access mechanism is found in many OSs, memory mapped files, \ndiscussed earlier in Chapter 11 on advanced memory techniques. This mechanism is \nvery different from the standard metaphor of a file. Because it is so different it has \nsome characteristics that make it very useful in certain situations. When an application \nprocess uses a memory mapped file it tells the OS the name of a file to map and the \nOS creates a byte-by-byte mapping of the addressing space for the file into the l ogical \nVirtual\nFile\nSystem\nFile\nSystem\nA\nNFS\nClient\nFile\nSystem\nB\nFile\nSystem\nApplication\nNFS Client System\nVirtual\nFile\nSystem\nFile\nSystem\nA\nFile\nSystem\nC\nFile\nSystem\nB\nNFS\nServer\nDaemon\nNFS Server\nFIGURE 13.4 \nNFS through VFS.\nelm49810_ch13_283-296.indd   292\nelm49810_ch13_283-296.indd   292\n12/11/08   6:43:54 PM\n12/11/08   6:43:54 PM\n",
        "category": "Category"
    },
    {
        "id": "314",
        "title": "Title for Chunk 314",
        "content": "Confirming Pages\n \nChapter 13 File Systems\u2014Examples and More Features \n293\naddressing space of the process. So the first interesting characteristic of a memory \nmapped file is that all of the mechanisms of the file system are not used to address \nthe space. Instead, the application treats the memory mapped file as a large array and \nuses subscripting or pointer arithmetic to address the file. The virtual memory manager \nthen keeps track of which portions of the file space are needed in physical memory, \ntracks changed pages, and writes them to the disk as required. These mechanisms use \nhardware support and are therefore much more efficient than the mechanisms of a file \nsystem. As you may recall, because of potential interactions with paging, normal file \nprocessing either locks pages into RAM and thereby inhibits the performance of the \npaging system or copies the I/O buffers into the kernel space before doing the I/O. \nMapping the file onto the paging mechanism avoids these problems. Applications are \nalso freed from having to do any memory allocation. \n The second interesting characteristic of a memory mapped file is that multiple \nprocesses are allowed to memory map the same file at the same time. (Interestingly, \nbecause of the virtual memory hardware they do not have to map the file into the \nsame logical memory address.) This creates a very efficient method for interprocess \ncommunication. In fact, the \u201cfile\u201d does not actually have to exist. Both processes \ncan name a temporary file purely for the purpose of interprocess communication. \nHowever, the memory mapped mechanism does not do any synchronization. If there \nis a possibility of conflicting operations being performed by multiple processes, then \nsome external synchronization mechanism must be used to protect the critical sec-\ntions of the processes. Another limit of the memory mapped file mechanism is that \nthe mapped files cannot easily grow in size. It is sometimes possible, but requires \ncareful remapping of the area. A third limitation is that there is no provision for \ndoing asynchronous I/O. Since the paging hardware is doing the reading and writing \ntransparently to the application, the I/O is blocking. When a page fault occurs the \nprocess will be blocked and will not be aware of it. One final precaution is that if the \nfile is larger than the available logical addressing space, then the mapping must be \ncarefully positioned over the file address space. \n 13.6 FILE SYSTEM UTILITIES \n All OSs come with a handful of utility programs and included among these are \nalways a group of programs for working with the file system. Some are designed to \nuse while the OS is running. They include mundane things like making a new direc-\ntory and deleting a file. These programs are often run from a command-line inter-\nface.  Table 13.3  lists some common file system utility programs for DOS/Windows \nand UNIX-like systems. Later versions of most OSs use mostly a GUI interface and \nthe commands do not have a name that most users are aware of. Note that some of \nthe commands do not exist in all versions of DOS/Windows or in UNIX/Linux. \n Those utilities are primarily things that a user decides to do. Other utilities \nare necessary as well that do things that may be important to the users but are not \ndone to satisfy any real need of the user. Rather, they do things to the file system to \nconfirm their integrity or improve the performance. Under DOS and Windows there \nwere two verification utilities known as scandisk and checkdisk. UNIX-like systems \nelm49810_ch13_283-296.indd   293\nelm49810_ch13_283-296.indd   293\n12/11/08   6:43:54 PM\n12/11/08   6:43:54 PM\n",
        "category": "Category"
    },
    {
        "id": "315",
        "title": "Title for Chunk 315",
        "content": "Confirming Pages\n294 \nPart 4 A Depth-Oriented Presentation of OS Concepts: File Systems and Input/Output\nhave a similar utility known as fsck. Besides verifying the consistency and integrity of \nthe file system, these utilities will optionally attempt to repair faults that they find. Win-\ndows also has a utility known as defrag, which reorganizes the files in a file system to \nimprove the performance of the system. This problem was discussed earlier in the sec-\ntion on linked file allocation. The backers of UNIX-like systems claim that the designs \nof their file system preclude the need for defragmentation utilities. The fact that such \nutilities are not being marketed suggests that this claim is at least fairly accurate. \n Some things that look like utilities are actually built-in commands in the OS com-\nmand interface. For example, under DOS or Windows there are no executable files \nthat execute the commands dir, del, time, type, and so on. These functions map very \nclosely to supervisor calls in the OS API, so that the command interpreter (command\n.com in the DOS case) has these functions built-in and no external module is needed. \nThis saves both disk space and time to load an external program into memory.  \n 13.7 LOG-BASED FILE SYSTEMS \n System failures are fairly rare, but they do happen. That is why those file system \nverification utilities were created. When an OS closes normally it will record an indi-\ncation of a normal shutdown to the file system. When the OS boots it will check to \nsee if the system was shut down normally or if it crashed. Traditionally, if the system \nhad crashed, then before mounting the file system the OS will run the file system \nintegrity checker. If a system that crashes is being used by only one individual, then \nthe likelihood that anything was actually happening at the time of the failure will be \nlow. Even in a fairly busy server there is not a high risk of loss. Any server failure is \nlikely to cause problems for more people than a crash on a single-user system. Still, \nTABLE 13.3 Some File Commands\nPurpose of Utility\nDOS/Windows\nUNIX/Linux\nChange file permissions\nattrib\nchmod\nCombine files\nbackup\ntar\nList files in a directory\ndir\nls\nCopy a file\ncopy\ncp\nDelete a file\ndel\nrm\nDelete a file system subtree\ndeltree\nrm \u2013R; rmdir\nEdit a text file\nedit\nvi\nFormat\nformat\nfdformat/ mkfs\nMove or Rename a file\nmove/rename\nmv\nList a file\ntype\nless\nChange the working directory\ncd\ncd; chdir\nView a file one page at a time\nmore \nmore\nCreate or edit disk partitions\nFdisk\ncfdisk, parted, etc.\nMake a new directory\nmd, mkdir\nmkdir\nelm49810_ch13_283-296.indd   294\nelm49810_ch13_283-296.indd   294\n12/11/08   6:43:54 PM\n12/11/08   6:43:54 PM\n",
        "category": "Category"
    },
    {
        "id": "316",
        "title": "Title for Chunk 316",
        "content": "Confirming Pages\n \nChapter 13 File Systems\u2014Examples and More Features \n295\nthe single user would rather not lose anything in any circumstances. OS developers \nsearched for a way to make file systems more resistant to failures. \n When a block has been added to a file and the file is closed, then several things \nmay have to happen. We will certainly have to write out records containing the data \nblock. We may have to find the next free block, update the free space information \nto show this block was used, update any directory entry for the file to show the last \ntime the file was written, and so on. We want all this information to be updated in \nan atomic fashion\u2014either all of it should reach the hard disk or none of it should. \nIn applications we call this  transaction processing. OS file systems that operate in \nsuch a manner are called  log-based,  log-structured,  transactional, or  journaling \nfile systems. In such systems, anytime metadata is to be updated, the system will \nfirst write a record to a log file that describes all the updates that are going to be \nmade. Whenever the system starts it will check the log file to see if there was a trans-\naction pending. If so, the system checks to see if all the steps of the transaction were \nsuccessfully applied. If not, then the system will attempt to finish the transaction. If \nit can, then all is fine and we have dodged a bullet. If the transaction can\u2019t be finished \nfor some reason, then the transaction will be aborted. We will have lost that last \nblock of data that was to be written to the file, but the file system is safe from further \ncorruption. Running with a file system with corrupt metadata would be disastrous. \n Of course, nothing is free, and the price we pay for the security of a log-based \nfile system is a performance hit. Since we take the time to write the transaction log \nevery time before we write the metadata, we will see decreased performance in the \nsystem. Also, the transaction that is logged does not necessarily include the actual \nuser data, though some OSs do include application data in the transactions. On the \nother hand, if a system has many files, then when it crashes we would have to do a \ncomplete file system scan to verify the integrity of the metadata before resuming sys-\ntem operation, and on a large server this could literally take hours. So it is normally \npreferable to slow the system response a bit in order to maintain integrity continu-\nously. This is especially true in a single-user system where there is often lots of spare \nCPU and disk time for this task while the user is typing or thinking. As a result, most \nfile systems developed in the last few years are transaction based. This includes JFS \nfor OS/2, HFS Plus for the Mac OS, NTFS for the Windows NT family, and many \nsystems for Linux, including Ext3, ReiserFS, XFS, and JFS. \n 13.8 SUMMARY \n In Chapter 12 we covered the concepts of file sys-\ntems and how they fit in an OS, including many pos-\nsible alternative designs. Real-file systems reflect \ndesign choices about mechanisms included in them. \nWe looked at several case studies of modern OS file \nsystems. These brief overviews showed how some \ncontemporary OSs use the mechanisms discussed in \nthe earlier chapter. We then discussed other issues \nrelated to file systems, beginning with mounting a file \nsystem. We continued with special topics like the \nreasons behind virtual file systems and related con-\ncepts and the purpose of memory mapped files. We \naddressed some of the utility programs an OS must \nprovide to manage file system information. We then \ncovered the ideas behind transactional or log-based file \ntechniques, which make more reliable file systems. \n In the next chapter we cover the lower levels of \nthe I/O system, primarily disk operation scheduling. \nelm49810_ch13_283-296.indd   295\nelm49810_ch13_283-296.indd   295\n12/11/08   6:43:55 PM\n12/11/08   6:43:55 PM\n",
        "category": "Category"
    },
    {
        "id": "317",
        "title": "Title for Chunk 317",
        "content": "Confirming Pages\n296 \nPart 4 A Depth-Oriented Presentation of OS Concepts: File Systems and Input/Output\n BIBLIOGRAPHY \n Larson, P., and A. Kajla, \u201cFile Organization: \nImplementation of a Method Guaranteeing Retrieval \nin One Access,\u201d  Communications of the ACM, \nVol. 27, No. 7, July 1984, pp. 670\u2013677. \n McKusick, M. K., W. N. Joy, S. J. Leffler, and R. S. \nFabry, \u201cA Fast File System for UNIX,\u201d  ACM \nTransactions on Computer Systems, Vol. 2, No. 3, \nAugust 1984, pp. 181\u2013197. \n Nelson, M. N., B. B. Welch, and J. K. Ousterhout, \n\u201cCaching in the Sprite Network File System,\u201d  ACM \nTransactions on Computer Systems, Vol. 6, No. 1, \nFebruary 1988, pp. 134\u2013154. \n Organick, E. I.,  The Multics System: An Examination of \nIts Structure. Cambridge, MA: MIT Press, 1972. \n Sandberg, R., et al., \u201cDesign and Implementation of \nthe Sun Network File System,\u201d  Proceedings of the \nUSENIX 1985 Summer Conference, June 1985, \npp. 119\u2013130. \n Sandberg, R.,  The Sun Network File System: Design, \nImplementation and Experience. Mountain View, \nCA: Sun Microsystems, Inc., 1987.  \n WEB RESOURCE \n http://www.linux.org \n http://technet.microsoft.com/en-us/sysinternals/default\n.aspx (Sysinternals, originally an outside technical \nreference, later bought by Microsoft) \n http://en.wikipedia.org/wiki/CP/M \n http://en.wikipedia.org/wiki/Virtual_file_system  \nhttp://www.yolinux.com/TUTORIALS/unix_for_dos_\nusers.html (A comprehensive comparison between \nDOS/Windows and UNIX/Linux commands) \n REVIEW QUESTIONS \n 13.1 Why was the FAT12 system designed with such \nsmall pointers? \n 13.2 The FAT organizations do not require any separate \nmechanism for tracking free space. Why not? \n 13.3 In the Windows NTFS, the directory entry for a \nfile might not contain a pointer to the data blocks \nfor the file. Why not?  \n 13.4 Why do UNIX/Linux i-nodes not contain a file \nname? \n 13.5 When does an OS mount the file system on a \nremovable disk drive? \n 13.6 Why are CDs mounted differently than removable \ndisk drives? \n 13.7 When a remote file system has been mounted by \nan OS, how does the remote file system appear to \nthe user and to application programs? \n 13.8 The virtual file system layer was used to allow \naccess to remote file systems. It had a more gen-\neral purpose, however. What was the purpose? \n 13.9 Briefly describe why memory mapped files are \nmore efficient than normal I/O. \n 13.10 Under the heading of File System Utilities we dis-\ncussed some utility commands that do not exist as \nutilities on the system. Why do they not exist?  \n 13.11 Briefly explain what it means to say that a file sys-\ntem is transactional or log based.  \nelm49810_ch13_283-296.indd   296\nelm49810_ch13_283-296.indd   296\n12/11/08   6:43:55 PM\n12/11/08   6:43:55 PM\n",
        "category": "Category"
    },
    {
        "id": "318",
        "title": "Title for Chunk 318",
        "content": "Confirming Pages\n257\n Chapter \n Chapter  12 \n 12 \n File Systems\u2014Basics \nIn this chapter: \n 12.1 Introduction 258\n 12.2 Directories 259\n 12.3 Access Methods 265\n 12.4 Free Space Tracking 269\n 12.5 File Allocation 273\n 12.6 Summary  280\n F\niles are one of the most important abstractions an OS can provide. The con-\ncept of files predates computers, so they are a metaphor that everyone under-\nstands. Programmers do not want to think about disk drives, tapes, or any \nother media. They want to think about the data they are processing, and they think \nof the data as a collection. In a computer, that collection is abstracted as a file. Pro-\ngrams need data to work on. We usually keep that data on secondary storage devices \nbecause primary storage is too expensive to keep all the data we need to have access \nto. Today, these devices are almost always rotating magnetic disk drives. As appli-\ncation programmers we do not want to be concerned with the details of operation \nof the thousands of different types of disk drives. We want to think of our data in \nterms of some abstraction. Usually, we think in terms of a file as being a collection \nof records or bytes. Therefore, a major function of most OSs is to provide for the \nabstraction of a file on secondary storage. The contents of a file are usually meaning-\nful only to application programs. By this we mean that the OS is typically not aware \nof the internal structure of the files. There are a few exceptions such as the execut-\nable (binary) programs that the OS can run and the object modules that are used to \nmake those files. Such files have structures that are defined by the OS itself. These \nstructures will be known by all the linker or loader utilities that are used to make the \nexecutable files and the compilers and assemblers that are used to produce the object \nmodules from source program files. \n In Section 12.1 we introduce the concept of file systems and how they fit in \nan OS. Modern computers typically contain hundreds of thousands of files. It must \nbe possible to organize the files so that things can be found. Next, we discuss the \nmechanisms used for supporting directories in file systems. Different applications \nhave different needs in terms of how they access the data in files. Sometimes the \nelm49810_ch12_255-282 New.indd   257\nelm49810_ch12_255-282 New.indd   257\n12/10/08   9:41:25 PM\n12/10/08   9:41:25 PM\n",
        "category": "Category"
    },
    {
        "id": "319",
        "title": "Title for Chunk 319",
        "content": "Confirming Pages\n258 \nPart 4 A Depth-Oriented Presentation of OS Concepts: File Systems and Input/Output\ndata can be processed sequentially. Sometimes the transactions are random. Some-\ntimes a special key number makes it easy to find a record. Other times we need to \naccess records based on their content. Section 12.3 describes various methods that \napplications can use for accessing the data in files. File systems on random-access \nmedia need to keep track of what parts of the media contain data and what parts are \nfree to use. So next we explore the need for tracking the space in a file system that is \nnot currently allocated to a file, and the different structures used to track that space. \nIn Section 12.5 we present the topic of the structure of the files themselves and dis-\ncuss the tradeoffs of the various methods. We conclude with a chapter summary in \nSection 12.6.  \n 12.1 INTRODUCTION \n File systems generally have layered designs, with each layer providing services to \nthe layer above it. Every OS has a unique partitioning of the functions across these \nlayers. Two things are true about all file systems: the top layer API is an abstraction \nof the concept of files and the bottom layer interacts directly with the hardware. As \nan example, a Linux file system organization is shown in  Figure 12.1  with the layers \nflowing left to right. We discuss file abstraction in this chapter and the bottom layers \nin the next chapter. \nDevice\nControl\nApplication Programs\nVirtual\nFile\nSystem\nBlock\nDevice\nDriver\nRemote\nServer\nCache\nManager\nNetwork\nProtocols\nNetwork\nInterface\nCharacter\nDevice Drivers\nSockets\nFile\nSystems\nFIGURE 12.1 \nLinux file and I/O \nsystems.\nelm49810_ch12_255-282 New.indd   258\nelm49810_ch12_255-282 New.indd   258\n12/10/08   9:41:29 PM\n12/10/08   9:41:29 PM\n",
        "category": "Category"
    },
    {
        "id": "320",
        "title": "Title for Chunk 320",
        "content": "Confirming Pages\n \nChapter 12  File Systems\u2014Basics  \n259\n 12.2 DIRECTORIES \n Before a program can use a file, it will need to find the file. The OS will need to \nprovide some sort of an index to the files that the program can search. We call \nthese indexes  directories. (Since more people have begun using computers who \nare not very knowledgeable about them, another term has also come into common \nusage for these structures:  folders. ) Directories will obviously have to store the \nname of the file, but they will also store other data about the file as well. In some \nOSs there may be a lot of other information kept for each file, but in others there \nis only a small amount. This other information about a file that is not part of the \nfile data is referred to as  file metadata. Some of these other items are almost uni-\nversal and others are found only rarely. Clearly, we will need a disk address that \npoints to the start of the file data. Usually, we also want to know the size of the file. \n Table 12.1  shows some examples of metadata we might find for a file on various \noperating systems. It is unlikely that any OS will have all of these items\u2014in some \ncases they represent different ways of accomplishing the same ends. In some OSs \nthis information is stored in the directory entry for a file. In other OSs it is stored \nin a separate structure\u2014most notably, UNIX-derivative OSs use an external table \ncalled an inode. \n 12.2.1 Logical structure \n There are many different logical structures that can be used to store a directory struc-\nture for a file system. We look at several common structures in this section. \n Single level \n How we logically organize the directory on a disk depends to some extent on the \nsize of the disk. As was discussed in Chapter 4, early disk drives were fairly small (a \nfew hundred thousand bytes) and the number of files was therefore small. In order \nto make maximum use of the limited space, the names were kept short (6\u20138 charac-\nters was fairly common) and the pointers to the blocks on the disk were kept small. \nThere was normally only a single directory for the entire disk. In  Figure 12.2 , we \nshow such a single-level directory structure. As we mentioned in earlier chapters, \nsome OSs with a single-level directory structure attempted to give the appearance of \nTABLE 12.1 Some Possible Directory Information Items\nFile Name\nArchived?\n Starting Block\nProtection (can be very complex)\nMaximum File Size\nEncryption Information\nCurrent File Size\nCompression Information\n Last Block\nOwner ID\nDate & Time Created\nFile Allocation Type\nDate & Time Last Written\nDate & Time Last Accessed\nelm49810_ch12_255-282 New.indd   259\nelm49810_ch12_255-282 New.indd   259\n12/10/08   9:41:29 PM\n12/10/08   9:41:29 PM\n",
        "category": "Category"
    },
    {
        "id": "321",
        "title": "Title for Chunk 321",
        "content": "Confirming Pages\n260 \nPart 4 A Depth-Oriented Presentation of OS Concepts: File Systems and Input/Output\na two-level structure by associating a group name with files so that a user could look \nat the directory and see only the files for a specific group. \n Tree structure \n Disk storage capacities have grown dramatically over time. Current disk drive tech-\nnology is such that drives with the capacity of several hundred billion bytes ( GB ) \nare standard equipment on a typical new personal computer. It is normal for such \na disk to have hundreds of thousands of files on it. An average user would have no \nspecific knowledge about many of them. A single directory would not work on such \nlarge drives. So a key development in the organization of the logical structure of disk \ndirectories was to allow for multiple directories. The main trick is simply to allow \ndirectories to refer to other directories in addition to referring to files. If we limit \nsuch references to link only to directories with no other link to them (including the \nstarting directory), the resulting structure is a tree structure with the starting direc-\ntory as the root of the tree. See  Figure 12.3 . \n With such a hierarchical directory organization we can divide the files up into \ndifferent categories. On machines that are used by more than one user, we can \nFilename\nLength\nStart\nMSDOS.SYS\n14\n0000404\nIO.SYS\n12\n0000303\nAUTOEXEC.BAT\n2\n0000505\nCONFIG.SYS\n1\n0000506\nCOMMAND.COM\n50\n0000600\nFIGURE 12.2 \nA single-level \ndirectory.\nW\nA\nQ\nT\nV\nA\nS\nR\nN\nS\nR\nN\nS\nR\nN\nS\nR\nN\nFile\n\u201cN\u201d\nFIGURE 12.3 \nA tree directory \nstructure.\nelm49810_ch12_255-282 New.indd   260\nelm49810_ch12_255-282 New.indd   260\n12/10/08   9:41:29 PM\n12/10/08   9:41:29 PM\n",
        "category": "Category"
    },
    {
        "id": "322",
        "title": "Title for Chunk 322",
        "content": "Confirming Pages\n \nChapter 12  File Systems\u2014Basics  \n261\ngive each user a \u201chome\u201d directory, which will contain all their data files in sub-\ndirectories. The various subdirectories can also be dedicated to different types of \nfiles\u2014perhaps one for utility programs, one for games, one for email, and so on. \nThis process can be continued to arbitrary depths. Email, for example, could be \nfurther divided into directories related to work, school, family, friends, and technol-\nogy. The school directory could be further divided into directories for each class, \nand so forth. \n A side effect of this organization is that we can have many files with the same \nfile name just by keeping them in separate directories. This would allow a group of \npeople working in different home directories to use identical file names.  Figure 12.3  \nshows the unlikely but perfectly legal case that many subdirectories contain the same \nset of file names. However, there was a price to pay for this feature\u2014the names of \nfiles can no longer be uniquely specified by a single name. In order to unambigu-\nously refer to a file we will have to give the entire  path of the directories leading to \nthe file. It is common to separate the subdirectory names with some delimiter that \ncannot be used as part of a file name. The characters  / and  \\ are the most often used \ncharacters. So in  Figure 12.3 , in order to unambiguously name the one file shown, \nwe would have to give the name \u201c \\W\\T\\N. \u201d \n Acyclic graph directories \n Unfortunately, the real world can\u2019t be accurately modeled by a tree structure. For \nexample, a canary is a bird. If we had a digital picture of a canary and we were \nstudying biology, then we might put it in a directory with cats and other animals. \nIt also flies, so if we were studying engineering we might put it in a directory with \nairplanes and other things that fly. It also is yellow, so if we were artists we might \nput it in a directory with butter and lemons and other things that are yellow. But if \nwe were studying biomedical engineering and working on color vision systems, we \nmight be at a loss as to how to classify this file. With only a tree structured directory \nwe are often in a quandary as to how we should classify some file. Furthermore, \nsometimes we later can\u2019t remember which folder we decided to put the canary pic-\nture in. A solution that is sometimes employed to help with this dilemma is to allow \ndirectories to form  directed acyclic graphs ( DAG s). The way to accomplish this \nis to use a special kind of directory entry called an  alias.  An alias is an entry that \ndoes not point directly to a file, but rather points to another directory entry. (The \nalias could actually point to the file, but there are some problems that arise with this \nmechanism, which we discuss later. The distinction between the two mechanisms \nis not relevant here.) \n Unfortunately, moving from a tree structure to a DAG introduces some prob-\nlems that must be considered. The simplest example is a one that would occur when \na program tries to sum up all the space in all the files on a system. If the aliases are \nnot considered, then the program might come up with the wrong total if some files \nare referenced more than once. Another large problem is how the system should \ndecide that a file can actually be deleted. Consider the case in  Figure 12.4 . Here we \nsee three directories. The top directory has two entries pointing to subdirectories, \n W and  Q. It also has a directory entry pointing to a file,  A. The subdirectory  W \ncontains an entry that also points to file  A. Suppose the user deletes file  A while \nelm49810_ch12_255-282 New.indd   261\nelm49810_ch12_255-282 New.indd   261\n12/10/08   9:41:30 PM\n12/10/08   9:41:30 PM\n",
        "category": "Category"
    },
    {
        "id": "323",
        "title": "Title for Chunk 323",
        "content": "Confirming Pages\n262 \nPart 4 A Depth-Oriented Presentation of OS Concepts: File Systems and Input/Output\nin subdirectory  W. The OS shouldn\u2019t actually remove the file because of the other \nreference to it in the top directory. \n There are two mechanisms that are sometimes used to resolve this issue. The \nfirst is to distinguish between the primary reference to a file and any aliases to a \nfile. The OS will also include a reference count in the primary directory entry. When \nan alias is added for a file, the reference count is incremented. Then if an alias is \ndeleted, the primary reference count is decremented, and if the count goes to zero \nthen the file can actually be deleted. There remains the issue of what happens when \nthe primary reference is deleted but aliases remain. The second technique is to make \nall aliases  symbolic references, including any path information. This is what we \nmeant earlier when we said that the alias should point to the directory entry for the \nfile instead of to the file itself. In this case, if the lower reference in the figure was the \nprimary reference, then the second directory entry would actually contain \u201c \\W\\A\u201d \nrather than a pointer to the file on the disk. \n 12.2.2 Physical structure \n In older systems there was considerable attention given to the speed of searching \ndirectories. As a result, older systems sometimes used techniques such as hashing to \nspeed up directory searches. However, over the last 20 years or so CPU and memory \nspeeds have speeded up by a factor of at least 10 faster than disk drives have speeded \nup. Therefore, most modern OSs don\u2019t worry about such matters, and directories \nare not sorted in any particular order. The search is simply sequential. In most cases \npeople tend to keep directories fairly small\u2014under 100 entries or so. \n 12.2.3 Operations on directories \n The OS must support several different operations on directories. One might think \nthat these would only be the operations that are supported on files, since directories \nare essentially files. However, there are a few differences. For one thing, because \nof the potentially catastrophic consequences of having an error in the file system, \nmost OSs do not allow an application program to write into a directory. Instead, the \napplication must call special routines to create a new file or directory or do any other \nsuch operations on directories.  Table 12.2  shows a number of operations that an OS \nmight support on directories. \nW\nA\nQ\nT\nV\nA\nS\nR\nN\nFIGURE 12.4 \nTwo directory entries \npointing to one file.\nelm49810_ch12_255-282 New.indd   262\nelm49810_ch12_255-282 New.indd   262\n12/10/08   9:41:30 PM\n12/10/08   9:41:30 PM\n",
        "category": "Category"
    },
    {
        "id": "324",
        "title": "Title for Chunk 324",
        "content": "Confirming Pages\n \nChapter 12  File Systems\u2014Basics  \n263\n The first operation listed is to change the working directory. As was mentioned, \neach subdirectory can contain files with the same local name as other subdirectories, \nso that a path name is required to unambiguously name a file. When we are enter-\ning names into a command line to run a program, we don\u2019t want to have to keep \ntyping path names all the time, so OSs use the concept of a working directory. The \nidea is that the user will take some action that specifies a specific directory to be \nthe  current working directory, or sometimes just the working directory. One way \nthe working directory can be determined is to log in to the system. Systems support-\ning such logins will usually assign the user\u2019s home directory to be the current work-\ning directory at login time. A reference to a file name that does not include any path \ninformation is called an  unqualified name. Any commands that make reference to \nan unqualified name will imply that the file is in the current working directory. So, \nin  Figure 12.5 , if directory  W were the current working directory, then a reference \nto file  S would be assumed to be a reference to the file in that directory. In order to \nrefer to the file  S in the subdirectory  T of directory  W, the program would have to \nspecify a path to that directory as a part of the name. In this case it could say either \n\u201c \\W\\T\\S \u201d or \u201c .\\T\\S. \u201d The first reference is an  absolute pathname. It begins with the \ndelimiter that separates directory names in the path so it is interpreted as starting at \nthe root of the tree. The second reference is called a  relative pathname. The \u201c . \u201d is a \nspecial name that specifies the current working directory. So this pathname says that \nTABLE 12.2 Operations OSs Must Support on Directories\nChange Working Directory\nCreate Directory\nDelete Directory\nList Directory\nCreate File\nDelete File\nSearch for a File\nRename a File\nCompletely Walk the Directory Tree\nW\nS\nQ\nT\nS\nA\nS\nR\nN\nS\nR\nN\nS\nR\nN\nFIGURE 12.5 \nPaths in a directory \nstructure.\nelm49810_ch12_255-282 New.indd   263\nelm49810_ch12_255-282 New.indd   263\n12/10/08   9:41:30 PM\n12/10/08   9:41:30 PM\n",
        "category": "Category"
    },
    {
        "id": "325",
        "title": "Title for Chunk 325",
        "content": "Confirming Pages\n264 \nPart 4 A Depth-Oriented Presentation of OS Concepts: File Systems and Input/Output\nthe path starts in the current working directory and goes to the subdirectory  T, where \nit will then find the file name  S. \n The other common mechanism for changing the current working directory is a \nChange Directory command\u2014usually something like  cd or  chdir. This command \ncan specify an absolute path or a relative path. Often, shorthand notation can be \nused, for example, so that  cd .. will change the working directory to the parent direc-\ntory of the current directory. On Linux and other UNIX-like systems the cd com-\nmand with no arguments will place the current working directory at the user\u2019s home \ndirectory. \n The commands to create and remove directories are fairly straightforward. \nAgain, these functions exist since we don\u2019t usually let applications write in direc-\ntories. Rather, we demand that they use special OS calls to do these functions. \nSpecial utility programs  mkdir and  rmdir exist to allow the user to request these \noperations through the command interpreter. Normally, the OS might not provide \na built-in function to list the contents of a file, but directories are very special \nfiles, so the OS must provide a function to list the contents of a directory for an \napplication. Again, utility programs ( dir or  ls ) are provided to make this func-\ntion accessible to a user through the command-line interface. However, when an \napplication program needs to create a new file, it must have a way to ask the OS \nto do that. Similarly, a program may want to delete a file that is no longer needed. \nThere is generally no simple utility to create a new file because such a file would \nbe empty. Usually a file is created as a byproduct of some other action. The clos-\nest thing to a utility would be a file copy command ( cp or  copy ). Under Linux \none can copy the special pseudo file /dev/zero to a file name to create a file of \nbinary zeros. Of course, files are often created with text editor utilities like  vi or \n notepad. Other applications create their own files such as .doc files or .xls files \nunder Microsoft Office. File deletion is usually exposed to the user with a utility \nthat will delete files like  del or  rm. Deleting directories is also a special utility \nwith a name like  rmdir. Searching a directory for a file is often something an \napplication needs to do. This is not for the purpose of opening the file for input. \nThe OS (or the language library modules) will do that. Rather, it is for when the \napplication wants to create a new file. It will first need to check to make sure that \nsuch a name is not already in use in the current directory. (Some language librar-\nies might do that as well.)  \n 12.2.4 File system metadata \n We mentioned before that directory entries contain information about files that \nis not a part of the file itself and that this information was called file metadata. \nThere is also other information in the file system that is not about specific files and \nthus is not part of the directory entries. For example, where is the first directory \nlocated in the file system? We will see later that there will be other structures that \nwill tell us things such as how to find free disk blocks. The details will vary with \nthe particular file system, but there are always these other structures, and they are \nvery important to the integrity of the file system. They are collectively known as \n file system metadata.  \nelm49810_ch12_255-282 New.indd   264\nelm49810_ch12_255-282 New.indd   264\n12/10/08   9:41:30 PM\n12/10/08   9:41:30 PM\n",
        "category": "Category"
    },
    {
        "id": "326",
        "title": "Title for Chunk 326",
        "content": "Confirming Pages\n \nChapter 12  File Systems\u2014Basics  \n265\n 12.3 ACCESS METHODS \n An OS presents an application program with an API that represents the abstraction of a \nfile. The API has to include semantics on how the application tells the OS which portion \nof the file it wants to access. Different applications need different modes of access.  \n 12.3.1 Sequential access \n Initially, computer applications were designed to process information in batches that \nwere sequenced by some key information such as a part number or customer num-\nber. Such applications needed to process files sequentially. At one time these files \nwere literally sorted decks of punched cards and later were sorted blocks of data on \na magnetic tape. The system might have an input file of transactions such as time \ncards and a master file such as the payroll records, both of which might be in order \nby the employee number. The application would start reading at the front of each file \nand would incrementally read each file, keeping them synchronized by the key field, \nin this case the employee number. For decks of cards the records were a fixed size. \nFor magnetic tape they could be any convenient size up to some maximum that the \nhardware or the OS would dictate. For sequential processing on disk storage the OS \n(or a software library) has to have some definition of what the record size is for each \nfile and it then has to keep track of the  current position (or  current record pointer ) \nfor each application that has the file open. This is seen in  Figure 12.6 . (Note that \ndifferent processes accessing the same file probably would have different current \nrecord pointers.) For normal sequential processing the OS will increment the current \nrecord pointer for each read or write. There is usually a command in the API to reset \nthe current record pointer to the start of the file. This operation would be analogous \nFIGURE 12.6 \nSequential file with \ncurrent record \npointer.\nCurrent Record Pointer\nfor process 104\nCurrent Record Pointer\nfor process 85\nSequential file\nelm49810_ch12_255-282 New.indd   265\nelm49810_ch12_255-282 New.indd   265\n12/10/08   9:41:31 PM\n12/10/08   9:41:31 PM\n",
        "category": "Category"
    },
    {
        "id": "327",
        "title": "Title for Chunk 327",
        "content": "Confirming Pages\n266 \nPart 4 A Depth-Oriented Presentation of OS Concepts: File Systems and Input/Output\nto rewinding a tape to the starting position. Since the disk blocks are a fixed size and \nmay not exactly match the record length requirements of the application, it is fairly \ncommon for the OS to combine more than one logical record into a physical data \nblock. Blocking is covered more fully in the next chapter. \n 12.3.2 Random access \n As disk drives got much cheaper, secondary storage migrated from being stored on \nmagnetic tapes to being stored on disk drives. Once the data was mostly kept online \nit became possible to process each transaction as it occurred rather than accumulat-\ning them to be processed in sequential batches. Transaction processing is generally \npreferable to batch processing because it allows management to track the status of \nan enterprise more nearly in real time. However, this meant that the application had \nto access the master file data in random order rather than purely sequential order. So \nthe file APIs were extended to include another model: random access. In this model \nthe application will tell the OS which record in the file it needs and the OS will move \ndirectly to that record and access it for reading or writing. Usually this will require \nsome simple mapping of a key value to the record number. For example, a small com-\npany might simply assign the employee numbers sequentially and use the employee \nnumber as the record number. In some OSs this addressing is expressed as a record \nnumber and in others it is expressed as a byte offset from the start of the file. \n Note that sequential access is still possible on random access files. When the \napplication accesses a record randomly this will leave the current record pointer \npositioned at the next record. The application can now issue a  read next operation \nand the OS will return the next record and increment the current record pointer. We \ncan see this in  Figure 12.7 , where the employee number for employee 34 is used to \nRecord for employee\n34 is in record 34.\nRandom file\nFIGURE 12.7 \nA random access \nmethod file.\nelm49810_ch12_255-282 New.indd   266\nelm49810_ch12_255-282 New.indd   266\n12/10/08   9:41:31 PM\n12/10/08   9:41:31 PM\n",
        "category": "Category"
    },
    {
        "id": "328",
        "title": "Title for Chunk 328",
        "content": "Confirming Pages\n \nChapter 12  File Systems\u2014Basics  \n267\naccess that record in the file. If the application does a read next operation it will get \nthe next record. \n In order to start accessing at any point in a random access file, the OS usually \nprovides a  seek command, which will position the current record pointer at the first \nrecord that has a key value greater than or equal to a given key value. When OSs only \nran one process at a time this command would actually position the disk head to this \nposition in the file (i.e., it would seek the physical location of the data). Now it is a \nlogical positioning only. \n 12.3.3 Higher-level access methods \n Most OSs provide at least these two different access methods. A few OSs provide one \nor more higher-level access methods. We describe two such mechanisms in the rest of \nthis section. Most of these higher-level access methods are also subsumed in database \nsystems and are sometimes provided as library modules as support for high-level lan-\nguages. Having the access methods provided by the OS means that less development \nwork needs to be done to support many high-level languages as long as the semantics \nof the APIs are similar enough for the OS access method to support them. \n Indexed access \n Random access often will not work as well for a larger company employee file as it \ndid for a smaller company. After a while many employees will retire, leave the com-\npany, get fired, and so on. The result would be that there would be many records in the \nmaster file that would not represent a current employee. For such situations the OS \nmight provide an access method called an indexed access method. A fairly common \nterm for such access methods is  ISAM, or  indexed sequential access method. \n How such access methods work can be seen in  Figure 12.8 . The figure shows \na data file for a retail store. It has three areas: the  primary data area where the data \nrecords are kept; the  primary key area, which is an index to the main key field in the \nrecord; and a  secondary key area, which is an index to a different variable. As records \nare added to the file they are written sequentially to the primary data area. However, \nfor each record written to the primary data area an additional record is written to the \nprimary key area and another record is written to the secondary key area. (Note that \nABC\n0\nIndex\nSKU\nNo.\nMFG\nNo.\nOther\nInfo.\n1\n2\n3\n4\n5\n6\n7\nCBA\nXYZ\nJKL\nMNO\nCBA\nABQ\nABQ\nRST\nUVW\nUnused\nPrimary Data Area\nABC\nSKU\nNo.\nIndex\nNo.\n0\nABQ\n3\nMNO\n2\nRST\n4\nXYZ\n1\nUnused\nPrimary Key Area\nABQ\nMFG\nNo.\nIndex\nNo.\n3\nCBA\n0\nCBA\n2\nJKL\n1\nUVW\n4\nUnused\nSecondary Key Area\n. . .\n. . .\n. . .\nFIGURE 12.8 \nAn indexed access \nmethod file.\nelm49810_ch12_255-282 New.indd   267\nelm49810_ch12_255-282 New.indd   267\n12/10/08   9:41:31 PM\n12/10/08   9:41:31 PM\n",
        "category": "Category"
    },
    {
        "id": "329",
        "title": "Title for Chunk 329",
        "content": "Confirming Pages\n268 \nPart 4 A Depth-Oriented Presentation of OS Concepts: File Systems and Input/Output\nthere might not be a secondary key area or there might be several of them.) Each record \nin any of the key areas is stored in order by the value of the associated key field. In the \nfigure there are two key fields that have been used to index the data: the SKU number \n(the stocking number of the retail store) and the manufacturer\u2019s item number. So when \nrecord 0 was written into the primary data area a record was written to the primary \nkey area that showed that SKU number ABC was found in data record 0 and another \nrecord was written to the secondary key area showing that manufacturer\u2019s number \nCBA was in data record 0. When the second record was written into the primary data \narea, then similar records were written into the key areas. However, when the third data \nrecord was added, the record that was added to the primary key area caused a problem \nsince it was not in order, so we had to sort this area by the value of the key. There are a \nnumber of techniques for building the key areas that avoid actual sorting of the entire \nfile, including  binary trees  (or  B-trees ), hashing, and multilevel indexing. \n Notice that the keys do not have to be a single field. An index might be created \nthat concatenated a last name and a first name, for example. Also notice that the \nkey fields may or may not allow duplicate keys. We see in  Figure 12.8  that a single \nmanufacturer\u2019s part number is stocked in the store with two different SKU numbers. \nIn a more likely scenario, in our employee file we might have two Bill Smiths, but \nwe should not have two employees with the same Social Security number. Such an \naccess method is close to being a database system but is somewhat simpler. \n The three \u201careas\u201d that we discussed in  Figure 12.8  could be portions of a single \nfile or they could be stored as separate files. Having them as separate files might \nmake it simpler to add an index on another key after the file was initially created. \nThe risk of having separate files is that it becomes very easy when backing up and \nrestoring files to end up with files that did not go together. Of course, we would \nlikely have a utility program that verified and possibly rebuilt the secondary index \nfiles, but on a large file this could take some time, and we might not realize immedi-\nately that there was a problem such that we should run that utility. \n Hashed access \n Another higher-level access method sometimes provided by OSs is a hashed access \nmethod. Hashing a key field can be used to create a random key value for use in \naccessing a random access file when the key values are not all used. Of course, gen-\nerating hash keys probably will create record numbers that collide for different val-\nues of the source key, so a mechanism must be provided to resolve these collisions. \nWhile not as common as indexed sequential access methods, a hashed file access \nmethod is still a useful tool for an OS to provide. \n 12.3.4 Raw access \n For some applications the services provided by the file system would be counter-\nproductive. This can happen when an application has high performance require-\nments and the patterns of accessing the files it uses are well known to the developers \nof the application. The services designed for most applications are provided for \nan \u201caverage\u201d or \u201ctypical\u201d application where the file processing demands are not \nunusual. In such cases the OS will sometimes provide a  raw access method. In \nelm49810_ch12_255-282 New.indd   268\nelm49810_ch12_255-282 New.indd   268\n12/10/08   9:41:31 PM\n12/10/08   9:41:31 PM\n",
        "category": "Category"
    },
    {
        "id": "330",
        "title": "Title for Chunk 330",
        "content": "Confirming Pages\n \nChapter 12  File Systems\u2014Basics  \n269\nthis case the OS does not provide any file structure, but reserves an area of the disk \nwherein the application can provide its own structure. Examples of applications \nwhere such raw access are useful include the paging store for the OS itself and \ndatabase systems.  \n 12.4 FREE SPACE TRACKING \n The OS will be storing files and directories in blocks on the disk. In order to do that \nit will have to keep track of which blocks have not been used yet. There are gener-\nally two ways to keep track of this  free space: linked lists and bitmaps. Initially, file \nsystems kept track of the smallest chunk of space that could be accessed on a disk \ndrive\u2014a sector. As disk drives got larger, the size of the pointers to the sectors on the \ndisk got larger. For example, modern disk drives are now extending into the terabyte \nrange. Anything larger than a 2 terabyte drive would require a pointer greater than \n4 bytes. Naturally, the file systems initially designed for floppy disks did not use \npointers that big. So when the disk drives outgrew the pointers in the file systems, \none easy solution was to allocate more than one sector at a time. Simply allocat-\ning two sectors together would double the reach of the pointer. The process was \nextended, and in some cases file systems have allocated up to 64 sectors at a time, \nthough sizes of 4 KB are more typical. The resulting structure is referred to as a \n block, or sometimes as a cluster. This seemed good, but one problem with the mech-\nanism was that it wasted space if the data stored on the disk included many small \nfiles. Most script (or batch) files, for example, are just a few lines of text. Few would \nfill a single sector, much less 64 sectors! Since this technique of allocating multiple \nsectors at a time is still very common, we will generally speak of allocating a block \nin this chapter rather than allocating a sector. \n 12.4.1 Linked list free space tracking \n One way to keep track of the free space is to put all the free blocks in a list. \n Figure 12.9  shows blocks on a disk drive. The OS must keep track of the first block \non the list. Each free block will then contain a pointer to the next free block. Notice \nthat the list is not in any order. We might initially start with an ordered list, but when \nan application frees up a block we will want to be able to put it in the list at the front \nso that we do not have to change any other sector on the disk to point to this newly \nfreed block. We will take the pointer to the block currently at the head of the list and \nput it in the newly freed block. We will write the sector of the block that actually \ncontains the next free block pointer to disk and we will record the newly freed block \nas the first block in the list. \n One good aspect of this mechanism is that the only \u201cextra\u201d space it requires to \nkeep track of the free space is the single pointer to the head of the list. All the rest \nof the pointers are kept in the free space itself. A bad aspect of this mechanism is \nthat it is normally very difficult to allocate contiguous blocks of space. So if appli-\ncations might want to have contiguous blocks of data on the disk drive, this is not \nelm49810_ch12_255-282 New.indd   269\nelm49810_ch12_255-282 New.indd   269\n12/10/08   9:41:32 PM\n12/10/08   9:41:32 PM\n",
        "category": "Category"
    },
    {
        "id": "331",
        "title": "Title for Chunk 331",
        "content": "Confirming Pages\n270 \nPart 4 A Depth-Oriented Presentation of OS Concepts: File Systems and Input/Output\na good mechanism to use. Another problem with this mechanism is that to get the \naddress of the next free block, the OS has to read the free block because it contains \nthe pointer to the next one. In the next section we discuss some ways to get around \nthis problem.  \n 12.4.2 Improved linked lists \n What linked lists need in order to work better is to have some way for us to not \nhave to read each sector before we use it in order to find the next available free \nsector. There are several ways to do this. Two common ways include grouping and \nindexing. With indexing we merely store a bunch of free space pointers in a single \nblock. Suppose a block was only a sector, 512 bytes, and our pointers were 32 bits, \nor 4 bytes. Then one block could store 128 pointers. So the block at the head of the \nchain, instead of just pointing to the next free block, would point at the next 128 free \nblocks. This first block would be called an  index block. An example is shown in \n Figure 12.10 . We could use all the blocks pointed to by the first index block and then \nuse the index block itself. The last block pointed to should be another index block. \nAs we use each data block we need to write the index block back to the disk so it will \nstay current, but a slight optimization there would be to take out several block point-\ners at the same time and rewrite the block, temporarily holding those block pointers \nin RAM. This is called  preallocation. It is a technique that can be used with many of \nthe free space tracking mechanisms in order to minimize the updating of the data on \nthe disk. Of course, there is some possibility that the system might go down and the \ninformation on the disk would show that those blocks were in use when they were \nnot. Having the system go down is a fairly low-probability event. If it does go down, \n14\n0\n6\n12\n18\n24\n30\n36\n15\n26\n27\n25\n20\n24\n16\n28\nBlock\nNumber\nFree Space\nHead = 8\nUnused\nUsed\n= end of list\nFIGURE 12.9 \nA free space chain.\nelm49810_ch12_255-282 New.indd   270\nelm49810_ch12_255-282 New.indd   270\n12/10/08   9:41:32 PM\n12/10/08   9:41:32 PM\n",
        "category": "Category"
    },
    {
        "id": "332",
        "title": "Title for Chunk 332",
        "content": "Confirming Pages\n \nChapter 12  File Systems\u2014Basics  \n271\nthe few blocks we lose track of is normally a small part of the available space. There \nwill be no loss of data in the files or metadata. Also, we will have file system check-\ning utilities that will recover the lost blocks at the cost of scanning the file system. \nTherefore, we will not worry about the possible loss of consistency in the metadata. \n Another mechanism that can improve linked list free space tracking is  group-\ning. In this technique the OS will take every opportunity to determine that two or \nmore blocks in the chain are adjacent. This can easily happen if blocks can be allo-\ncated to files in multiples rather than only one at a time. In this case, the first block \nin that group will contain not only a pointer to the next free block, but also an indica-\ntion of how many of the following blocks in the list are adjacent to one another. Such \na mechanism is shown in  Figure 12.11 . This will allow the allocation mechanism to \nsometimes allocate contiguous blocks more easily. But also, this first block can be \nread and then the rest of the blocks of the group handed out without having to read \nthe disk again. \n 12.4.3 Bitmap free space tracking \n Another approach to free space tracking is to have a bitmap in which each block in \nthe file system is represented by a single bit in a long string. If the bit is set one way, \nthen the block is free. If it is set the other way, then it is in use. Whether the \u201c1\u201d bit \nindicates that the block is free or it indicates that the block is in use depends mostly on \nthe instruction set of the computer. We will clarify this shortly. Recall that one prob-\nlem with the linked list mechanism is the difficulty in allocating multiple contiguous \nblocks. With a bitmap this is much simpler than it was with the linked list mechanisms. \nIt is merely necessary to find a string of contiguous bits of the required size. It is this \nFree Space\nHead = 8\n0\n6\n12\n18\n24\n30\n36\nBlock\nNumber\nUnused\nUsed\n= end of list\n14\n15\n16\n20\n24\n25\n26\n27\n28\nFIGURE 12.10 \nAn indexed free \nspace chain.\nelm49810_ch12_255-282 New.indd   271\nelm49810_ch12_255-282 New.indd   271\n12/10/08   9:41:32 PM\n12/10/08   9:41:32 PM\n",
        "category": "Category"
    },
    {
        "id": "333",
        "title": "Title for Chunk 333",
        "content": "Confirming Pages\n272 \nPart 4 A Depth-Oriented Presentation of OS Concepts: File Systems and Input/Output\nscan for a contiguous block that we will want to execute efficiently. The instruction set \nof the computer may be such that it is much more efficient to find a string of 0\u2019s than \na string of 1\u2019s. Or it may be the other way around. These would be the only consider-\nations that would make it important whether a \u201c1\u201d bit meant a free block or a block in \nuse. An example of a bitmap used for free space tracking is seen in  Figure 12.12 . \n Notice that using a bitmap to keep track of the available free space costs us more \nmemory than does the linked list mechanism. We need to keep in memory a portion \nof the bitmap. Most likely we will keep an entire block because it will be easier to \nread it that way. With the linked list we only kept one pointer\u2014maybe a few more if \nwe were preallocating the blocks. However, the cost of memory is already very low \nnow and is continually declining so this is probably not a significant factor. We do \nneed to update the disk copy of the bitmap as we allocate the blocks. But we can still \nuse the preallocation technique discussed with the linked list tracking mechanism. It \nis very important that we update the map before we actually begin to use the space. If \nwe don\u2019t then we run the risk of having a block allocated to more than one file. This \ndoes not work well. \n Not only does the bitmap take more RAM space, it also takes more disk space. \nThe bitmap has to be in a dedicated spot on the disk. That location cannot be used for \ndata storage. In the linked list mechanism the pointers were stored in the free blocks \nthemselves. Once again, however, disk space is relatively inexpensive and the price \nis constantly declining, so this is also probably not a significant factor today, though \nit certainly was at one time. \n There is one more common mechanism for tracking free space, but it is a byprod-\nuct of the mechanism used to link the blocks of the file together in the FAT structure, \nso we will discuss it under that heading. \n14\n0\n6\n12\n18\n24\n30\n36\n24\n15\u201317\n20\n24\u201328\nBlock\nNumber\nFree Space\nHead = 8\nUnused\nUsed\n= end of list\nFIGURE 12.11 \nA grouped free space \nchain.\nelm49810_ch12_255-282 New.indd   272\nelm49810_ch12_255-282 New.indd   272\n12/10/08   9:41:32 PM\n12/10/08   9:41:32 PM\n",
        "category": "Category"
    },
    {
        "id": "334",
        "title": "Title for Chunk 334",
        "content": "Confirming Pages\n \nChapter 12  File Systems\u2014Basics  \n273\n 12.5 FILE ALLOCATION \n The other major design decision about file systems is how the files themselves \nshould be organized on the disk drive. The abstraction(s) that the OS presents to the \nuser through the API will partly determine the types of organization that the OS can \nuse. There are basically three mechanisms for allocating the space to a file. These \nare contiguous, linked, and indexed mechanisms. Note that it is not necessary that \nan OS use only one of these mechanisms. Some OSs support multiple types of file \nallocation. All that is necessary are to have APIs that support both types of allocation \nrequests and to keep track of the free space correctly. \n 12.5.1 Contiguous allocation \n Contiguous allocation means that the blocks allocated to a file have numbers in a \nsequence strictly increasing by 1. For example, in  Figure 12.13 , we see File B occu-\npying contiguous blocks 1000\u20131799. Such blocks do not necessarily start on a track \nboundary. They are merely adjacent in the numbering scheme. This method of file \nspace allocation has some distinct advantages. For one thing, very little information \nis needed to find all of the data. All that is required are the sector address of the first \nblock and the length of the file in blocks. This allocation method makes random \naccess to the data very simple. The exact mechanism varies depending on the OS API \nand the block size being allocated. With some OSs, for example, the API requires \n0\n6\n12\n18\n24\n30\n36\nBlock\nNumber\nUnused\nUsed\n111111110000001110000000111100000000001100\nBitmap \u2013 1 bit = block is used\nFIGURE 12.12 \nUsing a bitmap for \nfree space tracking.\nelm49810_ch12_255-282 New.indd   273\nelm49810_ch12_255-282 New.indd   273\n12/10/08   9:41:33 PM\n12/10/08   9:41:33 PM\n",
        "category": "Category"
    },
    {
        "id": "335",
        "title": "Title for Chunk 335",
        "content": "Confirming Pages\n274 \nPart 4 A Depth-Oriented Presentation of OS Concepts: File Systems and Input/Output\nthat the application pass a byte number of an offset in the file at which the read is \nto start and a length of data to read\u2014normally a multiple of the sector size. In this \ncase the access method merely divides the byte offset by the block size and adds it to \nthe starting sector address of the first block in the file. Sequential access is trivial, of \ncourse. As was mentioned above, if the space tracking mechanism is a bitmap, then \nallocating contiguous space is fairly trivial. All that is necessary is to find a contigu-\nous string of bits in the bitmap that indicate free blocks. With a linked list free space \ntracking mechanism it would be highly impractical, though not technically impos-\nsible. The grouping mechanism we described might help somewhat in this regard. \n One problem with contiguous allocation is that once a file has been allocated it \ncan be difficult to make it any larger because it is likely that some other file will be \nallocated right after the file we want to make larger. For example, in  Figure 12.13 , \nFile A could not be made larger without moving File B. In order to avoid this prob-\nlem, programmers will tend to allocate more storage for the file than is currently \nrequired by the data. That way, the file can grow for some time before it needs to \nbe made larger. For example, the programmer might know that the system now has \n100 records and typically will add another two records per month. The file is then \nallocated with space for 130 records and can operate for somewhat more than 2 years \nwithout filling up and needing to be reallocated. We call this  programmer fragmen-\ntation. Unfortunately, this is wasteful of storage. If there is sufficient free space on \nthe disk drive to allocate another copy of the file, then the operation is fairly simple, \nbut it can be time-consuming if the file is large. If there is not sufficient space for \nthe new copy, then the file must be unloaded to a tertiary storage device, the old file \ndeleted, other files moved around to make enough contiguous space for the new file, \nthe new file allocated, and the data loaded into the new file. \n The awkwardness of this procedure led to a variation on the contiguous allocation \nmechanism\u2014the use of  extents. In this scheme a file is not limited to a single contigu-\nous allocation. The initial allocation is a contiguous block, but if it fills up, instead of \nmaking a new copy, a secondary allocation is made, not necessarily contiguous to the \ninitial allocation. This secondary extent is also contiguous, but is typically smaller than \nthe initial (primary) allocation. Additional secondary extents can be allocated, usually \nName\nStart\nDirectory\nSize\nFile A\n0\nFile B\n1000\nFile C\n2020\n1000\n800\n1200\nunused\nBlock FFFFF\nBlock 00000\nFile C\nunused\nFile B\nFile A\nFIGURE 12.13 \nContiguous file \nallocation.\nelm49810_ch12_255-282 New.indd   274\nelm49810_ch12_255-282 New.indd   274\n12/10/08   9:41:33 PM\n12/10/08   9:41:33 PM\n",
        "category": "Category"
    },
    {
        "id": "336",
        "title": "Title for Chunk 336",
        "content": "Confirming Pages\n \nChapter 12  File Systems\u2014Basics  \n275\nup to some small limit\u201416 or so. The calculation of random file addresses is now a bit \nmore complicated. With a single contiguous file we took the record or byte offset and \ncalculated a displacement from the front of the file. Now we need to have a table of \nstarting logical and physical addresses and sizes for the various extents. We calculate \nthe offset and then we look at the table. We find the extent that contains the offset and \nthen we calculate the offset from the start of that extent. This is still fairly trivial com-\npared to the speed of a hard drive. Extents are not a particularly new scheme, having \nbeen used, for example, at least as far back as OS/360 by IBM in the late 1960s. \n There are several instances of waste in the contiguous allocation scheme. The \nfirst instance is caused by the fact that the smallest portion of the space that we can \naccess is a sector. We usually compound that problem by tracking the allocation in \nblocks rather than in sectors. So, we might be allocating blocks of four sectors, but in \nmost cases we will not need all of that allocation. Sometimes we will fill up the last \nblock exactly, but sometimes we will only need one byte of the last block. On aver-\nage we will use only half of it. This unused space caused by the allocation granularity \nis called  internal fragmentation. We had exactly the same problem in Chapter 10\nin which we discussed primary memory allocation. Unless we have very many files \nthat are very short, internal fragmentation on disk drives is not usually of much con-\nsequence given the size and cost of disk drives today. \n Of greater consequence is the problem of  external fragmentation. Again, this \nproblem was discussed in Chapter 10 on primary memory management. The prob-\nlem arises when we come near to filling up the disk. As we allocate and free contigu-\nous files we will tend to chop up the free space because we keep taking a contiguous \nfree space out of bigger free spaces. Eventually, the leftover holes become too small \nfor the next allocation we want to make, even though there is sufficient free space \nfor the allocation. In  Figure 12.13 , for example, based on the sizes shown, we prob-\nably have space for about 2,000 blocks, but the space is broken into two pieces, so \nwe could not allocate a file that big, even though we have enough free space to do it. \nThe solution to the problem is somewhat ugly. It is known as  defragmentation. The \nbasic idea is to move some of the files into holes where they will fit, leaving larger \nholes for the files we want to allocate. The technique was described more fully in \nChapter 10, so we will not rehash it here. The third sort of \u201cfragmentation\u201d is the \n programmer fragmentation we discussed where the programmer allocates more \nspace to the file than is really needed. This, however, is more of a social problem \nthan a technical problem, but it comes about because of the difficulty of making a \ncontiguous file bigger, so it needs to be mentioned. \n 12.5.2 Linked allocation \n The second common file allocation mechanism is a linked list. This mechanism is just \nlike a linked list structure in primary memory, but here the linked elements are always \nthe same size\u2014one disk block. Each block will contain the starting sector address of the \nnext block in the file. So, one downside of the linked mechanism is that a part of each \nblock is spent on this link. In the worst case we have a single sector of probably 512 bytes \nwith a pointer of probably 4 bytes, so the waste is less than 1%. If the blocks are bigger \nthan one sector, then the overhead is even less.  Figure 12.14 shows such a structure. \nelm49810_ch12_255-282 New.indd   275\nelm49810_ch12_255-282 New.indd   275\n12/10/08   9:41:33 PM\n12/10/08   9:41:33 PM\n",
        "category": "Category"
    },
    {
        "id": "337",
        "title": "Title for Chunk 337",
        "content": "Confirming Pages\n276 \nPart 4 A Depth-Oriented Presentation of OS Concepts: File Systems and Input/Output\n There is another downside to the linked list allocation mechanism: it is some-\nwhat difficult to do random access methods on such files. It is not impossible, \nhowever. Consider the files shown in  Figure 12.13 . All that would be necessary to \nprovide random access to this file is to enlarge on the idea of the extents discussed in \nthe section on contiguous allocation. We merely need a table in RAM that contains \na pointer to the start of each disk block allocated to the file. Though this table might \nbe large in the case of a very long file, and it could take some time to follow the \nentire chain to build the table, it is probably a practical mechanism in most cases. \nIf the file is not going to be open for very long, then the space and time required to \nbuild and store the table might be too expensive. If there is going to be a good deal \nof random access on the file and the file is not too big, then it would be practical. \nIn addition, we would not necessarily need to follow the entire chain when the file \nwas first opened. We might follow the chain and fill in the table only as references \nto records caused us to need to access a part of the file where we had not yet read \nthe pointers. \n In  Figure 12.14 , we see a directory entry that describes a linked file. It contains \na pointer to the first block of the file and the length of the file in blocks. It also con-\ntains a pointer to the last block of the list. On first examination it might not seem \nnecessary to store the pointer to the end of the file, and actually it isn\u2019t, because we \ncould always follow the pointers in the list to find the end, but it is there for two \npractical reasons. The first is that sometimes we want to open the file in an \u201cappend\u201d \nmode\u2014we just want to add to the end of the file. Log files are a good example of \nsuch action. It will always be faster to be able to go directly to the end of the list. The \nName\nStart\nDirectory\nFile A\n12\nFile B\n3\nFile C\n31\nSize\n4\n3\n10\nEnd\n21\n11\n40\n4\n11\n0\n6\n12\n18\n24\n30\n36\n13\n20\n32\n33\n34\n35\n36\n37\n38\n39\n40\n21\nBlock\nNumber\nFIGURE 12.14 A linked list file allocation method.\nelm49810_ch12_255-282 New.indd   276\nelm49810_ch12_255-282 New.indd   276\n12/10/08   9:41:33 PM\n12/10/08   9:41:33 PM\n",
        "category": "Category"
    },
    {
        "id": "338",
        "title": "Title for Chunk 338",
        "content": "Confirming Pages\n \nChapter 12  File Systems\u2014Basics  \n277\nsecond reason has to do with redundancy. It is always good to have some redundancy \nin the file system metadata. Then  when problems arise, the utility programs that we \nwill run to repair the file system have a better indication of what might be the correct \ncourse of action. \n On the good side, with linked files we will have no programmer fragmentation. \nSince it is trivial to extend a linked file, there is no pressure to overallocate the initial \nfile space. \n In the section on contiguous file allocation we discussed the need for space com-\npression when there was sufficient free space available to satisfy an allocation request \nbut the available space was not contiguous. We mentioned that  defragmentation was \na name sometimes used for this process. Perhaps somewhat surprisingly, linked files \nalso suffer from a related structural problem, and the defragmentation term is proba-\nbly better applied to this problem. A linked file structure can be viewed as an extreme \ncase of a structure using contiguous extents, where the extents are a single block \nlong. The problem that happens with linked files is that as the file grows, the \u201cnext \navailable\u201d block can be anywhere on the disk. As a result, the linked list can tend to \nbounce back and forth on the disk, depending on which block was available when the \nfile was lengthened. An example of such extreme allocation is shown in  Figure 12.15 . \nProcessing such a file with a program that is doing much I/O and very little process-\ning can be very costly. Rearranging all the files so that the blocks allocated to each \nfile are in order and are contiguous is known as defragmentation. It can significantly \nspeed up the processing of the files. As was mentioned earlier, some systems sup-\nport both contiguous file allocation and linked allocation. Many modern OSs support \nName\nStart\nDirectory\nFile A\n8\nFile B\n...\nFile C\nSize\n10\nEnd\n27\n14\n0\n6\n12\n18\n24\n30\n36\n15\n16\n28\n24\n26\n27\n20\nBlock\nNumber\n25\n= end of list\nFIGURE 12.15 A fragmented file.\nelm49810_ch12_255-282 New.indd   277\nelm49810_ch12_255-282 New.indd   277\n12/10/08   9:41:33 PM\n12/10/08   9:41:33 PM\n",
        "category": "Category"
    },
    {
        "id": "339",
        "title": "Title for Chunk 339",
        "content": "Rev. Confirming Pages\n278 \nPart 4 A Depth-Oriented Presentation of OS Concepts: File Systems and Input/Output\nboth types, and the result is that they have both the external fragmentation problem \nand the random chain problem. In such systems defragmentation can assist with both \nproblems. \n 12.5.3 Indexed allocation \n Just as there is an indexed method for keeping track of the free space, there is a \nsimilar mechanism for keeping track of the structure of a file. In the simplest terms, \nthe indexed file structure is somewhat like a linked list except that we allocate a \nseparate index block to hold the pointers rather than placing the pointers in each data \nblock.  Figure 12.16  shows a number of blocks in a file that are pointed to by an index \nblock rather than being individually chained. As with the indexed free space tracking \nmechanism, in the simplest implementation we are limited to a single index block. \nThis restriction will limit the file size, since the blocks are a fixed size and therefore \nthe index can only hold pointers to a maximum number of blocks. There are two \nways we can expand this mechanism to remove this limit. We can use multiple levels \nof indexes, similar to the way we did with RAM page tables, or we can link the index \nblocks themselves into a list. \n Multilevel indexes \n With multilevel indexes we will again use one block to contain pointers, much as \nwith the simple index structure. But in this case the first index block will not contain \npointers to data blocks. Instead, it will contain pointers to second-level index blocks. \n0\n6\n12\n18\n24\n30\n36\nBlock\nNumber\n8\n14\n15\n16\n28\n20\n24\n26\n25\n27\n...\nName\nIndex\n6\n...\nDirectory\nFile A\nFile B\nFile C\nFIGURE 12.16 File stored with an indexed structure.\nelm49810_ch12_255-282.indd   278\nelm49810_ch12_255-282.indd   278\n12/22/08   1:06:57 PM\n12/22/08   1:06:57 PM\n",
        "category": "Category"
    },
    {
        "id": "340",
        "title": "Title for Chunk 340",
        "content": "Rev. Confirming Pages\n \nChapter 12  File Systems\u2014Basics  \n279\nWith a two-layer index structure those index blocks will contain pointers to data \nblocks. If an index block contained 100 pointers, then when we introduced a two-\nlayer structure we would multiply that by 100. We would then be able to address a \nfile containing 10,000 blocks. If this was not sufficient we could introduce another \nlayer of indexes, each time multiplying the original space by 100. The next level \nwould allow for 1 million blocks. Notice that we do not necessarily need to read \nthe entire set of index blocks into memory when the file is first opened. We can \nwait until the application tries to access the portion of the file covered by an index \nto read it. This is especially useful for very large files opened and read briefly\u2014for \nexample, looking up a word in a dictionary.  Figure 12.17  shows a multilevel indexed \nfile organization. \n Linked index block lists \n As with free space linked lists, we can simply link index blocks together in a chain. \nEach index block will thus contain one fewer pointers to data blocks because we \nneed one pointer to access the next index block, but this is unlikely to be a signifi-\ncant factor for most block and disk sizes.  Figure 12.18  shows a file organized with a \nlinked index structure. If a file is being accessed randomly, then this mechanism will \nrequire that we follow the linked chain when the file is opened and read the index \nblocks into main memory. Of course, we can postpone reading all the blocks until \nwe need them. If the file is being accessed sequentially we can just read each index \nblock when we are nearing the last pointer in the previous block. \n8\n14\n15\n16\n...\nTop-Level Index Block\n7\n43\n12\n18\n...\n27\n44\n19\n88\n...\nSecond-Level Index Blocks\nData Blocks\nName\nIndex\n6\n...\nDirectory\nFile A\nFile B\nFile C\n. . .\n. . .\nFIGURE 12.17 \nA multilevel indexed \nfile.\nelm49810_ch12_255-282.indd   279\nelm49810_ch12_255-282.indd   279\n12/22/08   1:06:57 PM\n12/22/08   1:06:57 PM\n",
        "category": "Category"
    },
    {
        "id": "341",
        "title": "Title for Chunk 341",
        "content": "Confirming Pages\n280 \nPart 4 A Depth-Oriented Presentation of OS Concepts: File Systems and Input/Output\n8\n14\n15\n16\n...\nFirst Index Block\n43\n12\n18\n...\nSecond Index Block\nData Blocks\n= end of list\nData Blocks\nName\nIndex\n6\n...\nDirectory\nFile A\nFile B\nFile C\n. . .\n. . .\nFIGURE 12.18 \nA linked indexed file.\n 12.6 SUMMARY \n Files are an important abstraction for an OS to pro-\nvide. Files were in use long before there were com-\nputers, so they are something everyone knows about. \nProgrammers do not want to think about hardware; \nthey want to think about a collection of data. In a com-\nputer system that collection is a file. In this chapter \nwe discussed the nature of file systems. We then \nintroduced the idea of OS file systems. Modern com-\nputer systems have many files. It needs to be pos-\nsible to organize the files so that we can find things. \nWe discussed directories in file systems. Different \na pplications need different methods of accessing \ndata, so we described various methods that applica-\ntions can be offered for accessing the data in files. \nFile systems need to keep track of what parts of the \ntotal space is currently free. We explored different \nstructures used to track that space. We then presented \nthe topic of the structure of the files themselves and \ndiscussed the tradeoffs of the various methods. \n In the next chapter we are covering a few case \nstudies of file systems in well-known OSs and a few \nother miscellaneous topics about OS file systems. \n BIBLIOGRAPHY \n Beck, M., et al.,  Linux Kernel Programming, 3rd ed., \nReading, MA: Addison-Wesley, 2002. \n Bovet, D. P., and M. Cesate,  Understanding the Linux \nKernel, 2nd ed., Sebastopol, CA: O\u2019Reilly & \nAssociates, Inc., 2003. \n Golden, D., and M. Pechura, \u201cThe Structure \nof Microcomputer File Systems,\u201d  Communications \nof the ACM, Vol. 29, No. 3, March 1986, \npp. 222\u2013230.  \nelm49810_ch12_255-282 New.indd   280\nelm49810_ch12_255-282 New.indd   280\n12/10/08   9:41:34 PM\n12/10/08   9:41:34 PM\n",
        "category": "Category"
    },
    {
        "id": "342",
        "title": "Title for Chunk 342",
        "content": "Confirming Pages\n \nChapter 12  File Systems\u2014Basics  \n281\n Koch, P. D. L., \u201cDisk File Allocation Based on the Buddy \nSystem,\u201d  ACM Transactions on Computer Systems, \nVol. 5, No. 4, November 1987, pp. 352\u2013370. \n Larson, P., and A. Kajla, \u201cFile Organization: \nImplementation of a Method Guaranteeing Retrieval \nin One Access,\u201d  Communications of the ACM, \nVol. 27, No. 7, July 1984, pp. 670\u2013677. \n Livadas, P. E.,  File Structures, Theory and Practice. \nEnglewood Cliffs, NJ: Prentice Hall, 1990. \n McKusick, M. K., W. N. Joy, S. J. Leffler, and R. S. \nFabry, \u201cA Fast File System for UNIX,\u201d  ACM \nTransactions on Computer Systems, Vol. 2, No. 3, \nAugust 1984, pp. 181\u2013197. \n Nelson, M. N., B. B. Welch, and J. K. Ousterhout, \n\u201cCaching in the Sprite Network File System,\u201d  ACM \nTransactions on Computer Systems, Vol. 6, No. 1, \nFebruary 1988, pp. 134\u2013154. \n Organick, E. I.,  The Multics System: An Examination \nof Its Structure. Cambridge, MA: MIT Press, 1972. \n Rosenblum, M., and J. K. Ousterhout, \u201cThe Design and \nImplementation of a Log-Structured File System,\u201d \n ACM Transactions on Computer Systems, Vol. 10, \nNo. 1, 1992, pp. 26\u201352. \n Russinovich, M. E., and D. A. Solomon,  Microsoft \nWindows Internals, 4th ed., Redmond, WA: \nMicrosoft Press, 2005.  \n WEB RESOURCE \n http://developer.apple.com/documentation/Performance/\nConceptual/FileSystem/Articles/MacOSXAndFiles\n.html \n http://labs.google.com/papers/gfs.html  (the Google File \nSystem) \n http://www.linux.org \n http://pages.prodigy.net/michaln/history/ (OS/2 history) \n http://technet.microsoft.com/en-us/sysinternals/default.\naspx (Sysinternals originally an outside technical \nreference, later bought by Microsoft) \n http://en.wikipedia.org/wiki/File_system  \n http://en.wikipedia.org/wiki/CP/M  \n REVIEW QUESTIONS \n 12.1 We mentioned several items that might be in a \nfile directory. Some are fairly rare. What few \nitems are most likely in every OS directory \nstructure?  \n 12.2 What is the main problem with single-level direc-\ntory structures for today\u2019s systems? \n 12.3 Since hierarchical directory structures allow for \nthe existence of multiple files with the same name, \nhow do we have to refer to them to uniquely spec-\nify them? \n 12.4 What kind of problem motivates the use of \naliases? \n 12.5 How are directories organized internally to opti-\nmize searching time? \n 12.6 Why does an OS typically provide special calls \nfor accessing directory entries? \n 12.7 What is the effect of the working directory on a \ncommand such as erase <filename>? \n 12.8 If a file is being processed via a sequential access \nmethod, what happens to the current record \npointer on a read? \n 12.9 True or false? An application using random access \ncan\u2019t just ask the OS for the next record. It must \nalways specify the record number. \n 12.10 True or false? For indexed sequential access, the \nprimary key field must contain unique key values \nfor each record. \n 12.11 What services does raw access provide? \n 12.12 What are the two BASIC mechanisms for free \nspace tracking in file systems? \n 12.13 There are two broad \u201cimprovements\u201d to one of \nour free space tracking mechanisms, and one of \nthose improvements had a variant as well. These \nimprovements were aimed at mitigating a sig-\nnificant performance issue associated with one \nof those tracking mechanisms. Which mechanism \nwas this and what was the issue that we were con-\ncerned about? \n 12.14 The variant mentioned in the previous question \nwas a technique that could also be applied in \nother free space mechanisms and their improve-\nments. What was that technique? \nelm49810_ch12_255-282 New.indd   281\nelm49810_ch12_255-282 New.indd   281\n12/10/08   9:41:34 PM\n12/10/08   9:41:34 PM\n",
        "category": "Category"
    },
    {
        "id": "343",
        "title": "Title for Chunk 343",
        "content": "Confirming Pages\n282 \nPart 4 A Depth-Oriented Presentation of OS Concepts: File Systems and Input/Output\n 12.15 What are the three basic mechanisms for file space \nallocation in file systems? \n 12.16 One of the file space allocation mechanisms is the \nmost convenient for random access files. Which \nmechanism is that? \n 12.17 That same allocation mechanism makes it difficult \nto increase the size of files. This problem caused \na secondary problem. What was the secondary \nproblem? \n 12.18 That same allocation mechanism makes it difficult \nto increase the size of files. We described a varia-\ntion on that basic mechanism that would allow the \nsize to be increased. What was the variation? \n 12.19 What is internal fragmentation and why is it no \nlonger much of a problem in most cases? \n 12.20 What is external fragmentation and why is it a big-\nger problem than internal fragmentation for some \nsystems? \n 12.21 We referred to a problem of \u201cprogrammer frag-\nmentation\u201d and said that one of the file allocation \nmechanisms did not have this problem. Which \nmechanism and why not? \n 12.22 That same mechanism has a serious drawback. \nWhat is it? \n 12.23 Briefly describe what defragmentation does for \nlinked files. \n 12.24 The simplest indexed file allocation method limits \nthe size of files because of the limited number of \npointers that can be stored in a single index block. \nWhat two mechanisms were discussed for extend-\ning this limit? \n 12.25 Which of those mechanisms would probably work \nbetter for random file access?  \nelm49810_ch12_255-282 New.indd   282\nelm49810_ch12_255-282 New.indd   282\n12/10/08   9:41:35 PM\n12/10/08   9:41:35 PM\n",
        "category": "Category"
    },
    {
        "id": "344",
        "title": "Title for Chunk 344",
        "content": "Confirming Pages\n415\n Chapter \n Chapter  18 \n 18 \n Windows NT\u2122 through \nVista\u2122 \n In this chapter: \n 18.1 Introduction: Windows NT Family History 416 \n 18.2 The User OS Environment 421 \n 18.3 Process Scheduling 423\n 18.4 Memory Management 425 \n 18.5 File Support 428 \n 18.6 Basic Input and Output 436\n 18.7 GUI Programming 439\n 18.8 Networking 440\n 18.9 Symmetric Multiprocessing 441 \n 18.10 Startup Speed of XP 441 \n 18.11 Summary  442\n I\nn this chapter, we discuss an operating system family that is clearly the domi-\nnant personal computer OS in terms of numbers of installations, the Windows \nNT Operating System family developed by Microsoft. It may appear to a casual \nobserver that it only supports a single user at one time using the console of a personal \ncomputer. It actually supports multiple users at remote terminals. It also supports \nmany concurrent users by running services for various remotely accessed functions \nsuch as file, print, and directory services, and serves as a platform for other higher-\nlevel services such as databases, HyperText Transport Protocol servers (HTTP or \nWeb), File Transfer Protocol servers (FTP), Web services, and many others as well. \nIn the later versions it also supports a function known as fast user switching. This \nfunction allows one user to log off the system while any applications that were run-\nning stay in memory. A second user can then log in and start other applications. \nThe second user can log off, again leaving all applications running and the first user \nlog back in and resume work where it was left off without having to restart those \napplications. \n Although the title of this chapter refers to Vista, we are using the term Windows \nNT to refer to the entire product release series. Formally, this term only applies to \nelm49810_ch18_413-444.indd   415\nelm49810_ch18_413-444.indd   415\n12/11/08   3:59:44 PM\n12/11/08   3:59:44 PM\n",
        "category": "Category"
    },
    {
        "id": "345",
        "title": "Title for Chunk 345",
        "content": "Confirming Pages\n416 \nPart 6 Case Studies\nthe NT Version 3.1, 3.5, 3.51, and 4.0 releases. However, the product family nam-\ning is not uniform and for the most part the differences between the releases are not \nsignificant for our purposes. Also, the term NT is often used casually to refer to the \nentire series of versions, and we will also use it that way. If we are referring to some \nfeature that was dropped or added in a specific release, then we may mention the \nspecific version\u2019s product name. \n We start this chapter with an overview of NT and some background about the \nhistory of the various Windows OSs in order to give some perspective about the \nvarious features and design decisions. In  Section 18.2  we discuss the nature of a \ntypical environment for the NT OS. There is also a discussion of the main goals of \nNT\u2014multiple hardware platform support and legacy OS application support. \n NT supports many simultaneously operating user processes as well as concur-\nrent server functions, so in  Section 18.3  we discuss the scheduling of processes and \ntasks in NT. NT uses secondary storage as an extension to primary storage, so com-\nplex memory handling mechanisms are needed. These are discussed in  Section 18.4 . \nOSs that support multiple server functions and multiple users require complex file \nsystems that provide for security of files as seen in the Linux OS.  Section 18.5  thus \ncovers the organization and structure of files and file system metadata in the NT \nOS and  Section 18.6  covers basic I/O functions that NT provides to support those \nhigher-level functions. \n The NT GUI allows for multiple overlapping windows, just as do the Mac OS \nand Linux, and thus requires an elaborate API for the GUI, so  Section 18.7  describes \nsome aspects of GUI programming with NT. PDAs running OSs like the Palm have \nelaborate communication options, but for the most part they are used one at a time. \nIn NT the user may be running many communication activities at the same time\u2014\nchecking email, playing a game over the Internet, synchronizing the database with a \nPDA, and so on.  Section 18.8  is a discussion of the many kinds of networking sup-\nport in Windows NT. NT often runs on systems with multiple CPUs, especially when \nbeing used primarily as a server rather than only as a workstation.  Section 18.9  deals \nwith the way NT supports such systems. In  Section 18.10  we describe the goal of the \nstartup speed of the XP release of NT and why it was important. We conclude with a \nchapter summary in  Section 18.11 . \n 18.1 INTRODUCTION: WINDOWS NT FAMILY HISTORY \n First some history: As was mentioned, the Windows OSs were initially developed \nfor supporting a single user on a personal computer. This support goes back to the \n8088/8086 processors. Microsoft began development of an OS that supported a \ngraphical user interface (GUI) in 1981. It was then called the Interface Manager \n(IM). The CPUs in use lacked the features necessary for protecting one process from \nanother. Because of this hardware limitation, most personal computer OSs prior to \nthis time were not multiprocessing systems, and neither was the IM. Multiple appli-\ncations could be open at the same time, but only one would actually be running. The \nwindows could not overlap but could only be tiled. Tiled windows do not partly cover \nelm49810_ch18_413-444.indd   416\nelm49810_ch18_413-444.indd   416\n12/11/08   3:59:47 PM\n12/11/08   3:59:47 PM\n",
        "category": "Category"
    },
    {
        "id": "346",
        "title": "Title for Chunk 346",
        "content": "Confirming Pages\n \nChapter 18 Windows NT\u2122 through Vista\u2122 \n417\none another, so the management of the windows is much simpler for the OS. By the \ntime IM was formally announced in 1983 the name had been changed to Windows. \nAs often happens in areas of technical development, the idea of a GUI was evolving \nat several places at the same time. The idea arose at the Xerox Palo Alto Research \nCenter (PARC). So Windows was not the first OS for the Intel CPU family with a \nGUI. Personal Software (which later changed their name to VisiCorp) had released \nVisiOn before Windows was released. This was actually an environment that ran on \ntop of the OS in a manner similar to X-Windows in UNIX. IBM was also working on \na multiprocessing 8x86 environment called TopView, though it did not have a GUI. \n The first release of the Windows OS was only marginally successful, primar-\nily because of the hardware architecture limitations and the processor speed. Later \nreleases took advantage of the more advanced features available in the 80286 proces-\nsor to provide better support for memory management, but the performance of PCs \nof this era were still marginal when displaying graphics. In addition, these versions \nof Windows were actually shells that ran on top of the original 16-bit DOS. Also \nthey were mostly or entirely written in assembly language and were increasingly \nharder to enhance, or even to maintain. When the 80386 processor became avail-\nable, Microsoft released a version of Windows known as Windows 3.0. This version \nwas extremely successful. Being built on portions of DOS, however, it still had sub-\nstantial problems. There were various iterations of this product, including Windows \n3.1 and Windows for Workgroups. Among other drawbacks, the instruction set and \naddressing space of the hardware allowed only for a design with a 16-bit memory \naddressing space. Later, substantial development went into a modified version of this \nWindows family, including use of a 32-bit instruction set and memory model. This \nOS series included Windows 95, Windows 98, Windows 98 SE (Second Edition), \nand Windows ME (Millennium Edition). \n In parallel with the development of the early versions of Windows, Microsoft \nwas also involved in the development of a similar OS with IBM called  OS/2. OS/2 \nwas originally viewed as a means of running several text-based programs at the same \ntime. Subsequently other versions of OS/2 were released that had a GUI interface \nand ran on the 80286 and 80386 processors. At some point they decided that writing \noperating systems in assembly language (as was DOS) was not a good idea, so OS/2 \nwas written mostly in C. OS/2 initially had an API that was an extension of the DOS \nAPI. Version 3 of OS/2 was started by Microsoft as a complete rewrite of the OS \nusing the OS/2 API, but the enormous success of Windows 3.x caused Microsoft to \nreevaluate their initial direction. As a result, the primary native API was changed to \nbe the 32-bit  Win32 interface developed for Windows 95 and later versions. Partly \nas a result of this change, IBM and Microsoft parted company on OS/2 and IBM was \nleft to develop OS/2 by itself. Microsoft changed the name of this release to NT. \n Besides the Win32 API, NT was also supposed to support the 16-bit applications \ndeveloped for DOS and the Windows 3.x products. In addition, a UNIX-style API \nwas required for many U.S. government and corporate procurements. As a result, NT \nalso includes support for applications written to the POSIX.1 API standardized for \nUNIX systems. (The POSIX interface is actually OS independent, but it was driven \nby the splintered UNIX community and is based largely on that API.) \nelm49810_ch18_413-444.indd   417\nelm49810_ch18_413-444.indd   417\n12/11/08   4:00:27 PM\n12/11/08   4:00:27 PM\n",
        "category": "Category"
    },
    {
        "id": "347",
        "title": "Title for Chunk 347",
        "content": "Confirming Pages\n418 \nPart 6 Case Studies\n At the time the Intel x86 processor did not have quite the dominant position in \npersonal computers (PCs) that it has today. If one processor family came to domi-\nnate the PC, Microsoft needed to ensure that their OSs would be able to run on that \nplatform. If no processor dominated, then they needed to run on most or all of them. \nThey thus determined that portability was a primary goal for their main OS product. \nThis meant that they had to move away from the DOS-based Windows products and \nwrite a new OS. In order to ensure portability they decided to write this new operat-\ning system in a high-level language. There are also many other reasons to use a high-\nlevel language, of course. To create this new OS they hired a crew of experienced OS \ndesigners. They originally aimed to write it in C \ufffd \ufffd and to initially target the Intel \ni860 processor, among others. The i860 was a Reduced Instruction Set Computer \n(RISC) processor. The version of the processor chip that this team was using was \ncalled the N10, and Microsoft was using an i860 emulator called the N10 (N-Ten). \nThis lead to the name NT, also referred to as New Technology. The hardware turned \nout to be too underpowered for supporting object-oriented programming, so the core \nof NT ended up being almost entirely written in standard C. \n The biggest difference between the various Windows products and Microsoft\u2019s \nearlier systems was the graphical user interface. Today, GUIs are very common, of \ncourse\u2014perhaps requiring little more explanation, but they were new to Microsoft \nOSs when Windows was first created. Such interfaces greatly enhance the user expe-\nrience, extending the ways that a user interacts with the system well beyond what is \navailable with text-oriented terminals and the ability to run more than one task at a \ntime. This combination of multiple programs running in separate but possibly over-\nlapping graphics-based task windows and controlled with a pointing device such as a \nmouse or a touch pad that moves an indicator on the screen has been wildly success-\nful. Today, there are few OSs that do not contain such an interface other than systems \nembedded in appliances and other machines. In some OSs such as UNIX, Linux, and \nthe Mac OS X the GUI interface is a separate layer on top of the OS. In the Microsoft \nWindows products the GUI interface is an integral portion of the OS design and has \nbeen a part of the kernel since at least the Windows 2000 release. \n Early work for NT was sometimes done on MIPS systems. Afterward, Micro-\nsoft decided that they would like to replace all existing DOS and Windows systems \nwith NT systems, so additional support was added for the 80x86 series of processors \nand the i860 was eventually dropped due to issues with the chip regarding general \nOS use. Support for other processors was also added, such as the DEC Alpha 64 bit \nprocessor, the MIPS RISC processor, and the PowerPC. (The MIPS chip is used in \nseveral families of machines, including Silicon Graphics workstations.) The market \neventually decided against these three processors for use in PCs, so they are not sup-\nported by later versions of NT. In the XP release of NT, however, support has been \nadded for the Intel Itanium 64-bit RISC processor and the Intel and AMD 64 bit x64 \nprocessor families. So the idea of hardware platform independence has remained as \nan important feature of the NT family. \n The NT family included Windows NT 3.1, 3.5, 3.51, and 4.0, Windows 2000 \n(kernel version NT 5.0), Windows XP (kernel version NT 5.1) and Windows Server \n2003, Windows XP x64 Edition, and now Windows Vista (kernel version 6.0). This \nOS product line includes support for a GUI interface, virtual memory, journaling file \nsystems, preemptive multitasking, and a full suite of networking protocols. Basically \nelm49810_ch18_413-444.indd   418\nelm49810_ch18_413-444.indd   418\n12/11/08   4:00:28 PM\n12/11/08   4:00:28 PM\n",
        "category": "Category"
    },
    {
        "id": "348",
        "title": "Title for Chunk 348",
        "content": "Confirming Pages\n \nChapter 18 Windows NT\u2122 through Vista\u2122 \n419\nit is a very high-end OS. Although there have been some significant enhancements to \nthe product family during this time, much of the system architecture we are describ-\ning in this chapter is essentially unchanged from the first release. \n 18.1.1 Windows Vista \n The latest version of NT is  Windows  Vista. Microsoft\u2019s primary objective with Vista \nwas to improve the security in the NT OS, but there are many other enhancements as \nwell. We briefly discuss a few of the features in this release as an illustration of the \nsorts of activity that are being undertaken in current OS development. Many of these \nfeatures are also found in other contemporary OSs. Other features of Vista that are \nrelated strictly to NTFS are discussed in Section 18.5.5. Several of the new features \nare related to security or reliability:\n Code Integrity Verification. The OS loader and the kernel now perform load-\ntime checks on all kernel mode binaries to verify that the modules have \nnot been changed on the disk. This helps prevent malicious programs from \ntaking control of a machine by modifying the OS. \n Service Security Improvements. Services can now specify which privileges \nthey require (e.g., shutdown, audit, write-restricted, etc.), which limits the \npower of these services. Privileges not explicitly specified are removed, thus \nlimiting the damage a damaged service can do to the OS. \n User Account Control. UAC improves security by limiting applications to \nstandard user privileges until an administrator authorizes an increase in \nprivilege level. A user may have administrator privileges, but an application \nthe user runs has only standard user privileges unless it is approved \nbeforehand or the user explicitly authorizes it to have higher privileges. \nUAC will prompt the user for additional privileges automatically or the user \ncan right-click a program icon and select \u201cRun as administrator.\u201d \n Address Space Layout Randomization. ASLR is a security technique for randomly \nassigning parts of the address space of a process. This usually includes the base \nof the executable program, libraries, and heap and stack space. This mechanism \nthwarts some security attacks by preventing an attacker from predicting the \naddresses of the components that are the target of the attack.  \n User-Mode Driver Framework (UMDF). Most drivers run in kernel mode with \ncomplete access to the physical address space and system data structures. \nSuch access allows a malicious or badly coded driver to cause problems that \naffect other drivers or the system itself and eventually crash the machine. \nDrivers that run in user mode have access only to the user address space and \nare a much less risk. Vista has added support for such user-mode drivers. \nUMDF is designed for devices like cameras and portable music players. \n Some other new features are related to reliability:\n Windows Error Reporting. This feature captures application software crash and \nhang data from end users who agree to report it. Software developers can \naccess data related to their applications online, monitor error trends, and \ndownload debug information. \nelm49810_ch18_413-444.indd   419\nelm49810_ch18_413-444.indd   419\n12/11/08   4:00:28 PM\n12/11/08   4:00:28 PM\n",
        "category": "Category"
    },
    {
        "id": "349",
        "title": "Title for Chunk 349",
        "content": "Confirming Pages\n420 \nPart 6 Case Studies\n Reliable Sleep State. Before now an application or driver could prevent the \nsystem from entering sleep or hibernate mode (a sleep state). The problem \nwith this was that a laptop user often did not realize the system had not \nentered the state and would end up with an overheated laptop in the bag, a \ndead battery, and eventually lost data. Vista does not ask processes before \nentering sleep states and has reduced the timeout for user-mode notifications \nfrom twenty seconds to two. \n Clean Service Shutdown. Before Vista services had no way to extend the time \nallowed for shutdown. After a fixed timeout the system halted with those \nservices still running. This could cause problems for services that needed to \nflush data to disk. With Vista, services that request notification of a pending \nshutdown can take as long as they need to shut down. The notification \nservice notifies these services first and waits for them to stop. After they all \nstop the system continues with a normal shutdown. \n Service Shutdown Ordering. Vista allows services to specify a shutdown order \nwhere service dependencies need to be followed by the shutdown. \n A few features are added to Vista, primarily to speed up the general performance or \nthe time needed to shut down or restart the system:\n Delayed Auto-Start Services. Services running in NT are often set to auto-\nstart because they will probably be needed later. However, they have \nbeen multiplying and are thereby increasing the time it takes to boot the \nsystem. However, many auto-start services do not have to be part of the \nboot sequence; they just need an unattended start so that they are ready \nfairly soon after the system starts. Vista provides a new option called \ndelayed auto-start. Services that are designated as delayed auto-start are \nstarted shortly after the system has booted. This improves boot and login \nperformance for the user. \n SuperFetch analyzes the regular use of applications and tries to keep the \nfrequently used applications in main memory so they can launch more \nquickly. It will also notice when any prefetched data is moved out to the \npage file and will monitor the application that caused the prefetched data to \nbe moved out to the page file. As soon as that application is done it will pull \nthe prefetched data back into memory. When the user again accesses the \napplication, the prefetched data will already be in main memory again. \n ReadyBoost can create a cache memory on a flash memory device. Although \nthe data transfer speed of such devices is less than current hard drives, flash \nmemory devices have neither seek nor rotational latency so they can boost the \napparent speed of the hard disk substantially. Note that this is consistent with \nour prediction in Chapter 14 about the future replacement of rotating memories.  \n Hybrid Hard Drives. These new drives incorporate a large flash buffer. They \nreduce drive power consumption significantly since the drive can be \npowered down most of the time while data moves between main memory \nand the flash RAM in the drive. Also, such drives will have increased \nreliability since the parts are moving less often. Finally, the system will have \nelm49810_ch18_413-444.indd   420\nelm49810_ch18_413-444.indd   420\n12/11/08   4:00:28 PM\n12/11/08   4:00:28 PM\n",
        "category": "Category"
    },
    {
        "id": "350",
        "title": "Title for Chunk 350",
        "content": "Confirming Pages\n \nChapter 18 Windows NT\u2122 through Vista\u2122 \n421\nfaster boot time since reading from the flash memory is much faster than \nwaiting for the platters to spin up and then looking for the data. ReadyDrive \nis the name for the Vista features that support these hybrid hard drives. \n 18.2 THE USER OS ENVIRONMENT \n Because the NT environment is primarily a GUI, the user can easily open up many \nwindows on the screen and start multiple applications. It is not at all unusual for an \nNT user to have a dozen or more applications running at any one time. Often there \nwill be an email reader checking for incoming mail from time to time; an appoint-\nment scheduler open; a Web browser, perhaps open to a portal page that updates the \nlatest news and statistics on the user\u2019s stock portfolio; an office-type application \nsuch as a spreadsheet the user is working on; a window showing a dictionary that \nthe user has just looked up a word in; and an \u201cinstant messenger\u201d application. This \ndoes not include numerous other utilities that may be running such as local firewalls, \nclipboard editors, battery status indicators, sound volume adjustment panels, and so \nforth. There may also be server functions running such as shared printing, personal \nWeb services, and so on. So while NT is viewed by many users as a single-user sys-\ntem, that by no means implies that the OS has only a few things running. \n 18.2.1 Goals: Multiple Hardware and OS Platform Emulation \n Two of the main goals of the developers of NT were being portable across multiple \nhardware platforms and supporting applications from legacy OSs. To achieve the \nfirst goal, Microsoft used two methods. First, to a substantial extent, certain low-\nlevel hardware-dependent portions of the OS kernel are isolated in a single module \ncalled the  Hardware Abstraction Layer, or HAL. Other modules also have portions \nof the code that have hardware dependencies; for example, the memory manager \nmust know what the physical memory page size is. But having the HAL simplified \nthe process of porting the system to a new hardware platform by partially isolating \nthe hardware-dependent portions of the OS in a single module. The HAL varies with \nsuch factors as the support chips used with the CPU (the interrupt controllers, for \nexample), whether the system is a uniprocessor or a multiprocessor system, and what \npower management features the BIOS supports. These chips connect the buses and \nother devices to the CPU and they sometimes require specific instructions, just as \ndoes the CPU. The second technique was to write all the rest of the OS in a higher-\nlevel language that was machine independent. The language initially chosen was \nC \ufffd \ufffd with the original intent of having the system be completely object oriented. \nLater, this strategy was relaxed and much of NT was built with C for reasons of \nefficiency. The fact that NT has been able to support several different CPUs without \nmajor rewrites shows that in this goal it succeeded well. \n The second goal of running legacy applications correctly and efficiently has also \nlargely been achieved. Since NT strongly enforces the restriction that only the OS is \nallowed to directly control the hardware, there are many DOS and a few Windows 3.x \nelm49810_ch18_413-444.indd   421\nelm49810_ch18_413-444.indd   421\n12/11/08   4:00:28 PM\n12/11/08   4:00:28 PM\n",
        "category": "Category"
    },
    {
        "id": "351",
        "title": "Title for Chunk 351",
        "content": "Confirming Pages\n422 \nPart 6 Case Studies\napplications that will not run under NT because they use the hardware directly. Most \napplications that do not directly manipulate the hardware will run correctly under NT. \nThe key concept for supporting legacy applications was to add another layer on top \nof the kernel. This layer supported legacy APIs by translating legacy API calls into \nnative NT API calls. In the NT family these extra layers are called \u201cenvironments\u201d or \n\u201csubsystems.\u201d In fact, even the 32-bit Windows API that is considered the standard \nfor the NT family is not the native API for the NT kernel itself. These subsystems \nare shown in  Figure 18.1 . By the time XP was released, the world had essentially \nmoved on from OS/2 and support for this subsystem was dropped in the XP release \nof NT. The POSIX support that was originally included with NT was only a minimal \nimplementation of the IEEE 1003.1/ ISO 9945-1 standard. It was withdrawn in the \nXP release and subsequently replaced with a more complete implementation. \n To be sure, originally there were many other goals of the NT OS family such \nas performance and reliability and a high-level goal of building a first-class operat-\ning system, unlike the earlier versions of Windows that were hobbled by limited \nresources. However, the goals of portability and compatibility were the ones that \nprobably had the most impact on the system design. \n These subsystems are not always straightforward, and running older applications \ncan sometimes cause problems. For example, DOS was a single-user system so appli-\ncations would typically start an I/O operation and then do a spin lock to wait for it to \nFIGURE 18.1 Original Windows NT family architecture.\nScheduler\nDevice\nDrivers\nHardware Abstraction Layer (HAL)\nKernel\nMode\nUser\nMode\nSystem Services\nI/O\nManager\nSecurity\nMonitor\nVirtual\nMemory\nProcesses\nand Threads\nObject \nManagement\nFile\nSystems\nLocal\nProcedure\nCall\nGraphic Device\nDrivers\nCache\nManager\nNetwork\nProtocols\nVolume\nManagement\nWin32 and\nGraphics\nDevice\nInterface \nDOS Application\nPOSIX Application\nWin32 Application\nDOS VDM\nWin16\nApplication\nWOW VDM\nWin32 Subsystem\nOS/2 Subsystem\nOS/2 Application\nPOSIX Subsystem\nelm49810_ch18_413-444.indd   422\nelm49810_ch18_413-444.indd   422\n12/11/08   4:00:29 PM\n12/11/08   4:00:29 PM\n",
        "category": "Category"
    },
    {
        "id": "352",
        "title": "Title for Chunk 352",
        "content": "Confirming Pages\n \nChapter 18 Windows NT\u2122 through Vista\u2122 \n423\ncomplete. NT will virtualize the CPU, so other applications will not get locked out, but \nin the meantime the DOS application can be burning lots of CPU cycles. Similarly, by \ndefault all 16-bit Windows applications run as threads in the  Windows on Windows \nVirtual DOS Machine ( WOW VDM). The way the threads are dispatched, if one \nWindows application stops taking input, all those applications will hang.  \n 18.3 PROCESS SCHEDULING \n NT uses a complex mechanism to control scheduling of the running processes. It runs \nmultiple processes and creates at least one thread for every process. Then it schedules \nthe threads for execution, not the processes. The mechanism it uses is a multilevel \nfeedback queue. Each thread in NT will have a priority ranging from 0 to 31 that tells \nthe OS how important it is that the process be run as promptly as possible. The thread \npriority is derived from the  base priority (defined below) of the process. For each of \nthe 32 priority levels there is a separate queue of threads that are ready to run. When \na thread starts running it is given a limited time quantum to run. When this limit is \nreached the thread is suspended and put at the back of the run queue for its priority level \nand the next thread at that priority level will be run. For each priority level the sched-\nuler will move to the next lower level only when all the threads that are ready to run at \nthat level have been exhausted. If an event occurs that a thread was waiting on, such as \nwaiting for the disk to read some data, then the OS will check to see if the thread that \nwas waiting on the event has a higher priority than the one that is currently running. If \nit does, then the current thread will be suspended and the higher priority waiting thread \nwill be run. Interrupting threads for time-slice expiration and for higher priority events \nare both examples of preemptive multitasking, as was discussed in Chapter 8. \n When a process is started, an initial  base priority class for that process is deter-\nmined. See  Figure 18.2 . This class is used to determine the base priority of all the \nthreads in the process. As threads in the process execute, their priorities may change \nin response to the operations they perform. This is known as a dynamic priority. \nThere are limits below which the thread priority cannot fall and above which it can-\nnot rise. This changing of priorities as the thread runs is the \u201cfeedback\u201d referred \nto in the phrase \u201cmultilevel feedback queuing.\u201d The intent of raising and lowering \nthe priority like this is to give higher priority to the interactive processes that are \nclosely focused on the user interface and lower to the background those processes \nthat appear to be less involved with the user interface. \n The NT scheduler therefore gives high priority to threads that are involved in \nsuch interactive tasks as typing on the keyboard. In order to do so it uses a mecha-\nnism that is slightly different from that discussed in Chapter 8. There are several \ncases when NT will raise the priority of a thread:\n \ufffd When a thread has made a blocking call and that request is finished, its dynamic \npriority is raised so that it can make good use of the completed operation. \n \ufffd When a window associated with a process that uses the NORMAL priority \nclass gains the focus, the scheduler boosts the priority of the process so that it \nis greater than or equal to that of all background processes. The priority class \nelm49810_ch18_413-444.indd   423\nelm49810_ch18_413-444.indd   423\n12/11/08   4:00:30 PM\n12/11/08   4:00:30 PM\n",
        "category": "Category"
    },
    {
        "id": "353",
        "title": "Title for Chunk 353",
        "content": "Confirming Pages\n424 \nPart 6 Case Studies\nreturns to its previous setting when the window associated with the process no \nlonger has the focus. \n \ufffd When a window receives input such as mouse events, timer events, or keyboard \ninput, the scheduler boosts the dynamic priority of the thread that owns the \nwindow. \n After raising a thread\u2019s dynamic priority, the scheduler decreases the priority \nby one each time the thread completes a time slice, until the thread drops back \nto its base priority. A thread\u2019s dynamic priority is never lowered below its base \npriority. \n NT has some threads that it runs that it considers \u201creal-time\u201d threads. These \ninclude handling time-critical devices like moving a mouse. All of the priorities from \n16 to 31 are considered to be real-time priorities. A normal user-created process runs \nthreads that take on only priorities from 0\u201315. Most of the real-time threads are OS \nthreads, but it is possible for a user process to also use real-time threads. NT is not \na hard real-time system, so these processes are soft real-time processes. That is to \nsay that the OS makes an effort to ensure that they get run as often and as soon as \ndesired. However, it does not make any attempt to guarantee that any timing criteria \nwill be met. The system does not boost the priority of real-time threads. \n When no other thread is ready to run, NT runs a special thread called the idle \nthread. If the power circuitry supports it, this thread puts the CPU into a lower power \nstate in which it runs more slowly, and then it goes into a tight loop. Having this \nspecial thread also allows the OS to determine how much of the system resources are \nbeing used for real work and how much is not being used because the system is wait-\ning for something to happen\u2014perhaps a direction from the user as to which other \nprogram to run. When a volunteer computing package such as BOINC is being run, \nthe idle thread will be replaced by the volunteer application. Volunteer computing \nprojects were discussed in Chapter 7. \nFIGURE 18.2 \nNT thread priority \nrelationships.\nN\nO\nR\nM\n\u2212\nN\nO\nR\nM\nCritical\nReal-time\n(fixed)\nNormal\n(dynamic)\nWorker\nthreads\nI\nD\nL\nE\n31\n30\n29\n28\n27\n26\n25\n24\n23\n22\n21\n20\n19\n18\n17\n16\n+\nN\nO\nR\nM\nH\nI\nG\nH\n15\n14\n13\n12\n11\n10\n9\n8\n7\n6\n5\n4\n3\n2\n1\n0\nelm49810_ch18_413-444.indd   424\nelm49810_ch18_413-444.indd   424\n12/11/08   4:00:30 PM\n12/11/08   4:00:30 PM\n",
        "category": "Category"
    },
    {
        "id": "354",
        "title": "Title for Chunk 354",
        "content": "Confirming Pages\n \nChapter 18 Windows NT\u2122 through Vista\u2122 \n425\n 18.4 MEMORY MANAGEMENT \n NT supports a  virtual memory system with  demand paging, as was described \nin Chapter 11. When the CPU is running a process, it generates logical memory \naddresses for the memory hardware to use to fetch or store instructions or data. \nThe memory management unit (MMU) hardware translates each of these gener-\nated addresses to a physical address that the memory system then uses to access the \ninformation. The memory is divided into pages of a fixed size. This size is deter-\nmined by the hardware, so the OS must work with whatever page size the hardware \nuses. For the Intel x86 family, the size of these pages is normally 4 KB. For other \nsystems, the page size may be different. Because NT is designed to be platform neu-\ntral, it must not depend on the actual size of these sections. Since NT was designed \nto run on many hardware platforms, it must be coded in such a way as to be flexible \nin the page size.  \n 18.4.1 The address space \n In NT the logical address space is divided into two parts, one for the OS and one \nfor the user application. See  Figure 18.3 . The figure shows the address space to be \nevenly divided between the user space and the kernel space, but this can be over-\nridden. This override might be used, for example, by an application like a database \nserver that needed a very large memory space. Two other areas of the logical address-\ning space are set aside to aid in error detection. They are called the guard area and \nthe null pointer catcher. If a program accidentally references an address in either of \nthese spaces, then the hardware will signal an error and the program will be aborted. \n(This mechanism is a convention used by the language support generally used with \nthe OS and is not actually enforced by the OS itself.) Recall that this address is a part \nof the logical address space, which is 4 GB. The purpose of these reserved blocks is \nto generate an interrupt via the hardware when these addresses are used accidentally. \nFIGURE 18.3 \nThe default Windows \nNT family x86 \nmemory map.\n0x00000000\u20130x0000FFFF\n0x00001000\u20130x7FFEFFFF\n0x7FFF0000\u20130x7FFFFFFF\n0x80000000\u20130xFFFFFFFF\nReserved\u2014Null pointer catcher\n2 GB User Address Space\n2 GB Kernel Address Space\nReserved\u2014Guard area\nelm49810_ch18_413-444.indd   425\nelm49810_ch18_413-444.indd   425\n12/11/08   4:00:31 PM\n12/11/08   4:00:31 PM\n",
        "category": "Category"
    },
    {
        "id": "355",
        "title": "Title for Chunk 355",
        "content": "Confirming Pages\n426 \nPart 6 Case Studies\nThis means that there is no physical memory assigned to these addresses, so we are \nnot wasting real memory for these functions. \n There is a special hardware feature in newer CPUs that are compatible with the \nIntel architecture that lets the kernel use a page size of 4 MB for itself so that a smaller \npage table is kept and the tables only need a few entries to point to the static parts of \nthe kernel and some additional pages for the parts of the kernel that can be paged.  \n 18.4.2 Page mapping \nThe NT system running on Intel 8x86\u2013compatible CPUs use a two-level table struc-\nture and special hardware to make this translation, as was described in Chapter 11.1 \n Figure 18.4 is similar to a figure from that chapter but shows the specific terminology \nused in NT. The two tables that are used are called a  page directory and a  page table. \nThe use of a two-level table allows the logical address space to be very large and very \nsparse and for the page table itself to be divided into pages. So if no page table entries \nare made in a given block of the logical address space, then that page table will not be \ncreated. The entries in the page table point to the actual frames in physical memory.\n 18.4.3 Page sharing and copy on write \n We have seen that designers go to great lengths to build walls between the OS and the \nrunning processes and between the processes as well. However, sometimes it is advan-\ntageous for processes to be able to share access to the same locations in memory. This \ntechnique must be used carefully when the processes are intentionally sharing pages. \n1 Other hardware platforms may use a more complex design. Intel-compatible CPUs must be at least an \n80386 architecture.\nFIGURE 18.4 \nA multilevel page \ntable.\nCPU\nLogical\naddress\nPage Directory\nPage Table\nf\np1\np2\nPage Directory\nAddress Register\nPhysical\naddress\np1\np2\nd\nf\nd\nPhysical\nMemory\nelm49810_ch18_413-444.indd   426\nelm49810_ch18_413-444.indd   426\n12/11/08   4:00:31 PM\n12/11/08   4:00:31 PM\n",
        "category": "Category"
    },
    {
        "id": "356",
        "title": "Title for Chunk 356",
        "content": "Confirming Pages\n \nChapter 18 Windows NT\u2122 through Vista\u2122 \n427\nHowever, sometimes the OS can allow processes to share pages without the processes \nbeing aware of it. One simple case is where a process does a  fork \u2014that is, the process \nasks the OS to create another copy of the process and to run both the new and original \ncopies. In this case, NT will create the second process, but will not create an actual \ncopy of all the pages. Instead, it will create a new set of page tables and point the tables \nto the same physical pages. In both sets of page tables it will mark the pages as read \nonly. Later, if one of the processes writes to a memory location in a given page, the \nCPU will generate an interrupt and the OS will make a separate copy of that page for \neach process and remove the read-only flag. This technique is called  copy on write, \ndiscussed in Chapter 11. It will save a lot of time and memory in the case of large \nobjects, especially shared libraries that should never modify themselves anyway.  \n 18.4.4 Page replacement \n In Chapter 11 we discussed the problem that occurs when a page needs to be brought \ninto memory and no free frame exists. A currently used page must be selected to \nbe replaced. There are a number of algorithms that we discussed for choosing the \npage to be replaced. Many of them use hardware features to assist the OS in choos-\ning a page to be replaced. Since NT is designed to be relatively independent of the \nhardware, the designers chose not to depend on the most advanced features available \nfor paging hardware. Instead, they use a (relatively) simple FIFO algorithm that is a \nvariant of the clock algorithm. When a page is brought into memory for the first time \na timestamp is recorded for the page. When a page is needed, the page table will be \nsearched and the oldest page will be discarded. Unfortunately, this sometimes turns \nout to be a page that is needed frequently. But as soon as it is reloaded it will get a \nnew timestamp, and it will likely not be chosen again soon. NT chooses the pages \nonly from the faulting process, known as local replacement. Linux and most other \nUNIX variants use a global replacement policy, choosing from all pages in memory.  \n 18.4.5 Prefetch profiles \n A clever optimization is used by NT and other OSs to speed up the loading of appli-\ncations. As was mentioned, when a program starts in a virtual memory system, the \nentire program is not loaded at once. Instead, when a process makes reference to a \npart of its logical address space that is not yet loaded, a page fault occurs and the \ndesired page is loaded into physical memory. As a result, when a large program is \nloading, say a Web browser, it will tend to load pages from different parts of the pro-\ngram, almost in random order, as the initialization code for various data structures is \nrun. As a result, there is considerable disk activity and head movement as the various \npieces of program code are fetched. NT will keep track of the page faults generated \nfor 10 seconds after a program starts. Later, when the system is not busy, it will sort \nthis list of the page faults and save this list in a  page fault profile for that program. \nWhen the program is run again later, the OS will prefetch all the pages that it knows \nwill normally be fetched in those first 10 seconds. This can result in substantial time \nsavings in moving disk heads, waiting for rotational delays and in doing I/O in larger \nblocks and therefore results in faster program startup times. \nelm49810_ch18_413-444.indd   427\nelm49810_ch18_413-444.indd   427\n12/11/08   4:00:32 PM\n12/11/08   4:00:32 PM\n",
        "category": "Category"
    },
    {
        "id": "357",
        "title": "Title for Chunk 357",
        "content": "Confirming Pages\n428 \nPart 6 Case Studies\n 18.5 FILE SUPPORT \n During the past 20 years or so, computing devices have dropped rapidly in price. At \nthe same time, the capacity of disk memory has risen as rapidly. When disk capaci-\nties were small, the file system structures were designed to match them. Early DOS \nfile system pointers were restricted to 12 bits because that was enough to point to \nall the sectors on the floppy disk drives then in use and the designers did not want to \n\u201cwaste\u201d space on larger pointers. As drive sizes have grown, however, the file sys-\ntem designs had to change to support the larger hard drives. As a part of the goal of \nupgrading existing PC systems to the NT series of OSs, a migration path was needed \nfor the various file systems that users might have. Most OSs have their own preferred \nfile system. NT does as well. It is called  NTFS (NT file system). However, NT also \nsupports other file systems, specifically those that Microsoft had developed earlier. \nThese are the  FAT12,  FAT16, and  FAT32 file systems, which were inherited from \nDOS and Windows. XP also supports the  ISO 9660 CD-ROM standard format for \nCDs ( CDFS in NT), UDF,  ISO 13346  standard format for writable CDs and DVDs, \nthe  HPFS (high performance file system) that came from OS/2, and quite a few \nother standard file systems. The HPFS support was eventually dropped because the \nnumber of machines that had never been converted from OS/2 was too small to be \nconcerned with. When NT was developed, there was not a large install base of any \nsingle version of UNIX on 80x86 machines, so Microsoft apparently did not feel it \nnecessary to support any particular UNIX file systems. \n 18.5.1 NTFS \n We discuss a few general characteristics of NTFS, and then the major goals for NTFS \nand how they were reached. Finally, we discuss a few advanced features of NTFS. A \nschematic of an NTFS volume is shown in  Figure 18.5 . \n Master file table \n The boot sector of an NTFS volume contains a pointer to the  master file table, or \n MFT. File systems have to record a lot of metadata  about files (as opposed to the \ndata that the files themselves contain). Key metadata for an NTFS volume itself are \nstored as special system files in the MFT. Every file or directory in an NTFS volume \nhas a record in the MFT that is from 1,024 to 4,096 bytes long.2 The metadata about \nfiles and directories are stored in MFT records as  attributes. The attributes are what \nwe would normally think of as the fields in a file system directory record. Since the \nattributes needed for a given file can vary greatly depending on the type of the file, \nmost of the attributes are stored as a pair, an identifier, and a value. A few attributes \nare always present and are stored at the front of the MFT entry for the file, but most \nof the attributes are in a variable sequence. Since the size of each MFT record is lim-\nited, there are different ways that NTFS can store a file\u2019s attributes: as either  resident \n2 NTFS is technically proprietary, so some of the details are subject to dispute, having been inferred from \nobservation.\nelm49810_ch18_413-444.indd   428\nelm49810_ch18_413-444.indd   428\n12/11/08   4:00:32 PM\n12/11/08   4:00:32 PM\n",
        "category": "Category"
    },
    {
        "id": "358",
        "title": "Title for Chunk 358",
        "content": "Confirming Pages\n \nChapter 18 Windows NT\u2122 through Vista\u2122 \n429\nattributes that are stored within the MFT record, or  nonresident attributes, stored \neither in other MFT records or in extents in non-MFT clusters of the file system:\n Resident Attributes. Attributes that require only a little space are kept in the \nfile\u2019s MFT record. Most common file attributes are resident. Some are \nrequired to be resident, for example, the file name and date/timestamps \nfor file creation, modification, and access are always resident.  Figure 18.6 \nshows an MFT record with resident attributes. \n Nonresident Attributes (AKA external attributes). If an attribute will not fit in \nthe MFT record, it is put in a separate place. A pointer in the MFT gives the \nlocation of the attribute. Nonresident storage is of two kinds: If the pointers \nto the value of an attribute will fit in the file\u2019s MFT record, then the value is \nplaced in a data run outside the MFT record called an extent, and a pointer \nto the run is placed in the MFT record. (This is most commonly true of the \nFIGURE 18.5 \nNTFS volume layout.\nPartition Boot Sector\nMaster File Table Area\nSystem Files\nFile\nArea\nFIGURE 18.6 \nMFT record with \nresident attributes.\nMFT Entry Header\nAttribute Header\n$FILE_NAME\nAttribute Header\n$STD_INFO\nAttribute Header\n(unused)\n$DATA\nResident attribute\nIdentifies the attribute\nValue of the attribute\nelm49810_ch18_413-444.indd   429\nelm49810_ch18_413-444.indd   429\n12/11/08   4:00:32 PM\n12/11/08   4:00:32 PM\n",
        "category": "Category"
    },
    {
        "id": "359",
        "title": "Title for Chunk 359",
        "content": "Confirming Pages\n430 \nPart 6 Case Studies\ndata attribute, but theoretically it can apply to any attribute.)  Figure 18.7 \nshows an MFT record with nonresident attributes. An attribute may be \nstored in many different runs, each with a separate pointer. If the attribute \nvalue has so many extents that even the pointers to them won\u2019t fit in the \nMFT record, then the entire attribute may be moved to an external attribute \nin a separate MFT record, or even multiple external records. \n NTFS has several predefined attributes. Some are associated only with a file or \nonly with a directory or only with some other structure in the metadata for the vol-\nume, while others are associated with more than one structure. Here are some of the \nmost common NTFS system-defined attributes:\n Volume Name, Volume Information, and Volume Version. The key name, \nversion, and other metadata for the volume itself. \n Bitmap. Contains the cluster allocation bitmap. This attribute is only used by \nthe bitmap metadata MFT record. \n File Name. The name of a file or directory. A file or directory can have \nmultiple file name attributes to allow an MS-DOS short filename or for \nPOSIX support for hard links from multiple directories. \n Standard Information. Data needed by all files and directories\u2014date/\ntimestamps for file creation, modification and access, read-only, hidden, etc.  \n Index Root. An index of the files in a directory. If the directory is small, the \nentire index may fit in the MFT. Otherwise, some of the information will be \nin nonresident attributes. \n Security Descriptor. Information controlling access to a file or directory (e.g., \nownership, access control lists, and auditing information). \nFIGURE 18.7 \nMFT record with \nnonresident data \nattributes.\nData attribute header\nBlock start\nBlock count\nPointer to first data cluster\nBlock count\nPointer to next data cluster\nBlock count\nHeader\nRun # 1\nRun # 2\nMFT Entry Header\nAttribute Header\n$FILE_NAME\nAttribute Header\n$STD_INFO\nAttribute Header\n0\n5\n12\n3\n47\n2\n(unused)\nelm49810_ch18_413-444.indd   430\nelm49810_ch18_413-444.indd   430\n12/11/08   4:00:33 PM\n12/11/08   4:00:33 PM\n",
        "category": "Category"
    },
    {
        "id": "360",
        "title": "Title for Chunk 360",
        "content": "Confirming Pages\n \nChapter 18 Windows NT\u2122 through Vista\u2122 \n431\n Attribute List. This is a meta-attribute\u2014it describes other attributes. If an \nattribute is nonresident, then that attribute\u2019s identifier is placed in the MFT \nrecord with a pointer to the nonresident attribute. \n Data. The data in a file is the value of the \u201cdata\u201d attribute. If all of the attributes \nof a file (including the data) will fit in the MFT record, then the data \nattribute will be resident in the MFT record itself. Such files require no \nother storage space on the volume, and more importantly they do not require \nan extra disk access to read the data, improving performance. \n Larger files are more complicated. If all of the attributes for a file do not fit into the \nMFT record, the attributes will be made nonresident. So most files will have their \ndata stored outside the MFT record. The attributes for a file obviously include point-\ners to the data. Very large files may be so large that the attributes pointing to the data \nwill not fit in the MFT record and thus become external attributes themselves. \n Keeping the MFT contiguous on the disk improves performance, so when an \nNTFS volume is initialized, about 13% of the disk space immediately following the \nMFT is reserved as the \u201cMFT zone.\u201d It is still usable, but normal files and directories \nwill not use this space until the rest of the space is used. Eventually, the MFT may \nuse up the \u201cMFT zone.\u201d If this happens, NTFS will allocate more space for the MFT. \nThis fragmentation of the MFT may reduce  performance by increasing the number \nof reads required for some files, and the MFT cannot generally be defragmented. \n Space tracking \n NTFS allocates disk space in blocks of sectors called clusters. It uses a bitmap to \ntrack whether or not each cluster has been allocated to a file. The bitmap itself is \nstored in the master file table as a special system file. \n Pointers to the clusters that have been allocated to a file are kept together in a \nblock. In Chapter 12 we described these as \u201cindex blocks\u201d to conform to the stan-\ndard terminology in OS literature. (This term should not be confused with NTFS \n$INDEX attributes, which apply to directories.) The index block pointers give the \ncluster number of the start of a  data run, which is a contiguous group of clusters \nthat are all allocated to this file. The index block has a starting cluster number and a \nrun length, or count of the contiguous clusters. An MFT record using such runs was \nshown in  Figure 18.7 . \n Major NTFS goals \n NTFS had two major goals: high reliability and security. High reliability was \napproached from two different directions, recoverability after a crash and software \ndata redundancy and fault tolerance (i.e., RAID). Beyond these three main goals \nNTFS provides many other advanced features. \n Recoverability  Probably the primary goal of the NTFS design was to increase the \nreliability of the file systems in the face of a crash. With previous file system designs, \nif the data that controlled the file system was corrupted due to an abnormal system \nshutdown, there was a strong possibility that whole files or large portions could be \nirretrievably lost. The mechanism that has evolved for the purpose of increasing file \nelm49810_ch18_413-444.indd   431\nelm49810_ch18_413-444.indd   431\n12/11/08   4:00:33 PM\n12/11/08   4:00:33 PM\n",
        "category": "Category"
    },
    {
        "id": "361",
        "title": "Title for Chunk 361",
        "content": "Confirming Pages\n432 \nPart 6 Case Studies\nsystem recoverability is a  log-based file system or  journaling file system, as was \ndiscussed in Chapter 13. Whenever any update is to be done to the file system meta-\ndata, NT first writes out a record to a log file, which lists the steps of the update that \nare to be made. This set of steps is referred to as a  transaction.  Then the individual \nsteps of the update are made. Finally, any file I/O for which the metadata updates \nwere being done is executed. Once the entire series of steps is finished, the record \nlisting those steps will be removed from the log file. If the system goes down, then \nwhen it comes back up it checks to see if an update transaction was in process. If \na record in the log file shows an update was in process, then the OS can recognize \nwhat part of the operation was not completed successfully, and it can either finish \nthe transaction if it is able or it can back out those portions that were already done if \nit cannot finish. In this way the file system will always be brought into a valid state. \nSome application data might have been lost, but at least the file system can continue \nto be used without fear that additional data will be lost in the future because the file \nsystem has been left in a corrupted state. The Vista release includes optional features \ncalled Volume Shadow Copy and Transaction Support, which can provide protection \nfor data files. These features are discussed in Section 18.5.5. \n Naturally, these extra steps take extra time and increase the load on the disk \ndrive. Since NT is designed primarily for a personal computer, the extra load is tol-\nerable because the system is probably not being overworked in most cases. Other \nNTFS design elements also allowed some performance gains over the other file sys-\ntems that NT supports, so the performance of NTFS overall is acceptable because of \nthe increased reliability over other Microsoft file systems. Also, if a system crashes \nand the file system is not a log-based system, then it is prudent to run a utility func-\ntion to check the integrity of the file system. On a system with very many files this \nmight take several hours to run. On a system that is being used as a server, such a long \ndelay is unacceptable. In such cases it makes more sense to distribute this perfor-\nmance impact so that guaranteeing the integrity is spread over the normal day-to-day \noperation rather than incurred at one time after a system crash.  \n Data redundancy and fault tolerance   Another disk reliability feature of NT is sup-\nport for three different software  RAID ( redundant array of independent disks ) \norganizations. RAID was discussed in more detail in Chapter 14. The RAID forms \nsupported by NT are RAID-0, RAID-1, and RAID-5. RAID-0 is strictly for perfor-\nmance enhancement and offers no increased reliability. RAID-1 is full mirroring\u2014\neverything written to one drive is automatically written to another drive. It offers \ngood reliability but at a higher hardware cost. For RAID-5 a parity block is written \nthat corresponds to a group of data blocks. It offers good reliability at a lower hard-\nware cost but with increased software overhead. Of course hardware RAID systems \ncan be used with NT rather than using software solutions. \n Security  In NT the fundamental building block of all OS data structures is an \nobject. Included in this group are files and directories. Each object has an owner, \noriginally the entity that created the object. Security can be applied to any object \nusing an access control list. You may recall that an ACL for an entity lists the enti-\nties (including groups and roles) that are allowed to operate on an object and the list \nof operations that the entity is allowed to perform. The owner can do several things \nelm49810_ch18_413-444.indd   432\nelm49810_ch18_413-444.indd   432\n12/11/08   4:00:34 PM\n12/11/08   4:00:34 PM\n",
        "category": "Category"
    },
    {
        "id": "362",
        "title": "Title for Chunk 362",
        "content": "Confirming Pages\n \nChapter 18 Windows NT\u2122 through Vista\u2122 \n433\nto the ACL, including changing it directly, allowing other entities to change it, and \nallowing other entities to become the owner. In NTFS the ACL for a file or directory \nis stored as an attribute of the object. The permissions used in NTFS are these:\n * R \u2014 read  \n * W \u2014 write \n * X \u2014 execute  \n * D \u2014 delete \n * P \u2014 modify the ACL  \n * O \u2014 make current account the new owner (\u201dtake ownership\u201d)  \n 18.5.2 Advanced features of NTFS \n NTFS includes many advanced features for supporting applications. Some fea-\ntures are available to application programs as API calls and others are only used \ninternally:\n Read-only support. Before the XP release NTFS required that volumes be \non writeable media so that it could write the transaction log files. XP \nintroduced drivers that can mount volumes on read-only media. This feature \nis needed by embedded systems that have read-only volumes in NTFS \nformat. \n Defragmentation. NTFS makes no special efforts to keep files contiguous. It \nprovides a defragmentation API that applications can use to move file data \nso that files occupy contiguous clusters. NT includes a defragmentation \ntool but it has several limitations. Third-party products usually offer more \nfeatures. \n Volume mount points. These are similar to UNIX mount points. In NTFS, this \nallows additional file systems to be visible without requiring a separate \ndrive letter for each. This includes remote volumes as well. \n POSIX support. One of the goals for NT was to support the POSIX standard. \nFor file systems this requires support for case-sensitive file and directory \nnames, a different method of determining access permissions when parsing \npath names, and a different set of timestamp semantics. None of these \nfeatures is compatible with NT itself. NTFS includes these optional features \nin support for POSIX. \n Encryption. Data stored on laptops can be exposed when a laptop is lost or \nstolen. File system protection is not perfect in this case because volumes \ncan be read by software that doesn\u2019t require NT to be running. Furthermore, \nNTFS file permissions are worthless when another user can use an \naccount with administrator privileges. So NTFS includes a function called \nencrypting file system (EFS) to encrypt the data stored in the data attribute. \nEFS is completely transparent to applications. Encrypted files can be \naccessed only by using the private key of an account\u2019s EFS private/public \nelm49810_ch18_413-444.indd   433\nelm49810_ch18_413-444.indd   433\n12/11/08   4:00:34 PM\n12/11/08   4:00:34 PM\n",
        "category": "Category"
    },
    {
        "id": "363",
        "title": "Title for Chunk 363",
        "content": "Confirming Pages\n434 \nPart 6 Case Studies\nkey pair, and private keys are locked using an account\u2019s password so the \nfiles can\u2019t be read without the password of an authorized account. \n Volume shadow copy. This service keeps historical versions of files and folders \non NTFS volumes by copying overwritten data to a hidden shadow backup. \nThe user can later request a switch back to an earlier version. This feature \nallows backup programs to archive files currently in use. \n Link tracking. Shortcuts allow users to place files on their desktop. Similarly, \nobject linking and embedding (OLE) allow documents from one application \nto be linked to documents of other applications. Such links provide an easy \nway to connect files with one another but they have been hard to manage, \nsince if the user moves the target of a link, the link will be broken. NTFS \nsupports distributed link-tracking, which maintains the integrity of shell and \nOLE links when link targets move. With NTFS link-tracking support, if a link \ntarget located on an NTFS volume moves to another NTFS volume in the \nsame domain, the link-tracking service can update the link to reflect the move. \n Single instance storage (SIS). Sometimes several directories have files with \nidentical content. Single instance storage allows identical files to be reduced \nto one physical file and many SIS references to the merged file. SIS is a \nfile system filter that manages changes to files and a service that searches \nfor files that are identical and need merging. Unlike hard links that point to \nonly one file, each SIS file remains distinct as far as the externals to the file \nsystem are concerned, and changes to one copy of a file will not change the \nothers. A distinct copy will be created for the one SIS file that is changed.  \n Per-user disk space quotas. Administrators often need to track or limit user disk \nspace usage, especially on servers, so NTFS includes quota-management \nsupport, which allows for per-user specification of disk space quotas. \n Change logging. Applications sometimes need to monitor volumes for file \nand directory changes. For example, an automatic backup program might \nmake incremental backups when files change. One way for this to happen \nis for the application to scan the volume and record the state of files and \ndirectories. Then on a later scan it can check for differences. This process \ncan significantly slow the system, however, especially when computers \ncommonly have hundreds of thousands of files. NTFS allows an application \nto ask NTFS to record information about file and directory changes to a \nspecial file called the change journal. The application can then read the \nchange journal instead of scanning the entire directory tree. \n Transaction support. With Vista, applications can use transactions to group \nchanges to files together into a transaction. The transaction guarantees \nthat all changes happen, or none of them do, and it will guarantee that \napplications outside the transaction will not see the changes until they \nare committed. Transactions have been commonly supported in database \nsystems and in the NTFS metadata. This feature brings the reliability of \ntransaction-based systems to normal files. \n Compression and sparse files. NTFS supports compression of file data. \nCompression and decompression are transparent, so applications don\u2019t \nelm49810_ch18_413-444.indd   434\nelm49810_ch18_413-444.indd   434\n12/11/08   4:00:34 PM\n12/11/08   4:00:34 PM\n",
        "category": "Category"
    },
    {
        "id": "364",
        "title": "Title for Chunk 364",
        "content": "Confirming Pages\n \nChapter 18 Windows NT\u2122 through Vista\u2122 \n435\nhave to be modified to take advantage of this feature. Directories can also \nbe compressed, and any files in compressed directories are automatically \ncompressed. NTFS has a related mechanism known as sparse files. If a file \nis marked as sparse, NTFS doesn\u2019t allocate space on a volume for portions \nof the file that are empty. NTFS returns 0-filled buffers when an application \nreads from empty areas of a sparse file. As with compressed files, sparse \nfiles are generally transparent to the application, though applications can \nbe aware of sparse files and possibly save considerable CPU and memory \nresources when processing portions of files that are actually null. \n Aliases. NTFS supports both hard and symbolic links. A hard link allows \nmultiple paths to refer to the same file. They are implemented much as was \ndiscussed in Chapter 12. NTFS prevents loops by the simple expedient of \nnot allowing a hard link to refer to a directory. NTFS calls symbolic links \n junctions. They are based on a more general mechanism called a  reparse \npoint. A reparse point is an extra attribute about the file or directory, such as \nits current location, that can be read by the I/O manager. When NTFS hits \na reparse point during a file or directory lookup, it tells the I/O manager to \ncheck the reparse data. The I/O manager can alter the pathname specified \nin the original operation and let it restart with the changed path. Reparse \npoints can also be used by tape archival software to show that a file has been \nmoved to an archive system. It moves a file to a tape, leaving reparse points \nin their directory entries that tell the software where the file is now located. \nWhen a process tries to access a file that has been archived, the driver \nremoves the reparse point attribute from the directory, reads the file data \nfrom the archival media back to the original media, and reissues the access. \nThus, the retrieval of the offline data is transparent to a process accessing an \narchived file. Of course, opening the file probably takes a little longer than \nnormal. \n Dynamic bad-cluster handling. If a data read accesses a bad disk sector, the \nread fails and the data is no longer available. If the disk is a fault-tolerant \n(RAID) volume, however, the driver fetches a good copy of the data and \nalso tells NTFS that the sector is bad. NTFS allocates a new cluster on the \nfailed drive to replace the bad cluster and copies the data there. It marks the \nbad cluster and thereafter ignores it. \n Indexing. NTFS allows  indexing of any of the file attributes on a disk volume. \nIndexing sorts the attributes. This lets the file system quickly find files that \nmatch any criteria, such as all the files in one directory. \n Complex file names. NTFS uses Unicode characters to store names of files, \ndirectories, and volumes. Unicode is a 16-bit character-coding scheme that \nallows each character in each of the world\u2019s major languages to be uniquely \nrepresented. Each element in a path name can be up to 255 characters long \nand can contain Unicode characters, spaces, and multiple periods. \n Multiple data streams. In NTFS a file\u2019s data is considered to be an attribute of \nthe file called the data stream. New attributes can be added by applications, \nincluding additional data streams, so files (and directories) can contain \nelm49810_ch18_413-444.indd   435\nelm49810_ch18_413-444.indd   435\n12/11/08   4:00:35 PM\n12/11/08   4:00:35 PM\n",
        "category": "Category"
    },
    {
        "id": "365",
        "title": "Title for Chunk 365",
        "content": "Confirming Pages\n436 \nPart 6 Case Studies\nmultiple data streams. NT uses an alternate stream to associate user \n\u201cproperties\u201d with the file, such as a title, subject, author, and keywords. It \nstores the date in an alternate stream called Summary Information. \n 18.6 BASIC INPUT AND OUTPUT \n The architecture of the total NT file system can be seen more closely in  Figure 18.8 . \nUnfortunately, as often happens with OS documentation, the names that we have \nbeen using in this text conflict with the names used by the NT system designers. For \nexample, they call the top layer of the I/O system the \u201cI/O Manager,\u201d while we have \nused that term for the lower-level I/O functions of an OS. In this chapter we use the \nterms as they are used by Microsoft. So the functions we were describing in the pre-\nvious section actually reside in the Partition/Volume Storage Manager and the Disk \nClass Manager. \n 18.6.1 Partitions \n Because hard drive support in PCs derived from the designs used in MS/DOS, there \nare certain things that any OS on a PC is going to support. For one thing, the design \nallows the system administrator to divide the disk drive into separate areas called \n partitions. The administrator will then use OS utility programs to establish a sepa-\nrate file system in each partition. These file systems may even be file systems native \nto other OSs. The I/O system will see each partition as a separate drive. As with the \nFIGURE 18.8 \nNT I/O architecture.\nDisk Class\nManager\nVirtual Memory\nManager\nMINI-\nPORT\nFile System Driver\nPartition/Volume\nStorage Manager\nApplication\nPORT\nCache Manager\nUSER\nKERNEL\nNT I/O Manager\nFile System Filters\nKarnel32/ntdll \nelm49810_ch18_413-444.indd   436\nelm49810_ch18_413-444.indd   436\n12/11/08   4:00:35 PM\n12/11/08   4:00:35 PM\n",
        "category": "Category"
    },
    {
        "id": "366",
        "title": "Title for Chunk 366",
        "content": "Confirming Pages\n \nChapter 18 Windows NT\u2122 through Vista\u2122 \n437\nfile systems themselves, the design of the partitioning structure has had to evolve to \ncope with the increasing size of hard disks. The partitioning mechanism creates a \nsmall table in the first sector of the hard disk called the  master boot block ( MBB ) \nor  master boot record ( MBR ). The original mechanism could create only four par-\ntitions on a single disk. Later extensions allowed one partition to be designated as \nan extended partition. This would allow up to 24 logical partitions to be created on \none disk.  \n 18.6.2 I/O system layering \n The separation of the layers in the I/O system allows additional extra layers to be \neasily inserted into the OS architecture. In many cases the NT I/O drivers expose the \nsame calls at their API as they use to invoke the drivers at the next lower level, and \neach alternative module at any given layer implements the same interfaces. Among \nother things, this layering allows a logical device to be defined on a system that is \nnot really a local disk partition but is instead located on another machine across a \nnetwork. In this case the system performs a  redirection so that to the user and to pro-\ngrams, network devices appear to be no different from local devices. It also allows a \ndevice to appear to be a disk drive when it actually is something else\u2014a USB flash \ndrive, for example. \n The layers also allow extra features to be inserted between layers. They are \nloaded as the system boots in the form of device drivers of a special class called \n filters. In the simple case where the average user might not want any extra features, \nthe basic I/O functions can be supported with very little overhead. When a user does \nwant some more exotic function, the extra features can be inserted between two \nlayers in a manner that is transparent to both the higher and lower layers. One exam-\nple of such extra functionality is that of virus scanners. By providing this interface \nbetween the layers, NT can allow third-party software to extend the features of the \nI/O system without violating the integrity of the OS code. Also, if any future unan-\nticipated functionality is developed it will be easy to add it to the I/O system because \nof this well-defined standard layered interface. \n 18.6.3 Plug and play \n When an OS is written it is a generic entity, capable of running on a wide variety of \nhardware configurations. When we install an OS on a specific machine it must be \nconfigured to match the hardware installed. If new hardware is later added or old \nhardware replaced or removed, then the OS must be adjusted to match the new con-\nfiguration. We need drivers for new hardware and we also don\u2019t want to waste space \non drivers that are no longer needed. \n In the early generations of the large mainframes it was common for the systems \nprogramming staff to have to perform a  sysgen (system generation) when installing \nor upgrading an OS. Briefly, this amounted to describing the hardware configuration \nwith a file of specification records, which were then used to generate an executable \nversion of the OS specifically tailored to match the hardware. For a moderate-sized \nconfiguration this took days and sometimes several tries to work correctly. \nelm49810_ch18_413-444.indd   437\nelm49810_ch18_413-444.indd   437\n12/11/08   4:00:38 PM\n12/11/08   4:00:38 PM\n",
        "category": "Category"
    },
    {
        "id": "367",
        "title": "Title for Chunk 367",
        "content": "Confirming Pages\n438 \nPart 6 Case Studies\n The original IBM PC was typical of hardware systems of that era, and configu-\nration of DOS to fit the hardware was very difficult. There were two to four different \npieces of information required to configure most controllers, including an interrupt \nrequest level (IRQ), a memory address, an I/O port (address), and a direct memory \naccess (DMA) channel number. These were set manually using small switches or \njumpers on the controller board. These addresses had to be selected so that they \ndid not conflict with one another. Installing a new controller in a machine could be \nquite challenging because it was often difficult to find out the settings on the existing \ncards. In addition, the hardware then had to be described to the OS using a file called \n config.sys. Hardware vendors usually supplied a utility program that would attempt \nto adapt the config.sys file for the new hardware, but they often would cause more \nproblems than they would fix. \n Beginning with the IBM MicroChannel\u2122 and EISA buses, the controllers were \nable to identify themselves to the OS and respond to configuration changes by the \nsoftware. This activity is known as  plug and play, or sometimes  PnP. This trend \ncontinued with the PCI bus and today most OSs are capable of recognizing most new \nhardware, setting the parameters for the cards dynamically, selecting configurations, \nthat will work with the existing hardware configuration, and customizing the OS by \ndynamically loading the correct device drivers for the hardware. The OS is still being \nadapted to fit the hardware, but the process is normally done dynamically by the OS \nand is much more transparent to the user. \n 18.6.4 Device drivers \n All of the hardware characteristics of the I/O devices are isolated in the lowest level \nof the kernel, the device drivers. This means, for example, that all higher-level mod-\nules should not concern themselves with how many sectors are on a disk track or how \nmany read/write heads a disk drive has. Nor should they be concerned with which \nbits in the status register indicate an error has occurred. Instead, they should focus on \nthe things that are common to all disk drives, and confine the details of any specific \ndevice (or controller) to the device driver for that particular device or controller. \n Since NT uses such device drivers to hide the details of the hardware, it is easy \nto change the hardware configuration of an NT system. Indeed, the drivers can be \ninstalled in or removed from the system dynamically. This means that when a device \nis added to the system it is not necessary to reboot the OS. Prior to this development \nsuch rebooting had been necessary when the hardware was changed. This was time-\nconsuming and in the case of very important systems such as servers it was highly \nundesirable. With device controllers that are physically inserted into the bus\u2014for \nexample, a new graphics card\u2014the system power has to be turned off anyway, so \nhaving to reboot the system is not a problem. However, several of the new methods \nfor connecting peripheral devices to the computer assume the device is external, like \na VCR or a camcorder, so powering it off is not necessary. Examples of such inter-\nfaces include  USB (Universal Serial Bus),  IEEE 1394, and  PC Card or  Card Bus \n(formerly called  PCMCIA ) devices. Furthermore, protocols are defined for these \ninterfaces such that the device identifies itself to the computer in a manner similar to \nthe plug and play features of a PCI bus. This dynamic identification means that the \nelm49810_ch18_413-444.indd   438\nelm49810_ch18_413-444.indd   438\n12/11/08   4:00:38 PM\n12/11/08   4:00:38 PM\n",
        "category": "Category"
    },
    {
        "id": "368",
        "title": "Title for Chunk 368",
        "content": "Confirming Pages\n \nChapter 18 Windows NT\u2122 through Vista\u2122 \n439\nOS can automatically load the drivers for any newly installed device without reboot-\ning the OS and generally without any assistance from the user other than possibly \nproviding a CD-ROM containing drivers for the device. Most users will also connect \ndevices to serial or parallel ports without shutting off the power, though manufactur-\ners of such devices do not generally recommend it. But devices connected through \nthese ports may not be able to identify themselves automatically like those with the \nnewer interfaces do. \n 18.6.5 Disk class, port, and miniport drivers \n The File System module calls on  storage driver functions at lower layers that move \nprogressively closer to the hardware. These layers are called the  storage class,  stor-\nage port, and  miniport drivers. At the top layer NT provides storage class drivers, \nwhich implement features common to all storage devices of a particular type such as \ndisks or tapes. At the next layer are storage port drivers, which have features com-\nmon to a particular bus such as SCSI or ATA. Disk drive vendors supply miniport \ndrivers that support a particular device or family of compatible devices. The class \ndrivers have the same API as the device driver interfaces. Miniport drivers use a \nport driver interface instead of the device driver interface. This approach simplifies \nthe role of miniport developers because they have APIs that are compatible with \nprevious Microsoft OSs. Storage class drivers can often handle many devices in the \nclass without having a storage port or miniport driver. The prime example of this is \nthe generic USB storage class driver, which can access many USB storage devices \nwithout any other drivers. \n 18.7 GUI PROGRAMMING \n For the user, arguably the defining feature of Windows is the GUI. The program-\nmer accesses the OS functions that manipulate the objects on the desktop through \nWindows\u2019 APIs. These interfaces provide functions that allow the programmer to \ndraw windows, make menus and dialog boxes, and so forth. The OS itself takes \ncare of common functions like making sure that when one window is closed that \nthe appropriate parts of any windows that were behind the closed window are \nupdated. Some facilities are provided for the programmer such as the common dia-\nlog box. See  Figure 18.9 . This is a standard window-based dialog that the program \ncan use to find a file (or files) to open, specify a name to save a file under, select \na font or a color, and several other common features that any program might want \nto allow. An application programmer can use this interface, but is not required to \ndo so. Using this interface provides a similar look-and-feel to different applica-\ntions. As programmers have developed more sophisticated interfaces, they have \noften tended to use them in the place of the standard interfaces. One can argue that \nthese new interfaces are more user-friendly or more appropriate to a given task, \nbut having a different interface for every application may make the overall system \nmore difficult for a novice to learn, so it is not clear that the tradeoff is always \nworth it. \nelm49810_ch18_413-444.indd   439\nelm49810_ch18_413-444.indd   439\n12/11/08   4:00:38 PM\n12/11/08   4:00:38 PM\n",
        "category": "Category"
    },
    {
        "id": "369",
        "title": "Title for Chunk 369",
        "content": "Confirming Pages\n440 \nPart 6 Case Studies\n 18.8 NETWORKING \n Another aspect of NT where the creators desired bringing compatibility with other \nOSs was in the networking protocols it supported. When NT was being developed \nthe Internet was already fairly popular in academic circles, but the TCP/IP protocols \nused in the Internet were not the overwhelmingly dominant network protocols that \nthey are today. The Novell Netware OS was the dominant personal computer file \nserver platform and it had its own protocols in the form of IPX/SPX. There were \nmany UNIX systems in operation, and in addition, many of the larger enterprises \nhad IBM mainframes and midrange systems that used IBM protocols. Systems from \nApple, Inc. ran a protocol known as AppleTalk over various hardware topologies. \nIn order to gain a place in the networks of customers who used these other systems, \nMicrosoft had to be able to install systems that could communicate easily with those \nsystems by supporting the protocols they used. Of course, NT also had to provide \ncompatibility with the protocols that earlier versions of Windows and DOS used. It \ntherefore incorporated all the standard protocols used by these other systems. (These \nprotocols were sometimes common to multiple systems\u2014VAX systems often used \nTCP/IP, for example.) Typically these protocols included:\n \n\ufffd \nIPX/SPX for Novell Netware \n \n\ufffd \nTCP/IP for UNIX \n  \ufffd \nDECNet for Digital Equipment VAX systems \n  \ufffd \nSNA and NetBEUI for IBM systems \n  \n\ufffd \nLAN Manager for Windows legacy systems \n Similar to most of the other major components of NT, the networking functions are \nlayered. For example, the lowest layer of the networking stack uses an interface called \n NDIS ( network driver interface specification ) that was defined by Microsoft and \nFIGURE 18.9 \nA File Open dialog \nbox.\nelm49810_ch18_413-444.indd   440\nelm49810_ch18_413-444.indd   440\n12/11/08   4:00:39 PM\n12/11/08   4:00:39 PM\n",
        "category": "Category"
    },
    {
        "id": "370",
        "title": "Title for Chunk 370",
        "content": "Confirming Pages\n \nChapter 18 Windows NT\u2122 through Vista\u2122 \n441\n3Com. This interface is specifically designed to allow a single hardware device driver \nto support multiple Network layer protocols. This allowed the network interface card \n( NIC ) vendors to write a single driver for each combination of NIC and hardware \nplatform without regard for the operating system or the Network layer software. \nIndeed, it allowed the driver to support multiple Network layer protocols at the same \ntime. As with the I/O system, this layered architecture allows the transparent insertion \nof extra functionality that is not needed by most users. One example is    a layer to pro-\nvide  SNMP ( Simple Network Management Protocol ) functions in a PC so that it \ncan be remotely monitored with an SNMP-based network management console. This \nprotocol was discussed in Chapter 15. When such monitoring is not needed it does \nnot have to be installed and waste resources. \n An interesting feature of NT networking support is that it includes an interface \nfor asynchronous transfer mode (ATM) hardware. ATM has several interesting char-\nacteristics that most people have overlooked in their rush to join the Ethernet band-\nwagon. For one thing, the maximum ATM frame size of 64 KB fits better with the \nmaximum IP frame size of 64 KB than does Ethernet with a maximum frame size of \n1,500 bytes. When the hardware can directly support the much larger blocks, it is a \nwaste of resources to break them into smaller pieces. For another, ATM supports qual-\nity of service (QoS) features in the hardware without resorting to software contortions \nand extra software layers. As multimedia applications have become more important, \nsome people have found that these applications work much better over ATM than they \ndo over Ethernet, and that NT already includes support for those features.  \n 18.9 SYMMETRIC MULTIPROCESSING \n The hardware platforms that support the NT OS family can scale up to fairly large \nsystems. One feature that is often found in systems that are designed for supporting \nhigh-volume servers is that they may have more than one CPU. Multiple CPU tech-\nnology is now moving down into average desktop systems with CPUs that can run \nmultiple processes concurrently and with multiple CPUs in a single chip. NT sup-\nports symmetric multiprocessing (SMP), as was discussed in Chapters 6 and 9. The \nmaximum number of CPUs supported by the NT family varies with the CPU word \nsize; 32-bit CPUs will support up to 32 CPUs and the 64-bit CPUs will support up \nto 64 CPUs. These limits are simply because masks about the individual CPUs are \nstored in a single data word. \n 18.10 STARTUP SPEED OF XP \n One of the interesting design goals of the XP release was to speed up the time required \nto boot the operating system. The goal depended on the way in which the system was \nstarted. From a cold start the goal was considerably longer than from a standby mode \nor a hibernate mode. For a restart from a standby state a five second boot time was the \ngoal. Note that this requires a hardware option called advanced configuration power \ninterface (ACPI). The time interval of this goal is interesting because it is roughly the \ntimeout of a human\u2019s short-term memory. If you begin to do some task and the actions \nrequired to start that task take more than about seven seconds, you will frequently find \nelm49810_ch18_413-444.indd   441\nelm49810_ch18_413-444.indd   441\n12/11/08   4:00:39 PM\n12/11/08   4:00:39 PM\n",
        "category": "Category"
    },
    {
        "id": "371",
        "title": "Title for Chunk 371",
        "content": "Confirming Pages\n442 \nPart 6 Case Studies\nthat your attention has wandered\u2014you will have forgotten that phone number you \njust looked up, for example. So if your PC is turned off and you decide to turn it on to \nlook up something interesting, if it takes more than seven seconds to boot up you may \nfind that the hot idea you had has just slipped away. So this was an important feature \nthat was probably not fully appreciated by many users but affected them nonetheless. \n 18.11 SUMMARY \n In this chapter, we discussed the features and con-\ncepts of a more advanced OS\u2014the Windows NT \nOperating System developed by Microsoft, Inc. We \nstarted this chapter with an overview of the NT OS \nand a bit of the history of the evolution of Micro-\nsoft OSs. We then moved to a brief discussion of the \nnature of a high-end single-user OS and the main \ngoals of the NT family\u2014support for applications \nfrom legacy OSs and support for multiple hardware \nplatforms. Next, we discussed the complexity caused \nby running multiple-user applications and server \napplications at the same time. This additional com-\nplexity shows in both the scheduling of processes \nand threads and in the additional memory manage-\nment functions supported by the NT OS family. \n Then we gave an overview of the support of files \nin the NT OS and the higher functions required by \nhaving multiple users and possibly multiple serv-\ners configured on the system, followed by coverage \nof the I/O functions that the OS provides. We then \nbriefly discussed some new aspects of the GUI func-\ntionality caused by having multiple windows open \nat the same time and we also touched on the sub-\nject of multiprocessor support under NT. Finally, we \naddressed the speed of the startup of XP. \n In the next section of the book we provide a case \nstudy of the Linux OS by covering some features \nthat were not covered in the spiral chapter where \nthe focus was primarily on those features that were \nrequired when supporting multiple users. \n BIBLIOGRAPHY \n IEEE: Information Technology\u2014Portable Operating \nSystems Interface (POSIX). New York: IEEE, 1990. \n Ricadela, A., \u201cGates Says Security Is Job One For Vista.\u201d \n InformationWeek News, February 14, 2006. \n Russinovich, M. E., and D. A. Solomon,  Microsoft \nWindows Internals, 4th ed., Redmond WA: Microsoft \nPress, 2005. \n WEB RESOURCES \n http://www.activewin.com/awin/default.asp (outsider \ninformation on Microsoft) \n http://book.itzero.com/read/microsoft/0507/Microsoft.Press.\nMicrosoft.Windows.Internals.Fourth.Edition.Dec.2004\n.internal.Fixed.eBook%2DDDU%5Fhtml/  (Microsoft \u00ae \nWindows \u00ae Internals, 4th ed. Microsoft Windows \nServer\u2122 2003, Windows XP, and Windows 2000, by \nRussinovich, M. E., and D. A. Solomon)  \n http://msdn.microsoft.com/en-us/default.aspx (Microsoft \nDeveloper News) \n http://www.osnews.com (news site on all OSs) \n http://technet.microsoft.com/en-us/library/bb878161.aspx \n(Windows XP resource kit) \n http://technet.microsoft.com/en-us/sysinternals/default\n.aspx (Sysinternals, originally an outside technical \nreference, later bought by Microsoft) \n http://pages.prodigy.net/michaln/history/ (OS/2 history) \n http://www.tasklist.org (software to list all processes \nrunning on a system) \n http://www.windowsitlibrary.com (magazine site)  \n http://www.winsupersite.com (outsider information on \nMicrosoft) \nelm49810_ch18_413-444.indd   442\nelm49810_ch18_413-444.indd   442\n12/11/08   4:00:40 PM\n12/11/08   4:00:40 PM\n",
        "category": "Category"
    },
    {
        "id": "372",
        "title": "Title for Chunk 372",
        "content": "Confirming Pages\n \nChapter 18 Windows NT\u2122 through Vista\u2122 \n443\n REVIEW QUESTIONS \n 18.1 What was the major change when Windows \nNT was being developed that made it differ-\nent from most of the previous OS products from \nMicrosoft? \n 18.2 What were some of the major goals for the XP \nfamily that were mentioned in the chapter? \n 18.3 When a process does a fork call, XP does not \nreally create a second copy of the program. What \ndoes it do instead? \n 18.4 How was the goal of hardware independence \naddressed? \n 18.5 What sorts of objects does NT use to schedule the \nCPU? \n 18.6 Describe the difference between the normal prior-\nity class and the real-time class. \n 18.7 What is so unusual about how the NTFS supports \nthe data in a file? Specifically, what happens if the \ndata is rather short? \n 18.8 True or false? Windows XP supports the OS/2 \nHPFS file system. \n 18.9 Which RAID configurations does NT support in \nsoftware? \n 18.10 Why is it important to have such a specific divi-\nsion between the IOS and the file system? \n 18.11 True or false? NT supports compression of files or \nentire portions of a file system. \n 18.12 What is the impact of a \u201clog-based\u201d file system? \n 18.13 What is the advantage of dynamically installable \ndevice drivers? \n 18.14 What is unusual about the command-line interface \nto Windows XP?  \n 18.15 One school of thought says that it is better for \napplications to stick to standard elements in the \nGUI interface. Another argues that improved ele-\nments can make applications better. Justify your \nchoice. \n 18.16 Why does XP support an ATM protocol stack?  \n 18.17 What does the NDIS specification do? \n 18.18 Which multiprocessing mechanism does XP \nsupport? \n \nelm49810_ch18_413-444.indd   443\nelm49810_ch18_413-444.indd   443\n12/11/08   4:00:40 PM\n12/11/08   4:00:40 PM\n",
        "category": "Category"
    },
    {
        "id": "373",
        "title": "Title for Chunk 373",
        "content": "elm49810_ch18_413-444.indd   444\nelm49810_ch18_413-444.indd   444\n12/11/08   4:00:40 PM\n12/11/08   4:00:40 PM\n",
        "category": "Category"
    },
    {
        "id": "374",
        "title": "Title for Chunk 374",
        "content": "Confirming Pages\n297\n Chapter \n Chapter \n Disk Scheduling and \nInput/Output Management \n In this chapter: \n 14.1 Introduction 297\n 14.2 Device Characteristics  298\n 14.3 I/O Technology 299\n 14.4 Physical Disk Organization 302\n 14.5 Logical Disk Organization 305\n 14.6 RAID 309\n 14.7 Disk Operation Scheduling 314\n 14.8 DMA and Disk Hardware Features 322\n 14.9 Summary 325\n 14.1 INTRODUCTION \n In the last chapter we looked at input and output from the way a user or an applica-\ntion programmer would look at it\u2014what are the capabilities and services that the OS \nprovides to the upper layers, what are the data structures needed to perform these \nservices, and how are these functions performed? In this chapter we look in the lower \nlayers to see how these things are done. In particular, the lowest layer of any file sys-\ntem is a collection of device drivers and interrupt handlers. In earlier chapters we \ndiscussed how I/O capabilities started with simple devices and structures and have \nprogressed to more complex systems and services. We take a closer look at modern \nhardware and the OS organization necessary to manage these devices effectively and \neconomically. \n In  Section 14.1  we introduce the topic of lower-level input and output manage-\nment, with a special focus on secondary storage and disk drives. Next, in  Section 14.2  \nwe discuss some broad classes of I/O devices and how they differ.  Section 14.3  \ndescribes some general techniques used in support of I/O devices. In  Section 14.4 , we \nthen explore the physical structure of disk drives, and in  Section 14.5  we discuss the \nlogical organization of the information stored thereon.  Section 14.6  covers the topic of \n 14 \n 14 \nelm49810_ch14_297-328.indd   297\nelm49810_ch14_297-328.indd   297\n12/18/08   11:28:19 AM\n12/18/08   11:28:19 AM\n",
        "category": "Category"
    },
    {
        "id": "375",
        "title": "Title for Chunk 375",
        "content": "Confirming Pages\n298 \nPart 4 A Depth-Oriented Presentation of OS Concepts: File Systems and Input/Output\nRAID, wherein assemblies of disks are used in special configurations to achieve greater \nthroughput and/or reliability. The very important topic of  scheduling disk operations \nfor optimum performance is covered in  Section 14.7.   Section 14.8  is about a special \ntype of device controller called a DMA controller that can significantly decrease the \nCPU load of I/O operations. This section also discusses some disk drive features that \naffect OS behavior. In  Section 14.9 we conclude with a chapter summary.  \n 14.2 DEVICE CHARACTERISTICS \n There are some categories of input/output that broadly divide them into groups that \nare treated differently by OSs. We discuss a few of those categories. \n 14.2.1 Random access versus sequential access \n In this chapter we are focused almost exclusively on secondary storage devices, spe-\ncifically disk drives. At one time magnetic tapes were used for secondary storage \non large mainframe computers. When personal computers were first developed they \nalso often had tape drives as the only secondary storage devices\u2014in this case it was a \nquarter-inch cassette tape drive that was originally developed for audio use. But tapes \nhave the unfortunate characteristic that they can\u2019t be read randomly. To get to any \nparticular piece of data on the tape you have to pass over all the other data between \nwhere the head is now and where it needs to be. Even on very fast tape drives this \ncould take several minutes. Fortunately, disk drives don\u2019t have that characteristic. \nBecause of this difference we speak of disk drives as being \u201crandom access\u201d devices. \nHowever, as we will see when we later look at disk drives in more detail, this does \nnot mean that the time to access the data is independent of the  location of the data. \nThis term is merely a reflection of the contrast with using a tape drive as the main \nsecondary storage device. \n 14.2.2 Device classes \n Most OSs broadly divide devices into three classes: block, character, and network. \nEach of those classes has substantially different characteristics and each class can \nbe abstracted in a meaningful way.  Table 14.1  gives some information about these \nclasses. \nTABLE 14.1  Characteristics of Linux Device Classes \nBlock\nCharacter\nNetwork\nRandom access\nYes\nNo\nNo\nSeek backward\nYes\nNo\nNo\nTransfer unit\nBlock (\ufffd 512)\nCharacter\nPacket\nSoftware\nFile System/Raw\nDevice\nProtocol\nelm49810_ch14_297-328.indd   298\nelm49810_ch14_297-328.indd   298\n12/18/08   11:28:21 AM\n12/18/08   11:28:21 AM\n",
        "category": "Category"
    },
    {
        "id": "376",
        "title": "Title for Chunk 376",
        "content": "Confirming Pages\n \nChapter 14 Disk Scheduling and Input/Output Management \n299\n Block devices \n A block device is read or written one block (a group of bytes, usually a multiple of \n512) at a time. Such devices include all sorts of disk drives and tape drives, for exam-\nple. The size of a block is determined partly by the hardware, since disk controllers \ncan only read or write whole disk sectors, but also by the system administrator when \nthe file system is set up. Normally, the block size will be some small multiple of \nthe physical sector size\u2014typically 4 or 8 KB. These devices often support random \naccess directly to any block on the device, that is to say that blocks may be read \nor written in any order. File systems typically reside on block devices and are the \nnormal mechanism for accessing these devices. There are caching mechanisms in \nplace for random access block structured devices. Sequential access block devices \nuse double buffering, as explained later. Occasionally, some software needs to access \nthese block devices directly rather than by using the file system. This is called  \nraw I/O. Examples of such software include utilities for maintaining or examin-\ning the file system itself (e.g.,  fsck for Linux and UNIX) and software that places \nextraordinary demands on the secondary storage and is sophisticated enough to \ninclude a preferred mechanism for caching or for scheduling disk operations (e.g., \nvery demanding database servers). \n Character devices \n Character mode devices transfer data a single byte at a time. They include printers, \nkeyboards, mice (and other pointing devices), and so on. They support most of the \nsame basic kinds of operations as a block mode file: open, close, read, and write. To \nperform an operation that doesn\u2019t fit the semantics of the file system model (e.g., \nreading the status of a printer), a program can use the  ioctl system call. Character \nmode devices obviously cannot support seeking backward. For example, one cannot \nread the character typed on the keyboard 20 characters previously, or a character \nprinted on the previous page. Some character devices will allow skipping characters \nin a forward direction. Character mode devices are never cached, though they may \nhave a buffer. \n Network devices \n Network devices do not fit at all well with the traditional semantics of file opera-\ntions. The problem is that applications waiting for input from a network never know \nwhen or even if the data might be available. A company might create a website with \nhigh hopes for selling widgets but never receive a single hit on the site. For this rea-\nson, network devices have an entirely different set of interfaces than do block and \ncharacter devices with their read and write operations. \n 14.3 I/O TECHNOLOGY \n In general, there are two ways that an I/O system can go about its work. Most large \nsystems have many functions going on more or less at the same time, and the only \nway to cope with them all is to use an interrupt system such as was described in \nelm49810_ch14_297-328.indd   299\nelm49810_ch14_297-328.indd   299\n12/18/08   11:28:22 AM\n12/18/08   11:28:22 AM\n",
        "category": "Category"
    },
    {
        "id": "377",
        "title": "Title for Chunk 377",
        "content": "Confirming Pages\n300 \nPart 4 A Depth-Oriented Presentation of OS Concepts: File Systems and Input/Output\nChapter 2. However, an alternative approach is often used in smaller systems with \nlow-power CPUs, that of  polling. In a polling system the control of the OS is written \nin a single large loop in which the OS will check the status of each device in turn to \nsee if it needs attention. This technique is often used in imbedded devices or simple \nhandheld games where only a few devices are available and checking them in turn \nis simpler than setting up an interrupt architecture and undergoing the overhead of \ncontext switching involved in servicing interrupts. \n General Techniques Used in I/O Systems \n There are several general techniques that are used in I/O systems. Before delving \ninto other I/O system details we cover some of those general techniques. \n 14.3.1 Buffering \n When we are inputting data into a computer system we typically are reading from one \ndevice and writing to another. For example, a user is writing a document by keying \nit on a keyboard and the computer writes it to disk. At another extreme we might be \nbacking up our hard drive to a tape drive. In each case we will use a technique called \n buffering. A buffer is a portion of memory where we store a record that will be used in \nan I/O operation. There are several reasons why we might use a buffer. The first might \nbe the size of the transfer. The user writing a document is producing a single character \nat a time. However, we can\u2019t write a single character to a disk. The smallest unit of \naccess is a sector. Block devices like disk and tape drives can only transfer data in large \nblocks. So we use a buffer to hold the characters that the user is keying until we have \nenough to fill a sector. Then we write the sector to the disk and start a new sector. \n In this particular situation the disk is probably fast enough that we can write the \nbuffer and empty it to receive the next keystroke before that keystroke could possibly \narrive. However, suppose that the difference in speeds between the devices were \nmuch smaller\u2014say a factor of three or four. In this case we might resort to a slightly \ndifferent technique,  double buffering. We will assign two buffers to the process. We \nwill first fill one buffer and then start the operation to write it to the output device. As \nwe start the write we will begin using the second buffer for the incoming data. By the \ntime the second buffer is full the write of the first buffer should be finished and we \ncan start to write the second one while we start to fill the first one again.  Figure 14.1  \nshows this process. In  Figure 14.1a  we see that Process A is filling Buffer 1 and \nBuffer 2 is waiting. In  Figure 14.1b Process A has filled Buffer 1, so it is now filling \nBuffer 2 and Buffer 1 is being written to the disk drive. \n Another reason we would use buffers might be that we are dealing with two \ndevices that are both block access devices, but the devices have a different block \nsize. For example, Ethernet network adapters typically transfer a maximum \nblock size of about 1,500 bytes. Token Ring adapters would allow a maximum trans-\nfer size of about 18,000 bytes. If a packet was being transferred from a Token Ring \nconnection to an Ethernet connection we would have to use a buffer to hold the \nToken Ring packet while we were breaking it up into multiple Ethernet packets to \nsend out. (There are other complications to this activity as well, but they are beyond \nthe scope of this text.) \nelm49810_ch14_297-328.indd   300\nelm49810_ch14_297-328.indd   300\n12/18/08   11:28:22 AM\n12/18/08   11:28:22 AM\n",
        "category": "Category"
    },
    {
        "id": "378",
        "title": "Title for Chunk 378",
        "content": "Confirming Pages\n \nChapter 14 Disk Scheduling and Input/Output Management \n301\n 14.3.2 Caching \n One of the most profound techniques in computer systems is caching. It is used \nboth in the hardware and in the software. Its purpose is to make a larger, slower, but \ncheaper memory appear to perform at the same speed as a smaller, faster, and there-\nfore more expensive memory. As was discussed in Chapter 2 and again in  Chapter 11, \ncaches work because processes do not actually access memory  randomly. Instead, \nthey operate according to the principle of locality of reference. This principle says \nthat a process is more likely to reference memory addresses that are near to those \nit has already referenced than it is to reference addresses that are not. For exam-\nple, most of the time a process runs instructions sequentially rather than branching \naround randomly. Subroutines are often called, but many instructions are typically \nneeded to set up the next subroutine call. Also, processes perform linear searches \nthrough sectors, arrays, strings, packets, and so on. The other aspect of the locality \nprinciple says that once a process has referenced a memory location it is more likely \nto reference it again than to reference another random location. Again, typically a \nprocess might work for some time to initialize a table, accessing many of the fields \nin the table.  \n 14.3.3 Blocking of small records \n One final general technique used in an I/O system is that of blocking. Blocking is \npacking several logical records into one physical block to write to a device. It is \nsomewhat similar to buffering between devices with different block sizes. Consider \na system that was originally designed to use punched cards but was converted to run \non magnetic tape. The record layouts are probably all very near to the 80-character \nsize of the punched cards. It is certainly possible to write 80-byte records to a tape \ndrive, but it is not very efficient. There is a gap between each tape record to allow for \nthe time it takes the drive to get the tape moving to the right speed and then to stop \nthe tape between records. This gap would hold many 80-character records and would \nthus waste much of the tape. By simply packing 10 records into a block and writing \nit to the tape in one operation, we save considerable space. A similar use of the term \n\u201cblocking\u201d is used on a disk file system where we will often allocate several  sectors \n(a) Process A is filling Buffer 1\nand Buffer 2 is waiting.\nBuffer 1\nBuffer 2\nProcess\nA\n(b) Process A is now filling Buffer 2\nand Buffer 1 is being written \nto the output device.\nBuffer 1\nBuffer 2\nProcess\nA\n FIGURE 14.1  \nDouble buffering.  \nelm49810_ch14_297-328.indd   301\nelm49810_ch14_297-328.indd   301\n12/18/08   11:28:22 AM\n12/18/08   11:28:22 AM\n",
        "category": "Category"
    },
    {
        "id": "379",
        "title": "Title for Chunk 379",
        "content": "Confirming Pages\n302 \nPart 4 A Depth-Oriented Presentation of OS Concepts: File Systems and Input/Output\nas a single block. This technique is used only because our file system  pointers were \nnot large enough to address all the sectors on some new large disk drive, so we \n allocated multiple sectors at a time. We will still normally read and write single sec-\ntors to the disk drive, however. \n 14.4 PHYSICAL DISK ORGANIZATION \n Before we discuss the software that controls the disk drives we will review the hard-\nware design so that we can see how the nature of the hardware dictates some of the \nsoftware design. \n 14.4.1 Sectors, Tracks, Cylinders, and Heads \n In Chapter 3 we showed a floppy disk in Figure 3.2. Hard disks are similar. In \n Figure 14.2  we show some additional concepts. Here we see two platters stacked \non a spindle so that they rotate together. Four arms reach out over the platters, each \ncontaining a magnetic read\u2013write head. The arms can move in and out. With the \narms stationary in any given position the platters will rotate so that a ring of a disk \nsurface will pass under the head. This ring is called a  track. The four arms are con-\nnected together so that they move in and out as a unit. This means that there will be \nfour tracks that the drive can read without moving the arms, one for each head and \nsurface. This group of tracks is called a  cylinder. Of course, if there are more platters \nLogical Cylinder\nTrack\nSector\nSpindle\nHead\nAssembly\nRead\u2013Write\nHead\nDisk Platter\nRotation\n FIGURE 14.2  \nA hard disk. \nelm49810_ch14_297-328.indd   302\nelm49810_ch14_297-328.indd   302\n12/18/08   11:28:22 AM\n12/18/08   11:28:22 AM\n",
        "category": "Category"
    },
    {
        "id": "380",
        "title": "Title for Chunk 380",
        "content": "Confirming Pages\n \nChapter 14 Disk Scheduling and Input/Output Management \n303\nand more heads there can be any number of tracks in a cylinder. A stack of 16 platters \nis about the maximum one will find in modern drives. \n A track is logically divided into  sectors. As we mentioned before, disk drives \nare block devices and will only transfer a complete unit of data rather than individual \ncharacters. The sectors are the smallest unit of data that a disk drive will transfer. In \nalmost all cases, for a given disk drive all the sectors on the drive will be the same \nsize. On most modern hard disk drives these sectors contain 512 bytes of data plus \nsome additional information. Other sector sizes are available, however, notably 256, \n1,024, or 2,048 bytes. Almost always the size is an even power of 2. CDs using the \nISO 9660 standard use 2,048-byte blocks. \n This arrangement of disk drive hardware leads to the concept of a disk address \nwhich could be specified by the cylinder, head and sector numbers, or  CHS address-\ning. A disk with C cylinders, H heads, and S sectors per track has C  \ufffd  H \ufffd  S sectors \nin all, and can normally store C \ufffd H \ufffd S \ufffd 512 bytes. For example, if the disk label \nsays C/H/S  \ufffd 4,092/16/63, then the disk has 4,092 \ufffd  16 \ufffd  63  \ufffd 4,124,736 sectors, \nand can hold 4,124,736 \ufffd  512  \ufffd 2,111,864,832 bytes (2.11 GB). \n 14.4.2 Sector count zones and sector addressing \n The number of bits that can be stored on a magnetic track is directly proportional to \nthe linear distance that passes under the head. A hard disk drive rotates at a constant \nspeed. The circumference of the outer tracks is longer than that of the inner tracks, \nso more information can be stored on the outer tracks than on the inner tracks. Older \ndisk drives used the same timing on all the tracks, so the bits on the outer tracks \nwere longer than those on the inner tracks. This was a waste of potential bits. The \nelectronics in the disk drives has gotten more sophisticated, and drives now include a \nseparate computer. As a result, most drives produced since the mid-1990s have used \na different technique for the timing called  zone bit recording ( ZBR ). They divide \nthe disk tracks into zones of tracks with a similar size and change the timing for the \ntracks in each zone. As a result, they place more sectors in the tracks in the outer \nzones and fewer sectors on the tracks in the inner zones. \n Since the number of sectors on a track was no longer constant for the whole \ndrive, the idea of addressing a sector with a CHS format no longer worked, so \n something had to change. But since some software was heavily oriented to the CHS \nconcept, it was desirable to try to keep as close to that format as possible. A CHS \ndisk address was 24 bits, divided as follows:\n cylinder number \n 0\u20131023  (10 bit) \n head number \n 0\u2013254 \n (8 bit) \n sector number \n 1\u201363 \n (6 bit) \n So the largest disk address that could be expressed with CHS addressing was \n8 GiB. In order to conform to the interface pattern of the older drives, newer drives \ncontinued to use the pattern of CHS addressing, and the OS was told that the drive \nhad some very large number of cylinders, heads, and sectors. The drive would take \nthose parameters and compute a  logical block address, or  LBA. This simply means \nthe sectors of a disk are sequentially numbered starting with zero and every sector is \nelm49810_ch14_297-328.indd   303\nelm49810_ch14_297-328.indd   303\n12/18/08   11:28:22 AM\n12/18/08   11:28:22 AM\n",
        "category": "Category"
    },
    {
        "id": "381",
        "title": "Title for Chunk 381",
        "content": "Confirming Pages\n304 \nPart 4 A Depth-Oriented Presentation of OS Concepts: File Systems and Input/Output\nidentified by its LBA number. The drive would then recompute the actual physical \naddress of the block desired based on the varying number of sectors in each zone. \nBIOS routines and drives were developed that allowed the OS to ignore the artificial \nCHS format and pass an LBA address directly. \n Eventually the drives got so large that the maximum LBA address that could be \nspecified was not large enough to address the entire disk drive. In order to accommo-\ndate these larger drives new address formats were specified that allowed either 28- or \n48-bit addresses to be used. This results in a disk size limit of 128 GiB or 128 PiB, \nrespectively, assuming the standard 512 bytes per sector. \n 14.4.3 Low-level formatting \n When disk drives are originally manufactured they contain no information what-\nsoever. The sectors that we want to access do not yet exist. A special writing mode \nmust be invoked to have the disk actually write the bytes on the disk that define \nthe location of the sectors. This mode is called  low-level formatting. Each sector \nwill contain a header that identifies the cylinder, head, and sector numbers of that \n sector. The sector will be blank and a checksum will be appended to the sector. \n(More  information about checksums in  Section 14.5.3 .) With older drive technolo-\ngies the user was expected to do this low-level formatting. Thankfully this is now \ndone by the manufacturers. \n 14.4.4 Speeds: Seek, transfer, and buffering \n One of the most important factors in OS performance is the hard drive  seek time. It \nis the time it takes the drive to move the head assembly from one track (or cylinder) \nto another. In most modern systems the CPU is idle much of the time, waiting on \nthe disk drive to transfer needed information. The biggest factor in the time taken \nto access the information is physically getting the read\u2013write head to the location \nof the sector. There are several possible ways to measure seek time. The measure \nwe are interested in is the average seek time, but for simplicity we will just refer \nto it as seek time since it has become an industry standard for specifying disk drive \nperformance. Leaving aside some early developments in the field, the seek time of \ndisk drives has changed very little. The rate of change is about  \ufffd 8% per year. This \nworks out to a drop of 50% over 10 years. For about the last 30 years this has been \nquite accurate. Today the average consumer drive has an average seek time of about \n6\u201312 milliseconds. The highest performance drives are about half that, ranging down \nto about 3 ms. \n A related factor is the rotational latency. Assume that we are looking for a par-\nticular sector and we seek to the right track. When the head assembly arrives at the \nright track it will stop. There are several sectors on a track and we are looking for a \nparticular one. (We might be going to transfer several sectors, but we will have speci-\nfied that the transfer starts at some particular sector number.) Most of the time the \nnext sector that will pass under the head will not be the one we are looking for. On \nthe average we will be in the wrong place by one-half the rotation time. This delay \nis referred to as  rotational latency. The rotational latency varies inversely with the \nelm49810_ch14_297-328.indd   304\nelm49810_ch14_297-328.indd   304\n12/18/08   11:28:23 AM\n12/18/08   11:28:23 AM\n",
        "category": "Category"
    },
    {
        "id": "382",
        "title": "Title for Chunk 382",
        "content": "Confirming Pages\n \nChapter 14 Disk Scheduling and Input/Output Management \n305\nrotation speed.  Table 14.2  shows the most common rotation speeds for disk drives \nand the associated average rotational latency. \n Until fairly recently the rotational delay was largely ignored since it was not \nvery easy for the OS to monitor the rotational position, and the seek time was so \nlarge that the rotational latency was not a big factor. Notice, however, that this delay \nis now about the same magnitude as the seek time. As a result, the rotational latency \nis beginning to be considered in disk scheduling algorithms. We have more to say \nabout this later in the chapter. \n 14.5 LOGICAL DISK ORGANIZATION \n An application program typically views secondary storage as a set of files filled \nwith records. At the lowest level the I/O system sees disk drives as masses of sec-\ntors. There needs to be some basic organization of the information on a disk drive so \nthat the I/O system can find the information it needs. Because personal computers \nare so widely available we describe the organization of a disk drive for a personal \ncomputer. Other platforms will use different organizations, but they will have similar \nelements. \n 14.5.1 Partitions \n When IBM released their first PC it did not even have an option for a hard disk\u2014\nfloppy disks were the only disk media. When the first hard disks were available they \nonly contained 10 MB or so. They used a file system organization called FAT12, \nwhich was discussed in the last chapter. In a fairly short time it was clear that this file \nsystem would not support the newer drives that were rapidly becoming available. We \npreviously discussed the idea of allocating multiple sectors at a time as one solution \nto this problem. Another simple solution was to allow a single disk drive to be divided \ninto multiple pieces and have each piece treated as a separate drive. Then the old file \n TABLE 14.2 Rotational Latency as a Function of Drive Rotation Speed \nSpindle Speed (RPM)\nAverage Rotational Latency (ms)\n3,600\n8.3\n4,200\n7.1\n4,500\n6.7\n4,900\n6.1\n5,200\n5.8\n5,400\n5.6\n7,200\n4.2\n10,000\n3.0\n12,000\n2.5\n15,000\n2.0\nelm49810_ch14_297-328.indd   305\nelm49810_ch14_297-328.indd   305\n12/18/08   11:28:23 AM\n12/18/08   11:28:23 AM\n",
        "category": "Category"
    },
    {
        "id": "383",
        "title": "Title for Chunk 383",
        "content": "Confirming Pages\n306 \nPart 4 A Depth-Oriented Presentation of OS Concepts: File Systems and Input/Output\nsystem could still be used. This solution is called  partitioning. 1 A utility program \ncalled  FDISK was provided with DOS that could be used to divide the disk into sepa-\nrate partitions. The original version of FDISK allowed a drive to be divided into only \nfour partitions and only one could contain a bootable OS. With Windows NT a new \nversion of FDISK was released that allows more partitions to be defined on a single \ndrive and allows multiple bootable (a.k.a. primary) partitions. This is a good step \nforward, but of course it is incompatible with older OSs that were created before this \nchange in format. Most modern OSs support this format of extended partition tables. \nFor some time most other OSs simply used the same utility program because it was \nnot used often and there was not much of a way to enhance the features. Today, most \nOSs provide their own partitioning utility program and many have a GUI interface. \n As it turns out, creating partitions is a useful technique for other things as well. \nFor one thing, it is a simple way of allowing a machine to contain two different oper-\nating systems and still allow each OS to assume it has sole control over the disk drive. \nIn  Figure 14.3 , we see a disk drive divided into four partitions containing three dif-\nferent OSs. In normal situations each partition will contain a file system. But another \nuse for partitions is for applications that are so specialized that they want to manage \ntheir own I/O rather than utilize the default file\u2013oriented I/O that the OS provides. \nAn example might be a database management system. Such systems are heavily \n optimized for the specific access patterns they expect to see and would not be nearly \nas efficient if they could only use the standard OS file I/O support. This API is known \nas raw I/O and it allows the application to treat the partition as an array of blocks that \ncan be accessed randomly rather than through the normal metaphor of a file. \n Eventually, new file systems were developed with larger pointers that could sup-\nport very large hard drives. Some applications required a larger file space than could \nbe covered with a single hard drive of the sizes that were available at the time. As a \nresult, the mechanisms of partitioning can be reversed, allowing two or more hard \ndrives to be combined with the partitioning mechanism and to appear to the upper \nlayers of the OS as a single drive.  Figure 14.4  shows a single partition spanning parts \nof two disk drives.  \n1 This technique did not originate with PC systems. It was earlier used on some mainframe systems for \nsome of the same reasons alluded to here. \nPartition 1\nWindows\nPartition 2\nLinux\nPartition 4\nRaw I/O\nPartition 3\nOS/2\n FIGURE 14.3  \nA disk drive \ncontaining several \nOSs in different \npartitions.  \nDisk\nDrive 1\nDisk\nDrive 2\nPartition 1 \ncontaining\nthe OS\nPartition 2 \ncontaining the\ndata files\n FIGURE 14.4 \n A single partition \nspanning parts \nof two disk drives.  \nelm49810_ch14_297-328.indd   306\nelm49810_ch14_297-328.indd   306\n12/18/08   11:28:23 AM\n12/18/08   11:28:23 AM\n",
        "category": "Category"
    },
    {
        "id": "384",
        "title": "Title for Chunk 384",
        "content": "Confirming Pages\n \nChapter 14 Disk Scheduling and Input/Output Management \n307\n 14.5.2 Boot block \n In Chapter 3 we discussed the concept of booting the system from a disk drive. When \na computer is reset it will normally try to bootstrap an OS from one or more of the \ndevices on the system. Most PCs contain a special memory that is powered by a bat-\ntery. It is commonly referred to as the  CMOS memory, or sometimes as the BIOS. \nSettings in this memory may specify a set of several different devices that the system \nis allowed to boot from, among other things. The system will try to boot from them in \nthe order specified. A given device may not work when the system tries to boot from \nthat device. For example, a floppy drive or a CD-ROM drive might not contain a disk. \nA hard drive might not have an OS installed on it yet. If the OS cannot boot from one \ndevice, then the next device is tried. If they all fail then a diagnostic error that no nor-\nmal user would understand is displayed on the video screen. If the OS finds a drive \nthat it can boot from, the bootstrap program in the hardware ROM will load the first \nsector from the device and begin executing the code that is contained there. \n The information about the partitioning of a hard disk is stored in a part of the \nfirst physical sector on the disk, regardless of how the partitioning is set up. This \n sector is called the  master boot record ( MBR ) or  boot block of the disk and it \ncontains the  partition table. It also contains a short program that looks in the parti-\ntion table, checks which partition is currently the  active partition, and reads the first \nsector of that partition. That partition\u2019s boot sector contains another small program \nthat reads the first part of the OS stored on that partition and starts executing it. The \nremainder of the bootstrap program will read in parts of the kernel and mount the \nroot of the directory structure that is found in that partition. \n After the OS bootstraps itself into memory it will mount the file system that \nit finds on the boot volume. The details of mounting the file system depend on the \nOS and the format of the partition that the OS was booted from. It may mount other \npartitions as well. \n 14.5.3 Error detection and correction \n When information is written to a hard disk unit, extra information is written with it. \nThis information is used for detecting errors and often for correcting them as well. \nThere are various schemes for creating and using this information. The schemes \nused depend on the type of errors expected in the drive, the amount of reliability \ndesired, and the intended relative price of the drive. The more elaborate techniques \nproduce a more reliable drive. At the same time, they require more complex calcu-\nlations and therefore they require a faster and more powerful processor in the disk \ndrive. In addition, the more complex techniques store more redundant information \non the disk, so they will hold less user data. Thus, for a given amount of user storage \nthey will require a larger drive. But error correction allows manufacturers to make \nfaster, higher-capacity drives that appear to the user to be error-free. The more the \ntechnology for storing data is pushed, the more sophisticated the error correction \nmechanisms need to be to reach the same level of reliability. \n A large body of research and development has been done on the calculation of \nthis redundant information, called  error detection codes ( EDC ) or  error  correction \nelm49810_ch14_297-328.indd   307\nelm49810_ch14_297-328.indd   307\n12/18/08   11:28:24 AM\n12/18/08   11:28:24 AM\n",
        "category": "Category"
    },
    {
        "id": "385",
        "title": "Title for Chunk 385",
        "content": "Confirming Pages\n308 \nPart 4 A Depth-Oriented Presentation of OS Concepts: File Systems and Input/Output\ncodes ( ECC ). The techniques all compute a small number that is a function of the \ncontents of the data block. The computation is made when the data is written to the \ndisk and the computed value is written along with the data. When the data is read \nback from the disk, the function is computed again and compared with the value \nstored during the write operation. If the two values do not agree, then an error was \nmade either on the read or on the write. (Errors on the read may reflect that the data \nhas been damaged since it was written.) \n The simplest error detection codes include a  cyclic redundancy check, or  CRC, \nalso sometimes called a  longitudinal redundancy check, or  LRC. In this case \nthe function calculated is expressed as a polynomial. For example, the  polynomial \nX 4  \ufffd X 2  \ufffd 1 would be 10101. The binary digits represent the multiplier of the expo-\nnents of the values of the polynomial. We could write X 4  \ufffd X 2  \ufffd 1 more exactly like \nthis: (1  \ufffd X 4 )  \ufffd (0 \ufffd X 3 )  \ufffd (1 \ufffd X 2 )  \ufffd (0 \ufffd  X 1 )  \ufffd (1  \ufffd  X 0 ). The calculation can \nbe thought of as dividing the data in the block by the binary number expressed by \nthe polynomial. After this division the remainder is the CRC. This type of calcula-\ntion is in widespread use in computing, especially in networking. Because the types \nof errors expected in networks are somewhat different than those expected in a disk \ndrive, the polynomials used are usually different. Several different commonly used \npolynomials are shown in  Table 14.3 . Sometimes errors are likely to occur in a num-\nber of bits in a row. Such situations are called  burst errors. A polynomial code can \ndetect any error burst of a length less than or equal to the length of that polynomial. \nThis type of calculation has been used for some time because a simple, fast hardware \nimplementation using shift registers was developed. \n CRC-12 is used for serial communication lines of 6-bit characters and generates \na 12-bit CRC. Both CRC-16 and CRC-CCITT are used for 8-bit serial communica-\ntion and result in a 16-bit CRC. The last two are widely used in the United States and \nEurope, respectively, and give adequate protection for most applications. CRC-CCITT \nis used in disk drives. CRC-32 generates a 32-bit CRC. The CRC-32 polynomial is \nused in IEEE-802 networks such as Ethernet, Token Ring, and wireless LANs. \n More complex calculations are used in more modern drives. These functions \ninclude Hamming and Reed-Solomon codes. They produce more redundant informa-\ntion than the various CRC functions. A typical drive might store 12 bytes of redun-\ndancy code with a 512-byte data block and be able to correct burst errors as long as \n22 bits. In particular, Reed-Solomon codes are used in CD-ROM drives where they \nstore 24 data bytes and 8 error correction bytes in a frame for error correction pur-\nposes. This higher level of redundancy is required since the media is easily damaged \nand the drives are often used when a system is in motion, such as a car CD player. \n TABLE 14.3 Several Commonly Used CRC Polynomials \n                   CRC-12:   \n  X 12  \ufffd X 11  \ufffd X 3  \ufffd X 2  \ufffd X  \ufffd 1 \n CRC-16: \n X 16  \ufffd X 15  \ufffd X 2  \ufffd 1 \n CRC-CCITT: \n X 16  \ufffd X 12  \ufffd X 5  \ufffd 1 \n CRC-32: \n X 32  \ufffd X 26  \ufffd X 23  \ufffd X 22  \ufffd X 16  \ufffd X 12  \ufffd X 11  \ufffd \nX 10  \ufffd X 8  \ufffd X 7  \ufffd X 5  \ufffd X 4  \ufffd X 2  \ufffd X  \ufffd 1 \nelm49810_ch14_297-328.indd   308\nelm49810_ch14_297-328.indd   308\n12/18/08   11:28:24 AM\n12/18/08   11:28:24 AM\n",
        "category": "Category"
    },
    {
        "id": "386",
        "title": "Title for Chunk 386",
        "content": "Confirming Pages\n \nChapter 14 Disk Scheduling and Input/Output Management \n309\n 14.6 RAID \n Modern hard drives are very reliable. We measure the reliability in terms of the  mean \ntime between failures, or  MTBF. However, we can improve on this reliability to \ngive even longer lifetimes by using multiple drives in special ways. The techniques \nwe describe in this section are called  redundant arrays of inexpensive disks or \n RAID. Some writers replace the term \u201cinexpensive\u201d with \u201cindependent,\u201d but the \nformer term is the one that was used when the term \u201cRAID\u201d was first coined by \nthe researchers who systematically investigated the use of multiple-drive arrays. The \noriginal purpose was to show that by combining inexpensive drives in clever ways \nthe reliability of much more expensive drives could be achieved with less money. \nBut these days even inexpensive drives are very reliable. However, an important \npoint in these techniques is that in order for them to work well, the failure modes \nof the drives must be independent. This means that the drives must be operating on \nseparate I/O channels and I/O controllers as well to achieve optimum reliability and \nperformance. If not, the techniques will still keep data from being lost, but the data \nmight be unavailable while a shared component is replaced. \n Support for RAID configurations is often done in the disc controllers.  However, \nRAID does not have to be done in a special controller. For some of the RAID \n configurations it is possible to control the RAID process with a software module in \nthe OS. Today, RAID 0 and 5 are commonly offered in software in most OSs. These \nconfigurations are explained in the next section. \n The original RAID specifications included six configurations. They are called \nRAID 0 through RAID 5. Most of these configurations will be more reliable than \nusing individual drives. Some of them also yield improved performance in some \nareas and worse performance in others. RAID 0 is the exception since it yields only \nimproved performance on reads. \n 14.6.1 RAID configurations \n The following figures show several RAID configurations. Each is intended to repre-\nsent a storage system that holds the same amount of user data. In each case the drives \nare all of the same size and we are showing how many drives it takes to yield four \ndrives\u2019 worth of storage with that configuration. The higher levels of the OS will \nsee each configuration as a single drive with four times the storage as the individual \ndrives of which it is made. There are three main techniques used in RAID. These are \nmirroring (copying data to more than one drive), striping (breaking files across more \nthan one drive), and error correction (redundant data is stored, allowing detection \nand possibly fixing of errors). Different RAID configurations use one or more of \nthese techniques. \n RAID 0 \u2014 Striped disk array without parity. This configuration utilizes  data \nstriping, spreading out blocks of each file across multiple disk drives, but no redun-\ndancy. The developers of the RAID technology used the term  strip rather than the \nterm  block, but in practice the implementations are always based on blocks. It \nimproves performance because multiple reads and multiple writes can be carried \nout in parallel. But it does not increase fault tolerance. In fact, this configuration \nelm49810_ch14_297-328.indd   309\nelm49810_ch14_297-328.indd   309\n12/18/08   11:28:24 AM\n12/18/08   11:28:24 AM\n",
        "category": "Category"
    },
    {
        "id": "387",
        "title": "Title for Chunk 387",
        "content": "Confirming Pages\n310 \nPart 4 A Depth-Oriented Presentation of OS Concepts: File Systems and Input/Output\nactually decreases reliability, since if one drive fails then all data in the array is lost \nbecause the OS is treating the array of drives as a single drive. Having  N drives spin-\nning means that the configuration is  N times as likely to fail. If the RAID support is \nbeing provided by the disk controllers, then the OS has no access to the remaining \ndrives at all. If the support is being done by the OS device driver software, then the \nremaining drives would theoretically still be accessible, but it is unlikely that any \nfiles would reside completely on the remaining drives. See  Figure 14.5 . The numbers \nin the drives show the logical block numbers (seen by the file system) as they are \nwritten to the drives. \n RAID 1 \u2014 Mirroring (a.k.a.  duplexing ). In RAID 1 there is a duplicate set of \ndisk drives. When any data is written to one drive it is also written to the duplicate \n(mirror) of that drive. See  Figure 14.6 . The shaded set of drives is the mirror set. \nAssuming that a primary drive and its mirror can be read at the same time, this con-\nfiguration provides twice the read transaction rate of single disks. It has no effect on \nthe write transaction rate because each individual block must be written to both the \nprimary and the secondary so the effect of any parallelism is lost. If one drive fails, \nthe data will be safe but the performance will be reduced when accessing that mirror \npair because only one drive will be available to service that request. This is the most \nexpensive RAID configuration. \n RAID 2 \u2014 Error-correcting coding and  RAID 3 \u2014 Bit-interleaved parity. \nThese two techniques turned out to be prohibitively expensive and inferior to other \ntechniques so we will not describe them here. For high performance they also required \nthat the spinning of the drives needed to be synchronized. They are not in use today. \n RAID 4 \u2014 Dedicated parity drive. This configuration provides block-level \nstriping (like Level 0) with a parity disk. The parity block that is written to this drive \n1\n9\n5\n13\n2\n10\n6\n14\n3\n11\n7\n15\n4\n12\n8\n16\n FIGURE 14.5  \nRAID 0\u2014Striped \ndisk array. \n1\n3\n2\n4\n41\n43\n42\n44\n81\n83\n82\n84\n121\n123\n122\n124\n1\n3\n2\n4\n41\n43\n42\n44\n81\n83\n82\n84\n121\n123\n122\n124\n FIGURE 14.6  RAID 1\u2014Disk mirroring.  \nelm49810_ch14_297-328.indd   310\nelm49810_ch14_297-328.indd   310\n12/18/08   11:28:24 AM\n12/18/08   11:28:24 AM\n",
        "category": "Category"
    },
    {
        "id": "388",
        "title": "Title for Chunk 388",
        "content": "Confirming Pages\n \nChapter 14 Disk Scheduling and Input/Output Management \n311\ncovers the other blocks in the stripe, in this case, blocks 1\u20134. See  Figure 14.7 . If a \ndata disk fails, the parity data is used to create a replacement disk. A disadvantage \nto RAID 4 is that every time a block is written the parity block must also be read, \nrecalculated, and rewritten. The parity disk therefore becomes an I/O bottleneck. It \nprovides almost the same reliability as RAID 1, but if a drive fails the performance \nhit will be much worse. However, the cost is a single extra drive, so it is much supe-\nrior in price if the configuration has several drives in it. \n RAID 5 \u2014 Block interleaved distributed parity. RAID 5 is very much like \nRAID 4, except that rather than keeping the parity block always on the same drive \nthe parity block is assigned to the drives in a round-robin fashion. See  Figure 14.8 . \nThis technique removes the problem of excessive use of the parity drive that we saw \nwith RAID 4. Level 5 is one of the most popular configurations of RAID. \n The following RAID configurations were not part of the original RAID speci-\nfication. These have been fairly widely accepted and can generally be regarded as \nstandard. \n RAID 6 \u2014 Independent data disks with double parity. Provides block-level \nstriping with parity data distributed across all disks as in RAID 5, but instead of a \nsimple parity scheme it computes parity using two different algorithms at the same \ntime. Several methods of calculations, including dual check data computations (  parity \nand Reed-Solomon), orthogonal dual parity check data, and diagonal  parity have \n1\n9\n5\n13\n2\n10\n6\n14\n3\n11\n7\n15\n4\n12\n8\n16\nParity 1\u20134\nParity 9\u201312\nParity 5\u20138\nParity 13\u201316\n FIGURE 14.7 \n RAID 4\u2014Dedicated \nparity drive.  \n1\n9\n5\n13\n2\n10\n6\nParity 13\u201316\n3\nParity 9\u201312\n7\n14\n4\n11\nParity 5\u20138\n15\nParity 1\u20134\n12\n8\n16\n FIGURE 14.8 \n RAID 5\u2014Block \ninterleaved \ndistributed parity. \nelm49810_ch14_297-328.indd   311\nelm49810_ch14_297-328.indd   311\n12/18/08   11:28:25 AM\n12/18/08   11:28:25 AM\n",
        "category": "Category"
    },
    {
        "id": "389",
        "title": "Title for Chunk 389",
        "content": "Confirming Pages\n312 \nPart 4 A Depth-Oriented Presentation of OS Concepts: File Systems and Input/Output\nbeen used to implement RAID 6 configurations. See  Figure 14.9 . The two  different \nparity blocks are shown as P&Q functions of the blocks (or strips) in the stripe and \nare shown in contrasting shades. RAID 6 requires an extra disk drive (over RAID 5) \nbut it will tolerate the loss of two drives at the same time. \n RAID 0 \ufffd 1 \u2014 Mirror of stripes. In this configuration two RAID 0 stripes are \ncreated, and a RAID 1 mirror is created over them. This is shown in  Figure 14.10 . \nThe striping provides improved performance and the mirroring provides reliability. \nGenerally, it will perform better than RAID 5. \n RAID 1 \ufffd 0 (a.k.a.  RAID 10 )\u2014 Stripe of mirrors. Multiple RAID 1 mirrored \ndrive pairs are created, and a RAID 0 stripe is created over these. See  Figure 14.11 . \nThis configuration has performance and reliability characteristics similar to RAID \n0 \ufffd 1. However, the performance and reliability is slightly better when a drive is lost. \nWith RAID 0 \ufffd 1 the loss of a drive means that the entire stripe set is lost, so the other \nstripe set will have to take on all the work. With RAID 1 \ufffd 0 only the drive that loses \n1\nA\nB\nC\nD\nE\nF\n9\n5\n13\nP (...)\n2\n10\n6\nP (13\u201316)\nQ (13\u201316)\n3\nP (9\u201312)\nQ (9\u201312)\n7\n4\nP (5\u20138)\nQ (5\u20138)\n14\nP (1\u20134)\n11\n15\n8\nQ (1\u20134)\n12\n16\nQ (...)\n FIGURE 14.9  RAID 6\u2014Independent data disks with double parity. \nStripe Set A\nMirrored\nStripe Set B\n13\n9\n5\n1\n14\n10\n6\n2\n15\n11\n7\n3\n16\n12\n8\n4\n13\n9\n5\n1\n14\n10\n6\n2\n15\n11\n7\n3\n16\n5\n6\n7\n8\n12\n8\n4\n1\n2\n3\n4\n FIGURE 14.10 \n RAID   0 \ufffd 1 \n\u2014A mirror of stripes.  \nelm49810_ch14_297-328.indd   312\nelm49810_ch14_297-328.indd   312\n12/18/08   11:28:25 AM\n12/18/08   11:28:25 AM\n",
        "category": "Category"
    },
    {
        "id": "390",
        "title": "Title for Chunk 390",
        "content": "Confirming Pages\n \nChapter 14 Disk Scheduling and Input/Output Management \n313\nits mirror pair will have to do all the work for that pair. The work on the other pairs \ncan be distributed across both drives as before.  \n 14.6.2 RAID failures \n We could build a RAID 0 \ufffd 1 configuration by using two controllers to build the stripe \nsets and using software at the device driver level to mirror the two stripe sets. In this case \nthe failure of a single drive would result in the loss of the entire stripe set, as described \nearlier. However, if the controllers running RAID 0 \ufffd 1 were aware of the entire con-\nfiguration, then when drive 3 failed it would continue striping to the other four drives in \n\u201cstripe set A,\u201d and if drive 6 later failed it would use drive 2 in its stead, since it should \nhave the same data. This would theoretically make RAID 0 \ufffd 1 just as fault-tolerant as \nRAID 1 \ufffd 0. Unfortunately, most controllers aren\u2019t designed this way. \n When a failed drive is replaced the system will have to rebuild the information \nthat was on the lost drive. In RAID 0 \ufffd 1, if drive 2 fails, the data on five hard disks \nwill need to be rebuilt, because the whole \u201cstripe set A\u201d will be wiped out. In RAID \n1 \ufffd 0, only drive 2 has to be rebuilt. Again here, the advantage is to RAID 1 \ufffd 0. \n There is also a plethora of other RAID configurations that are proprietary. They \ninclude many trademarked terms. They may or may not be of some benefit in a \nparticular situation. Analysis of test configurations and especially their behavior in \na variety of failure scenarios is a nontrivial matter but might be warranted in special \nsituations. \n When a single drive fails in RAID configurations more advanced than RAID 0, \nthe array can continue to run. Sometimes the performance is lower and sometimes \nwe simply have more exposure to risk. For example, loss of a drive in a RAID 1 \nconfiguration mostly means that we are now at some increased risk since failure of \nthe other drive in that pair would mean that we had lost all of that information. We \ncan continue to run with only one loss. We will notice some drop in performance in \nsome reads since we only have one drive to do the reads where we had two to share it \nbefore the loss of the drive. At other times we will probably have to shut the system \nStripe Set\nMirrored \nPair 1\nMirrored \nPair 2\nMirrored \nPair 3\nMirrored \nPair 4\n13\n9\n5\n1\n14\n10\n6\n2\n15\n11\n7\n3\n16\n12\n8\n4\n13\n9\n5\n1\n14\n10\n6\n2\n15\n11\n7\n3\n16\n12\n8\n4\n FIGURE 14.11  \nRAID   1 \ufffd 0 \n\u2014A stripe of mirrors.  \nelm49810_ch14_297-328.indd   313\nelm49810_ch14_297-328.indd   313\n12/18/08   11:28:25 AM\n12/18/08   11:28:25 AM\n",
        "category": "Category"
    },
    {
        "id": "391",
        "title": "Title for Chunk 391",
        "content": "Confirming Pages\n314 \nPart 4 A Depth-Oriented Presentation of OS Concepts: File Systems and Input/Output\ndown because the performance of the system would be unacceptable. For example, \nin RAID 6, if we lose a drive, the performance of a write will be very bad because we \nwill have to read all the other drives to be able to calculate the parity for the missing \ndrive. This would probably be only marginally acceptable. However, as soon as the \nbroken drive has been replaced we can begin the processes of rebuilding the infor-\nmation that was on the bad drive. \n This brings up a point that for RAID configurations we will want to use drives \nthat are \u201chot swappable.\u201d This means that the failed drive can be unplugged from \nthe system and a new drive plugged in without turning off the power on the system. \nWhile this technology is well understood, it does require special hardware that is \nmore expensive than normal drives. The decision will probably hinge on whether the \nrunning system is critical to some operation or whether it is only the existence of the \ndata that is critical. In the latter case we might prefer to take some system downtime \nrather than pay extra for the drives. \n In some cases the running system is a requirement. Systems in hospitals, for \nexample, may be critical to patient care and the loss of the system might mean the \nloss of life. In such cases we might choose to go a step further and have a spare drive \non the shelf ready to plug in if one of the drives fails. In extreme cases we may have \nthe drive in a  warm standby situation\u2014already plugged in to the drive rack but not \npowered on or at least not spinning. When the OS detects a failure it can turn on the \npower to the drive, spin it up, and begin the rebuild process. Of course, disk mirror-\ning is the extreme form of  hot standby. \n 14.7 DISK OPERATION SCHEDULING \n We mentioned earlier that seek time was one of the most critical measurements of \na disk drive as far as performance of the system is concerned. If we have a large \nnumber of disk operations to do, it turns out that the order in which we handle the \nrequests can have a significant impact on overall system performance. The perfor-\nmance of CPUs has been increasing by a rate of roughly 50% per year for at least \nthe last couple of decades. The performance of disk drives has only increased at a \nrate of about 10% per year during the same time. It is reasonable to assume that we \ncan spend some of that CPU speed to improve the performance of the disk systems. \nTo illustrate the point, let us assume that we have a series of disk requests to service. \nA seek operation on the disk drive moves all the heads together to some track or \n cylinder. So we will just look at track numbers, and realize that we are actually posi-\ntioning (potentially) many heads at the same time\u2014certainly at least two. Accord-\ningly, we will take a list of track numbers that have come to the I/O system from \nvarious processes that are running on the system. We will look at the seek time nec-\nessary to perform those requests and then see if we can improve on that. In all these \ncases we assume that the disk drive has 80 tracks, that the head is presently resting at \ntrack 28 and we have the following set of requests in a queue:\n 17, 30, 24, 37, 15, 27, 11, 75, 20, 5 \nelm49810_ch14_297-328.indd   314\nelm49810_ch14_297-328.indd   314\n12/18/08   11:28:25 AM\n12/18/08   11:28:25 AM\n",
        "category": "Category"
    },
    {
        "id": "392",
        "title": "Title for Chunk 392",
        "content": "Confirming Pages\n \nChapter 14 Disk Scheduling and Input/Output Management \n315\n 14.7.1 FCFS \n The simplest way to handle these requests would be to take them as they are in the \nqueue,  first in, first out, or  FIFO. (This is also often known as  first come, first \nserved, or  FCFS. ) This algorithm is appealing because it is simple to implement. \nIt also has the advantage that it is  fair. It is fair in the sense that the process that \nasked first gets served first. However, this does not necessarily give the best overall \n system performance. Moreover, it might not even give the best performance to a sin-\ngle application, as we will see later. In the case of the FCFS algorithm, the OS will \nmove the head from track to track in the order that the requests are in the queue. So \nit will move from 28 to 17, then to 30, then to 24, and so on. In processing this queue \nin this order the system will seek over 227 tracks. This is shown in  Figure 14.12 . \nSince we have no idea about the rotational latency involved, we will use the number \nof tracks that the system has to seek over to service the requests as our measure of \nhow efficient the algorithm is.  \n 14.7.2 Pickup \n A variation on FCFS that is mentioned by some authorities is called  pickup. In this \nalgorithm the requests are generally taken in order as with FCFS, but as the system \nis moving the head it will stop for any tracks that are being passed over that have a \nrequest in the queue. (In Linux this is called the  Noop scheduler.) For example, given \nthe requests in our sample, it would start at track 28 and begin moving toward 17, the \nfirst request in the queue. But on the way it would pick up tracks 27, 24, and 20. The \ntotal sequence would be:\n 27, 24, 20, 17, 30, 37, 15, 11, 75, 5 \n This sequence would result in a total seek time of 191 tracks, a considerable improve-\nment over FCFS.  Figure 14.13 charts the Pickup algorithm.  \nFIFO\n0\n10\n20\n30\n40\n50\n60\n70\n80\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n FIGURE 14.12 \n FIFO.  \nelm49810_ch14_297-328.indd   315\nelm49810_ch14_297-328.indd   315\n12/18/08   11:28:26 AM\n12/18/08   11:28:26 AM\n",
        "category": "Category"
    },
    {
        "id": "393",
        "title": "Title for Chunk 393",
        "content": "Confirming Pages\n316 \nPart 4 A Depth-Oriented Presentation of OS Concepts: File Systems and Input/Output\n 14.7.3 SSTF \n Next, we will look at an algorithm called  shortest seek time first, or  SSTF. (It is \nalso sometimes known as  shortest positioning time first, or  SPTF. ) When we used \nsimilar algorithms in other parts of an OS such as virtual memory page replacement \nor process scheduling we usually said that they were optimum, but that we could not \nreally use them because we could not predict the future. In the case of disk schedul-\ning, however, we can use this algorithm because all the requests we are concerned \nwith are there in the queue for us to look at. Again, we start with the head at track 28. \nThe nearest entry on the queue is 27, so we next move the head to that track. Now \nthe next nearest is back at 30, so we move there. As is shown in  Figure 14.14 , the \nsequence is\n 28, 27, 30, 24, 20, 37, 17, 15, 11, 5, 75 \nfor a total of 133 tracks. This is almost twice the performance of FCFS. However, \nit is not very fair. The first request in the queue, the one that has been waiting the \nlongest, is not serviced until the queue is about half empty. Also notice that the head \nPickup\n0\n10\n20\n30\n40\n50\n60\n70\n80\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n FIGURE 14.13  \nPickup.  \nSSTF\n0\n10\n20\n30\n40\n50\n60\n70\n80\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n FIGURE 14.14 \n SSTF.  \nelm49810_ch14_297-328.indd   316\nelm49810_ch14_297-328.indd   316\n12/18/08   11:28:26 AM\n12/18/08   11:28:26 AM\n",
        "category": "Category"
    },
    {
        "id": "394",
        "title": "Title for Chunk 394",
        "content": "Confirming Pages\n \nChapter 14 Disk Scheduling and Input/Output Management \n317\nkept passing back and forth across the middle of the disk. As a result, a process that \nwas accessing blocks that were located in the middle of the disk would tend to get \nbetter service than one that was accessing blocks located at either extreme on the \ndrive. Also, notice that while this algorithm is running, more requests will probably \nbe made of the OS and will get placed in the queue with the rest. Since processes in \nthe middle are getting favored, they will also get more opportunities to place addi-\ntional requests, compounding their advantage. This algorithm can be looked at as \ngiving priority to some requests\u2014notably those closest to the current head position. \nAs with any prioritization mechanism, we have to be concerned about starvation of \nthe lower priority requests. The outlying blocks can be gradually raised in priority \nso that they will be serviced sooner. This variant of SSTF is sometimes called  aged \nshortest seek time first, or  ASSTF. The algorithm simply adjusts the actual seek \ntime by subtracting a weighting factor times the time that the request has been in \nthe queue. If T eff is the effective (or weighted) seek time for a request, T  pos is the \nactual time the seek would require, W is a weighting factor we want to assign to old \nrequests, and T wait is the time the request has been in the queue, the aging formula \nwould be:\n \nT\nT\nW\nT\neff\npos\nwait\n\ufffd\n\ufffd\n\ufffd\n 14.7.4 LOOK \n The next algorithm we will study is commonly called  LOOK. Another popular name \nfor it is the \u201c elevator algorithm. \u201d In this algorithm, once the OS starts seeking in \none direction it will not reverse the direction it is seeking until there are no other \ntracks to access in that direction. In other words, the system \u201clooks\u201d ahead to decide \nwhen to reverse the seek direction. This is analogous to the way an elevator works. \nOnce it starts going up it will only go in that direction until it has no more requests \nin that direction. It will then reverse itself. (As with many analogies it is a bit weak, \nbecause an elevator also considers whether the request from a floor is to go up or \ndown and will not stop for users wanting to go up if it is going down. But an OS only \nneeds to position the head to the track. The seek request contains no notion of direc-\ntion of the seek.) Let us again look at our reference string. Let us also assume that \nthe OS starts seeking in the direction of the lower numbered tracks. In this case the \norder of the seeks would be\n 28, 27, 24, 20, 17, 15, 11, 5, 30, 37, 75 \nfor a total of 93 tracks. This is shown in  Figure 14.15 . \n If the OS had started in the direction of the higher numbered tracks the sequence \nwould be\n 28, 30, 37, 75, 27, 24, 20, 17, 15, 11, 5 \nfor a total of 117. This is shown in  Figure 14.16 . In either case it would be better \nthan FIFO or SSTF. However, for every time it moves toward either end it will pass \nover the middle of the disk both coming and going; it still tends to favor blocks in the \nmiddle of the disk, so it is less fair than FIFO but not as bad as SSTF. \nelm49810_ch14_297-328.indd   317\nelm49810_ch14_297-328.indd   317\n12/18/08   11:28:26 AM\n12/18/08   11:28:26 AM\n",
        "category": "Category"
    },
    {
        "id": "395",
        "title": "Title for Chunk 395",
        "content": "Confirming Pages\n318 \nPart 4 A Depth-Oriented Presentation of OS Concepts: File Systems and Input/Output\nLOOK starting down\n0\n10\n20\n30\n40\n50\n60\n70\n80\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n FIGURE 14.15 \n LOOK starting down.  \n FIGURE 14.16 \n LOOK starting up.  \nLOOK starting up\n0\n10\n20\n30\n40\n50\n60\n70\n80\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n Some authorities also discuss a separate algorithm called  SCAN. This algorithm \nis the same as LOOK, but instead of reversing direction when no more requests are \nin the queue in the direction that is currently being traveled, this algorithm would \nhave to move all the way to the end of the disk in the direction of the travel. Since \nnobody would actually implement this algorithm we will ignore it, mentioning it \nonly for completeness, since some of the other algorithms are called something \nrelated to SCAN. \n 14.7.5 C-LOOK \n In an effort to make a fairer algorithm, a variation on the LOOK algorithm was \ndevised. When the disk head has moved to the last track in one direction, instead \nof reversing direction and seeking to the nearest track, the OS will seek to the \ntrack that is the furthest in the queue in the opposite direction. It will then begin to \n perform the seeks moving back in the direction it was originally traveling before. \nThe objective is to remove the unfair advantage given to files in the middle of \nelm49810_ch14_297-328.indd   318\nelm49810_ch14_297-328.indd   318\n12/18/08   11:28:26 AM\n12/18/08   11:28:26 AM\n",
        "category": "Category"
    },
    {
        "id": "396",
        "title": "Title for Chunk 396",
        "content": "Confirming Pages\n \nChapter 14 Disk Scheduling and Input/Output Management \n319\nthe drive since on one pass over the middle the disk is not servicing any requests. \nThe name of this algorithm is  C-LOOK, short for  circular-LOOK  (some authori-\nties call this method  cylindrical-LOOK or  cyclic elevator ). The thought behind \nthe name is to consider the address space (track numbers) of the disk as being \nwrapped around a cylinder, so that after seeking to track 0, say, the next track to \nbe considered is track 80. Unfortunately, this algorithm results in a very long seek \nin the middle of servicing the queue. But this long seek is not quite as bad as it \nmight seem. Normally, we quote the average seek time when we talk about the seek \n performance of a disk drive. However, seek times do not increase linearly with the \ndistance of the seek. Just as with a moving object, the arm on a disk that holds the \nheads will start slowly and gradually get faster and faster. As a result, a seek across \nthe entire disk will not be double the average seek. It will be somewhat quicker \nthan that. Since it is not possible to predict this exactly, we will ignore it and simply \nmake the same sort of calculation that we have made before, stipulating that things \nwill not really be quite this bad. Again, the exact sum will depend on whether we \nstart in the direction of the lower numbered tracks or the higher numbered tracks. \nBecause of the long seek in the middle of the sequence, the difference between the \ntwo directions will not be as large a percentage as it was with LOOK. As seen in \n Figure 14.17 , the sequence is\n 28, 27, 24, 20, 17, 15, 11, 5, 75, 37, 30 \nfor a total of 138. In  Figure 14.18 , we see a sequence of\n 28, 30, 37, 75, 5, 11, 15, 17, 20, 24, 27 \nfor a total of 139. The attraction of C-LOOK is that it offers lower  service \n variability \u2014the performance of any given disk request is more predictable in gen-\neral and less dependent on file placement on the disk. C-LOOK is better than LOOK \nonly when the disk access level is a very high load since it reduces the starvation \nproblem. As with the SCAN algorithm mentioned above, some authors discuss a \nC-SCAN that also travels to the extremes of the disk before reversing directions.  \nC-LOOK starting down\n0\n10\n20\n30\n40\n50\n60\n70\n80\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n FIGURE 14.17 \n C-LOOK starting \ndown.  \nelm49810_ch14_297-328.indd   319\nelm49810_ch14_297-328.indd   319\n12/18/08   11:28:27 AM\n12/18/08   11:28:27 AM\n",
        "category": "Category"
    },
    {
        "id": "397",
        "title": "Title for Chunk 397",
        "content": "Confirming Pages\n320 \nPart 4 A Depth-Oriented Presentation of OS Concepts: File Systems and Input/Output\n 14.7.6 F-SCAN \n Another disk scheduling algorithm is commonly called  F-SCAN.  Despite the name, \nit is a variant on the LOOK algorithm. This mechanism uses two queues, say X and \nY. Queue X is started first and the system freezes request queue X when a scan is \nstarted. Any requests that come in while this scan is under way are put into queue \nY. After the scan with queue X is finished, queue Y is frozen and another scan is \nstarted with it, any incoming requests now going into queue X. This mechanism is a \ncompromise between the fairness of FCFS and the efficiency of LOOK without the \nexpensive long seek of C-LOOK. It thus avoids long periods of starvation. \n 14.7.7 N-step SCAN \n One last variation of the LOOK algorithm batches requests in groups of  N requests. \nOne batch is scanned before the next batch is processed. Like F-SCAN, N-Step \nSCAN prevents indefinite postponement (starvation). The other purpose of N-Step \nSCAN is to set an upper bound on how long a request can go without being serviced. \nIt is thus useful for very heavily loaded systems, and for systems with a large number \nof soft real-time applications. Note that the effect of N-Step SCAN is heavily depen-\ndent on the size of  N. If  N equals 1, then N-Step SCAN is effectively FCFS, and if \n N is large enough that almost all requests are serviced in the first scan, then N-Step \nSCAN is equivalent to LOOK. \n 14.7.8 Linux schedulers \n Linux has more scheduler variations available than most OSs. We look at three that it \ncurrently supports. They are variants of the sorts of algorithms we have been looking at. \n Anticipatory scheduler \n The  anticipatory scheduler was for a time the default scheduler in Linux. It merges \nrequests like the Pickup algorithm and uses a one-way elevator sequence like the \nLOOK algorithm. A unique feature is that it tries to anticipate reads by holding off a \nC-LOOK starting up\n0\n10\n20\n30\n40\n50\n60\n70\n80\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n FIGURE 14.18 \n C-LOOK starting up.  \nelm49810_ch14_297-328.indd   320\nelm49810_ch14_297-328.indd   320\n12/18/08   11:28:27 AM\n12/18/08   11:28:27 AM\n",
        "category": "Category"
    },
    {
        "id": "398",
        "title": "Title for Chunk 398",
        "content": "Confirming Pages\n \nChapter 14 Disk Scheduling and Input/Output Management \n321\nbit after a synchronous read command if it thinks a process might ask for more data \nnearby. If a new request comes in from the last process it may reverse the seek direc-\ntion if the distance is not too great. \n Deadline scheduler \n The  deadline scheduler also merges requests like the Pickup algorithm and uses a \none-way elevator sequence like the LOOK algorithm. It also imposes a deadline on \nall operations to prevent resource starvation. Linux returns immediately from a write \nrequest and holds the data to write in the cache. So the deadline scheduler will give \npriority to read requests as long as the deadline for a write request hasn\u2019t passed. \nThis is the preferred scheduler for database systems, especially if the disks are high-\nperformance drives. \n Complete fair queuing scheduler (\u201ccfq scheduler\u201d) \n The  complete fair queuing scheduler also merges requests like the Pickup algo-\nrithm and uses a one-way elevator sequence like the LOOK algorithm. In addition, it \ntries to give all processes using a particular device the same number of synchronous \nIO requests over a measured time interval. It is likely to be more efficient for mul-\ntiuser systems than are the other schedulers. It is currently the default scheduler for \nmost Linux distributions. \n 14.7.9 Sending commands to the controller \n Tagged queuing is a technique initially developed in the realm of SCSI disk drives. \nIt is sometimes called  command queuing or  native command queuing ( NCQ. ) \nIt basically delegates all or part of the task of disk operation scheduling to the disk \ncontroller. The device drivers for such drives pass all I/O requests directly to the \ndrive controller and the controller does all the scheduling of the I/O operations. \nThe theory is that the disk controller has a different level of information about the \ndisk geometry and the current status of the disk mechanism and can therefore do a \nbetter job of scheduling multiple disk requests. Such migration of functions closer \nto the hardware is a phenomenon we often see in the OS world. Once a technique \nproves useful in the OS we start thinking about putting the function into the hard-\nware where it can often be done more cheaply and sometimes better and frees up \nvaluable CPU and memory resources. In this case, the controller can do a better \njob because it is able to also consider rotational latency. When much of the work \nwas initially done on these disk scheduling algorithms the seek time was much \ngreater than the rotational latency. Improvements in the seek mechanism over the \nlast couple of decades have meant that the seek time is now about the same as the \nrotational latency. (See  Table 14.2 .) In general, the OS does not have that much \ninformation about the  rotational position of a drive. In addition, because of sector \nzoning and LBA addressing the disk driver may not even understand the real geom-\netry of the drive. The controller, however, has all that information and can therefore \nuse an algorithm that includes both rotational and seek time to arrive at an optimum \n schedule. In many situations a performance increase of 30% has been reported, but \nelm49810_ch14_297-328.indd   321\nelm49810_ch14_297-328.indd   321\n12/18/08   11:28:27 AM\n12/18/08   11:28:27 AM\n",
        "category": "Category"
    },
    {
        "id": "399",
        "title": "Title for Chunk 399",
        "content": "Confirming Pages\n322 \nPart 4 A Depth-Oriented Presentation of OS Concepts: File Systems and Input/Output\nthis depends highly on the details of the situation. Tagged queuing is implemented \nin most modern OSs. The technique is also now finding its way into the latest high-\nperformance ATA disk drives.  \n 14.7.10 Which algorithm is best? \n After all this discussion of disk scheduling algorithms it would seem reasonable to \nask which algorithm is the best. Unfortunately, the answer to that question is one \nfrequently heard in the computer business\u2014\u201cthat depends.\u201d In fact, there is no one \nalgorithm that is the best in all situations. FCFS is the simplest and consumes the \nleast resources. If a system is usually so lightly loaded that there are not multiple \ndisk requests in the queue, then all algorithms behave the same\u2014like FCFS. In this \ncase no other algorithm would be justified. \n However, many systems are moderately to heavily loaded, so we can\u2019t get away \nwith such an easy answer. In such cases FCFS will give high service variability \nand is thus generally the worst choice. The next question that needs to be asked, \nthen, is what parameter are we trying to optimize? In most cases we are trying to \noptimize disk throughput. However, we saw earlier that the optimum throughput \ncame at the expense of some unfairness to processes that were accessing files that \nwere not in optimum places. These requests would suffer either significantly delayed \nresponse time or a variance in response time that was unpredictable and therefore \nunacceptable. Users can stand a long response if the program can warn them, but \nhigh  variance in the response time makes it impossible for the program to adequately \nwarn the user. In most cases, then, some variation on the LOOK algorithm is prob-\nably the best. This assumes that your system does not contain new equipment that \ncan handle the scheduling itself. If such hardware is available, then it can almost \ncertainly do a better job than the OS can. \n 14.8 DMA AND DISK HARDWARE FEATURES \n There are several special hardware features of disk controllers that need to be dis-\ncussed as they will impact the design of OS device handlers. \n 14.8.1 DMA Controllers \n Originally I/O controllers were designed to transfer one byte or one word of data \nat a time. The CPU would load control information into the proper registers. This \ninformation would include the type of operation (read, write, or control), a memory \naddress, and possibly a device address. The CPU would then issue an I/O instruction. \nWhen the I/O operation was complete the controller would issue an interrupt and the \nCPU would set up for the next word or byte. This was acceptable for devices like \nkeyboards, modems, and even for the early text-only CRTs that were on very early \nPCs, because very many instructions could be executed by the CPU before the next \ninterrupt would occur. However, when devices began getting faster, the number and \ntiming of interrupts began to overwhelm the CPU. \nelm49810_ch14_297-328.indd   322\nelm49810_ch14_297-328.indd   322\n12/18/08   11:28:27 AM\n12/18/08   11:28:27 AM\n",
        "category": "Category"
    },
    {
        "id": "400",
        "title": "Title for Chunk 400",
        "content": "Confirming Pages\n \nChapter 14 Disk Scheduling and Input/Output Management \n323\n As a result, an innovation was made in the design of the I/O section of \n computers\u2014a  direct memory access controller, or  DMA. The main CPU will give \nthe DMA controller the same information it would have put into the registers before, \nplus it will add a length of the data to be transferred (in the case of a read or write). \nThe DMA controller will take on the job that the CPU was doing before, except that \nwhen the device controller has finished transferring one word it will notify the DMA \ncontroller rather than interrupt the CPU. As each byte (or word) is transferred to or \nfrom the memory the DMA controller will decrement the count of the data to be \ntransferred and increment the memory address to be used. When the count reaches \nzero the DMA controller knows it is finished and it will then interrupt the CPU. This \ntechnique greatly reduces the overhead of I/O on the CPU. Many modern controllers \nwill have a DMA circuit built-in to the controller rather than sharing one with other \ncontrollers. \n 14.8.2 Other disk drive features \n There are several other common features of modern disk drives that will have an \neffect on operating systems. The first is buffering in the disk drive. A common speci-\nfication for the small disk drive of today is that it contains 8 MiB of RAM. This ram \nis used as a cache memory. In this case it can also be called a  track buffer. The main \nlimiting factors on disk drive performance today is the combination of the seek time \nand the rotational latency. In our discussions of caching we always mention spatial \nlocality\u2014the idea that when a program references a piece of data it is highly likely \nthat it will soon reference data that is located near to the first data. If we were read-\ning a file sequentially and processing the blocks fairly quickly, then we might ask for \nsector 5 and begin processing it. We soon finish that sector and ask for sector 6. In \nthe meantime, however, sector 6 has already begun to pass under the head, and we \nwill have to wait for an entire rotation of the disk before we can read sector 6. Then \nthe same thing will happen on sector 7, and so on. \n So when we give a command to a modern disk drive to read a specific sector on \na track it will most often read the entire track into memory once the head is over the \ntrack. If sector 10 comes up next it will begin reading and will read the entire track \nuntil it wraps around and reads up to sector 9. It will then return the sector we had \nasked for and hold those others in the cache buffer as long as it can, knowing that it \nis probable we will ask for some of them soon. \n 14.8.3 Sector sparing and sector relocation \n Over time disk drives will start to fail. The process starts slowly, however, and may \nbe very gradual at first. Occasionally, a brand new disk drive will have a few bad \nsectors at the outset. In order to cope with these failures, disk drives are typically \nformatted with a few \u201cspare\u201d sectors scattered around\u2014perhaps one per track. These \nsectors are not originally part of the numbering scheme. Instead, they are held in \nreserve so that when a failure is detected the system can reassign them\u2014that is, data \nfrom the old sector will be copied to the spare sector, and its number will be changed \nto match the failed sector. The failed sector will get a number that will not be used. \nelm49810_ch14_297-328.indd   323\nelm49810_ch14_297-328.indd   323\n12/18/08   11:28:28 AM\n12/18/08   11:28:28 AM\n",
        "category": "Category"
    },
    {
        "id": "401",
        "title": "Title for Chunk 401",
        "content": "Confirming Pages\n324 \nPart 4 A Depth-Oriented Presentation of OS Concepts: File Systems and Input/Output\nIn some cases the drive hardware may perform this function. In other cases it is up to \nthe device driver software to do the recovery and relocation. \n 14.8.4 S.M.A.R.T. \n Sector sparing is a reactive technology. It addresses how we cope with failure when \nwe find it.  Self-monitoring and reporting technology, or  S.M.A.R.T., is a  predictive \ntechnology. It addresses how we might project a future failure and avoid it or  mitigate \nit. It is a standard interface through which a hard disk drive can report its status to \nthe host OS, and provide an estimation of a future failure date. With  sufficient notice, \na system or user can back up data prior to a drive\u2019s failure. S.M.A.R.T. is defined \nfor both ATA and SCSI environments. Originated by Compaq, it is under continuing \ndevelopment by disk drive manufacturers. \n S.M.A.R.T. technology includes a set of parameters specific for each model of \ndisk drives because drive architectures vary from model to model. Attributes and \nthresholds that detect failure for one model may not be useful for another model. \nA disk drive must be able to monitor many elements in order to have a thorough \nreliability management plan. One of the most crucial factors in such a plan is under-\nstanding failure modes. Failures can be divided into two classes: predictable and \nunpredictable. \n Unpredictable failures occur quickly, like electronic and mechanical problems, \nsuch as a power surge that can cause chip or circuit failure. Improvements in qual-\nity, design, process, and manufacturing can reduce the incidence of unpredictable \n failures. For example, the development of steel-belted radial tires reduced the num-\nber of blowouts common among older tire designs. \n Predictable failures are characterized by degradation of an attribute over time, \nbefore the disk drive fails. This creates a situation where attributes can be  monitored, \nmaking it possible for predictive failure analysis. Many mechanical failures are \n typically considered predictable, such as the degradation of head flying height, \nwhich would indicate a potential head crash. Certain electronic failures may show \ndegradation before failing, but more commonly, mechanical problems are gradual \nand predictable. For instance, oil level is a function, or attribute, of most cars that \ncan be monitored. When a car\u2019s diagnostic system senses that the oil is low, an oil \nlight comes on. The driver can stop the car and save the engine. In the same manner, \nS.M.A.R.T. gives the system administrators sufficient notice to start backup proce-\ndures and save the system data. Mechanical failures, which are generally predictable, \naccount for 60 percent of drive failures. This number shows a large opportunity for \nreliability prediction technology. With the S.M.A.R.T. system many future failures \ncan be predicted, and data loss avoided. \n 14.8.5 A look into the future \n Over the last two decades the performance of CPUs as measured in operations per \nsecond per dollar has increased by a factor of 100% per year. The cost of storing a \nmegabyte of data has dropped from $70 to $1 over the same span. In addition, the \ntransfer rate of disk drives has increased from one megabyte per second to over \nelm49810_ch14_297-328.indd   324\nelm49810_ch14_297-328.indd   324\n12/18/08   11:28:28 AM\n12/18/08   11:28:28 AM\n",
        "category": "Category"
    },
    {
        "id": "402",
        "title": "Title for Chunk 402",
        "content": "Confirming Pages\n \nChapter 14 Disk Scheduling and Input/Output Management \n325\n300 megabytes per second. However, the limiting factor in our utilization of disk \ndrives for secondary storage is the average seek time and the rotational latency. Each \nof these factors has only dropped about a factor of 10 in that same time frame. Fur-\nthermore, the rotational latency is limited by the speed of sound at the outer tracks \nand this will not change. This means that these two factors now totally dominate the \ntime it takes to randomly access any particular information on a hard drive. Having \ndrives that are still very slow in relation to CPUs has pushed the performance of \ncomputer systems way out of balance. \n On the OS side we have thrown large blocks of cache RAM at the disk drive \nin order to make the speed seem more like RAM. We also developed elaborate \n scheduling algorithms to optimize the performance of the head positioning mecha-\nnism. We are spending large amounts of our resources to manage these devices that \nare increasingly out of synch with the processors. \n Tape drives were once the normal secondary storage device on mainframe com-\nputers. By the 1970s they had vanished in that role and had been replaced by the disk \ndrive. Tapes were relegated to tertiary storage because of the low cost of the media. It \nis becoming increasingly clear that the same thing needs to happen to the disk drive. \nIt is not yet clear what that new class of devices will be, but we make a strong predic-\ntion that within the next 5\u201310 years we will see a new class of storage devices avail-\nable that will essentially have near random latency and costs below the disk drives \nof today. Two likely candidates are pure electronic memories and microelectrome-\nchanical systems ( MEMSs ).  Hybrid hard drives ( HHDs ) are already  available that \nincorporate flash memory as well as rotating media. Windows Vista can already uti-\nlize extra flash memory as a high-speed extension to the cache memory. Much of the \ntechnology of this chapter will become obsolete and we will have to rethink how we \nuse secondary storage. Perhaps we will do something more like the Palm OS does. \n 14.9 SUMMARY \n In this chapter, we introduced the topic of lower-\nlevel input and output management, with a special \nfocus on secondary storage and disk drives. Next, we \ndiscussed some broad classes of I/O devices and how \nthey differ. We described some general techniques \nused in support of I/O devices. We then explored the \nphysical structure of disk drives, and we discussed \nthe logical organization of the information stored \nthereon. We covered the topic of RAID, wherein \nassemblies of disks are used in special configurations \nto achieve greater throughput and/or reliability. The \nvery important topic of scheduling disk  operations for \noptimum performance was covered. We addressed a \nspecial type of device controller called a DMA con-\ntroller that can significantly decrease the CPU load \nof I/O operations. We also discussed some disk drive \nfeatures that affect OS behavior, drive reliability, and \nso on. \n BIBLIOGRAPHY \n Hofri, M., \u201cDisk Scheduling: FCFS vs. SSTF Revisited,\u201d \n Communications of the ACM, Vol. 23, No. 11, \npp. 645\u2013653. \n Iyer S., and P. Druschel, \u201cAnticipatory Scheduling: \nA Disk Scheduling Framework to Overcome \nDeceptive Idleness in Synchronous I/O,\u201d \nelm49810_ch14_297-328.indd   325\nelm49810_ch14_297-328.indd   325\n12/18/08   11:28:28 AM\n12/18/08   11:28:28 AM\n",
        "category": "Category"
    },
    {
        "id": "403",
        "title": "Title for Chunk 403",
        "content": "Rev. Confirming Pages\n326 \nPart 4 A Depth-Oriented Presentation of OS Concepts: File Systems and Input/Output\n WEB RESOURCES \n http://www.osdata.com (Operating System technical \ncomparison) \n http://www.pcworld.com/article/18693/how_it_works_\nhard_drives.html (hard disk characteristics and \narchitecture) \n http://www.littletechshoppe.com/ns1625/winchest.html \n(disk drive price per megabyte) \n http://www.answers.com/topic/hard-disk (disk transfer \nrates) \n http://en.wikipedia.org/wiki/RAID  \n REVIEW QUESTIONS \n 14.1 Distinguish between double buffering and caching \nas applied to disk systems. \n 14.2 True or false? The reason that disk scheduling \nalgorithms traditionally ignore rotational latency \nis that it is so small compared to the seek time. \n 14.3 Briefly define a cylinder. \n 14.4 Which of these disk drive organizations provides \nincreased performance but no redundancy?\n a. RAID 0 \n b. RAID 1 \n c. RAID 5 \n d. RAID 6 \n e. All of the above require the same number of \ndrives. \n 14.5 Which of these disk drive organizations pro-\nvided redundancy but at the highest cost in extra \ndrives?\n a. RAID 0 \n b. RAID 1 \n c. RAID 5 \n d. RAID 6 \n e. All of the above require the same number of \ndrives. \n 14.6 What is the advantage of RAID 6 over RAID 5?\n a. It is faster on a multiblock read. \n b. It is faster on a multiblock write. \n c. It can stand the loss of two drives at the same \ntime. \n d. It requires fewer extra drives. \n e. None of the above is an advantage of RAID 6 \nover RAID 5.  \n     14.7 True or false? The C-LOOK disk scheduling \nalgorithm gives about the same number of tracks \nseeked over regardless of whether the first direc-\ntion selected is up or down. \n     14.8 At the end of Chapter 14 we discussed several \nmechanisms that had been introduced to increase \nthe abilities of disk systems. Several were for \nperformance and some were for reliability. \nWhich of the following was  NOT for increased \nperformance?\n a. Tagged queuing (native command queuing) \n b. Disk (controller) hardware buffering \n c. Dynamic memory access \n d. Sector sparing \n e. All of the above were for increased performance.     \n     14.9 What does the acronym CHS refer to? \n 14.10 What does the first sector on a PC hard disk \ncontain? \n 14.11 If the FIFO algorithm is the fairest (by definition), \nwhy don\u2019t we just use that?  \n 14.12 Briefly describe the \u201cpickup\u201d disk scheduling \nalgorithm. \n 14.13 Why was the concept of partitioning drives \nintroduced? \n Symposium on Operating Systems Principle,  2001, \npp. 117\u2013130.  \n Love, R.,  Linux Kernel Development. Indianapolis, IN: \nSams Publishing, 2004. \n Patterson, D., G.A. Gibson, and R. Katz, \u201cA Case for \nRedundant Arrays of Inexpensive Disks (RAID),\u201d \n SIGMOD Conference, 1988, pp. 109\u2013116. \n Russinovich, M. E., and D. A. Solomon,  Microsoft \nWindows Internals, 4th ed., Redmond WA: Microsoft \nPress, 2005. \n Teorey, T. J., and T. B. Pinkerton, \u201cA Comparative \nAnalysis of Disk Scheduling Policies,\u201d  SIGOPS \nOperating Systems Review, Vol. 6, No. 1/2, 1972, \npp. 114\u2013121. \nelm49810_ch14_297-328.indd   326\nelm49810_ch14_297-328.indd   326\n12/22/08   1:09:51 PM\n12/22/08   1:09:51 PM\n",
        "category": "Category"
    },
    {
        "id": "404",
        "title": "Title for Chunk 404",
        "content": "Confirming Pages\n \nChapter 14 Disk Scheduling and Input/Output Management \n327\n 14.14 What is the function of a CRC or LRC on a disk \ndrive? \n 14.15 What is the function of a ECC on a disk drive? \n 14.16 How is the C-LOOK scheduling algorithm an \nimprovement over LOOK? \n 14.17 What is the main advantage of a DMA controller? \n 14.18 Some new disk drives support native command \nqueuing or tagged queuing. What is that and why \nis it an improvement? \n 14.19 Some new disk drives support so-called S.M.A.R.T. \nWhat is that about?  \nelm49810_ch14_297-328.indd   327\nelm49810_ch14_297-328.indd   327\n12/18/08   11:28:29 AM\n12/18/08   11:28:29 AM\n",
        "category": "Category"
    },
    {
        "id": "405",
        "title": "Title for Chunk 405",
        "content": "elm49810_ch14_297-328.indd   328\nelm49810_ch14_297-328.indd   328\n12/18/08   11:28:29 AM\n12/18/08   11:28:29 AM\n",
        "category": "Category"
    },
    {
        "id": "406",
        "title": "Title for Chunk 406",
        "content": "Confirming Pages\n329\nPart\nPart\nIn this part:\nChapter 15: Introduction to Computer Networks 331\nChapter 16: Protection and Security 359\nChapter 17: Distributed Operating Systems 385\nT\nhis part of the text deals with topics that are not found in all operating systems. \nOne infamous computer hardware system officer noted that \u201cthe network is \nthe computer.\u201d This is a strange statement, but it does point to the importance \nthat we today place on the connection of most of our computers to other computers \nin general and to the Internet in particular. So this part of the book deals with those \naspects of operating systems that deal with networking, distributed systems, and the \nissues of security and protection that arise in such instances.\nChapter 15 deals with the basics of computer networking. This topic by itself \nis the subject of many computer science textbooks and a very active research area, \nso this treatment is very brief. It takes a top-down approach and deals mostly with \nonly the hardware and protocols in use today. The Internet features heavily, of \ncourse. The topics covered include why we want to network computers, application \nlayer protocols, TCP/IP, the Data Link layer, WANs, the Physical layer, and network \nmanagement, including remote monitoring.\nSimple single-user systems that were not connected to one another by networks \noften did not need protection and security mechanisms. As a result, early OSs did \nnot provide many features in this area, if any. However, today we find that many \nmachines have multiple users, especially in homes, and most machines are connected \nto local area networks or the Internet or both. So security is today an important con-\nsideration, and Chapter 16 deals with it accordingly. The topics include authentica-\ntion, authorization, and encryption.\nAfter computers were networked we soon began to develop systems that include \nportions that ran on different computers, distributed systems. So this is the topic of \nChapter 17. Again, this is topic that fills many books and courses, and much current \nresearch is being done in this area, so the treatment is also brief, as in Chapter 16. \nSubtopics include communication, processes, naming, alternative distributed system \nparadigms, synchronization, and fault tolerance.\nNetworks, Distributed Systems, \nand Security\n5\nelm49810_ch15_329-358.indd   329\nelm49810_ch15_329-358.indd   329\n12/18/08   12:28:38 PM\n12/18/08   12:28:38 PM\n",
        "category": "Category"
    },
    {
        "id": "407",
        "title": "Title for Chunk 407",
        "content": "Confirming Pages\n330\nelm49810_ch15_329-358.indd   330\nelm49810_ch15_329-358.indd   330\n12/18/08   12:28:40 PM\n12/18/08   12:28:40 PM\n",
        "category": "Category"
    },
    {
        "id": "408",
        "title": "Title for Chunk 408",
        "content": "Confirming Pages\n445\n Chapter \n Chapter  19 \n 19 \n Linux: A Case Study  \nIn this chapter: \n 19.1 Introduction 446\n 19.2 Process Scheduling 447\n 19.3 Memory Management 451\n 19.4 File Support 452\n 19.5 Basic Input and Output 454\n 19.6 GUI Programming 458\n 19.7 Networking 460\n 19.8 Security 462\n 19.9 Symmetric Multiprocessing 463\n 19.10 Other Linux Variants 463\n 19.11 Summary  466\n I\nn Part 2 of the book we discussed some basic features of the Linux operating \nsystem and how a multiuser design placed some different requirements on an \nOS. In that chapter we also presented an overview of Linux and some back-\nground about its history and we discussed the general nature of a multiuser OS, the \nscheduling of processes and processes in Linux, and the nature of user logons and \nfile protection mechanisms. \n In this chapter, we present further information about Linux in a case study of \nOS and how it implements some of the standard features that we expect to see in any \nmodern OS. This chapter is intended to be studied with Chapter 6 so that material is \nnot repeated unnecessarily. We start this chapter with a brief review of Linux and its \nhistory.  Section 19.2  discusses the scheduling of processes in Linux and  Section 19.3  \ncontinues, discussing the memory management features necessitated by supporting \nmany users who are working at many different processes.  Section 19.4  covers the \norganization of files in the Linux OS. Linux supports many different file systems \nbecause of its unique evolutionary history.  Section 19.5 covers the basic I/O func-\ntions that Linux provides and  Section 19.6  describes support for GUI programming, \nwhich was derived from the design used in UNIX. In  Section 19.7  is a discussion of \nthe networking support in Linux, which, like the file systems, is complex because of \nthe history of Linux and the environments it must coexist in.  Section 19.8  deals with \nsome special security aspects of Linux and  Section 19.9  discusses a problem that \nelm49810_ch19_445-468.indd   445\nelm49810_ch19_445-468.indd   445\n12/10/08   9:39:57 PM\n12/10/08   9:39:57 PM\n",
        "category": "Category"
    },
    {
        "id": "409",
        "title": "Title for Chunk 409",
        "content": "Confirming Pages\n446 \nPart 6 Case Studies\narose with Linux support for multiple CPUs.  Section 19.10  covers hard real-time \nand embedded variants of the Linux OS. We conclude with a chapter summary in \n Section 19.11 . \n 19.1 INTRODUCTION \n 19.1.1 Linux history \n The Linux OS is largely oriented around UNIX, an older OS that supported multiple \nusers using terminals connected to a large computer. Today, there are versions of \nLinux that are used as the OS on a personal computer for a single user. These ver-\nsions still maintain the internal structure of a multiuser facility. Indeed, a single user \ncan run multiple virtual terminals and can switch between them as though there were \nseveral users on the system and can support concurrent sessions from users with \nremote connections. Other versions of Linux are intended to be used purely remotely \nas servers for various functions, to act as routers in networks, to control real-time \nsystems, and to be embedded in equipment with no human interface. As was pointed \nout in Chapter 6, Linux is released in production versions and development versions. \nThe features described in this chapter mostly relate to version 2.6. \n The history of Linux is shorter than many other OSs. Here is a short summary of \nthe more significant releases and features:\n \ufffd V. 1.0, March 1994 supported only single-processor i386 machines \n \ufffd V. 1.2, March 1995 added support for Alpha, SPARC, and MIPS CPUs \n \ufffd V. 2.0, June 1996 added support for more processors and SMP \n \ufffd V. 2.2, January 1999 \n \ufffd V. 2.4.0, January 2001\n \ufffd \nHewlett-Packard\u2019s PA-RISC processor \n \ufffd \nAxis Communications\u2019 ETRAX CRIS \n \ufffd \nISA Plug-and-Play, USB, PC Card, and Bluetooth \n \ufffd \nRAID devices \n \ufffd V. 2.6, December 17, 2003\n \ufffd \nuClinux (for machines with no paged MMU) \n \ufffd \n Hitachi\u2019s H8/300 series, NEC v850, Motorola\u2019s embedded m68k \nprocessors \n \ufffd \nIntel\u2019s hyperthreading and physical address extension (PAE) \n \ufffd \nMaximum number of users and groups (each) now 4,294,967,296 \n \ufffd \nMaximum number of process ids now 1,073,741,824 \n \ufffd \nFile systems of up to 16 terabytes \n \ufffd \nInfiniband support        \n 19.1.2 Kernel architecture \n The structure of the Linux kernel is monolithic. It is quite modular, however, allow-\ning individual subsystems to be replaced with experimental versions quite easily. \nThe relationships among the individual modules are complex. Indeed, there are few \nelm49810_ch19_445-468.indd   446\nelm49810_ch19_445-468.indd   446\n12/10/08   9:39:59 PM\n12/10/08   9:39:59 PM\n",
        "category": "Category"
    },
    {
        "id": "410",
        "title": "Title for Chunk 410",
        "content": "Confirming Pages\n \nChapter 19  Linux: A Case Study  \n447\nmodules that do not interact with most of the other major modules in some way. \n Figure 19.1  shows some of the major components and the most significant relation-\nships among the modules. In the remaining sections of this chapter we discuss the \noperation of some of the major system modules.  \n 19.2 PROCESS SCHEDULING \n The process scheduler module was redesigned in Linux 2.6. The motivation was to \ncreate a scheduler that used an algorithm that ran in O(1) time. The scheduler used \nin prior kernel releases was O(n) and performed poorly when the load was too high. \nThe Process Scheduler module (SCHED) is responsible for selecting which process \nshould have access to the CPU. Linux documentation often uses the term \u201ctask\u201d \ninstead of the term \u201cprocess,\u201d but for most purposes we can consider these to be the \nsame thing. Linux uses a priority-based scheduling algorithm to choose from among \nthe runnable processes in the system. (A runnable process is one that is waiting for \na CPU to run on.) \n There is a  runqueue made up of 140 lists, one for each priority. An example is \nshown in  Figure 19.2 . (In a multi-CPU system there will be similar structures for each \nCPU but we will ignore that for now.) The individual lists are each scanned in FIFO \norder. Processes that are scheduled to execute are added to the end of their respective \nrunqueue\u2019s priority list. Most processes have a time slice, or  quantum, that limits \nFIGURE 19.1 The Linux system architecture.\nA\np\np\nl\ni\nc\na\nt\ni\no\nn\nP\nr\no\ng\nr\na\nm\ns\nS\ny\ns\nt\ne\nm\nC\na\nl\nl\ns\nVirtual File\nSystem\nProtocols:\nIP, TCP, UDP\nNetwork\nManagement\nCharacter\nDevices\nBlock\nDevices\nProcess\nScheduler\nInterrupts\nMemory\nManager:\nkmalloc\nDevice\nModule\nFile Systems:\next3, ...\nInterprocess\nComm.\nProcess\nMemory\nmmap\ncache\nNFS\nProc and sysfs\nFile Systems\nKernel\nSockets\nVirtual\nMemory\nProcess\nControl\nNetwork\nDrivers\nCharacter\nDevices\nDisk\nDrivers\nMemory\naccess:\nPages, faults\nBus\nDrivers\nswap\nCPU\nRegisters\nNetwork\nCards\nMonitors,\netc.\nDisk\nControllers\nSCSI, ATA, ...\nMMU,\nRAM\nBus\nControllers\nPCI, USB, ...\nelm49810_ch19_445-468.indd   447\nelm49810_ch19_445-468.indd   447\n12/10/08   9:39:59 PM\n12/10/08   9:39:59 PM\n",
        "category": "Category"
    },
    {
        "id": "411",
        "title": "Title for Chunk 411",
        "content": "Confirming Pages\n448 \nPart 6 Case Studies\nthe time they are permitted to run. The time it takes the scheduling algorithm to find \na process to run thus depends not on the number of active processes but rather on the \nnumber of priority lists.  \n The runqueue we have been discussing is properly called the  active runqueue. \nIn addition to this queue there is also an  expired runqueue. When a process on the \nactive runqueue uses all of its time slice, it is moved to the expired runqueue. At the \nsame time its next time slice and its priority are recalculated. If there are no processes \non the active runqueue, the pointers for the active and expired runqueues are swapped, \nand the expired runqueue becomes the active one. At this point all the processes will \neffectively have a fresh time quantum. A scheduling  epoch  is the time between when \nall runnable processes begin with a fresh time quantum and when all runnable pro-\ncesses have used up their time and the queues need to be swapped. \n The scheduler always schedules the highest priority process on a system. If \nthere are multiple processes at the same priority they are scheduled in round-robin \nfashion. The runqueue structure not only makes finding the highest priority process \na constant-time operation, it also makes round-robin behavior within priority levels \npossible in constant-time. As well, having two runqueues makes transitions between \ntime slice epochs a constant-time operation. \n 19.2.1 Real-time processes \n The standard Linux scheduler provides soft real-time scheduling support, meaning \nthat while it does a good job of meeting scheduling deadlines, it does not guaran-\ntee that deadlines will be met. This scheduler uses two different scheduling classes \nto ensure that all processes will have fair access to the CPU, but still ensure that \n necessary hardware actions are performed by the kernel on time. Linux thus separates \nFIGURE 19.2 The active runqueue.\nQueue 139\nQueue 138\nQueue 137\nQueue 136\nQueue 8\nQueue 7\nQueue 6\nQueue 5\nQueue 4\nQueue 3\nQueue 2\nQueue 1\n100 Real-Time\nProcess Queues\n40 Normal\nProcess Queues\nQueue 0\nnull\n\u2192 task 137,0\nnull\n\u2192 task 139,0\n\u2192 task 0,0\nnull\n\u2192 task 2,0\nnull\nnull\n\u2192 task 5,0\nnull\nnull\nnull\n\u2192 task 137,1\n\u2192 task 139,1\n\u2192 task 2,1\n\u2192 task 5,1\n\u2192 task 137,2\ntask 2,2\n. . .\nelm49810_ch19_445-468.indd   448\nelm49810_ch19_445-468.indd   448\n12/10/08   9:39:59 PM\n12/10/08   9:39:59 PM\n",
        "category": "Category"
    },
    {
        "id": "412",
        "title": "Title for Chunk 412",
        "content": "Confirming Pages\n \nChapter 19  Linux: A Case Study  \n449\nprocesses into two classes: normal and real time. The first 100 priority lists of the \nrunqueue are reserved for real-time processes, and the last 40 are used for user pro-\ncesses. Since real-time processes have lower priorities than non-real-time processes, \nthey will always run before non-real-time processes. (This might be somewhat con-\nfusing because a \u201clower\u201d priority number has a \u201chigher\u201d priority in the sense that it \nwill be run first, but that is the way Linux documentation describes it.) As long as \nreal-time processes are runnable, no normal processes will run. Real-time processes \nare scheduled with two scheduling schemes, namely  FIFO (or SCHED_FIFO) and \n round robin (or SCHED_RR.) A process that needs to run as a real-time process \nwill make a system call to tell the OS which of these schedulers to use. If it does not \nmake such a call, then it is a  normal process, as discussed in the next section. \n FIFO processes are scheduled in a first-in first-out manner. If there is a FIFO \nprocess ready to run on a system it will preempt any other higher priority processes \nand run for as long as it needs to run since FIFO processes do not have time lim-\nits. Multiple FIFO processes are scheduled by priority and lower priority FIFO pro-\ncesses will preempt higher priority processes. RR processes are identical to FIFO \nprocesses except that they have time quantum limits and are always preempted by a \nFIFO process. Within a given priority level, SCHED_RR processes are scheduled in \na round-robin fashion. Each SCHED_RR process runs for its allotted time quantum \nand then goes to the end of the list in its runqueue. \n 19.2.2 Normal processes \n Non-real-time processes are marked SCHED_NORMAL (previously known as \nSCHED_OTHER)\u2014the default scheduling behavior. To prevent a process from \nholding the CPU and starving other processes that also need CPU access, the sched-\nuler can dynamically alter a process\u2019s priority. It does so by raising the priority num-\nber (and thus lowering the priority) of processes that are CPU-bound and lowering \nthe number of processes that are I/O-bound. I/O-bound processes commonly use the \nCPU to set up an I/O and then wait for the completion of the I/O. While a process \nwaits on I/O, other processes get access to the CPU. Processes that communicate \nwith the user are generally doing lots of I/O and therefore are given preference over \nnoninteractive processes, resulting in better interactive responsiveness. \n The priority of I/O-bound processes is decreased by a maximum of five prior-\nity levels. CPU-bound processes have their priority increased by up to five levels. \nProcesses are determined to be I/O-bound or CPU-bound based on an interactivity \nheuristic. The  interactiveness of a process is calculated based on how much time the \nprocess executes compared to how much time it sleeps. Computing is much faster \nthan typical I/O operations. Since I/O-bound processes call for an I/O operation and \nthen wait for it to complete, an I/O-bound process spends more time waiting than \ncomputing, increasing its interactiveness. \n 19.2.3 Nice \n Sometimes it is desirable to run a program with a priority other than the normal \ndefault. For example, a program might be providing a background function that is \na lower priority than an interactive user function. Conversely, a process might be \nelm49810_ch19_445-468.indd   449\nelm49810_ch19_445-468.indd   449\n12/10/08   9:40:00 PM\n12/10/08   9:40:00 PM\n",
        "category": "Category"
    },
    {
        "id": "413",
        "title": "Title for Chunk 413",
        "content": "Confirming Pages\n450 \nPart 6 Case Studies\nrunning that needs a higher priority than normal. There are two ways that a program \npriority can be changed. First, a user can run a program with a priority other than \nnormal using the  nice command, and second, a program can issue a system call to \nchange its priority while it is running. The original concept of the nice command was \nthat a user could voluntarily run a command with a higher priority number (and thus \na lower priority). Such a command would look like this: \n nice [-n increment]... [Command [Arg]...]  \n -n increment  increment must be in the range 1\u201319. If not specified, an increment \nof 10 is assumed. An increment greater than 19 is set to 19. A user \nwith administrative privileges may run commands with priority \nhigher than normal by using a negative increment such as  \ufffd 10.  \n command \n The name of a command that is to be invoked. \n argument \n A string to be used as an argument when invoking the command. \n Alternatively, a process can alter its own priority by calling an OS function such as \n sched_setparam. This is a POSIX function. There are other OS calls that may also \nbe used. In the following example, sched_setparam sets the scheduling parameters \nassociated with the scheduling policy for the process identified by  pid. The inter-\npretation of the parameter  p depends on the selected policy. As discussed above, \nthe following three scheduling policies are supported under Linux:  SCHED_FIFO, \n SCHED_RR, and  SCHED_NORMAL. \n #include <sched.h>\nint sched_setparam (pid_t pid, const struct sched_param *p);\nstruct sched_ param {\n    ...\n    int\n    ...\n};  \n 19.2.4 SMP load balancing \n Since release 2.0 Linux has supported symmetric multiprocessing ( SMP ). We \nmentioned that when a system has multiple CPUs there will be multiple active \nr unqueues\u2014one per CPU. When processes are created in an SMP system, they\u2019re \nplaced on the runqueue for some CPU. Some processes will be short and others \nmight run for a long time and the OS has no way in advance to know which is which. \nTherefore, it is impossible to initially allocate processes across multiple CPUs in \na balanced fashion. To maintain a balanced workload across CPUs, work can be \nmoved from an overloaded CPU to a less loaded one. The Linux scheduler does such \nload balancing. Every 200 milliseconds, the OS checks to see whether the CPU loads \nare unbalanced. If so, it tries to balance the loads. One negative aspect of moving a \nprocess to another CPU is that the caches in the new CPU do not hold any informa-\ntion for the process. This makes the effective memory access time go way up tempo-\nrarily, but lightening the load on the busier CPUs makes up for the problem. \nelm49810_ch19_445-468.indd   450\nelm49810_ch19_445-468.indd   450\n12/10/08   9:40:00 PM\n12/10/08   9:40:00 PM\n",
        "category": "Category"
    },
    {
        "id": "414",
        "title": "Title for Chunk 414",
        "content": "Confirming Pages\n \nChapter 19  Linux: A Case Study  \n451\n 19.3 MEMORY MANAGEMENT \n The  memory manager (MM) permits multiple processes to share securely the \nmachine\u2019s main memory system. In addition, the memory manager supports virtual \nmemory that allows Linux to support processes that use more memory than is avail-\nable in the system. Unused memory is swapped out to persistent storage using the \nfile system and swapped back in if it is needed again later. \n Linux was designed from the outset to be independent of the hardware it is run-\nning on. This brings up several interesting points about the sizes of various internal \ndata structures in the OS. The first problem that Linux must cope with is the fact that \nthe basic word size of the machine may be different on different CPUs that Linux \nmight be running on. Other details may also vary\u2014the memory page size, how the \nmemory management hardware works, and so on. Linux deals with these problems \nby being very modular and very configurable. Although Linux is a monolithic ker-\nnel OS rather than a micro-kernel OS, it is still very modular, and it is reasonably \nstraightforward to replace one module, such as the memory manager, with a different \none. Such module replacement may happen, for example, in an effort to use a new \nmechanism that is developed when research has shown that a mechanism that is \ncurrently used is not using the most efficient methods. It can also happen when the \nimplementation of that replacement turns out to have been rushed and actually leads \nto worse performance than the previous release. In Linux 2.2, for example, the page \nreplacement algorithm that had replaced the algorithms used earlier turned out to be \nflawed. While it worked in the general cases, there were some situations where the \nperformance was very bad. So in release 2.4, parts of the earlier mechanism were \nreintroduced. The 2.6 version introduced the O(1) scheduler described earlier. \n The memory manager in the modern Linux kernels is a full virtual memory man-\nager with demand paging. We discussed this technique thoroughly in Chapter 11 so \nwe will not repeat that here. Linux uses a two-level page table on x86 processors and a \nthree-level table on 64-bit processors. In theory, paging eliminates the need for contig-\nuous memory allocation, but some operations like DMA ignore paging circuitry and \naccess the address bus directly while transferring data. To allow for this problem Linux \nimplements a mechanism for allocating contiguous page frames called the  buddy sys-\ntem algorithm. Pages are kept in one of 10 lists of blocks that contain 1, 2, 4, 8, 16, \n32, 64, 128, 256, or 512 contiguous frames, respectively. When asked for a contiguous \nblock the memory manager looks in the list for the right size or larger, dividing the \nblock if necessary. When a block is released, the manager iteratively tries to merge \ntogether pairs of free blocks into larger blocks. Linux keeps a separate set of buddy \nlists for addresses that are in low memory and thus suitable for DMA operations. \n Linux has a separate mechanism for dealing with requests for small memory areas \ncalled the  slab allocator. Rather than allocate all storage requests randomly from a sin-\ngle heap, it views memory as collections of similar objects such as process descriptors. \nThe slab allocator allocates similar objects from a block called a slab, which holds only \nobjects of a single type. Initializing many of these objects takes more time than reallo-\ncating one, so when an object is released it is cached for later reuse as the same type of \nobject. The slab mechanism is not limited to system-defined objects. Applications can \ncreate their own slab lists and have the memory manager manage them in the same way. \nelm49810_ch19_445-468.indd   451\nelm49810_ch19_445-468.indd   451\n12/10/08   9:40:00 PM\n12/10/08   9:40:00 PM\n",
        "category": "Category"
    },
    {
        "id": "415",
        "title": "Title for Chunk 415",
        "content": "Confirming Pages\n452 \nPart 6 Case Studies\n The modular design of Linux allows for using different memory managers in differ-\nent versions or distributions. So, for example, a distribution intended for only a real-time \nversion of Linux would probably have to avoid a virtual memory architecture because it \nwould not have deterministic performance. Similarly, a Linux-based system embedded \nin a PDA or a microwave that did not have secondary storage could use a memory man-\nager more appropriate for those environments. In Chapter 20 we describe a very clever \nuse of paging hardware in the Symbian OS that shows such a memory manager.  \n 19.4 FILE SUPPORT \n One decision every OS designer must make is the physical and logical layout of the \nfile system on secondary storage\u2014usually disks. Several alternative file system lay-\nouts may be used and the differences can have dramatic effects on the performance \nof the OS. The modular nature of Linux shows again in the area of file support. \n 19.4.1 Standard file systems \n As was previously mentioned, the original version of Linux was developed on a \nMINIX system. Not surprisingly, the file system that was used in that initial Linux \nversion was designed around the physical and logical layout of the MINIX file sys-\ntem. Even today, the MINIX file system layout is still supported by Linux. Because \nvarious developers of Linux have had different uses as goals for their version of \nLinux OS, many other file system layouts, including MS-DOS, OS/2, CDs, and \nDVDs, as well as other (non-Linux) UNIX versions, are supported. Something of \na standard file system does exist for Linux for hard disks, however,  ext2fs. Much \nLinux system documentation discusses the \u201cLinux file system\u201d as though it were the \nonly one currently used. One of the complications caused by open source projects is \nthat developers are free to create whatever variations they like to the operating sys-\ntem. This is often good in that it encourages experimentation and creativity. It can, \nhowever, be a problem in that it can complicate choices for beginners. Some argue \nthat from the viewpoint of the larger Linux user community, scarce resources might \nbe more profitably spent if they were focused on only a few file systems.  Table 19.1  \nshows some of the other Linux file systems that have been created.\n 19.4.2 The virtual file system \n The idea of having many different, yet coexisting, file systems is not new with Linux. \nUNIX was developed in a fashion similar to Linux, in the sense that many universities \ntook the source and \u201cimproved\u201d it to fit some specific local need. One common change \nwas to design a new file system for UNIX to work with an existing file system from \nsome legacy OS. For example, see the HPFS in  Table 19.1 . In order to cope with this \nmultiplicity of file systems, UNIX introduced the concept of the  virtual file system, or \n VFS. The virtual file system was an additional layer in the OS between the kernel system \ncalls and the file systems, and it is invisible to application programs. See  Figure 19.3 . \nThe API for this layer is identical to the API for standard UNIX file systems. When a file \nis opened through the VFS layer, it looks to see what file system was on the device being \nreferenced and passes the request to the appropriate file system driver for that device. \nelm49810_ch19_445-468.indd   452\nelm49810_ch19_445-468.indd   452\n12/10/08   9:40:00 PM\n12/10/08   9:40:00 PM\n",
        "category": "Category"
    },
    {
        "id": "416",
        "title": "Title for Chunk 416",
        "content": "Confirming Pages\n \nChapter 19  Linux: A Case Study  \n453\nNeither the driver nor the application program is aware of the additional layer. In other \noperating systems this concept is sometimes called a file  redirector.  \n This simple mechanism has fostered many developments that might have been \notherwise difficult. For example, when CD-ROM devices were introduced, the \nindustry was able to standardize on a single data file format (music CDs follow a \nTABLE 19.1 Other Linux File Systems\nEXT\nExtended File System (replaced MINIX)\nEXT2\nSecond Extended File System \nEXT3\nThird Extended File System\nXFS\nSilicon Graphics [IRIX] Journaling File System\nHFS\nMacintosh Hierarchical File System\nEFS\nSilicon Graphics [IRIX] Extent File System\nVxFS\nVeritas File System\nUFS\nEarly BSD UNIX File System\nBSD FFS\nBSD UNIX File System\nAIX\nIBM RS/6000 UNIX\nJFS\nIBM\u2019s Journaling File System \nHPFS\nOS/2 High-Performance File System\nBeFS\nBeOS File System\nQNX4 FS\nQNX4 [OS] File System \nAFFS\nAmiga Fast File System\nFAT16\nMS-DOS File System\nFAT32\nWindows File System\nReiserFS\nBalanced Trees (under development)\nXia\nNew MINIX File System\nFIGURE 19.3 \nThe Linux virtual file \nsystem (VFS).\nFile\nSystem\nA\nFile\nSystem\nB\nFile\nSystem\nC\nVirtual File\nSystem\nFile\nSystem\nD\nApprication\nPrograms\nRemote Server (NFS)\nPartition\n2\nPartition\n1\nelm49810_ch19_445-468.indd   453\nelm49810_ch19_445-468.indd   453\n12/10/08   9:40:01 PM\n12/10/08   9:40:01 PM\n",
        "category": "Category"
    },
    {
        "id": "417",
        "title": "Title for Chunk 417",
        "content": "Confirming Pages\n454 \nPart 6 Case Studies\ndifferent, older format). In part, this was because UNIX (and other OSs as well) were \nable to support a different file system format on these devices than on hard disks or \nfloppies. This has been a great benefit to the industry and to the user community. \nImagine if every OS had its own format for CDs! You don\u2019t really have to think very \nhard to imagine it\u2014it would be much like the floppy disk industry used to be. You \nhad to buy floppy disks formatted for the OS you were going to use, disks could be \nhard or soft sectored, with various densities (number of sectors that would fit on a \ntrack). At least in the floppy disk case, when MS-DOS became popular, it\u2019s format \nwas so ubiquitous that every OS was obliged to somehow cope with that format, so \nthe situation was not as bad as it might have otherwise been. Sun Microsystems was \nable to use this mechanism to introduce a \u201cfile system\u201d that was actually a network \nprotocol that accessed files that were not on a local disk; rather, they were resident \nacross a network. The remote nature of this mechanism was totally transparent to \napplication programs, but naive use of this feature sometimes could seriously impact \nperformance. This file system is called the  network file system, or  NFS. \n 19.4.3 The /proc file system \n Linux (and some variations of UNIX) also makes use of the file system interface in \na very creative way. The  proc file system is not really a physical file system in that it \ndoesn\u2019t refer to files on a disk. It is sometimes called a virtual or  pseudo file system \nand is referred to as being nonpersistent. It responds to most of the same system calls \nthat any other file system does, but instead of accessing a storage device it returns \ninformation about variables in the OS kernel. The root file system is accessed with \nstandard I/O calls, so that one merely opens a proc entry (in the proc subdirectory) \nand reads its contents. The information that is returned does not actually exist, in \nthat format, in the kernel (though some parts might), but is instead created on-the-fly \nwhen the read operation is performed. These records include information about the \nprocesses running on the system as well as information about other modules such as \nnetworking, memory management, and so forth. The proc file system even appears to \nusers to have directories in it. For example, there is a /proc/net directory that includes \nall information about the network modules. Other directories correspond to the pro-\ncesses running on the system. These directories sometimes contain subdirectories \ncorresponding to subfunctions of a particular module. For example, the /proc/net \ndirectory contains subdirectories for the arp table and for parameters and counters for \nthe TCP and IP networking protocols. Note that the proc file system supports writing \nas well as reading, so that data in the kernel can be carefully changed. Normally this \nmeans that only a user with  root (supervisor) privileges can write to this file system. \n 19.5 BASIC INPUT AND OUTPUT \n 19.5.1 The /dev table \n Observable in a Linux system is a separate \u201cfile system\u201d similar to the /proc file \nsystem called the /dev \u201cfile system.\u201d Most devices on a Linux system have a corre-\nsponding \u201cfile\u201d in /dev, network devices being the exception. The files in /dev each \nelm49810_ch19_445-468.indd   454\nelm49810_ch19_445-468.indd   454\n12/10/08   9:40:01 PM\n12/10/08   9:40:01 PM\n",
        "category": "Category"
    },
    {
        "id": "418",
        "title": "Title for Chunk 418",
        "content": "Confirming Pages\n \nChapter 19  Linux: A Case Study  \n455\nhave a major and minor device number associated with them. The kernel uses these \nnumbers to map references from a device file to the appropriate driver. \n The major device number identifies the driver with which the file is associ-\nated (in other words, the type of device). These numbers are assigned by the Linux \nAssigned Names And Numbers Authority (LANANA). The minor device number \nusually identifies which particular instance of a given device type is to be addressed. \nFor example, with hard disks there may be different types of hard disks, SCSI and \nSATA, and there may be two SATA disks, differentiated by minor device number. \nThe minor device number is sometimes called the unit number. \n You can see the major and minor number of a device file by entering the follow-\ning command in a Linux shell: \n ls -l /dev/sda\nbrw-rw---- 1 root  disk   8,  0 Mar 3 2007 /dev/sda  \n This example shows the first SCSI disk on a Linux system. It has a major num-\nber of 8 and a minor number of 0. The minor device number is sometimes used by \nthe driver to select the particular characteristic of a device. For example, one tape \ndrive can have several different files in /dev representing various configurations of \nrecording density and rewind characteristics. In essence, the driver can use the minor \ndevice number in any way that it wants. \n Note that here the \u201cls\u201d command, which normally is used to list files in a direc-\ntory, is being used to show device characteristics just the same as if it were an actual, \nphysical file. \n 19.5.2 Device classes \n As do most OSs, Linux broadly divides devices into three classes\u2014block, character, \nand networking\u2014and treats each of those classes differently.  Figure 19.4  shows a \ndiagram of some of the kernel I/O modules and the relationships between them. \n Block devices \n For Linux the access to block mode devices is usually through the file system, even \nfor tape storage. Linux also supports raw I/O directly to devices. \n Character devices \n Character mode devices transfer data a single byte at a time and include printers, \nkeyboards, mice (and other pointing devices), and so on. A program can use the  ioctl \nsystem call to access most character mode devices. \n Network devices \n Network devices do not fit the semantics of files since applications waiting for input \nnever know when they might arrive. As a result, network devices have an entirely \ndifferent set of interfaces than do other devices. \n Network devices do not show up in the /dev table since their operations are so dif-\nferent. Instead, they have a generic network interface that conforms, most often, to the \nelm49810_ch19_445-468.indd   455\nelm49810_ch19_445-468.indd   455\n12/10/08   9:40:01 PM\n12/10/08   9:40:01 PM\n",
        "category": "Category"
    },
    {
        "id": "419",
        "title": "Title for Chunk 419",
        "content": "Confirming Pages\n456 \nPart 6 Case Studies\nTCP/IP (or UDP) protocol stack model, and are most frequently accessed with a pro-\ngramming model called a  socket. This model is an API that lets an application make a \nnetwork connection to another application, presumably but not necessarily on a differ-\nent system, and to send and receive either a stream of data or a series of blocks of data \nbetween the two applications. This model has layers for the data link, network, and \ntransport control services. Most classes of device drivers keep various usage statistics \nabout their operation (including errors) so that the system administrator can optimize \nperformance of the system. Network drivers are more aggressive than most other driv-\ners, and typically keep many different types of statistics, including error counters and \nnumber of packets sent and received. The network modules have a generic network \ninterface with common operations for connecting, sending, receiving, timeout han-\ndling, statistic collection, and routing. Since the origins of UNIX are tightly connected \nto utilization of TCP/IP, it is not surprising to learn that the Linux drivers are optimized \nfor TCP/IP support. Once again, however, the open nature of Linux and the diverse \nneeds of Linux supporters have resulted in the adaptation of many other network pro-\ntocols for Linux. Here are some of the many other protocols available for Linux:\n \ufffd Network protocols (software protocols)\n \ufffd \nIP version 6 - the Internet and Internet 2 \n \ufffd \nIPX/SPX - Novell \n \ufffd \nAppleTalk Protocol Suite - Apple \n \ufffd \nNetBEUI - IBM and Microsoft \n \ufffd \nNetBIOS - IBM and Microsoft \n \ufffd \nCIFS - Microsoft \n \ufffd \nSNA - IBM \n \ufffd \nAPPC - IBM \n \ufffd \nDECNet - Digital Equipment Corporation \nFIGURE 19.4 \nThe Linux I/O \nsystems.\nApplication\nPrograms\nFile\nSystems\nDevice\nControl\nSockets\nFile\nSystem\nX\nNetwork\nProtocols\nBlock\nDevice\nDriver\nNetwork\nInterface\nKernel\nCharacter\nDevice\nDrivers\nRemote Server\nNFS, Samba\nelm49810_ch19_445-468.indd   456\nelm49810_ch19_445-468.indd   456\n12/10/08   9:40:02 PM\n12/10/08   9:40:02 PM\n",
        "category": "Category"
    },
    {
        "id": "420",
        "title": "Title for Chunk 420",
        "content": "Confirming Pages\n \nChapter 19  Linux: A Case Study  \n457\n \ufffd Physical protocols (hardware protocols or router and switch interfaces)\n \ufffd \nISDN - Integrated Services Digital Network \n \ufffd \nPPP - Point-to-Point Protocol \n \ufffd \nSLIP - Serial Line Interface Protocol \n \ufffd \nPLIP - Parallel Line Internet Protocol \n \ufffd \nAmateur Radio - AX25 \n \ufffd \nATM - Asynchronous Transfer Mode \n \ufffd \nARCNet - Datapoint Corp., among others \n \ufffd \nFDDI - Fiber Distributed Data Interface \n \ufffd \nFrame Relay \n \ufffd \nToken Ring - IBM \n \ufffd \nX.25 - Slow, asynchronous \n \ufffd \n802.11 - wireless LAN \n \ufffd \nBluetooth - wireless \n In keeping with its UNIX orientation, Linux gives strong support to the sockets and \ndatagram mechanisms. They were included in the 1.0 release in 1994. This mecha-\nnism was introduced to the UNIX world with BSD 4.3 UNIX. The network inter-\nfaces and mechanisms were discussed more in Chapter 15. \n Disk scheduling \n In Chapter 14 we discussed the many options that OSs have for scheduling opera-\ntions on disk drives, for example, when to move to the next track and which track to \nmove to. One of the strengths of Linux that has been emphasized in this chapter is \nits modularity. This modularity allows replacement of individual modules in Linux \nwith a different implementation that is more appropriate for a particular situation. \nThe scheduling of disk operations is a good example. While the default scheduler \nis generally fair and performs quite well, the overall performance of any particular \nsystem depends greatly on the type of processing that is being done. Web servers, \nfor example, place very different demands on a system than does a database server. \nAccordingly, several different disk schedulers are available to fit certain situations \nbetter than others. Historically the default disk request scheduler in Linux has been \nC-LOOK. It treats the disk like a cylinder, starting at one end of the drive and pro-\ncessing operations in order as it goes. When it reaches the end of the queue of opera-\ntions it moves the head all the way back to the other end without processing any \nrequests and begins processing the operations that piled up after the head had passed \nthem by on the last scan. Later releases of Linux have begun to incorporate more \nadvanced scheduling algorithms. \n The recent history of disk schedulers in Linux demonstrates how having a replace-\nable module was used to great advantage. As was mentioned, the disk scheduler in \nLinux was basically a C-LOOK scheduler that merely merged requests in the direction \nof the seek. It was noted that this sometimes caused very poor performance of requests \nthat were very far away from the bulk of the other requests. In order to improve the \nperformance of such requests the scheduler was modified such that each new request \nwas given a deadline. If the deadline for a request drew near, then it would be serviced \nimmediately. This algorithm gave better performance in certain situations. \nelm49810_ch19_445-468.indd   457\nelm49810_ch19_445-468.indd   457\n12/10/08   9:40:02 PM\n12/10/08   9:40:02 PM\n",
        "category": "Category"
    },
    {
        "id": "421",
        "title": "Title for Chunk 421",
        "content": "Confirming Pages\n458 \nPart 6 Case Studies\n Unfortunately, applications that do a lot of reading tend to use synchronous I/O. \nTypically they read a block, process it a bit, and issue a read for the next block. While \nthe processing was going on, the head was moved to another part of the drive and the \nnext block could not be read until much later. In order to improve the performance of \nsuch applications, a new  anticipatory  scheduler  was introduced in Version 2.6. This \nscheduler is basically C-LOOK, but when performing a read, this scheduler would \ndelay moving the head away from the block read for a short time (a few milliseconds) \non the theory that the application might shortly issue a new read for the next block. \nIt performed well in some cases such as compilation, but was miserable in others, \nprimarily interactive tasks. This poor performance was caused by not keeping the \nseeking mechanism busy all the time. \n So yet another scheduler was released. It is known as complete fair queuing \nscheduler, or  CFQ scheduler. CFQ places synchronous requests into separate queues \nfor each process and allocates time slices for each of the queues to access the disk. \nThe length of the time slice and the number of requests a queue is allowed to sub-\nmit depends on an I/O priority assigned to the process. Asynchronous requests are \nbatched together into separate queues for each priority. CFQ does not do anticipatory \nIO scheduling, but it gives good throughput for the system as a whole by allowing a \nprocess queue to idle at the end of synchronous I/O, thereby \u201canticipating\u201d further \nclose I/O from that process. The CFQ scheduler was released as part of the 2.6.18 \nkernel. It is the default scheduler in kernel releases. \n Since no scheduler is optimum for all circumstances, there are presently four \nschedulers available for Linux:\n \ufffd Noop Scheduler \n \ufffd Anticipatory IO Scheduler (\u201cas scheduler\u201d) \n \ufffd Deadline Scheduler \n \ufffd Complete Fair Queuing Scheduler (\u201ccfq scheduler\u201d) \n One can change schedulers by setting the kernel option \u2018elevator\u2019 at boot time. You \ncan set it to one of \u201cas,\u201d \u201ccfq,\u201d \u201cdeadline,\u201d or \u201cnoop.\u201d In addition, some of the sched-\nulers have parameters that can be tuned at runtime. \n 19.6 GUI PROGRAMMING \n When UNIX was created, very little computing work was done in a graphics mode. \nInstead, many users connected to the computer with a terminal that was basically a \ntypewriter (or Teletype), a printer with a keyboard built in. When CRT terminals came \ninto use they normally displayed text only, much like the printer terminals then being \nused. Terminals that supported graphics might cost as much as the computer that they \nwere connected to. As a result, UNIX kernels do not assume that the user interface \nis a graphical user interface (GUI). Instead, if a GUI is desired, it must be provided \nas a facility apart from the OS kernel. The  X-Window system was created to pro-\nvide a mechanism to display graphics in UNIX. The X-Window system is a platform-\nindependent, client/server-based protocol for displaying graphics. A block diagram of \nthe components of the X-Window system is seen in  Figure 19.5 . The naming of the \nelm49810_ch19_445-468.indd   458\nelm49810_ch19_445-468.indd   458\n12/10/08   9:40:02 PM\n12/10/08   9:40:02 PM\n",
        "category": "Category"
    },
    {
        "id": "422",
        "title": "Title for Chunk 422",
        "content": "Confirming Pages\n \nChapter 19  Linux: A Case Study  \n459\ncomponents can be somewhat confusing today\u2014the system where the graphics are \nviewed is called an X-Window server and the system where the graphics are generated \nis called an X-Window client. Both the server and the client can be running on the same \nmachine as they often are in a Linux PC environment, or they can be different systems \non opposite sides of the world, connected through a network.  \n The X-Window (or  X11 ) protocol requires a third component to actually display \nwindows, menus, boxes, and scroll bars, which may be drawn however the manager \ndetermines. This component is called a  window manager. The window manager \ndetermines the way the interface looks and how the user interacts with it\u2014the so- \ncalled  look-and-feel. Running an X-Window server and window manager on a single \nmachine provides a familiar GUI. There are currently two very popular window man-\nagers in the Linux world\u2014the  Kool Desktop Environment ( KDE ) and  GNU Net-\nwork Object Model Environment ( GNOME ). Both of these window managers are \nfound in most Linux distributions, and occasionally they include other managers that \nare not as popular. Since Linux applications most often use the X-Windows API to \ndraw on the system, programs that work with any one manager usually work correctly \nwith any other windows manager as well. However, dialog boxes, menus, scroll bars, \nand moving between windows may appear differently to the user. So, for example, \nthe Apple Mac OS version X is built on a UNIX kernel but the window manager \nlooks and works like the prior releases of the Mac OS. A drawback to having the win-\ndow manager as an external component is that there may be multiple, different GUI \ninterfaces, so books and training materials will need to be customized for each. While \nthis might not matter so much to an individual, it is a problem for institutions of all \nkinds who have to support many users who may choose different managers. \n With UNIX this is not a problem confined only to GUI interfaces. Traditionally, \nUNIX commands are given to the OS by typing them on a line in a textual command \ninterpreter, or shell. The UNIX text-oriented shell is a separate external module, just \nas are the GUIs. In the case of UNIX there were quite a few of them. See  Table 19.2 .\n Different shells were sometimes only slightly different from one another, but \nsome were very different in the way that they could be programmed, assist in helping \nusers complete commands, and keeping and repeating command histories, among \nFIGURE 19.5 \nX-Windows.\nKeyboard\nDisplay\nX-Application\nX-Toolkit\nX-Intrinsics\nX-Server\nX-Protocol\nMouse\nDevice-Dependent\nModule\nXLib\nX-Protocol\n[LAN]\nelm49810_ch19_445-468.indd   459\nelm49810_ch19_445-468.indd   459\n12/10/08   9:40:02 PM\n12/10/08   9:40:02 PM\n",
        "category": "Category"
    },
    {
        "id": "423",
        "title": "Title for Chunk 423",
        "content": "Confirming Pages\n460 \nPart 6 Case Studies\nother things. These differences made choosing a shell a very personal decision. It \nalso made the life of help desk personnel more complicated and limited the ability of \none user to help another. \n 19.7 NETWORKING \n The  network interface (NET) module of the OS provides access to several network-\ning standards and a variety of network hardware. \n 19.7.1 Network layering \n The networking model used in the Linux OS is based on the standard TCP/IP model. \nSince the physical interface is implemented by the network interface card (NIC), Linux \ngenerally ignores the Physical layer, so the model only shows three service layers and \nthe Application layer. See  Figure 19.6 . The three service layers were also shown in \n Figure 19.2 . Often OS developers create each network protocol layer in total isolation. \nThe result is often that high overhead is caused by excessive copying of messages from \nlayer to layer as the successive layers add headers and sometimes trailers to the mes-\nsage. Linux avoids this problem by allocating the space for a message in a buffer called \na socket buffer, or  skbuff. An skbuff contains pointers to locations in a contiguous block \nof memory that stores the whole packet. When data is passed from one layer to a lower \nlayer, the header of the lower layer is added to the data, and likewise, the header of the \nlower layer is stripped off when data is passed from a lower layer to an upper layer. \nWhen an skbuff is allocated, Linux will calculate the amount of memory including the \nmaximum length of the headers of various layers needed by the packet. The initial mes-\nsage is put into the middle of the buffer, leaving room for the headers from lower layers. \nTABLE 19.2 Popular UNIX and Linux Shells\nShell\nComments\nKSH\nLinux version of Korn shell\nTCSH\nTurbo C shell\nBASH\nBourne Again shell\nCSH\nLinux version of C shell\nASH\nZSH\nAdvanced command-line editing\u2014not for scripting\nBourne\nEnhanced original shell\nKorn\nOriginated with AT&T and System V\nC\nUC Berkeley\nSH\nThe original UNIX shell\nrc\nPlan 9 from Bell Labs\nes\nRC-like syntax with Scheme semantics\neshell\nEmacs\nCLISP\nCommonLisp\nelm49810_ch19_445-468.indd   460\nelm49810_ch19_445-468.indd   460\n12/10/08   9:40:03 PM\n12/10/08   9:40:03 PM\n",
        "category": "Category"
    },
    {
        "id": "424",
        "title": "Title for Chunk 424",
        "content": "Confirming Pages\n \nChapter 19  Linux: A Case Study  \n461\nSo when a packet is passed between layers the only need is to set the pointers that indi-\ncate the new location of the start of the header or trailer of the corresponding skbuff.  \n 19.7.2 Connection super-server \n Linux uses a super-server called  inetd, which listens on many ports used by common \nIP services such as HTTP, POP3, and Telnet. When an IP packet arrives on one of \nthese port numbers, inetd launches a selected server program. For services that are \nnot used frequently this mechanism uses memory more efficiently, as the specific \nservers run only when needed. Also, no network code is required in the applications, \nsince inetd connects the sockets directly to the stdin, stdout, and stderr functions of \nthe server process. For protocols that have more frequent use, a dedicated server that \nhandles the server requests directly would be used instead. \n 19.7.3 SAMBA \n Since Linux presently exists in a world dominated by Microsoft OS software, a great \ndeal of effort goes into making Linux systems work well with Microsoft products. \nWe briefly touched on file systems that support present and past Microsoft file sys-\ntem formats. We also mentioned a few networking protocols that Linux offers sup-\nport for. But one server package dominates in the networking area\u2014Samba. \n Samba is a server that implements many Microsoft services and protocols, \nincluding SMB (Server Message Block), CIFS (Common Internet File System), \nDCE/RPC (Distributed Computing Environment/Remote Procedure Calls), MSRPC, \na WINS server (a NetBIOS Name Server, NBNS), NetBIOS over TCP/IP (NBT), the \nNetwork Neighborhood protocols, the NT Domain protocols including NT Domain \nLogons, a Secure Accounts Manager (SAM) database, Local Security Authority \n4 - Application\n3 - Transport\n2 - Network\n1 - Device\nFIGURE 19.6 \nThe Linux Network \nlayer model.\nelm49810_ch19_445-468.indd   461\nelm49810_ch19_445-468.indd   461\n12/10/08   9:40:04 PM\n12/10/08   9:40:04 PM\n",
        "category": "Category"
    },
    {
        "id": "425",
        "title": "Title for Chunk 425",
        "content": "Confirming Pages\n462 \nPart 6 Case Studies\n(LSA) service, NT-style printing service (SPOOLSS), NTLM, and Active Directory \nLogon using Kerberos and LDAP. Samba also uses these protocols to see and share \nlocal resources including printers. \n Samba sets up network shares for chosen Linux directories (including subdirec-\ntories). These appear to Microsoft Windows users just as folders. Linux users can \neither mount the shares or can access the files with a utility program that acts like an \nFTP program. Each directory can have different access privileges aside from normal \nLinux file protections. Samba is also available on most other UNIX-variant systems.    \n 19.8 SECURITY \n 19.8.1 The Linux security module \n The Linux community has been divided on the issue of security. The crux of the \ndivision has to do with the fact that the security community is itself divided about \nhow security should be implemented. A primary consideration with security is that \nsupporting high levels of security involve substantial resources, obviously including \nhardware such as memory and CPU utilization but also administrative and user time \nto set it up and use it correctly. If high levels of security are not needed in a particular \ninstallation, then those resources should not have to be spent. The solution in Linux \nhas been the inclusion of a module called the  Linux security module, or  LSM. It \nconsists of a set of hooks that a specific security implementation can attach itself to \nin order to perform authorization checks when objects are accessed. \n There are several different security systems that have been designed to run under \nLinux using the LSM hooks. The most well known is  Security-Enhanced Linux \n( SELinux ), which provides a secure access control mechanism based on the trust (clear-\nance) level of the individual requesting access. Others include  AppArmor ( Application \nArmor ),  Linux Intrusion Detection System,  BSD Secure Levels, and  Commercial \nIP Security Option (CIPSO). As of release 2.6 of Linux, none of these modules had \nprevailed over the others, so the LSM approach continues to be supported.  \n 19.8.2 Networking security \n Because the source code for Linux is freely available it is often used as the OS of \nchoice both for security analysts and hackers. As a result, there are many tools for \nboth hacking and security protection available for Linux. \n Port scanners are software packages that try to determine what services are \nrunning on a target machine. Generally they will try to make a connection to each \npossible port on the machine. Based on the results of this attempt a hacker may be \nable to tell if the machine is vulnerable to a known exploit. Port scanners can be set \nto attack a single machine, a group of machines, or all machines on a network. There \nare many software packages that do port scanning.  Nmap,  SATAN,  ISS, and  SAINT \nare some of the better known ones. \n There are also  stealth port scanners. These scanners use a low-level interface to \ncreate TCP or UDP packets that do not correctly conform to the protocol. For example, \na TCP packet with the ACK bit set will likely get through a packet-filtering firewall \nbecause it looks like part of an established connection. If such a packet is received \nelm49810_ch19_445-468.indd   462\nelm49810_ch19_445-468.indd   462\n12/10/08   9:40:04 PM\n12/10/08   9:40:04 PM\n",
        "category": "Category"
    },
    {
        "id": "426",
        "title": "Title for Chunk 426",
        "content": "Confirming Pages\n \nChapter 19  Linux: A Case Study  \n463\non a port that had no established session with the sender, then the TCP software will \nrespond with an appropriate message and the hacker can assume that there is a process \nthat is reading that port. \n TCP Wrapper ( tcpd) is used to filter network access to IP services run on Linux \nor other UNIX-like variants. When IP services are started by a super-server like  inetd \nthe TCP wrapper program is invoked to check the source of the connection. It sup-\nports filtering on host or subnet IP addresses or names. In addition, these IP services \ncan be linked to an  ident service. This service will first query the source IP address \non TCP port 113. It will expect a query reply that identifies the source system. Only if \nthe reply is received and matched against a database will the connection be allowed. \nMost network service programs can be directly linked with the library that does the \nfiltering. This method is used by services that operate without being started by a \nsuper-server, or by any service that handles multiple connections. Otherwise, only \nthe first connection attempt would get checked against the database by tcpd.  \n 19.9 SYMMETRIC MULTIPROCESSING \n With SMP the OS can be running on more than one CPU at one time. As was discussed \nin Chapter 6, the two (or more) instances of the running OS must be prevented from \nchanging the same data structure at the same time by using locks. Early releases of the \nLinux SMP support used a single lock for the entire kernel, the so-called  Big Kernel \nLock.  This was not very efficient, since many times the different instances of the OS \nwould not be manipulating the same data structures at all. So later releases have begun \nreplacing those references to that one lock with references to more localized locks. \nSome references to the Big Lock still remain as of version 2.6, but the multiprocessor \nperformance is greatly improved over prior versions. The Linux kernel also uses spin-\nlocks on a special read\u2013write type of semaphore that allows multiple readers but only \none writer at a time, when a structure is read mostly. For example, the table of network \ndevices changes only very rarely but is read frequently, so allowing multiple readers is \nbeneficial. When a change needs to be made to the table, then locking all the readers \nout briefly while it is changed by only one writer is not a frequent problem.  \n 19.10 OTHER LINUX VARIANTS \n Since the source code for Linux is readily available, there are several variants of \nLinux that have been created for special purposes. Two special areas are versions \nfor real-time applications and for embedding Linux in small systems with limited \nresources. \n 19.10.1 Real-time Linux \n The normal Linux OS is not a hard real-time OS. This is true for most OSs. A hard \nreal-time system guarantees that real deadlines are met, for example that a process or \nthread will be run in the next 50 milliseconds. Hard real-time systems preclude many of \nthe mechanisms that have evolved for traditional OSs, mechanisms that use stochastic \ntechniques and try to be fair in providing services to processes. Hard real-time systems \nelm49810_ch19_445-468.indd   463\nelm49810_ch19_445-468.indd   463\n12/10/08   9:40:05 PM\n12/10/08   9:40:05 PM\n",
        "category": "Category"
    },
    {
        "id": "427",
        "title": "Title for Chunk 427",
        "content": "Confirming Pages\n464 \nPart 6 Case Studies\nneed to establish deadlines for events and for the servicing of requests and the normal \nOS mechanisms do not allow us to provide such deadline support. Embedded applica-\ntions are also important, where a computer is a controlling component in a piece of \nequipment rather than a general-purpose computing tool. Such embedded applications \nare often real-time systems as well. This means that there is a considerable overlap \nbetween embedded Linux implementations and real-time Linux implementations. \n There are two main schools of thought about how to make a real-time system out \nof Linux. Some of the implementations of real-time Linux use a small real-time OS \n( RTOS ) as a host OS and they run a version of the Linux kernel that runs as a single \nthread in the host OS kernel at a background or idle priority. In other words, when there \nis no real-time process to run, then any normal Linux applications can run. This model \nis known as  RTLinux. The other school uses the Linux kernel but modifies it heav-\nily to include only scheduling mechanisms that allow the support of a real-time API. \nThese mechanisms would include at least the process scheduler and the disk sched-\nuler and probably the networking protocol stack. This  real-time application interface \nmodel is also known as  RTAI. There are also other interesting approaches that do not \nfit either of these categories. Deciding on the correct package to use for a project could \nbe quite complex. Fortunately there is  real-time Linux common API,  an open source \nAPI that allows programmers to code to a common API when using either RTLinux or \nRTAI.  Table 19.3 lists some embedded and real-time implementations of Linux.\n 19.10.2 Embedded Linux \n Linux has also been modified to run in very limited environments. Such environ-\nments include platforms like those discussed in the chapter on the Palm OS, but it \nalso include devices like microwave ovens and home heating controls where the user \nenvironment is very limited. The open source and modular nature of Linux make it \nideal for such situations. However, there are many issues that must be resolved in \nusing Linux as an OS in such systems:\n \ufffd These devices typically have no secondary memory and thus don\u2019t really need \npaged memory. But standard Linux presumes that these exist. So one modifica-\ntion that is often found in embedded Linux systems is the removal of paged \nmemory hardware support requirements. They also need no caching manage-\nment system or features like memory mapped files. \n \ufffd The very limited user interface is also significant because Linux does not pre-\nsume a GUI. Rather, the GUI is an add-on and the standard interface is a com-\nmand line. Even this may be too strong an assumption for a microwave where \nthe display might be limited to an LCD panel that can only display a few digits. \nSome embedded Linux systems are found in complex devices such as small \nrouters. These devices now often support the HTTP protocol and can be man-\naged by a remote browser. \n \ufffd Process scheduling in Linux typically uses the concept of \u201cinteractiveness\u201d to \npromote the priority of a process that is interacting with a user. But in an embed-\nded system there is no elaborate, interactive user interface. There may be a small \ndisplay and a few buttons that can be handled quite adequately with some real-\ntime processes or normal interrupt handlers. So the process scheduler may be a \nstripped-down version that does not incorporate dynamic priority changes. \nelm49810_ch19_445-468.indd   464\nelm49810_ch19_445-468.indd   464\n12/10/08   9:40:05 PM\n12/10/08   9:40:05 PM\n",
        "category": "Category"
    },
    {
        "id": "428",
        "title": "Title for Chunk 428",
        "content": "Confirming Pages\n \nChapter 19  Linux: A Case Study  \n465\nTABLE 19.3 Common Linux Variants\nCommercial platforms:\nFSMLabs: RTLinuxpro - RTCore - a hard real-time platform that runs Linux as an idle thread.\nLineo Solutions: uLinux - hard real-time Linux kernel - targets consumer electronics devices.\nLynuxWorks: BlueCat - time-critical handling of interrupts and other hardware operations - implements Linux \nkernel as a thread.\nMontaVista Software: Real-Time Solutions for Linux - MontaVista Linux for embedded and real-time \napplications - includes a preemptable Linux kernel.\nConcurrent Computer Corp.: RedHawk - a Linux-based RTOS kernel for multiprocessor systems - uses CPU \nshielding - processors can be designated as locked out from Linux so hard real-time processes execute on a \nshielded CPU with guaranteed interrupt response time.\nREDSonic: REDICE-Linux - a real-time Linux kernel with extra preemption points that allow RTAI support \nand quality of service (QoS) guarantees.\nTimeSys: TimeSys Reservations - dynamically installed kernel modules extend a Linux RTOS. Reservations \nretain a fixed amount of CPU and network bandwidth for a specific process or set of processes.\nOpen-source implementations:\nAccelerated Technology - provides embedded developers with a real-time operating systems (RTOS).\nADEOS - provides a hardware abstraction layer that allows a real-time kernel and a general-purpose kernel to \ncoexist. Supports dual-kernel hard real-time Linux environments like RTLinux or RTAI free from technology \npatent.\nART Linux - a real-time extension to the 2.2 Linux kernel.\nFlight Linux - a real-time variation designed for onboard spacecraft use.\nKURT\u2014The KU Real-Time Linux - a real-time Linux kernel developed at the University of Kansas.\nLinux/RK - a \u201cresource kernel\u201d enhancement to Linux based on a loadable kernel module that provides timely, \nguaranteed, and enforced access to system resources for applications. Development based at Carnegie Mellon \nUniversity.\nOnCore\u2019s Linux for Real-Time\u2122 - allows embedded designers to pick a memory footprint and performance \nmodel appropriate to the problem.\nRED-Linux - a real-time version of Linux; based at the University of California, Irvine.\nRTAI - real-time application interface, a comprehensive real-time API usable both for uniprocessors and SMPs. \nAllows control of real-time processes from user space - soft real-time with fine-grained process scheduling. \nAtomicRTAI is a small-footprint (single floppy) version.\nRTLinux - a \u201chard real-time\u201d mini OS runs Linux as its lowest priority preemptable user thread so real-time \nthreads and interrupt handlers are never delayed by non-real-time operations. Supports user-level real-time \nprogramming. MiniRTL is a small-footprint version.\nRedIce Linux - RedIce Linux allows RTAI and RED-Linux to run concurrently, enabling real-time jobs \nrequiring very low latency and hard real-time user applications with complete Linux kernel support to run under \none structure.\nelm49810_ch19_445-468.indd   465\nelm49810_ch19_445-468.indd   465\n12/10/08   9:40:06 PM\n12/10/08   9:40:06 PM\n",
        "category": "Category"
    },
    {
        "id": "429",
        "title": "Title for Chunk 429",
        "content": "Confirming Pages\n466 \nPart 6 Case Studies\n 19.11 SUMMARY \n This chapter is one of several case studies of real \nOSs showing how they implement several standard \nOS features. This chapter discussed such features in \na multiuser OS, Linux. We started this chapter with \na discussion of the process scheduling mechanisms \nand followed it with a rundown on the virtual mem-\nory management by the OS necessitated by sup-\nporting potentially many users doing very different \nprocesses. We then gave an overview of the support \nof files in Linux and the many different file systems \nsupported because of the unusual history of Linux, \nfollowed by coverage of the I/O functions that the \nOS provides. We then briefly discussed the imple-\nmentation of the GUI. Sections on networking and \nsecurity were also provided. Next, we touched on the \nsubject of multiprocessor support under Linux, and \nfinally we addressed some variations of Linux that \nhave resulted from its being used in situations where \nan OS such as Linux would not normally be found \nsuch as hard real-time and embedded environments. \n BIBLIOGRAPHY \n Bovet, D. P., and M. Cesate,  Understanding the Linux \nKernel, 2nd ed., Sebastopol, CA: O\u2019Reilly & \nAssociates, Inc., 2003. \n Gorman, M.,  Understanding the Linux Virtual Memory \nManager.  Upper Saddle River, NJ: Prentice Hall, 2004.  \n Love, R.,  Linux Kernel Development. Indianapolis, IN: \nSams Publishing, 2004. \n Stevens, R.,  Advanced Programming in the UNIX \nEnvironment. Boston, MA: Addison-Wesley, 1992. \n Stevens, R.,  Unix Network Programming. Upper Saddle \nRiver, NJ: Prentice Hall, 1990. \n Yaghmour, K.,  Building Embedded Systems. Sebastopol, \nCA: O\u2019Reilly & Associates, Inc., 2003.  \n WEB RESOURCES \n http://www.linux.org (the home of Linux kernel \ndevelopment) \n http://www.kernel.org (a repository of historic kernel \nsources) \n http://www.tldp.org (the Linux Documentation Project) \n REVIEW QUESTIONS \n 19.1 What was the specific objective of the redesign of \nthe scheduler for Linux 2.6? \n 19.2 True or false? In the Linux scheduler the real-time \nprocess queues are serviced in a FIFO manner. \n 19.3 Briefly describe SMP load balancing. \n 19.4 True or false? Linux uses a standard demand pag-\ning virtual memory manager. \n 19.5 What is the buddy system? \n 19.6 True or false? Linux offers only a simple file sys-\ntem derived from MINIX. \n 19.7 True or false? One of the main contributions of \nLinux is that it uses a unique disc scheduling \nalgorithm not found in other OSs. \n 19.8 How does Linux provide protection for files \nbelonging to different users? \n 19.9 In the Windows NT OS family the GUI is intrin-\nsic to the OS. How is a GUI provided in Linux? \n 19.10 What does Linux do to keep from having exces-\nsive buffer copying when passing messages \nelm49810_ch19_445-468.indd   466\nelm49810_ch19_445-468.indd   466\n12/10/08   9:40:06 PM\n12/10/08   9:40:06 PM\n",
        "category": "Category"
    },
    {
        "id": "430",
        "title": "Title for Chunk 430",
        "content": "Confirming Pages\n \nChapter 19  Linux: A Case Study  \n467\ndown through the layers of the networking \narchitecture? \n 19.11 On a multiprocessor system the Linux kernel \ncan be executing on multiple CPUs at the same \ntime. When it is necessary for the kernel to enter \na critical section it can\u2019t just call the OS to WAIT \nbecause it is the OS. What does it do instead? \n 19.12 Real-time OSs have some timing requirements \nthat are ignored by most OSs. There are many \ncommercial and open source variants of Linux. \nWe described two different approaches to sup-\nporting real-time requirements under Linux. One \napproach involved heavily modifying the Linux \nkernel process scheduling module. The other \napproach was conceptually cleaner and simpler. \nBriefly describe that approach. \n 19.13 What is the Big Kernel Lock and what is happen-\ning to it? \nelm49810_ch19_445-468.indd   467\nelm49810_ch19_445-468.indd   467\n12/10/08   9:40:06 PM\n12/10/08   9:40:06 PM\n",
        "category": "Category"
    },
    {
        "id": "431",
        "title": "Title for Chunk 431",
        "content": "elm49810_ch19_445-468.indd   468\nelm49810_ch19_445-468.indd   468\n12/10/08   9:40:06 PM\n12/10/08   9:40:06 PM\n",
        "category": "Category"
    },
    {
        "id": "432",
        "title": "Title for Chunk 432",
        "content": "469\n Chapter \n Chapter  20 \n 20 \n Palm OS: A Class \nCase Study   \nIn this chapter: \n 20.1 Overview 469\n 20.2 The Multi-Process OS Environment 470\n 20.3 Palm Process Scheduling 471\n 20.4 Palm Memory Management 471\n 20.5 File Support 472\n 20.6 Input/Output Subsystems 472\n 20.7 GUI Programming 473\n 20.8 Network Programming 473\n 20.9 Programming Environments 475\n 20.10 Similar Systems and Current Developments 476\n 20.11 Summary 480\n20.1 OVERVIEW \n In Chapter 4 we discussed some elements of the Palm operating system. That discus-\nsion was mainly limited to issues that arose as we studied the more complex design \ngoals of this OS compared to the ones studied before it. This chapter is nominally \nabout the Palm OS versions prior to version 5. This OS represented a particular niche \nin the hierarchy of OSs that was described in Part 2 of this text. As such there is not \na great deal more that can be said about this OS that was not covered in Chapter 4. \nSo this chapter starts with a series of sections that parallel the other two case study \nchapters and provide some details that were not relevant to Chapter 4. But other \nmaterial is added here that helps place this OS in the computer industry as it is evolv-\ning today. We discuss some aspects of programming such platforms and the trends of \nthe applications that are developing in the industry. \n We begin this chapter with a brief restatement of the type of environment that the \nPalm OS is designed for in Section 20.2. Sections 20.3 through 20.5 briefly  summarize \nthe related points of Chapter 4. Section 20.6 then discusses several developments that \n",
        "category": "Category"
    },
    {
        "id": "433",
        "title": "Title for Chunk 433",
        "content": "470 \nPart 6 Case Studies\nhave occurred in the area of the input/output subsystems in the Palm OS beyond the \nfundamental things we covered in Chapter 4. These features are typical of new hand-\nheld platforms. Sections 20.7 and 20.8 also summarize related sections of Chapter 4. \nSection 20.9 explains the nature of the cross-development systems needed to develop \nprograms for such a limited environment. PDAs, cell phones, and multimedia players \nwere originally different sorts of devices, but these platforms are currently undergo-\ning a merger. So Section 20.10 discusses how software is evolving in these platforms. \nIt also touches on some of the developments in later releases of the Palm OS. We \nconclude with a chapter summary in Section 20.11.  \n 20.2 THE MULTI-PROCESS OS ENVIRONMENT \n The Palm OS and its environment were discussed in Chapter 4, but they are reviewed \nhere for convenience. The Palm OS is designed for a very specific type of environ-\nment. There are several characteristics of this environment that restricted the design \nof the OS. The environment characteristics are briefly outlined in  Table 20.1 .  \n The primary characteristic of the Palm OS is the small screen size. This means \nthat the user is only interacting with one program at a time so that applications \nassume that their window fills the entire screen at all times except for small notice \nboxes that may pop up in front of the main window. \n Although later models sometimes included disk drives, especially as an add-on \nfeature, the initial machines did not include them and the OS design assumes that all \nprograms reside in primary memory. The lack of a keyboard means that the OS must \nprovide for handwriting recognition. This feature is a real-time application, so a real-\ntime kernel underlies the Palm OS. User applications, however, are not real time and \nare single threaded. The resulting OS design choices are listed in  Table 20.2 .  \nTABLE 20.1 Unusual Characteristics of the Palm Platform\nSmall screen size\nNo secondary storage\nNo text keyboard\u2014touch screen\nLimited power for better battery life\nSlow CPU to reduce power\nLimited primary memory\nTABLE 20.2 Unusual Characteristics of the Palm OS\nPrograms never stop\nNo demand paging (virtual memory) or disk caching\nSingle-window GUI\nMultiple text input options\nReal-time OS tasks but non-real-time applications\nNo application multithreading\n",
        "category": "Category"
    },
    {
        "id": "434",
        "title": "Title for Chunk 434",
        "content": " \nChapter 20  Palm OS: A Class Case Study  \n471\n 20.3 PALM PROCESS SCHEDULING \n 20.3.1 Real-time tasks \n The process scheduler in the Palm OS is a preemptive multitasking priority sched-\nuler. It will dynamically determine which task that is ready has the highest priority \nand it will interrupt the running of a less important task to run a more important one \nthat becomes ready. The underlying OS is a real-time kernel for support of hand-\nwriting recognition, but user application programs cannot access these functions. \nHandwriting recognition is divided into two parts: stylus tracking and character rec-\nognition. The stylus tracking task processes interrupts from the stylus using a stan-\ndard interrupt mechanism. When the stylus tracking determines that the stylus has \nchanged direction, stopped, or is no longer touching the screen, it will calculate a \nvector describing the movement and will pass this information on to another task \nthat is running, the character (graffiti) recognizer. If this routine recognizes a char-\nacter, then it will pass this information on to the OS so that it can decide what to do \nwith the character. Usually the character will be passed to the application that has the \nfocus to be placed on a control on the current form where the user is entering text. Of \ncourse, the character might be a control character instead of a text character and the \napplication may then be given a message telling it about the event. If the screen touch \nis not in the graffiti area, then the OS must detect screen taps on form buttons or pass \nthe information on to the application\u2014perhaps it is a drawing tool, for example. \n 20.3.2 Other tasks \n Only a single-user application has the focus, and that application is most likely \nwaiting for user input as just described. But it is normal for Palm systems to have \nbackground communication functions running such as telephony, database synchro-\nnization, Bluetooth connection to local devices such as headphones, and Internet \naccess for browsing and email. In addition, certain user features such as searching \nfor a name will invoke a search function in applications that do not currently have the \nfocus. Tasks that do not have the focus will be running in an event loop waiting for \nsignals about events requesting them to do some work. The Palm scheduler module \nwill see that each application gets some time to do its work. \n 20.4 PALM MEMORY MANAGEMENT \n Processes in the Palm OS are always resident in primary memory. Once a process \nhas begun running it never really stops. It may lose the focus, in which case it will \nnot be running anymore, but it is still there waiting to be selected from the menu \nagain and resume execution. \n The memory manager in the Palm OS treats a large block of a primary memory \nas a heap. As memory is allocated and freed on the heap, the eventual result is exter-\nnal fragmentation. This requires occasional compaction to aggregate larger blocks \nof memory. To facilitate this, items in memory are addressed indirectly through a \n",
        "category": "Category"
    },
    {
        "id": "435",
        "title": "Title for Chunk 435",
        "content": "472 \nPart 6 Case Studies\nmemory pointer table (MPT). Thus, when the memory manager moves an item, it \nmerely updates the MPT entry that points to the item. The details of this mechanism \nwere covered extensively in Chapter 4. \n 20.5 FILE SUPPORT \n The Palm OS programmer\u2019s documentation refers to \u201cdatabases,\u201d but these are actu-\nally random access flat files. They are accessed by an \u201cindex\u201d value that is a 16-bit \ninteger. Records are of variable length and can be resized dynamically, and added \nand deleted. The file manager maintains an index for each database giving the cur-\nrent location in memory of each record in that database. A database must fit entirely \nwithin a single memory card. \n 20.6 INPUT/OUTPUT SUBSYSTEMS \n Early Palm devices were merely used as PDAs. As was mentioned, these systems \nhave evolved to cover many additional functions including games, cell phones, Web \nbrowsers, and media players. The initial Palm releases had limited functionality in \nthe audio area in particular, and these have been enhanced significantly through the \nvarious releases. In addition, the platform evolution has also seen advances in com-\nmunication and networking functions. This section discusses the audio functions. \nThe networking functions are covered in a later section in order to maintain a parallel \nstructure with the other case study chapters. \n 20.6.1 Audio I/O \n The continuing development of technology has led to a rising interest in portable \nmusic devices. In addition, the advanced games that users want to have on these \nmachines needed enhanced audio features. The initial sound support in the Palm \nOS was limited to short sounds for alerts and a few noises for games. Later ver-\nsions added support for a low-level implementation of a  musical instrument device \ninterface (MIDI) so that more elaborate musical sounds could be created by an \napplication. This led to a number of interesting applications for musicians to use \na Palm OS device as a simple musical tool, such as a tone generator and a metronome. \nLater versions of the platform also added more advanced sound support, allowing \nthese devices to be used as cell phones and to play music files. Later they also added \nthe ability to perform voice recording and playback\u2014audio notes to oneself\u2014and the \nrecording and sending of audio to other cell phones.  \n 20.6.2 Stream I/O \n For purposes of ease of programming, the Palm OS also includes a version of file \nstreams similar to the  stdin/stdout functions available in most C language libraries. \nThese functions use the database structure discussed in the File Support section but \nallow easier porting of some applications to the Palm OS. \n",
        "category": "Category"
    },
    {
        "id": "436",
        "title": "Title for Chunk 436",
        "content": " \nChapter 20  Palm OS: A Class Case Study  \n473\n 20.6.3 RAM disk driver \n The underlying OS is designed to be used in embedded systems where there is com-\nmonly no secondary memory. But many applications are developed to run from a \nstandard file system\u2013style interface. Therefore, the AMX OS comes with a pre-\ndefined RAM \u201cdisk\u201d driver that uses a portion of RAM to emulate a disk drive. This \nallowed the Palm OS to readily define a RAM drive as a DOS-formatted floppy drive \nso that porting applications to the Palm were easier and programmers did not have to \nlearn a separate interface to use the system. \n 20.6.4 Cameras \n The development of low-cost, high-resolution CMOS image sensor technology has \nmeant that many cell phones and PDAs now include cameras. Moreover, since larger \nmemories are now available, the cameras can even record video files as well as static \nimages. So now these devices are capable of transmitting image and video files in \naddition to audio files. \n 20.6.5 Communication circuits \n Bluetooth and 802.11 Wi-fi communication circuits are now available and have been \nincorporated in the latest Palm devices. These allow other synchronization pathways \nbut also a merging of the PDA and cell phone device classes and to Internet access \ndevices such as the Blackberry \u2122 . \n 20.7 GUI PROGRAMMING \n The GUI environment on the Palm platform was extensively covered in Chapter 4. \nThe principle factors that distinguish this platform are the small screen size and lim-\nited memory. As a result of the small screen size, the Palm system does not support \ntiling the forms of applications. (The Palm OS uses the term \u201cform\u201d for a normal \nwindow.) Pop-up boxes from a single application are allowed but the pop-up boxes \nmust be closed before the application can continue. (The Palm OS calls these boxes \nwindows.) The limited Palm memory led to the development of specific windows \nthat can be created by Palm applications merely by filling in specific data structures \nand calling OS routines. The OS will then take on the task of displaying the window \nand closing it when the user selects an option. \n 20.8 NETWORK PROGRAMMING \n 20.8.1 Personal data synchronization \n It is natural that a portable device would need to have strong support for communica-\ntion protocols. Since the Palm devices were initially envisioned as PDAs, the most \nimportant communication application was synchronizing with a PC so that the data \n",
        "category": "Category"
    },
    {
        "id": "437",
        "title": "Title for Chunk 437",
        "content": "Confirming Pages\n474 \nPart 6 Case Studies\nin the handheld unit could be backed up. Accordingly the initial interfaces provided \nwith the Palm OS were low-level drivers for serial, infrared, and USB ports. At the \nsame time there was a higher-level interface provided for writing applications for \nsynchronization personal information such as contact lists and appointment calen-\ndars. A consortium of interested vendors was created known as the Versit Consor-\ntium. They have defined a set of standards concerning  personal data interchange \n(PDI) that include standards for a  vCard, an electronic business card, and  vCalen-\ndar, an electronic calendar and scheduling exchange format. These standards are \nnow maintained by the Internet Mail Consortium. The Palm OS includes a library \nthat allows an application to open a PDI stream as either a reader or a writer to facili-\ntate the development of synchronization applications. \n 20.8.2 Other data synchronization \n Some users will be concerned with developing custom applications that go beyond \ntraditional PDA applications. They may have specific data files that need to be syn-\nchronized between a Palm application and a similar application on another platform. \nSo the Palm OS provides  exchange libraries, which act as plug-ins to an OS module \ncalled the Exchange Manager. They allow Palm OS applications to import and export \ndata records without being concerned with the transport mechanism. For example, \none exchange library always available to Palm Powered \u2122 handhelds implements the \nIrDA protocol, IrOBEX. This allows applications to beam objects by way of infrared \nfrom one Palm Powered handheld to another. Similar exchange libraries exist for \nother hardware ports and other protocols such as the SMS (short message service) \nlibrary, email protocols, and the Bluetooth library. \n 20.8.3 Internet applications \n During the last several years the Internet has risen in popularity to the point where it \nis almost mandatory that handheld units be able to access many of the popular fea-\ntures found there. In particular, these include accessing World Wide Web (WWW) \nsites as well as the email protocol already mentioned. Accordingly, more protocol \nstacks and APIs have been added to the Palm OS to support networking applica-\ntions. The first addition was the widely used and well-known lower-level  Berkeley \nSockets API. This interface allows a programmer to connect to services on other \nsystems using a variety of protocols without having to implement that protocol in the \napplication. The interface included with the Palm OS allows either TCP (connection-\noriented) or UDP (connectionless) communications. \n The second level of protocol supported in the Palm OS includes support for \nApplication layer protocols such hyperText Transport Protocol (HTTP), the protocol \nused for the WWW. This protocol is used by Web browser and Web service appli-\ncations for Palm devices. There are some interesting problems to be solved when \ndeveloping a browser for a Palm unit because initially few websites are developed \nwith the very small screen space of a handheld unit in mind. However, current HTML \nattributes allow a Web server to determine that a browser is running on a mobile plat-\nform and to adjust its output to fit. \nelm49810_ch20_469-482.indd   474\nelm49810_ch20_469-482.indd   474\n12/10/08   8:30:05 PM\n12/10/08   8:30:05 PM\n",
        "category": "Category"
    },
    {
        "id": "438",
        "title": "Title for Chunk 438",
        "content": " \nChapter 20  Palm OS: A Class Case Study  \n475\n 20.8.4 Telephony applications \n In Section 20.10 we discuss the current merging of PDA devices with cellular tele-\nphones. The Palm Telephony Manager provides a set of functions that allow an \napplication to access a variety of telephony services. The telephony API organizes \nthe functions in groups called service sets. Each service set contains a related set of \nfunctions that may or may not be available on a particular mobile device or network. \nOne of the API functions allows the application to find out if a given service set is \nsupported in the current environment. A list of some of the more common service \nsets is shown in  Table 20.3 .  \n 20.9 PROGRAMMING ENVIRONMENTS \n The resources available on a computer designed to run the Palm OS are usually not \nsufficient to develop software. The Palm OS programming website suggests that pro-\ngrams designed for a Palm-based system be designed to support only a minimum \namount of data entry. This suggestion is made partly because of the difficulty of input-\nting data with the handwriting recognition, but also because of the very limited screen \ndisplay. Instead, Palm suggests that the user should mainly input data on a desktop \nsystem and use the Palm system for referencing the data. Furthermore, once a program \nis running on the Palm OS there would be no simple way of getting any debugging \nTABLE 20.3 Telephony API Service Sets\nService set\nFunctionality\nBasic\nFunctions always available\nConfiguration\nConfigure phones including SMS\nData\nData call handling\nEmergency calls\nEmergency call handling\nInformation\nRetrieve information about the current phone\nNetwork\nNetwork-oriented services, including authorized networks, \ncurrent network, signal level, and search mode information\nOEM\nAllow manufacturers to add features to the Telephony \nManager and provide a new set of functions for a device\nPhone book\nAccess the Subscriber Identity Module (SIM) and address \nbook\nPower\nPower supply\u2013level functions\nSecurity\nProvide PIN code management and related services for \nphone and SIM security-related features\nShort Message Service\nEnable reading, sending, and deleting of short messages\nSound\nPhone sound management, including the playing of key \ntones and muting\nSpeech calls\nHandle the sending and receiving of speech calls; also \nincludes Dual-tone multi-frequency (DTMF) signaling\n",
        "category": "Category"
    },
    {
        "id": "439",
        "title": "Title for Chunk 439",
        "content": "476 \nPart 6 Case Studies\ninformation displayed and the environment is obviously not well suited for the entry \nand editing of program source code. Moreover, there rarely are printers attached to \nPalm systems and as was noted before, the CPUs are very slow and there is generally \nlimited RAM and rarely any secondary storage. Most program development is there-\nfore done on another system, a concept known as cross-platform development. \n There is a wide variety of languages and tools for development of software for \nthe Palm OS. Some is available from Palm itself and others are available from third \nparties. These include commercial integrated development environments (IDEs) such \nas CodeWarrior \u2122 from Metrowerks and free tools such as PRC-Tools, which is a gcc-\nbased compiler tool chain for building Palm OS applications in C or C \ufffd \ufffd . Tools that \nare supplied by Palm include a Software Development Kit (SDK) that includes the \nheaders, libraries, and tools for Palm OS platform development on Windows, Linux, \nand the Mac OS. It also includes a version of the Palm OS running in native X-86 code \non a Windows machine. This emulation offers an easy way to test applications destined \nfor the Palm OS for compatibility. Compilers are also available for developing applica-\ntions in other languages, including Visual Basic, Pascal, Forth, Smalltalk, and Java. \n An essential feature is a package that Palm calls an Emulator. This is a soft-\nware package that emulates the hardware of the various models of Palm OS platform \ndevices on Windows, Linux, or Mac OS computers. Since various platforms have \ndifferent features available in their ROM, ROM images for use with the Palm OS \nEmulator are available to emulate each desired model. \n Once a program has been developed with the cross-platform tools, it can be \ninstalled on a Palm device using the synchronization tools included with Palm PDAs \nthat are available for the various cross-development platforms. \n 20.10 SIMILAR SYSTEMS AND CURRENT DEVELOPMENTS \n One of the difficulties facing authors who write about computer science is that the \nstate of the industry changes so rapidly that a book is not reflective of the latest \ndevelopments even on the day it is printed. Operating Systems are no exception. \nThere have been rapid developments in the hardware systems used for the Palm OS \nand others of its ilk discussed in this chapter. In addition, a different functional view \nhas captured the minds of the public and the vendors that have forced some changes \nin the OS. As a result, other OSs that were developed for this different view have \nsome features that are more complex than the Palm OS described here. But then, so \ndo later versions of the Palm OS. \n In this section we describe some features found in other OSs for small systems. \nWe mostly mention the Symbian OS. This OS is developed by Symbian Ltd. It is a \ndescendant of Psion\u2019s EPOC OS and runs only on ARM processors. Symbian is a \nconsortium of manufacturers of cell phones. \n 20.10.1 New functional models \n In addition to the use of more advanced CPUs, the basic functions of small handheld \nsystems have also evolved in the last few years. At the beginning of this century the \nproducts in this area were mostly envisioned as either PDAs or cell phones. In PDAs \n",
        "category": "Category"
    },
    {
        "id": "440",
        "title": "Title for Chunk 440",
        "content": "Confirming Pages\n \nChapter 20  Palm OS: A Class Case Study  \n477\nthe applications were things like phone and address books, appointment calendars, \ncalculators, memo pads, to-do lists, specialized data bases, and an occasional special-\nized application. In cell phones the main application was the phone book or contact \nlist. In either case, these were primarily standalone applications that required occa-\nsional connection to another computer for purposes of synchronization, backup, and \nloading new applications. In the cell phone the actual telephone application was a \nreal-time task that was considered to be a fundamental function of the device rather \nthan a separate application. These cell phones were closed systems in that installation \nof additional applications was not part of the design. \n Lately, however, a new model has evolved for handheld devices. This evolu-\ntion has come about partly because of the revolution in the availability of communi-\ncations technology and ubiquitous connectivity. The devices are now positioned as \nmobile communications platforms\u2014but as much more than just replacements for cell \nphones. The main feature that distinguishes a cell phone from a PDA is that PDAs are \nturned on, used for some single function and then turned off, while a cellular phone \nis normally left on most of the time and is continuously connected to the network \nand waiting for incoming calls. In addition to waiting for calls, a cellular phone does \nother work to manage the connection such as keeping the time synchronized and \nconversing with the cellular network so that if a cell phone is turned on the network \nknows where it is. In order for the PDA functions to be used while the cell phone is \nhandling the network connection, the OSs for these mobile communicating devices \nhave to incorporate multiple active tasks at the same time. In a pure PDA device \nsuch as the original Palm products, the OS provided only a few separate tasks so that \nhandwriting recognition and synchronization could take place while a user interface \n(UI) application was also running. (You may recall the screens are so small that there \nis no room for more than one UI application to be executing at a time.) However, \nthere was no provision for applications to provide any separate background function \nsuch as managing the connection to a cellular network and checking for incoming \ncalls. As a result, these OSs all have added more features to support application mul-\ntithreading. More importantly, applications can now start a thread as part of a back-\nground task in addition to the single foreground UI thread. An example of the utility \nof such a feature would be that a service can be built that will handle multiple TCP/IP \nconnections at the same time, so that several TCP/IP-based applications can all be \nrunning at the same time using a single TCP/IP multithreaded service. The TCP/IP \nservice will be running as a \u201cuser\u201d application rather than as part of the OS kernel. \nAnother important example is a Web browser. When a page is fetched from a server, \nthe images and other included items are not automatically sent. The browser must \nparse the initial page and then individually request each referenced element. The \nbrowser must be able to continue to work on displaying the main page for the user \nwhile the other elements are being fetched from the server. This gives the user some \nimmediate access to the contents and a smoother browsing experience. \n As in the case of the cellular phone connectivity, other applications can ben-\nefit from these background tasks without having control of the UI. Some of the \nmore obvious ones are playing an audio file, downloading new audio files to play, \ninstant messaging, and having an email program connect to a server to check for new \nemail. Other, less obvious background functions exist as well, such as synchronizing \nelm49810_ch20_469-482.indd   477\nelm49810_ch20_469-482.indd   477\n12/10/08   8:30:06 PM\n12/10/08   8:30:06 PM\n",
        "category": "Category"
    },
    {
        "id": "441",
        "title": "Title for Chunk 441",
        "content": "Confirming Pages\n478 \nPart 6 Case Studies\nchanges to distributed databases and updating installed software. These new tasks \nhelp cell-phone manufacturers to differentiate their products from one another. In \naddition, users are asking for these features because they are beginning to value the \ninstant access to information through messaging, email, and the World Wide Web. In \norder to provide these features, these devices have incorporated advanced hardware \ncomponents to handle the multiple communication streams, multimedia streams, and \nso forth. The OSs have had to improve as well. Not only can applications start many \nthreads and set different priorities for each thread, they have new mechanisms to syn-\nchronize between the threads and with other processes, to share memory segments \nwith other processes, to communicate with other processes, and to protect databases. \n 20.10.2 Advanced communication models \n Other advanced facilities being provided by the OSs now include encryption and \nother security mechanisms, new Data Link layer modules such as Bluetooth and \n802.11x, and APIs so that new user applications can easily access these OS func-\ntions. As the cost of bandwidth from communication services continues to decrease, \nwe are beginning to see more and more intense multimedia applications. The near \nterm projections of the marketplace include more streaming multimedia applica-\ntions. These applications have heavy hard and soft real-time requirements. These \nsmall OSs will continue to evolve with the increasing requirements. \n 20.10.3 Thread scheduling \n As discussed earlier, cell phones are used somewhat differently than PDAs. PDAs \nare generally turned off when not being used, but cell phones stay on all the time so \nthat they can wait for incoming calls and keep the network updated about the loca-\ntion of the phone. In addition, the demands of the cellular technology are such that \nreal-time tasks are needed to service the network. Accordingly, the scheduler used in \nthe Symbian OS is a priority-based multithreading scheduler. Any application can be \na \u201cserver\u201d and can create multiple threads of execution within its address space. The \nPalm OS included a real-time scheduler because of the needs of the graffiti handwrit-\ning recognition program, but user applications were not able to create real-time tasks \nor threads. We discussed such schedulers in Chapter 8. \n 20.10.4 User interface reference design \n The  user interface (UI)  for most PC systems is very flexible. Windows can fill the \nscreen, shrink to a smaller size, move around, cover one another, and so on, depend-\ning on the whim of the user. These smaller systems, however, have simpler interfaces \nthan personal computers do. Often the application assumes that its window fills the \nentire screen. There are generally three different types of UI in such devices. They \nroughly represent the classes of a cell phone, a PDA, and a handheld computer. The \nuser interface class is an abstraction of the features that the members of each family \nhave in common. These classes are summarized in  Table 20.4 . \n The challenge for the OS designers and for application programmers is to write \nOSs and applications that will run on any of these different platforms without a major \nelm49810_ch20_469-482.indd   478\nelm49810_ch20_469-482.indd   478\n12/10/08   8:30:06 PM\n12/10/08   8:30:06 PM\n",
        "category": "Category"
    },
    {
        "id": "442",
        "title": "Title for Chunk 442",
        "content": "Confirming Pages\n \nChapter 20  Palm OS: A Class Case Study  \n479\nrewrite. The desire for such portability forces system implementation into strict object-\noriented designs in order to isolate the UI functions from the rest of the application. \nIndustry estimates are that about 80% of an application can be isolated from the UI. \n The rise of the popularity of the Internet have lead to the incorporation of several \nstandard applications in these new devices. In particular, users want to send instant \nmessages, work with their email, view (or listen to) streaming multimedia transmis-\nsions, browse the World Wide Web, and upload multimedia files to their websites. \nThese small systems have very limited screen size, and Web pages are typically set \nup for at least 800  \ufffd 600 pixels. As a result, a browser on a cell phone has to work \nreally hard to make an intelligent display of a larger Web page. Initially a separate \nstandard was created for building Web pages intended to be viewed on a handheld \nsystem\u2014 wireless markup language (WML), a part of a larger standard,  wireless \naccess protocol (WAP). Later developments seem to indicate that standard browsers \ncan be modified to display standard Web pages on handheld systems. This is an area \nof active research. \n An additional protocol has been developed for sending short text messages when \na phone call is not appropriate. For example, it might be used when the recipient is in \na very noisy environment, in a lecture or arts performance, or in a meeting. IT can also \nbe used for short queries where a complex interaction is not needed. This protocol is \nthe  short message service,  or  SMS.  It allows the sending of messages up to 160 bytes \nlong. It can be used similarly to  instant messaging (IM)  services on normal PCs, but \nIM is typically interactive while SMS typically uses one-way messages.  \n 20.10.5 Location-aware applications \n Another obvious but still interesting facet of these systems is that they move around \nwith the user. After some time it became clear that there were some interesting appli-\ncations that could be created if the application knew where the phone was. The initial \nimpetus was probably the emergency location system that has been mandated for \ncell phones. In an emergency there is obviously a great benefit available if the cell \nphone can tell the emergency call handlers where the cell phone is located within a \nfew tens of meters. \nTABLE 20.4 Small Systems Device Families\nCell phone\nSmall vertical screen\nKeyboard with digits and a few buttons\nAlmost no user input\nApplication has full screen\nPDA\nLarger vertical screen\nStylus input and a few buttons\nLimited user data input\nApplication has full screen\nAdvanced\nLarger still horizontal screen\nFull QWERTY (usually) keyboard\nMore extensive user input\nApplication windows can overlap, etc.\nelm49810_ch20_469-482.indd   479\nelm49810_ch20_469-482.indd   479\n12/10/08   8:30:06 PM\n12/10/08   8:30:06 PM\n",
        "category": "Category"
    },
    {
        "id": "443",
        "title": "Title for Chunk 443",
        "content": "480 \nPart 6 Case Studies\n There are many other location-based applications that can be created as well. \nSince the cellular carriers in the United States were mandated to have the network \nable to locate the phone, they have decided to make lemonade out of those lemons by \ndevising services that they can offer to their users (for a modest fee, of course) based \non the current location of the phone. Where is the nearest pizza restaurant? Dial *1411 \n(or some similar special number) and a friendly operator will get your location from \nthe network, ask what you are looking for, search a location-indexed database for the \nnearest Chinese restaurant, and give you the information. Some of the other obvious \napplications are general driving directions, traffic reports, and weather reports. Of \ncourse, these systems can also be computerized, eliminating the human operator. \n An interesting question is, how does the phone (or the network) find out where \nthe phone is? One answer is the federal GPS system. There are a few dozen satellites \nthat are in orbit purely for this function. Initially they were installed for the benefit \nof the military, but since using the satellites merely involves listening to their broad-\ncasts, it was impossible to keep civilian uses out forever. By locating several satel-\nlites at one time any device can determine its present location, including altitude. \nThis is an extremely accurate mechanism, to within a few feet in many cases. How-\never, the hardware costs are still somewhat high compared to most of the rest of the \nphone. Fortunately, there are at least two other ways to find the location of a phone. \nThe first is just triangulation of the phone by the network. All the cells that can hear \nthe phone will report the timing of the signals from the phone and the network will \nbe able to locate the phone within a hundred feet or so. This is not accurate enough \nto drive a car, but it is usually accurate enough to locate the nearest post office, for \nexample. The other location mechanism is for the network merely to report which \ncell is currently servicing the mobile device and perhaps a distance from the tower \nbased on signal propagation times. Although this method is even less accurate than \nthe triangulation, it is still accurate enough for many purposes. \n 20.10.6 Later Palm OS releases \n Beginning with release 5 the Palm OS supports an ARM processor instead of the \nMotorola CPU used in previous platforms. Beginning with the 5.4 release the PAI \ncame to be known as Garnet. The PalmSource company that had been spun off of \nPalm Inc. was purchased by a Access Co. Ltd. They have created a release of Linux \nwith the Garnet API for use on mobile platforms. The latest release of Palm OS was \nversion 6. It is named Cobalt. \n 20.11 SUMMARY \n In this chapter, we discussed further the features and \nconcepts of a simple modern OS\u2014the Palm Operat-\ning System \u2122 developed by Palm, Inc. This OS was \ndeveloped for small handheld devices. Although this \nis a single-user system, it can concurrently run some \nOS processes and a small number of applications. \n We started this chapter with a recap of the pro-\ncess scheduling and memory management functions \nof the OS. We then followed this by discussing sev-\neral additional I/O subsystems in the Palm OS, GUI \nand network programming, and by explaining the \nprocess of developing programs for these limited \n",
        "category": "Category"
    },
    {
        "id": "444",
        "title": "Title for Chunk 444",
        "content": " \nChapter 20  Palm OS: A Class Case Study  \n481\nenvironments using simulators and cross-compilers \non larger systems. We continued with a discussion \nof some similar OSs for limited environments and \nhow they differ from the Palm OS, including later \nversions of the Palm OS itself, actually a different \nOS for a different CPU. We further discussed some \nof the new types of applications emerging from the \nconvergence of PDA and cell phone platforms. \n BIBLIOGRAPHY \n Exploring Palm OS: Palm OS File Formats, Document \nNumber 3120-002. Sunnyvale, CA: PalmSource, \nInc., 2004. \n Exploring Palm OS: System Management, Document \nNumber 3110-002. Sunnyvale, CA: PalmSource, \nInc., 2004. \n Palm OS Programmer\u2019s Companion, Volume 1, \nDocument Number 3120-002. Sunnyvale, \nCA: Palm, Inc., 2001. \n Palm OS Programmer\u2019s Companion, Volume 2, \nCommunications, Document Number 3005-002. \nSunnyvale, CA: Palm, Inc., 2001. \n Palm OS \u00ae Programmer\u2019s API Reference, Document \nNumber 3003-004. Sunnyvale, CA: Palm, Inc., 2001.  \n Rhodes, N., and McKeehan, J.  Palm Programming: The \nDeveloper\u2019s Guide.  Sebastopol, CA: O\u2019Reilly & \nAssociates, Inc., 2000.  \n SONY Cli\u00e9, Personal Entertainment Organizer, Sony \nCorporation, 2001.  \n WEB RESOURCES \n http://www.accessdevnet.com (ACCESS Linux Platform \nDevelopment Suite) \n http://www.freescale.com \n http://www.freewarepalm.com (free Palm software) \n http://www.freesoft.org/CIE/ ( Connected: An Internet \nEncyclopedia ) \n http://www.imc.org/pdi/  \n http://oasis.palm.com/dev/palmos40-docs/\nmemory%20architecture.html \n http://www.palm.com (Palm home page) \n http://www.palmsource.com/developers/ \n http://www.pocketgear.com/en_US/html/index.jsp \n(software for mobile devices) \n http://prc-tools.sourceforge.net (programming tools \nsupporting for Palm OS) \n http://www.symbian.com (Symbian OS) \n http://www.w3.org/Protocols/ (HTTP, primarily) \n http://en.wikipedia.org/wiki/Graffiti_2 (article on Graffiti 2) \n http://en.wikipedia.org/wiki/Palm_OS (history of the \nPalm OS versions)  \n REVIEW QUESTIONS \n 20.1 Since almost no websites are developed with the \nassumption that the screen size is 160  \ufffd 160 pix-\nels, of what use is the HTTP protocol support? \n 20.2 What does a Palm device need a RAM disk \ndriver for? \n 20.3 How does a programmer go about creating and \ntesting programs for the kind of handheld plat-\nforms discussed in this chapter? \n 20.4 What are some of the new device types and fea-\ntures that have been added to the Palm platform \nsince the earlier models and what sorts of applica-\ntions do they facilitate? \n 20.5 What is a vCard? \n 20.6 What is a \u201clocation aware application?\u201d  \n 20.7 Describe the three different families of handheld \nsystems. \n 20.8 One of the major differences between a cell phone \nand a PDA is that a PDA is turned off and on and \na cell phone usually stays on most of the time. \nWhat major feature did this force to be included \ninto OSs designed for cell phones? \n",
        "category": "Category"
    },
    {
        "id": "445",
        "title": "Title for Chunk 445",
        "content": "elm49810_ch20_469-482.indd   482\nelm49810_ch20_469-482.indd   482\n12/10/08   8:30:07 PM\n12/10/08   8:30:07 PM\n",
        "category": "Category"
    },
    {
        "id": "446",
        "title": "Title for Chunk 446",
        "content": "Confirming Pages\n209\n Chapter \n Chapter  10 \n 10 \n Basic Memory \nManagement  \nIn this chapter \n 10.1 Introduction: Why Manage Primary Memory? 209\n 10.2 Binding Model: Steps in the Development Cycle 210\n 10.3 A Single Process 211\n 10.4 Multiple Processes with a Fixed Number of Processes  216\n 10.5 Multiple Processes with a Variable Number of Processes 218\n 10.6 Summary 223\n10.1 INTRODUCTION: WHY MANAGE PRIMARY MEMORY? \n In the last two chapters we discussed one of the main jobs that an OS has to do: man-\naging processes running on the CPU. In this chapter we discuss the second main job \nof the OS: managing primary memory. As with all system resources, the OS attempts \nto manage the primary memory of the system. Usually primary memory is random \naccess memory (RAM) made of electronic circuits.  1 The basic goal of memory man-\nagement is to allow as many processes to be running as possible. The OS provides \nAPI functions to allow us to allocate, access, and return memory. When memory is \nallocated to processes, the OS must keep track of which parts of the memory are \nfree, which parts are allocated, and to which processes they are allocated. The OS \nsometimes may also preempt memory from processes. In this case it must be pre-\npared to save the current contents of the primary memory on secondary memory, to \ntrack where the contents are stored for each part of each process, and to restore the \ncontents of primary memory when the preempted process is resumed. \n1 Systems have been built with other types of primary memory. Early systems used acoustic waves in \ntanks of mercury or rotating drums, for example. For some years almost all computer systems used the \npolarity of magnetization in iron oxide cores to store bits. The phrase \u201ccore dump\u201d\u2014a printout of the \ncontents of the memory allocated to a program that had crashed\u2014comes from this era. This memory had \nthe property that it retained its contents even when the power was turned off. This strikes us as a peculiar \nproperty today since we normally presume that primary memories are volatile. \nelm49810_ch10_209-224.indd   209\nelm49810_ch10_209-224.indd   209\n12/11/08   7:36:56 PM\n12/11/08   7:36:56 PM\n",
        "category": "Category"
    },
    {
        "id": "447",
        "title": "Title for Chunk 447",
        "content": "Confirming Pages\n210 \nPart 3 CPU and Memory Management\n In most situations the OS will try to manage memory in ways that are transparent \nto the application. However, we note later in the next chapter that in some cases the \ntransparency is not complete. Naive use of memory services can sometimes cause prob-\nlems for a large system that is trying to optimize performance. Indeed, one of the main \nreasons we study OSs is to gain the information and understanding necessary to get past \nsuch problems. \n Having discussed why we want to manage memory, in Section 10.2 we show the \ntraditional model of the cycle of developing and running a process and the steps in \nthe binding of a reference to an item in a program to the physical memory location \nwhere that item is stored. We later use these steps to explain the various memory \nmanagement mechanisms. We then discuss memory management in progressively \nmore complex situations, starting with a single process in Section 10.3 and discuss-\ning such aspects as relocation and overlays. We then move to situations where mul-\ntiple processes are involved, again discussing gradually more complex mechanisms, \nincluding operating with a fixed number of processes in Section 10.4 and with a vari-\nable number of processes in Section 10.5. We end with a summary of the chapter. \n 10.2 BINDING MODEL: STEPS IN THE DEVELOPMENT CYCLE \n First, let us describe the standard model of the steps of building an application, loading \nit into memory, and running it. In the later sections of the chapter we use this model to \nexplain the common features of how an OS manages the way a process uses memory. \n There are really five steps in the sequence of events that result in a process in \nexecution in memory. First, we write (or  code ) the program. Usually this is done \nwith some symbolic language, either a lower-level assembly language or a higher-\nlevel problem-oriented language. Second, we use a translator program (usually an \nassembler or a compiler but occasionally an interpreter) to  translate this symbolic \nprogram into a sequence of instructions for the target machine, creating an \u201cobject \nmodule.\u201d Normally this object module is not ready to run yet. In the third step, we \n link that module with similar modules that were created separately. Those modules \nmight be other modules we created. They may also be library modules that we pur-\nchased or that came with the OS. Fourth, we  load the program into memory, and \nfifth we actually  run the program. \n A word of caution about the names of these steps: Historically there have been \nmany different software packages designed to assist a programmer in implementing \na program. Because different systems were used to solve different problems in dif-\nferent environments, the capabilities of some of these steps have sometimes been \ncombined into a single model. The function we described as combining the modules \ntogether is most often called  linking and the function of bringing the process into \nmemory is usually called  loading. Sometimes, however, these functions have been \ndone in one step. In other literature you may see either word used to describe either \nstep or to a combination of both of these steps at one time. \n Let us suppose that we are creating a process that consists of two modules. We \nhave a main procedure that we call a subroutine named XYZ that we have written \nearlier. As we go through progressively more complex models, the idea we focus on \nelm49810_ch10_209-224.indd   210\nelm49810_ch10_209-224.indd   210\n12/11/08   7:36:59 PM\n12/11/08   7:36:59 PM\n",
        "category": "Category"
    },
    {
        "id": "448",
        "title": "Title for Chunk 448",
        "content": "Confirming Pages\n \nChapter 10  Basic Memory Management  \n211\nis a question of  binding.  Binding is the process of determining where in the physical \nmemory the subroutine should go and making the reference in the main routine point \nto the subroutine. However, binding occurs with all references to items that are not a \npart of our main program, not just with subroutines, but including data items as well.   \n 10.3 A SINGLE PROCESS \n 10.3.1 Binding at coding time \n In a very simple environment like an embedded system with a very tiny BIOS, we \nmight manually decide where each piece of the program was going to go. We might \nput the main module at location 100 and the subroutine XYZ at location 500. If we \ncoded the main module in assembly language we might include assembler directive \nlike  ORG 100 and in the subroutine we might include an  ORG 500. These direc-\ntives cause the assembler to generate code that absolutely references these memory \naddresses. In our main module we would know that the subroutine XYZ was going \nto be at address 500, so instead of issuing a call to XYZ we could actually issue the \ncall to location 500. In this case we have made the binding decision during the cod-\ning step and have told the assembler of this through the ORG directives. As unlikely \nas this might seem to us today, it is by no means an extreme example of early bind-\ning. Here are three extreme examples: \n When computers were first developed, and again when minicomputers and personal \ncomputers were first developed, the first systems had very little software and few \nperipherals. Programmers not only assigned the addresses manually, they wrote the \nprograms in machine language and even entered them into the memory manually \nby manipulating switches and buttons on the front panel of the machines. In some \nmachines there were peripheral devices that used a fixed memory address as a buffer \nso that the programmer did not even have a choice. Needless to say, having pro-\ngrammers allocate memory manually was error-prone and time-consuming. It was a \nphase that didn\u2019t last long. \n The IBM 650 had a primary memory that was a rotating drum. The instructions \ntook a variable amount of time to execute. While the instruction was executing, of \ncourse, the drum continued to rotate. As a result, each instruction included a field \nthat gave the address of the next instruction. The programmer had to try to optimize \nthe program by placing the next instruction in the location that would be coming up \nnext under the drum\u2019s read head when the current instruction finished. Obviously \nthat phase didn\u2019t last long either. An assembler called SOAP, Symbolic Optimizing \nAssembler Program, was developed at Columbia University. Its main job was the \noptimum placement of the instructions on the drum. \n When programs were routinely punched into cards and no magnetic tapes or \nrotating memories were available, it was a fairly complex process to load the assem-\nbler program into memory, feed in the source program, obtain an object module \npunched into cards, load the linker program into memory, feed that object module to \nthe linker, punch out an executable program, and finally load the object program into \nthe computer and run it. As a result, it was common to  patch executable programs \nthat had been punched into cards. The assembler listings included the machine lan-\nguage that was output for each instruction. This allowed the programmer to find the \nelm49810_ch10_209-224.indd   211\nelm49810_ch10_209-224.indd   211\n12/11/08   7:36:59 PM\n12/11/08   7:36:59 PM\n",
        "category": "Category"
    },
    {
        "id": "449",
        "title": "Title for Chunk 449",
        "content": "Confirming Pages\n212 \nPart 3 CPU and Memory Management\ncard containing an incorrect instruction, load it into a keypunch, and fix the program \nby changing the machine language. Unfortunately, that practice did continue for \nsome time, and it was also error-prone. Programmers would insert multiple patches \nin a card deck. Eventually the number of patches would become unwieldy, so the \nprogrammer would go back to the source deck, make all the changes to the source \nprogram, and do the reassembly. Unfortunately, it was all too easy to miss one of \nthe changes to the source, so it was not uncommon to find oneself fixing bugs in the \nsource code that one had already fixed with a patch.  \n 10.3.2 Binding at linking time \n In the environment of CP/M, all programs were supposed to start at location 100, so \nwe might include the ORG 100 statement in the main module. However, we prob-\nably did not care where subroutine XYZ ended up, so in our main routine we use the \nsymbolic name XYZ. When the assembler outputs our object module, it includes all \nof our instructions and data, but it also includes information that will tell the linker \nprogram that we have some references that it needs to fix up, or link. After the linker \nprocesses our main routine it will have a list of names that it needs to resolve. It \nwill then begin to process other modules we told it to include. As it includes these \nmodules in the load step, it will find in those modules the names that were defined \nin them. In this case, \u201cXYZ\u201d will be defined in one of the modules that we tell the \nlinker to process. When the linker figures out where the module XYZ will reside \nin our address space, it will go back and link (or bind) the references in the main \nmodule to the addresses in the subroutine module. Now we have made the binding \ndecision at link time rather than at coding time. Notice that when we put off the bind-\ning until a later step we gain somewhat in flexibility. If we decided at coding time \nto put module XYZ at location 500 and we later found that we needed to move it to \nsome other location, we have to go to a lot of trouble to change all the references to \nthat address. Letting the linker decide where to put the module makes it easier. How-\never, we pay a little for the increased flexibility. In this case we are carrying around \nextra information in the object modules that define the names and the references to \nthe names, and we spend a little extra time in the link step while it does the binding. \nAs computers have gotten bigger and faster, however, this extra time and space has \nbecome such a small price to pay that we most likely don\u2019t even give it a thought. \n 10.3.3 A single process \n In the CP/M environment, the OS resided at the top of memory. Application programs \nstarted at location 100 to avoid the interrupt vector in low memory, and grew upward. \nUnfortunately, as the operating system grew (and it always does) it might eventually \nget so big that an upgraded OS might be using the memory that was needed by a \nprogram that had been running fine before the upgrade. It would now crash and it was \nprobably not obvious what the problem was. MS-DOS, therefore, took a different \ntack: The OS was loaded into low RAM and the program was loaded above it. When \nthe application tried to load, if there was enough memory left over, then the program \nwould load and run. If not, then at least the failure was clearly defined. Initially, when \none created an application program under MS-DOS, one linked the program to run \nelm49810_ch10_209-224.indd   212\nelm49810_ch10_209-224.indd   212\n12/11/08   7:36:59 PM\n12/11/08   7:36:59 PM\n",
        "category": "Category"
    },
    {
        "id": "450",
        "title": "Title for Chunk 450",
        "content": "Confirming Pages\n \nChapter 10  Basic Memory Management  \n213\non a specific release of the OS. This step defined the address of the service routines in \nthe OS and the address at which the application should begin loading. Unfortunately, \nthis meant that when a release of MS-DOS came out that changed the absolute size of \nthe resident OS, all applications had to be relinked to run on the new release. \n Many mainframe OSs had similar architecture, but they employed additional hard-\nware to protect themselves. In  Figure 10.1  we see a typical early OS architecture for \na mainframe that ran only a single process. The executable program would be created \nto reside at a particular address that was above the OS kernel. In addition, a  base reg-\nister would be loaded with an address below which the executable program could not \naddress. If the program did reference memory below this address, an interrupt would \nbe generated and the program would be terminated. Such systems still had the problem \nthat if the OS grew then the programs had to be linked with new addresses. The solu-\ntion to this problem was to change the function of the base register somewhat.  \n 10.3.4 Dynamic relocation \n This change in function also resulted in a change in name. What had been called a \nbase register was now called a  relocation register, as shown in  Figure 10.2 . The \nvalue loaded into the register was no longer a limit. Instead, the executable program \nwas created to act as though it were located at address 0, and the value in the reloca-\ntion register was added to every memory reference made by the program. Now the \nprogram did not have to be relinked every time the OS changed since every memory \nreference is automatically relocated as the program runs. \nApplication\nProgram\nResident\nMonitor\nhigh memory\nlow memory\nBase Register\nFIGURE 10.1 \nA single-process OS.\nApplication\nProgram\nApplication\nProgram\nResident\nMonitor\nhigh memory\nlow memory\nPhysical address \n10000\nLogical\naddress 0\nRelocation\nRegister\nFIGURE 10.2 \nA single-process \nOS with relocation \nhardware.\nelm49810_ch10_209-224.indd   213\nelm49810_ch10_209-224.indd   213\n12/11/08   7:37:00 PM\n12/11/08   7:37:00 PM\n",
        "category": "Category"
    },
    {
        "id": "451",
        "title": "Title for Chunk 451",
        "content": "Confirming Pages\n214 \nPart 3 CPU and Memory Management\n 10.3.5 Physical RAM space versus logical RAM space \n This new relocation function introduces an important concept: the difference between \nthe logical address space and the physical address space. Originally when we com-\npiled a program we created a program that was to be loaded into RAM at the address \nthat was assigned to it either in the translation step or the linking step. The execut-\nable program was compiled to reference a range of addresses that corresponded one \nto one with the actual physical memory addresses. Though it was not clear at this \npoint in the evolution of the hardware, there were actually two different address \nspaces in use. The first address space is the set of addresses that the CPU would gen-\nerate as the program executed. This address space is called a  logical address space. \nWe loaded the executable program into the primary memory. The set of addresses \nused to access this memory is known as the  physical address space. When we intro-\nduced the relocation register it became clear that the program\u2019s logical address space \nand its physical address space were different. We see this illustrated in  Figure 10.2 . \nThe executable program on the disk was created so that it generated addresses with \na low address of zero. But when it was located into memory it was actually loaded \ninto physical memory address 10000. The memory address hardware dynamically \nrelocated the logical addresses generated by the program as it ran, and by adding the \nvalue in the relocation register it mapped the logical address space into the physical \naddress space.  Figure 10.3  shows a more specific example of the process. The appli-\ncation as it is running in the CPU generates a memory reference. This might be the \naddress of the next instruction in the program, a subroutine call, a reference to a data \nitem, or many other things. In this case the reference is to address 456 in the logical \naddress space of the program. The OS, however, has loaded the relocation register \nwith the physical address of the start of the program, in this case 10000. The memory \nhardware adds the value in the relocation register to the logical address and generates \nthe physical address of 10456. \n 10.3.6 Programs larger than memory \n As time has gone by, RAM has gotten much cheaper. But at one point primary mem-\nory was a very large part of the total price of a system. As a result, most early sys-\ntems had fairly small primary memories. It was quite common to have a mainframe, \nminicomputer, or early microprocessor with a primary memory measured in Kilo-\nwords or Kilobytes rather than Gigabytes. Programmers spent a lot of time trying \nCPU\n10000\n10456\n456\nRelocation\nRegister\nPhysical address\nLogical address\nFIGURE 10.3 \nThe memory \naddress hardware \ndynamically maps \nthe logical address \nspace into the \nphysical address \nspace.\nelm49810_ch10_209-224.indd   214\nelm49810_ch10_209-224.indd   214\n12/11/08   7:37:00 PM\n12/11/08   7:37:00 PM\n",
        "category": "Category"
    },
    {
        "id": "452",
        "title": "Title for Chunk 452",
        "content": "Confirming Pages\n \nChapter 10  Basic Memory Management  \n215\nto squeeze more function or more information into very small memories. It was this \npressure that lead to the Y2K problem, for example. Since it was going to be 30 years \nor so before years started with anything but \u201c19,\u201d why waste memory on storing \nthose two extra digits in every date? Today we may still have to deal with embedded \nsystems that have limited primary memory. But typically this is now done for rea-\nsons of space or power requirements, not because of the price of the memory. \n 10.3.7 Overlays \n Programmers often needed to add functions to programs that ran in these small \nmemories. It was (and still is) fairly common to have a program that has three parts: \nan initialization phase, a main computation loop, and some final reporting phase. \nProgrammers realized that these parts of a program didn\u2019t need to be in memory at \nthe same time, so they decided to let these parts of the program  overlay one another \nin memory.  Figure 10.4  shows such a program. The main portion of the program is \njust a series of calls to subroutines that implement the three phases, perhaps \u201cinit,\u201d \n\u201cmain-loop,\u201d and \u201cwrap-up.\u201d OS function calls would be added to the program to \nload the appropriate subroutine before the call was made. The main portion was \nalways in memory and the other phases were brought in before they were called. In \nelaborate interactive systems this could get to be a bit tricky. A simple program like \nan assembler or compiler might easily fit into memory without using overlays, but \nhaving it broken into phases allowed the translator to process larger source programs \nin a given memory space. \n 10.3.8 Swapping \n As the price of main memory began to fall relative to the rest of the machine, the \nadministrators of the machine looked at what was going on and realized that with \nonly one program running they were not getting very good utilization of their very \nexpensive system. Some programs would do a little I/O and compute for a long time \nand others would mainly do I/O with very little CPU execution because the program \n\u201cinit\u201d\n\u201cinit\u201d\n\u201cmain-loop\u201d\n\u201cwrap-up\u201d\nCall \u201cload\u201d (\u201cinit\u201d) \nCall \u201cinit\u201d\nCall \u201cload\u201d (\u201cmain-loop\u201d)\nCall \u201cmain-loop\u201d\nCall \u201cload\u201d (\u201cwrap-up\u201d)\nCall \u201cwrap-up\u201d\nResident\nMonitor\nApplication\nProgram\nMain\nportion\nFIGURE 10.4 \nA program with \noverlays.\nelm49810_ch10_209-224.indd   215\nelm49810_ch10_209-224.indd   215\n12/11/08   7:37:00 PM\n12/11/08   7:37:00 PM\n",
        "category": "Category"
    },
    {
        "id": "453",
        "title": "Title for Chunk 453",
        "content": "Confirming Pages\n216 \nPart 3 CPU and Memory Management\nwas always waiting on the I/O to complete. Some techniques like SPOOLing grew \nout of this situation. In a single-process batch system the OS could read in the cards \nthat contained the next programs to be run and the associated data and store them on \nthe disk. This reading would be overlapped with the execution of the current job. As \nthe job tried to print its output the print lines would be stored in a disk file and the \nactual printing would be overlapped with the processing of the following jobs. \n But in the long run it was realized that even SPOOLing was not enough\u2014there \nwas still much waste in lost CPU cycles and lost I/O time. It began to look like the \nsolution was to run several programs at the same time. Hopefully, some would be \ncomputing while others were doing I/O and the whole machine would stay busier. \nThis was quite desirable when the machines cost a million dollars. By this point in the \nhistory of computing most systems had a secondary memory comprised of magnetic \ndisks or drums. The first technique was to keep several programs running by  swap-\nping them out. This worked as shown in  Figure 10.5 . The figure shows program A \nrunning in the main memory. This program calls for a line to be printed on the printer, \nan operation that will take hundredths of a second at least. In this time we can do a \nlot of disk I/O and a lot of computing, so we would swap program A out by writing \nthe contents of the primary memory to the disk and swap in program B. We would let \nit run until it issued an I/O to a slow device and then we would swap it back out and \nbring back in program A. Swapping is sometimes called  roll-out/roll-in. Obviously \nthe time to wait on the I/O operation must be greater than the time for the swap, but \nwith direct memory access hardware swapping a contiguous block of memory can be \nvery fast and places little overhead on the CPU.  \n 10.4 MULTIPLE PROCESSES WITH A FIXED NUMBER \nOF PROCESSES \n Even the technique of swapping was not enough however, and the owners of these \nexpensive machines wanted to get more work done for the money they were spend-\ning. So the OS designers began to search for better ways to organize the processing. \nProgram A\nResident\nMonitor\nApplication\nProgram\nProgram A\nProgram B\nProgram C\nFIGURE 10.5 \nAn OS with \nswapping.\nelm49810_ch10_209-224.indd   216\nelm49810_ch10_209-224.indd   216\n12/11/08   7:37:01 PM\n12/11/08   7:37:01 PM\n",
        "category": "Category"
    },
    {
        "id": "454",
        "title": "Title for Chunk 454",
        "content": "Confirming Pages\n \nChapter 10  Basic Memory Management  \n217\nPrimary memory was continuing to get cheaper, so they began thinking about ways \nto keep multiple programs in primary memory and run more than one by alternat-\ning between them without swapping them out\u2014swapping being an operation that \nrequires lots of resources. Eventually they realized that the relocation register could \nrun a program anywhere, not only at the top of the resident OS. So they moved to an \nOS memory organization like that shown in  Figure 10.6a . At first the base register \nhad been used to keep applications from harming the OS. Then the use of this regis-\nter was changed to a relocation register, primarily to solve the problem of the growth \nof the OS. Now when the OS is running multiple programs and one program does an \nI/O operation to some slow device, the OS simply puts the memory address of the \nsecond program in the relocation register and starts to run the second program. This \nsituation is shown in  Figure 10.6b . (It does more than that, but here we are focused \njust on the memory aspects.) \n At this point we progressed to where there were other applications running in the \nprimary memory, so it was necessary to fix things so that the applications couldn\u2019t \nharm one another. The solution was to add a limit register that would establish an \nupper bound beyond which a program could not address, just as it couldn\u2019t address \nbelow the relocation register setting. One might expect that this would be simply \nanother register that contained the high address, but for reasons we address later it \nis almost universally true that this register instead contains the size of the program \nrather than the high address. The hardware adds this address to the relocation address \non the fly to establish the upper bound. As with the lower bound, if the program tries \nto access memory beyond the limit set by the limit register, the hardware will gener-\nate an addressing error interrupt and the OS will abort the application. So when the \nOS shifts from running one program to another it must now set both the relocation \nregister and the limit register. \n 10.4.1 Internal fragmentation \n When this type of OS is installed the administrator will decide how much memory to \nset aside for each program area, or  partition. The OS will not change the size of these \npartitions as the system runs. With the earlier OS models a program might not use all \nof the memory. If it didn\u2019t use it all then we didn\u2019t worry about it. Now the OS is try-\ning to put more programs into the same memory. If we have set aside 100 KB for each \npartition and we want to run a program that only needs 6 KB, then we are wasting the \nrest of the space in that partition. This unused space is called internal fragmentation \nApplication\nProgram 2\nhigh memory\nlow memory\n(a) Application 1 running\n(b) Application 2 running\nRelocation Register\nLimit Register\nApplication\nProgram 1\nResident\nMonitor\nApplication\nProgram 2\nApplication\nProgram 1\nResident\nMonitor\nFIGURE 10.6 \nA multiple-process \nOS with a fixed \nnumber of \nprocesses.\nelm49810_ch10_209-224.indd   217\nelm49810_ch10_209-224.indd   217\n12/11/08   7:37:01 PM\n12/11/08   7:37:01 PM\n",
        "category": "Category"
    },
    {
        "id": "455",
        "title": "Title for Chunk 455",
        "content": "Confirming Pages\n218 \nPart 3 CPU and Memory Management\nand is shown in  Figure 10.7 . We might set up a small partition or two to run small \nquick jobs and a larger partition or two for our big applications. This would tend to \nminimize the space wasted due to internal fragmentation. If the administrator is clever \nabout setting up the partition sizes, then the programs that are running will come close \nto filling primary memory and we will have a better chance of keeping that expensive \nhardware fully utilized.  \n 10.4.2 Time Sharing \n Another case where swapping is utilized is in systems that are designed to support \nmany users at terminals in a mode called  time sharing. When users are interactively \nediting programs and testing them, the vast majority of the time that process is wait-\ning on the user at the terminal. In this case the system can swap out the process \nwhile the user is thinking or keying. In the case that was described in Section 10.3 \nthere was only one partition and thus only one process actually executing. Any other \nprocesses could be swapped out to secondary storage. In the case of time sharing \nit is more likely that we will have several partitions, perhaps even many partitions. \nWe might keep in memory only the ones that are not waiting for the user to finish \nentering a line and are either running, ready to run, or waiting on something other \nthan terminal I/O. The fixed size of the partitions wastes memory, of course. Recall \nthe internal fragmentation that we just discussed. In that case we only had fragmen-\ntation of a single partition. Now we have internal fragmentation in every partition. \nWe would like to be able to use those fragments. If we saved enough memory then \nmaybe we could run another program and keep the CPU busier. Although these tech-\nniques worked well enough for the time, modern time-sharing systems generally use \ntechniques described in the next chapter. \n 10.5 MULTIPLE PROCESSES WITH A VARIABLE NUMBER \nOF PROCESSES \n A partial solution to that internal fragmentation is to not make the partitions fixed \nin size or in number. Instead, we use as much memory as we need to run a pro-\ngram. We require that a programmer estimate in advance of running the program the \nApplication\nProgram 1\nTop of\nApplication\nProgram 1\nInternal\nFragmentation\nResident\nMonitor\nPartition 1\nPartition 2\nFIGURE 10.7 \nInternal \nfragmentation.\nelm49810_ch10_209-224.indd   218\nelm49810_ch10_209-224.indd   218\n12/11/08   7:37:01 PM\n12/11/08   7:37:01 PM\n",
        "category": "Category"
    },
    {
        "id": "456",
        "title": "Title for Chunk 456",
        "content": "Confirming Pages\n \nChapter 10  Basic Memory Management  \n219\nmaximum amount of primary memory that the program will need. When we start \nthe program we allocate that much memory to the program. If the program tries to \nuse more memory than the programmer said it would, then the OS will end it with \nan error. When a program ends the OS will again make that memory available to \nrun another program. This space is normally referred to as a  hole, or sometimes an \n external fragment \u2014a block of memory that we are currently not using at all. In \n Figure 10.8a  we see a situation where the system is currently running four applica-\ntions. In  Figure 10.8b  we see that applications two and four have ended, so the holes \nwhere they were running are now available for use in running other programs. The \nOS usually keeps a list of the holes available. In  Figure 10.8c  we see that the OS has \nstarted application 5 in a part of the hole left where application 2 was running. There \nis now a smaller hole left over. \n Now suppose that the OS has another program to run and there are many holes \navailable to choose from. Which hole should the OS choose? As with most of the \nalgorithm classes we study in this book, the first algorithm is simply to scan through \nthe list of holes and use the first one we find that is big enough to run the program. \nThis algorithm is called  first fit. It has the advantage of being simple. But this may \nnot be the best choice. Another algorithm is to use the hole that is the smallest that \nwill fit the program we want to run. This algorithm is called  best fit. It has an intui-\ntive appeal\u2014we waste the smallest amount of primary memory. Unfortunately, this \nalgorithm requires that we either scan the entire list or keep the list in order by size. \nEither requires extra processing. \n But what if our average program needs 10 MB, we have a program to run that \nneeds 8 MB, and we have holes of 12 MB and 18 MB? If we use the 12 MB hole \nthen we will have a leftover hole of 4 MB and on average we will not be able to use \nit. If we use a part of the 18 MB hole then we will have a 10 MB hole left and we \nwill be able to use it, on average. So the next algorithm says that we should use the \nhole that is the  worst fit on the grounds that it leaves the biggest (and therefore most \nuseful) hole. Again, this algorithm requires that we either scan the entire list or keep \nit in order by size. \nApplication\nProgram 1\nApplication\nProgram 2\nApplication\nProgram 3\nApplication\nProgram 4\nResident\nMonitor\n(a) 4 jobs running\nApplication\nProgram 1\nApplication\nProgram 3\nunused\nunused\nunused\nResident\nMonitor\n(b) Jobs 2 and 4 ended\nApplication\nProgram 1\nApplication\nProgram 5\nApplication\nProgram 3\nResident\nMonitor\n(c) Jobs 5 goes in a hole\nunused\nFIGURE 10.8 \nA multiple-process \nOS with a variable \nnumber of \nprocesses.\nelm49810_ch10_209-224.indd   219\nelm49810_ch10_209-224.indd   219\n12/11/08   7:37:02 PM\n12/11/08   7:37:02 PM\n",
        "category": "Category"
    },
    {
        "id": "457",
        "title": "Title for Chunk 457",
        "content": "Confirming Pages\n220 \nPart 3 CPU and Memory Management\n A slight variation on the first fit algorithm is called  next fit.  In this variation we \ndo not start each search from the front of the list. We do not keep the list sorted, and \nwe always start the next search from where the last one left off. The first fit algorithm \nwill tend to break up the holes at the front of the list the most, so we will end up with \na bunch of small holes that we keep looking through but can seldom use. The next fit \nvariation will tend to distribute this fragmentation through the list. In practice, worst \nfit turns out to be worst. Either best fit or next fit are better, and next fit is very easy \nto implement. \n Now suppose that we have two holes that are each 5 MB and we have a process \nto run that says it may need 8 MB. We have 10 MB of free memory blocks in the two \nholes, enough free memory in total to run this process. But the free memory is not \nin one piece so we can\u2019t run the program. This situation is known as  external frag-\nmentation. Recall that our processes are relocatable\u2014they can run anywhere in the \nphysical memory because the memory hardware relocates their logical addressing \nspace dynamically as they run. So, it is possible to move a program in memory even \nafter it has started running. Normally, the process is suspended, moved to another \nlocation and restarted. The OS only has to change the value that is placed in the \nrelocation register to point to the start of the new location of the application in physi-\ncal memory. For example, in  Figure 10.9a , if the two holes (marked \u201cunused\u201d) were \ntogether big enough to run application 6, the OS could stop application 3, move it \nto the space just above application 5, and put that address in the relocation register \nwhenever application 3 was restarted, It could then start application 6 running in \nthe resulting larger hole. This result is shown in  Figure 10.9b  This process is called \n compaction. Naturally, the situation is usually much more complex than this simple \ncase, and often several programs have to be relocated to find a hole large enough to \nrun the program we want to run. One can appreciate that when the OS is moving pro-\ngrams around in memory, no work is being done on behalf of the applications. The \nOS is choosing to spend the CPU and memory bandwidth for the purpose of running \nmore jobs in parallel. \nunused\nApplication\nProgram 1\nApplication\nProgram 5\nApplication\nProgram 3\nResident\nMonitor\n(a) There is enough RAM for Application 6\nbut the holes are not contiguous\nunused\nunused\nApplication\nProgram 1\nApplication\nProgram 5\nApplication\nProgram 3\nRelocation\nRegister\nResident\nMonitor\n(b) Application 3 is relocated to\nbring the two holes together\nFIGURE 10.9 \nCompaction.\nelm49810_ch10_209-224.indd   220\nelm49810_ch10_209-224.indd   220\n12/11/08   7:37:02 PM\n12/11/08   7:37:02 PM\n",
        "category": "Category"
    },
    {
        "id": "458",
        "title": "Title for Chunk 458",
        "content": "Confirming Pages\n \nChapter 10  Basic Memory Management  \n221\n Now we can appreciate why the relocation hardware uses a length for an upper \nbound instead of using the upper end of the program. If it used the upper address then \nwhen we relocated a program we would also have to recompute the upper bound. \nThis is not an overwhelmingly complicated calculation, and it does not need to be \ndone all that often, but if the hardware can work just as well the other way then we \nare lucky not to have to do it. \n One complication in this process can be that the I/O hardware may not utilize \nthe relocation hardware. In other words, I/O is done using physical addresses rather \nthan logical addresses. This means that if a process has I/O pending, then we cannot \nmove it in memory. So processes that start I/O may have to be marked temporarily \nas unmovable. \n We also may still suffer from internal fragmentation. This comes about because \nour holes can keep getting smaller and smaller. It is not efficient for the OS to keep \ntrack of very small chunks of memory, so there is some minimum amount of mem-\nory that the OS will try to manage. It is common for this minimum to be in the range \nof 256 bytes to 4 KB. When the program starts it will be allocated a block of memory \nthat is an integral multiple of this minimum piece. On the average, any program will \nnot need half of its last piece, so it will go to waste\u2014internal fragmentation. \n 10.5.1 Dynamic loading \n With overlays we do not load the entire program into primary memory at one time. \nInstead, the programmer explicitly decides when to load the overlays and when \nto call the routines that are in the overlay. It is also possible for the system to do \nsomething similar. When the OS loads a program into main memory it might load \ninto memory only the main body of the program. To access various subroutines \nit might make use of a table that shows which routines are already loaded into \nmemory and which are not. Many programs follow roughly the \u201c80-20\u201d rule\u201480% \nof the code of a program is for situations that only happen 20% of the time. So if \nwe don\u2019t load the subroutines when the program first starts we might never need to \nload them at all. Therefore, the program starts somewhat faster. If the program later \ncalls the routine then we can load it at that time and we will have paid very little \npenalty for waiting\u2014a small bit of RAM for the table and a few extra instructions \nexecuted whenever we first call the routine.  \n 10.5.2 Dynamic link libraries \n We can, however, postpone the binding even a step further. We can put off even \nlinking the subroutine with the main module. In this case the library routine itself \ndoes not become a part of the executable program. Instead, we leave intact the sym-\nbolic reference to the library routine that was produced by the compiler. As with \ndynamic loading, if the routine is never referenced, then not only did we not bother \nto load it into memory, we didn\u2019t even bind the symbol to a logical address. We \nleave the subroutines in special libraries that are usually called dynamic link librar-\nies, or DLLs. In Linux and most other UNIX variants such libraries are referred to \nelm49810_ch10_209-224.indd   221\nelm49810_ch10_209-224.indd   221\n12/11/08   7:37:02 PM\n12/11/08   7:37:02 PM\n",
        "category": "Category"
    },
    {
        "id": "459",
        "title": "Title for Chunk 459",
        "content": "Confirming Pages\n222 \nPart 3 CPU and Memory Management\nas shared object libraries or dynamic libraries and normally have \u201c.so\u201d as a part of \ntheir name. When a subroutine in such a library is referenced, then the OS will load \nthe routine into memory and bind the link at program execution time. \n Notice that we get several other benefits from this mechanism at the same time:\n \ufffd Since the subroutines are not a part of the executable program, the program is \nsmaller so it take up less space on the disk drive and loads faster into RAM. \n \ufffd Normally, we will have many programs that use the same library modules. Some \nlibrary modules are so commonly used that they will be referred to by literally \nthousands of programs on the hard drive. Having only one copy of the code can \nsave us a lot of disk space. \n \ufffd If a bug is fixed in one of the library modules it is only necessary to fix the one \nlibrary routing and load it onto the system. This will automatically fix that bug \nin every program that references that DLL. \nThis last feature is a great boon to application software developers because it \nmeans that if a fix is made to a system library by the OS manufacturer, the appli-\ncation developer does not have to reload their application with the new libraries \nand redistribute the executable programs to every customer who is running that \nplatform. If the customer calls with a complaint related to a DLL provided by \nanother vendor, the application developer merely explains that the problem is in \nthe system libraries and that a fix is available in release x.y.z.1.5 of the library \nmodule, which is downloadable from the library vendor\u2019s website at . . . If the \napplication vendor is really lucky, the customer finds the problem in some other \napplication first and the fixed library is downloaded before the customer ever has \na problem with their application. \n Unfortunately, there is a problem with dynamic libraries. When the developer \nof a software package is using a particular set of functions in a DLL, their code \nmay also depend on bug fixes in a particular version of the library. They will \nwant to make sure that the set of functions and bug fixes they are using is in the \nversion of the library that is available on any system the package is installed on. \nSo the package installation can include a version that is at least as late as the one \nthe vendor developed with. Unfortunately, the target system may already include \na later version that was installed by another package that depends on functions \nor bug fixes in that version. Installing an older version would cause the already \ninstalled package to fail. The vendor of the package that suddenly quits work-\ning may be quite surprised to get the resulting request for support and will be \nunderstandably annoyed when the problem is finally resolved and time has been \nwasted solving a problem that is not related to anything their company did. Of \ncourse, the installation software is supposed to check to see that any DLL being \ninstalled is a newer version than the one already installed. Unfortunately, this is \nnot always done or may be done incorrectly. This problem is colloquially called \n DLL Hell. Newer OS releases allow an application to specify a version number \nfor a dynamic link library, so this problem is being minimized by allowing a sys-\ntem to carry multiple versions of a single library. This takes up some additional \nspace, but nowhere near as much as was consumed by having the library as a part \nof every application that used it.  \nelm49810_ch10_209-224.indd   222\nelm49810_ch10_209-224.indd   222\n12/11/08   7:37:02 PM\n12/11/08   7:37:02 PM\n",
        "category": "Category"
    },
    {
        "id": "460",
        "title": "Title for Chunk 460",
        "content": "Confirming Pages\n \nChapter 10  Basic Memory Management  \n223\n 10.6 SUMMARY \n In this chapter we discussed many ways that primary \nmemory can be managed by the OS. We began with \na discussion of why an OS manages memory, that \npurpose being to run programs that are larger than \nthe primary memory of the machine and to allow \nas many programs to be running as possible. We \nthen discussed the software development cycle as \nan aid to understanding the various possible times \nfor address binding. Next, we looked at progres-\nsively more complex memory models, beginning \nwith a single process and covering fixed and vari-\nable multiprocessing contiguous memory organiza-\ntions. Through this discussion we also focused on \nthe hardware required to support these OS tech-\nniques. We ended with a section that covered the \nadvantages and disadvantages of dynamic loading \nof routines. \n In the next chapter we discuss some modern \napproaches to solving the problems of memory \nmanagement through paging and segmentation. \n BIBLIOGRAPHY \n Daley, R. C., and J. B. Dennis, \u201cVirtual Memory, \nProcesses and Sharing in Multics,\u201d  CACM, Vol. 11, \nNo. 5, May 1968, pp. 306\u2013312. \n Dennis, J. B., \u201cSegmentation and the Design of \nMultiprogrammed Computer Systems,\u201d  Journal of \nthe ACM, Vol. 12, No. 4, October 1965, pp. 589\u2013602.  \n Kilburn, T., D. J. Howarth, R. B. Payne, and \nF. H. Sumner, \u201cThe Manchester University Atlas \nOperating System, Part I: Internal Organization,\u201d \n Computer Journal, Vol. 4, No. 3, October 1961, \npp. 222\u2013225. \n Knuth, D. E.,  The Art of Computer Programming: \nFundamental Algorithms, Vol. 1, 2nd ed. Reading, \nMA: Addison-Wesley, 1973. \n Organick, E. I.,  The Multics System: An Examination \nof Its Structure. Cambridge, MA: MIT Press, 1972.  \nThe bibliography for this chapter overlaps considerably \nwith the next chapter.\n REVIEW QUESTIONS \n 10.1 What is the fundamental reason an OS has to be \nconcerned with managing primary memory? \n 10.2 What are the five steps leading from the creation \nof a program to its execution in memory? \n 10.3 What is meant by the term \u201cbinding\u201d? \n 10.4 In which of the five steps listed in Question 10.2 \ncan binding be done? \n 10.5 What is the difference between a logical address-\ning space and a physical addressing space?   \n 10.6 Attempting to run several jobs at the same time \nwe created a few fixed partitions. We ran into a \nproblem of internal fragmentation. Describe this \nproblem. \n 10.7 An alternative to fixed partitions was to allow \nvariable partitions. This minimized the internal \nfragmentation but created a new problem\u2014that \nof external fragmentation. Describe this problem.  \n 10.8 What did we do about that external fragmentation?  \n 10.9 When running variable partitions we might have \nseveral holes that were big enough to run the next \njob we wanted to run. We listed four algorithms \nfor selecting the hole to use from among those \nlarge enough to run the process. Name and briefly \ndescribe those algorithms. \n 10.10 Describe the difference between dynamic loading \nand dynamic linking. \n 10.11 Dynamic linking has one huge advantage and a \nnumber of smaller ones. Name the huge one and a \ncouple of the little ones.  \nelm49810_ch10_209-224.indd   223\nelm49810_ch10_209-224.indd   223\n12/11/08   7:37:03 PM\n12/11/08   7:37:03 PM\n",
        "category": "Category"
    },
    {
        "id": "461",
        "title": "Title for Chunk 461",
        "content": "elm49810_ch10_209-224.indd   224\nelm49810_ch10_209-224.indd   224\n12/11/08   7:37:03 PM\n12/11/08   7:37:03 PM\n",
        "category": "Category"
    },
    {
        "id": "462",
        "title": "Title for Chunk 462",
        "content": "Confirming Pages\n3\n Chapter\n Chapter 1 1 \n Getting Started \n In this chapter: \n \n1.1 Introduction 4\n \n1.2 What Are Operating Systems All About? 5\n \n1.3 User versus System View of an OS 6\n \n1.4 Some OS Terms, Basic Concepts, and Illustrations 10\n \n1.5 A Small Historical Diversion 15\n \n1.6 Summary 17\n O\nperating systems are at the heart of every computer. The  Operating System\n(or  OS for short) provides services to users and programmers that make it \npossible to utilize a computer without having to deal with the low-level, dif-\nficult-to-use hardware commands. It provides relatively uniform interfaces to access \nthe extremely wide variety of devices that a computer interacts with, from input/\noutput devices such as printers and digital cameras, to wired and wireless network \ncomponents that allow computers to communicate. It allows users to create, manage, \nand organize different types of files. In addition, most modern OSs provide graphical \nuser interfaces (GUIs) to allow a relatively easy-to-use interface for computer users. \n In this opening chapter, we start in  Section 1.1  with a brief introduction to \nshow how important an Operating System is and how they are used not only in \ncomputers but also in many types of electronic devices that we all use in our \ndaily routines.  Section 1.2  is a more technical look at why even simple devices \ncontain an Operating System. Then in  Section 1.3  we discuss the different views \nof what an Operating System does by looking at the Operating System from two \nperspectives: the user\u2019s perspective and the system\u2019s perspective. We also discuss \nthe requirements that each type of user has for the Operating System.  Section 1.3  \nnext gives a few simple examples to illustrate some sequences of functions that \nan Operating System goes through to perform seemingly simple user requests. \nIn  Section 1.4  we present some basic terminology and concepts, and give some \nfigures to illustrate typical components for a simple Operating System. We give a \nbrief historical perspective in  Section 1.5  and conclude with a chapter summary \nin  Section 1.6 .  \nelm49810_ch01_001-018.indd   3\nelm49810_ch01_001-018.indd   3\n12/10/08   10:15:48 PM\n12/10/08   10:15:48 PM\n",
        "category": "Category"
    },
    {
        "id": "463",
        "title": "Title for Chunk 463",
        "content": "Confirming Pages\n4 \nPart 1 Operating Systems Overview and Background\n 1.1 INTRODUCTION \n For many years, OSs were viewed by most people as uninteresting\u2014except for \nOS programmers and computer \u201cnerds.\u201d Because of a number of high-profile cases, \nOSs have occasionally become front-page news in recent years. Suddenly, the OS \nis seen by some as controlling all computing. There are very strongly felt opinions \nabout what constitutes good versus bad OSs. There is also quite a bit of disagree-\nment about what functionality should be provided by the OS. While many people \n(and some courts!) believe that one company dominates the OS market, others say \nthat the OS is increasingly unimportant\u2014the  Internet browser  is the OS. In fact, \nthere is a very wide variety of types of OSs, and OSs exist at some level on every \nconceivable computing device, including some that may surprise many people. \n For example, handheld personal digital assistants ( PDA s) have very capable, \ncomplex, and flexible OSs. Most electronic devices that have some intelligence \nhave complex, yet easy-to-use OSs and system software to control them. The OS \nthat was once thought of as the arcane world of process management and memory \nmanagement techniques is now occasionally a conversation topic in caf\u00e9s, bars, \nand computer stores. Many people now seem to be experts\u2014or at least have an \nopinion\u2014on OSs. \n(Perhaps) Surprising places to find an OS:\nPersonal digital assistants\nCable TV controller boxes\nElectronic games\nCopiers\nFax machines\nRemote controls\nCellular telephones\nAutomobile engines\nDigital cameras\n While we also have our opinions, we try to get behind the hype\u2014generated \nby marketing and salespeople as well as millions of opinionated users\u2014in order \nto explain the real systems. We also throw in our own opinions when needed and \nexplain why we hold these beliefs. We give many examples of currently used sys-\ntems to demonstrate concepts and show what is good and bad about the various sys-\ntems. We try to avoid the so-called religious issues, such as: Which is the better OS: \n Windows or  Mac-OS? Or are  UNIX and its variations such as  Linux better than \nboth? Instead, we point out how these systems came about and what they provide to \nusers and programmers. \nelm49810_ch01_001-018.indd   4\nelm49810_ch01_001-018.indd   4\n12/10/08   10:15:53 PM\n12/10/08   10:15:53 PM\n",
        "category": "Category"
    },
    {
        "id": "464",
        "title": "Title for Chunk 464",
        "content": "Confirming Pages\n \nChapter 1 Getting Started \n5\n Increasingly, certain parts of the OS\u2014particularly those handling user and \napplication program interaction\u2014are visible to users and programmers and often \nmay be critical in marketing a computer or electronic\u2014or even mechanical\u2014\ndevice. Buyers are becoming very critical and have higher expectations of what the \nOS should provide them. More than ever before, the system must not only provide \nnew features and be easier to use but it must also support those old features and \napplications that we are used to. Of course, as we add new devices\u2014video devices \nand disks, high fidelity sound, and wireless networking, for example\u2014we want the \nsystem to easily adapt to and handle those devices. In fact, a good OS architecture \nshould even allow the connection of new devices that were not yet available and \nmay not even have been thought of when the OS was created!   \n 1.2 WHAT ARE OPERATING SYSTEMS ALL ABOUT? \n In this section, we give a simple example\u2014a simple handheld game system\u2014to \nillustrate some of the basic functionalities that an OS should provide. \n Think about a handheld electronic game system, one that is very cheap but has a \nsmall screen, a few buttons, and several games. Although this game system might not \nrequire an OS, it probably has one. The main reason is to consolidate the common \nfunctions needed by the various games installed on the game system. \n The games typically have some common parts. For example, each game needs to \nget some input from the buttons, and to display something on the screen. While those \nactions sound easy, they do require some not-so-simple software programming. Get-\nting the input from a button\u2014that sounds easy. Well, except that the user may push two \nbuttons at once\u2014what then? It is also likely that a cheap game does not use sophis-\nticated and expensive buttons, so there is electronic noise that may distort the signal \ncoming in\u2014how should the games deal with that? The easy solution is to handle each \nof these common issues in one, single place. For example, all button pushes can be read \nin, have any noise cleaned up, and so forth in a single software routine. Having a single \n read-the-button software routine has the advantage of providing a consistent user inter-\nface\u2014all games treat button input in the same way. It also allows the routine to occupy \nspace in only one place in system memory instead of occupying space in each individ-\nual game. And where should that  read-the-button software routine be placed? It should \nbe in the OS\u2014where every game that needs to read a button can call this routine. \n The OS should also handle unexpected events. For example, a user may quit a \ngame in the middle (when losing) and start another game. No reboot of the game sys-\ntem should be necessary. The user\u2019s need to switch from game to game (task to task) \nis natural and expected. In fact, users (5-year-olds) may push buttons at unexpected \ntimes and the screen should continue to be updated (refreshed) while the game is being \nplayed\u2014even while waiting for a button to be pushed. This is called  asynchronicity, \nwhich can be defined informally as the occurrence of events at random or unexpected \ntimes\u2014a very important feature in even simple systems like a handheld game. \n Several important OS concepts are part of this game system: When a game is \nstarted, some part of its software may be loaded into memory, whereas other parts \nelm49810_ch01_001-018.indd   5\nelm49810_ch01_001-018.indd   5\n12/10/08   10:15:53 PM\n12/10/08   10:15:53 PM\n",
        "category": "Category"
    },
    {
        "id": "465",
        "title": "Title for Chunk 465",
        "content": "Confirming Pages\n6 \nPart 1 Operating Systems Overview and Background\nmay have been preloaded in ROM (read-only memory) or fixed memory  1 ; dynamic \nmemory is reserved for use by the game and is initialized; timers may be set. All on \na cheap (but fun) game! What more does one expect from an OS?\n 1.3 USER VERSUS SYSTEM VIEW OF AN OS \n You have probably heard the old adage; \u201cThere are two sides to every question.\u201d \n(Maybe that should be \u201ctwo  or more sides.\u201d) The idea is that trying to look at some \nquestion from different perspectives often helps our understanding. One of the impor-\ntant methods to learning something new is to view it from different perspectives. For \nan OS, the two most important perspectives are the  user view and the  system view. \n The user view pertains to how users or programs\u2014programs are the main users \nof the OS\u2014utilize the OS; for example, how a program reads a keystroke. The sys-\ntem view pertains to how the OS software actually does the required action\u2014how it \ngets keystrokes, separates out special ones like  shift, and makes them available to the \nuser or program. We present OS facilities, concepts, and techniques from both user \nand system points of view throughout the book. First, we elaborate on the different \ntypes of users and their views of the OS. \n 1.3.1 Users\u2019 views and types of users \n The term  user is often too vague\u2014especially for persons whose role in computing \nis so critical\u2014so it is important to first describe the various types of users. Trying to \npin down the role of a user of an OS is not simple. There are various types of users. \nWe primarily want to distinguish among end users, application programmers, system \nprogrammers and system administrators.  Table 1.1  lists some of the most important \nconcerns about what the OS should provide for each of the three main types of users. \nOf course, there is some overlap among these concerns. We are merely trying to \nshow how those viewpoints sometimes diverge. Further complicating the issue is \nthat sometimes users fit into several of the roles or even all of them. Such users often \nfind themselves having conflicting needs. \n Application Users (or End Users) \u2014this group includes all of us, people who \nuse (or run) application or system programs. When we use a word processor, a web \nbrowser, an email system, or a multimedia viewer, we are a user of that application. \nAs users, we expect a quick, reliable response (to keystrokes or mouse movement), \na consistent user view (each type of command\u2014such as scrolling or quitting an \napplication\u2014should be done in a similar manner), and other features that depend on \neach specific type of OS. Other needs are listed in  Table 1.1 . In general, this group of \nusers is most often called simply  users, or sometimes  end users. \n Application Programmers \u2014this group includes the people who write appli-\ncation programs, such as word processors or email systems. Programmers are very \ndemanding of the OS: \u201cHow do I read and write to a file?\u201d, \u201cHow do I get a user\u2019s \nkeystroke?\u201d, and \u201cHow do I display this box?\u201d are typical questions programmers \n1 We define these terms in Chapters 2 and 3. \nelm49810_ch01_001-018.indd   6\nelm49810_ch01_001-018.indd   6\n12/10/08   10:15:54 PM\n12/10/08   10:15:54 PM\n",
        "category": "Category"
    },
    {
        "id": "466",
        "title": "Title for Chunk 466",
        "content": "Confirming Pages\n \nChapter 1 Getting Started \n7\nask when learning to use a new OS. The facilities that the OS provide are the pro-\ngrammers\u2019 view of the OS. Sometimes they are called system calls or an API (appli-\ncation program interface). They may also appear as language library functions or \nsometimes just as packages of classes. Programmers also want the software they \ndevelop to be easily ported to other platforms. \n Systems Programmers \u2014these are the people who write software\u2014either pro-\ngrams or components\u2014that is closely tied to the OS. A utility that shows the status \nof the computer\u2019s network connection or an installable driver for a piece of hardware \nare examples of systems programs. Systems programmers need to have a detailed \nunderstanding of the internal functioning of the OS. In many cases, systems pro-\ngrams need to access special OS data structures or privileged system calls. While OS \ndesigners sometimes are concerned with portability to other platforms, often they \nare not\u2014they are charged with developing a specific set of functions for a specific \nplatform and portability is not a concern. \nTABLE 1.1 Concerns of Various User Classes\nEnd Users\nEasy to use and learn\nAdapts to user\u2019s style of doing things\nLively response to input\nProvides lots of visual cues\nFree of unpleasant surprises (e.g., deleting a file without warning)\nUniform ways to do the same thing (e.g., moving an icon or scrolling down a \nwindow\u2014in different places)\nAlternative ways to do one thing (e.g., some users like to use the mouse, \nothers like to use the keyboard)\nApplication Programmers\nEasy to access low-level OS calls by programs (e.g., reading keystrokes, \ndrawing to the screen, getting mouse position)\nProvide a consistent programmer view of the system\nEasy to use higher-level OS facilities and services (e.g., creating new \nwindows, or reading from and writing to the network)\nPortability to other platforms\nSystems Programmers\nEasy to create correct programs\nEasy to debug incorrect programs\nEasy to maintain programs\nEasy to expand existing programs\nSystem Managers and \nAdministrators\nEasy addition or removal of devices such as disks, scanners, multimedia \naccessories, and network connections\nProvide OS security services to protect the users, system, and data files\nEasy to upgrade to new OS versions\nEasy to create and manage user accounts\nAverage response is good and predictable\nSystem is affordable\nelm49810_ch01_001-018.indd   7\nelm49810_ch01_001-018.indd   7\n12/10/08   10:15:54 PM\n12/10/08   10:15:54 PM\n",
        "category": "Category"
    },
    {
        "id": "467",
        "title": "Title for Chunk 467",
        "content": "Confirming Pages\n8 \nPart 1 Operating Systems Overview and Background\n System Administrators \u2014this group includes the people who manage computer \nfacilities, and hence are responsible for installing and upgrading the OS, as well as \nother systems programs and utilities. They are also responsible for creating and man-\naging user accounts, and for protecting the system. They need to have a detailed \nunderstanding of how the OS is installed and upgraded, and how it interacts with \nother programs and utilities. They must also understand the security and authoriza-\ntion features of the OS in order to protect their system and users effectively.  \n 1.3.2 System view \n The system view refers to  how the OS actually provides services. In other words, it \nrefers to the internal workings of the OS. This is a less common view. Often only a \nfew people, the OS designers and implementers, understand or care about the inter-\nnal workings of an OS. Indeed this information is often considered secret by com-\npanies that produce and sell OSs commercially. Sometimes the overall workings of \nmajor parts of the system\u2014management of files, running of programs, or handling \nof memory\u2014may be described to help programmers understand the use of those \nsubsystems. In some cases, the whole source code for an OS is available. Such sys-\ntems are known as  open source systems. 2 \n The majority of this book is concerned with the  how \u2014how does the system run \na program, create a file, or display a graphic. To understand the actual \u201chow\u201d\u2014the \ninternal details\u2014we describe algorithms and competing methods for implement-\ning OS functions. We now illustrate the system view (or views) with two examples: \ntracking mouse and cursor movement, and managing file operations. Although these \nexamples may seem a bit complex, they serve to illustrate how the OS is involved in \npractically all actions that are performed by a computer user. \n 1.3.3 An example: moving a mouse (and mouse cursor) \n While the movement of a mouse pointer (or cursor) on a screen by moving the \nmouse (or some other  pointing device  such as a pad or trackball) seems straightfor-\nward, it illustrates the many views of an OS.  Figure 1.1  illustrates this process. When \nthe pointing device is moved, it generates a hardware event called an  interrupt, \nwhich the OS handles. The OS notes the movements of the mouse in terms of some \nhardware-specific units\u2014that is, rather than millimeters or inches the readings are in \nnumber of pulses generated. This is the  low-level system view. The actual software \nreading the mouse movements is part of the OS, and is called a  mouse device driver. \nThis device driver reads the low-level mouse movement information and another \npart of the OS interprets it so that it can be converted into a  higher-level system \nview, such as screen coordinates reflecting the mouse movements. \n On the \u201cother side\u201d or view is the question, What does the user see? The  user\u2019s \nview is that the cursor will smoothly move on the screen and that as the mouse moves \ngreater distances faster, the screen movement will appear faster too. In between these \n2 The Linux OS is a well-known example of an open source operating system. \nelm49810_ch01_001-018.indd   8\nelm49810_ch01_001-018.indd   8\n12/10/08   10:15:54 PM\n12/10/08   10:15:54 PM\n",
        "category": "Category"
    },
    {
        "id": "468",
        "title": "Title for Chunk 468",
        "content": "Confirming Pages\n \nChapter 1 Getting Started \n9\nviews is the  application programmers\u2019 view, How do I get the mouse movement \ninformation in order to use it and display it in my application? Another issue is how \nthis information on mouse movements is presented to the application programmer. \nThis is the higher-level system view mentioned earlier. \n And to complete these views a bit let us return to the system\u2019s view, Which \napplication gets this mouse movement if there are multiple open windows? The \nmouse movements may need to be queued up if there are multiple movements \nbefore the application retrieves them. The movements may even be lost if the OS \nis busy doing other things\u2014for example, loading a Web page through a network \nconnection\u2014and cannot receive the device driver\u2019s input in a timely manner. \n 1.3.4 Another (bigger) example: Files \n Sometimes the most critical  end user\u2019s view of an OS is the file system\u2014in particu-\nlar, file names. Can file names contain spaces? How long can they be? Are upper- \nand lowercase letters allowed? Are they treated as different or the same characters? \nHow about non-English characters or punctuation? An OS may even be called good \nor bad simply because long file names are not used or the difference between upper- \nand lowercase characters is not distinguished. \n In the  application programmer\u2019s view, the file system is a frequently used, \ncritical part of the system. It provides commands for creating a new file, using an \nexisting file, reading or appending data to a file, and other file operations. There \nmay even be several different types of files provided by the system. The  system \nApplication \nProgram\nDevice\nDrivers\nInterrupt\nRoutines\nMemory\nMouse\nController\nVideo\nController\nBus\nCursor\nmotion\nMouse\nmotion\n FIGURE 1.1   \n The cursor tracking \nmouse motion.  \nelm49810_ch01_001-018.indd   9\nelm49810_ch01_001-018.indd   9\n12/10/08   10:15:55 PM\n12/10/08   10:15:55 PM\n",
        "category": "Category"
    },
    {
        "id": "469",
        "title": "Title for Chunk 469",
        "content": "Confirming Pages\n10 \nPart 1 Operating Systems Overview and Background\nview of the file system is so large it is usually divided into subparts: file naming and \nname manipulation (directory services), file services such as locating and mapping \na file name to its data (file allocation and storage), trying to keep parts of open files \nin main memory to speed up access to its data (file buffering and caching), and the \nactual management of the storage devices (disk scheduling). \n For example, suppose that a user types the name of a file to be copied from a CD \nto a hard disk. The program may first need to see whether that file exists on the CD, \nand if it would overwrite a file with that name on the hard disk. The OS then needs to \ncreate an entry for the file in the hard disk directory, find space on the hard disk for \nstoring the data, and find and get the data from the CD, which has been recorded in \npieces (sectors) that will be copied. And all this should be done in a few seconds or \neven a fraction of a second! See  Table 1.2 . \n 1.4 SOME OS TERMS, BASIC CONCEPTS, AND ILLUSTRATIONS \n We now list and define some important OS concepts and terms. Then we give some \ndiagrams to illustrate these concepts. \n 1.4.1 Basic terminology \n Operating System (or just  System ). Although we can give different definitions \nbased on the different views of an OS, the following informal definition is a good \nstarting point: The OS is a collection of one or more software modules that manages \nand controls the resources of a computer or other computing or electronic device, \nand gives users and programs an interface to utilize these resources. The managed \nresources include memory, processor, files, input or output devices, and so on. \n Device.  A device is a piece of hardware connected to the main computer system \nhardware. Hard disks, DVDs, and video monitors are typical devices managed by \nan OS. Many devices have a special electronic (hardware) interface, called a  device \ncontroller, which helps connect a device or a group of similar devices to a computer \nTABLE 1.2 The Steps in Copying a File from a CD to a Hard Disk\nCheck for file on CD\nCheck for file on hard disk\u2014confirm overwrite\nCreate file name in hard disk directory\nFind space for file on hard disk\nRead data sectors from CD\nWrite data sectors to hard disk\nUpdate hard disk directory\nUpdate hard drive space information\nDo all this in seconds (or less!)\nelm49810_ch01_001-018.indd   10\nelm49810_ch01_001-018.indd   10\n12/10/08   10:15:55 PM\n12/10/08   10:15:55 PM\n",
        "category": "Category"
    },
    {
        "id": "470",
        "title": "Title for Chunk 470",
        "content": "Confirming Pages\n \nChapter 1 Getting Started \n11\nsystem. Examples include hard disk controllers and video monitor controllers. There \nare many types of hard disk controllers that usually follow industry standards such \nas SCSI, SATA, and other common but cryptic acronyms. Device controllers are the \nhardware glue that connects devices to the main computer system hardware, usually \nthrough a  bus. \n Device driver.  A device driver is a software routine that is part of the OS, and is used \nto communicate with and control a device through its device controller. \n Kernel.  This term usually refers to that part of the OS that implements basic func-\ntionality and is always present in memory. In some cases the entire OS is created as \none monolithic entity and this entire unit is called the kernel. \n Service.  Services are functions that the OS kernel provides to users, mostly through \nAPIs via OS calls. These services can be conveniently grouped into categories based \non their functionality, for example, file manipulation services (create, read, copy), \nmemory allocation services (get, free), or miscellaneous services (get system time). \nThe key to a programmer\u2019s understanding a system is to understand the OS services \nit provides. \n Utility.  These are programs that are not part of the OS core (or kernel), but work \nclosely with the kernel to provide ease of use or access to system information. A \n shell or  command interpreter is an example of a utility. The shell utility provides \na user interface to many system services. For example, user requests such as listing \nfile names in a directory, running a program, or exiting (logging out), may all be \nhandled by the shell. The shell may invoke other utilities to actually do the work; for \nexample, directory file listing is sometimes a utility program itself. \n 1.4.2 How about some pictures? \n Figure 1.2 is a simplified view of a small personal computer showing some basic \ndevices connected to the computer memory and CPU (processor). The OS program \n(or kernel) will include various device drivers that handle the peripherals (devices) of \nthe system under CPU control. For example, part of the contents of memory may be \ntransferred to the video controller to be displayed on the monitor, or the contents of a \npart of the disk (a sector) may be transferred to the disk controller and eventually to \nmemory (for a disk read operation). \n Figure 1.3  is a simplistic view of part of an OS. The OS controls (or manages) \nthe system resources: it controls the disks, keyboards, video monitor, and other \ndevices. It controls allocation of memory and use of the CPU by deciding which pro-\ngram gets to run. It provides services to the shell and other programs through the use \nof system calls. It also provides an abstraction of the hardware by hiding complex \ndetails of hardware devices from programs. \n Figure 1.3 , a common one used to illustrate OSs, is a logical view, not a physi-\ncal one. For example, the OS kernel physically resides inside the memory unit and \nit is running (executing) on the CPU. Thus, the arrows between the kernel\u2014which \nis software\u2014and the devices\u2014which are hardware\u2014represent a logical control, not \nphysical. \nelm49810_ch01_001-018.indd   11\nelm49810_ch01_001-018.indd   11\n12/10/08   10:15:55 PM\n12/10/08   10:15:55 PM\n",
        "category": "Category"
    },
    {
        "id": "471",
        "title": "Title for Chunk 471",
        "content": "Confirming Pages\n12 \nPart 1 Operating Systems Overview and Background\nShell \n(Command \nInterpreter)\nUtilities\nDevices\n(disks, keyboards)\nMemory\nCPU\nOther\nPrograms\n(browsers,\ngames, word\nprocessing)\nOperating System Kernel\nFIGURE 1.3 \nA simplistic view \nof the OS software \nin relationship to \nhardware.\nBus\nBus\nCPU\nCPU\nMemory\nMemory\nKeyboard\nController\nKeyboard\nController\nVideo\nController\nVideo\nController\nDisk\nController\nDisk\nController\nHard\nDisk\nHard\nDisk\nVideo\nMonitor\nVideo\nMonitor\nKeyboard\nKeyboard\nFIGURE 1.2 \nHardware: A very \nsimplistic view of \na small personal \ncomputer.\n(Note: This picture is too \nsimple. In reality there \nare often multiple buses, \nsay between video and \nmemory. We will get to \nmore detailed pictures in \nthe Appendix.)\n Figure 1.4  represents a layered view of the OS, where the outermost circle rep-\nresents the utilities/applications layer that accesses the OS kernel layer, which in turn \nmanages access to the hardware layer. \n 1.4.3 Closer to reality: A personal computer OS \n Figure 1.5  shows more detail of a simple OS for a personal computer or PC. The OS \nhas two additional components that were not shown in  Figure 1.3 :  device drivers \nelm49810_ch01_001-018.indd   12\nelm49810_ch01_001-018.indd   12\n12/10/08   10:15:57 PM\n12/10/08   10:15:57 PM\n",
        "category": "Category"
    },
    {
        "id": "472",
        "title": "Title for Chunk 472",
        "content": "Confirming Pages\n \nChapter 1 Getting Started \n13\nand a  BIOS ( Basic Input/Output System ). The BIOS abstracts the hardware\u2014that \nis, the BIOS manages common devices, such as keyboards, basic video, and the sys-\ntem clock. This allows the main or higher-level part of the OS to deal with all devices \nof the same type\u2014for example, all keyboards\u2014in the same way. Thus, the OS kernel \ndoes not change whether a keyboard has 88 keys, 112 keys, or some other number, \nor even in cases where keys may not appear where they might on different keyboards \nbecause of different language characters or accent keys. Device drivers also provide \na similar abstraction to similar devices. For example, a DVD device driver can be \nsupplied by a device manufacturer to provide an abstract or common view of the \nDVD device to the OS, so that the OS does not have to vary with every idiosyncrasy \nof DVD drives, regardless of the manufacturer. \n The next section elaborates further on why it is important to provide abstraction \nlayers when designing an OS. \nHardware\nOS Kernel\nApplications+\nUtilities+Shell\nFIGURE 1.4 \nA layered view \nof an OS.\nShell\n(Command\nInterpreter)\nUtilities\nOperating System Kernel\nDevice Drivers\nDevice\n(disks, keyboards)\nMemory\nCPU\nBIOS\n(interface to hardware)\nOther\nPrograms\n(browsers,\ngames, word\nprocessing)\nFIGURE 1.5 \nThe PC (small \nsystem) model \nof an OS.\nelm49810_ch01_001-018.indd   13\nelm49810_ch01_001-018.indd   13\n12/10/08   10:15:57 PM\n12/10/08   10:15:57 PM\n",
        "category": "Category"
    },
    {
        "id": "473",
        "title": "Title for Chunk 473",
        "content": "Confirming Pages\n14 \nPart 1 Operating Systems Overview and Background\n 1.4.4 Why the abstraction layers? \n Good question. Early in the days of personal computers, computer hobbyists had \nfun assembling and building the hardware and getting simple programs to work, \nusually written in assembly language or machine language. This was a good learn-\ning tool for some, but programming was very tedious. But people wanted to enjoy \nthe experience of writing more interesting and therefore larger and more complex \nprograms. So better tools were needed. These tools include easy-to-use editors and \ncompilers or interpreters for high-level languages. For end users, the desire was \nto use the computer as a business or productivity tool. These users needed word \nprocessing, spreadsheets, and communication software. Certainly there were many \nvery dissimilar computer hardware systems being built. But there were also a num-\nber of similar, but not identical, computers, built by many manufacturers. These \nsystems might either have the same CPU from the same CPU manufacturer, or use \na compatible CPU that had the same instruction set. However, they may have video \ndevices that were quite different. For example, one system might have a terminal-\nlike device attached to a serial port, whereas another might have a built-in video \ncontroller with many capabilities for advanced graphics. Keyboards would typically \ndiffer in function keys or \u201carrow\u201d or cursor movement keys, with other keys being \nadded or missing. \n In order for programmers to be able to create programs that would run on these \ndifferent systems with minor or no changes required to the program when moving it \nto a different system, the OS provided the same interface to the hardware for all the \ndifferent devices supported by that OS. For instance, a program could read a key-\nstroke from a keyboard regardless of what type of keyboard it was by a system call \nto read a key. The OS would take care of translating the keys which were in different \nplaces on different keyboards or which were coded differently. \n To avoid the complexity and cost of having different versions of the OS for dif-\nferent keyboards, different video monitors, different disks, and so forth, the OS was \nsplit into a part that was adapted to the different hardware devices (the BIOS and \ndevice drivers) and a part that remained the same for all hardware (shown as the ker-\nnel in  Figure 1.5 ). This technique of dividing complicated work into several  layers, \nor  levels, is an established software technique used in large and complex software \nsystems including OSs. Thus, adapting an OS to a new compatible computer system \nwith different devices involved changing (or writing) a BIOS but using the same \nmodule for the rest of the kernel and the same programs and utilities. This was a very \nattractive idea for everyone\u2014users, manufacturers, and OS writers. \n A problem arose when a computer peripheral manufacturer (e.g., a video card \nmanufacturer) designed a new device and wanted to sell it to users so they could \nupgrade their computer to newer hardware designs. Often the existing BIOS in \nthe computer was installed in ROM (read only memory) and would be difficult \nand expensive to replace. The solution to this problem was the creation of a modi-\nfiable BIOS by allowing device drivers to be loadable at the time the OS was \nloaded into memory. Having BIOS code that could be replaced when the system \nwas booted allows adding new features to the computer or replacing features in \nthe BIOS with new software and perhaps supporting new functions on existing \nhardware.  \nelm49810_ch01_001-018.indd   14\nelm49810_ch01_001-018.indd   14\n12/10/08   10:15:57 PM\n12/10/08   10:15:57 PM\n",
        "category": "Category"
    },
    {
        "id": "474",
        "title": "Title for Chunk 474",
        "content": "Confirming Pages\n \nChapter 1 Getting Started \n15\n 1.5 A SMALL HISTORICAL DIVERSION \n We close this chapter with a historical perspective on how OSs were developed, and \nthe different views about what type of functionality should be included in an OS. We \ngive a more detailed historical timeline of OS development at the end of Chapter 3, \nafter we have introduced some additional concepts. \n 1.5.1 Origins of operating systems \n Before personal computers there were of course many larger computers. Early on \nthese machines were very large and very expensive, but by modern standards primi-\ntive, and there were few programmers. Programs were limited in their capabilities \nbecause main memory was quite small, the CPU processors were very slow, and only \na few simple input and output devices existed. A typical early computer system may \nhave had a few thousand  words   3 of main memory, a processor that executed several \nthousand instructions per second, and a Teletype  4 device for input/output. The lim-\nited capabilities of these early computers required very careful and well-thought-out \nprograms which were mostly written in the basic machine code of the computer, \nmachine language or assembly language.\n These programs were amazing in that in a few hundred or thousand machine \ninstructions they accomplished a tremendous amount of work. But they all faced \nsimilar needs: How can a program print some output? How can a program get loaded \ninto memory to begin execution? These needs\u2014the need to load programs into \nmemory, to run a program, to get input and produce output\u2014were the impetus for \ncreating early OSs. At those early times the few programmers on a system knew each \nother and would share routines (program code) that had been debugged to simplify \nthe job of programming. These shared routines (e.g., \u201cprint the value in register A on \nthe Teletype\u201d) would eventually be combined into a  library that could be combined \n(linked) with an application program to form a complete running program. \n These early computers were  single-user systems. That is to say that only one \nuser\u2014and one program\u2014could run at any one time. Typically programmers would \nreserve the use of the computer in small blocks of time\u2014perhaps increments of \n10\u201315 minutes. A programmer would use this time to run or debug a program. \nBecause computers were expensive and computer time was very valuable, often big-\nger blocks of time were available only in the middle of the night or early in the morn-\ning when things were quieter, few managers were around, and one could get much \nmore done than in the daytime. This tradition, started in the early days of computing, \nis one of the few that has lasted until today! \n The programs, once written and assembled, were linked or bound with utility \nroutines for input, output, mathematical functions,  5 printout formatting, and other \n3 A  word was typically six characters, but differed from system to system. \n4 A  Teletype is an electromechanical printer and keyboard, built for telegraphy, that could print or type at \na speed of a dozen or so characters per second. \n5 Early computer hardware often did not have instructions for complex mathematical and even arithmetic \noperations\u2014for example, long division\u2014so these operations were implemented in software utility routines. \nelm49810_ch01_001-018.indd   15\nelm49810_ch01_001-018.indd   15\n12/10/08   10:15:58 PM\n12/10/08   10:15:58 PM\n",
        "category": "Category"
    },
    {
        "id": "475",
        "title": "Title for Chunk 475",
        "content": "Confirming Pages\n16 \nPart 1 Operating Systems Overview and Background\ncommon tasks, into an executable program ready to be loaded into memory and run. \nThe program might be stored on punched paper tape or punched cards. The computer \nhardware would know how to start reading from the input device, but it would only \nload the first card or the first block of the tape. So that block had to include a small \nroutine that would be able to load the rest of the application into memory. This short \nroutine is called a  loader. The loader would in turn read the programmer\u2019s execut-\nable program and put it and the needed utility routines into memory at a specified \nlocation, usually either the first memory address or some special fixed location. Then \nit would transfer execution\u2014by a branch or \u201csubroutine\u201d call\u2014to the program it \nhad loaded. The loadable program tape or card deck might look as illustrated in \n Figure 1.6 . 6 The END delimiter tells that loader that there are no more routines to be \nloaded since there might be data records following the routines.\n As programmers had time to develop more utility routines, the loader grew more \nsophisticated. Loaders were soon able to load programs that had been translated \n(compiled) from higher-level programming languages. As the size of loaders, util-\nity routines, and users\u2019 programs grew, the card decks or paper tapes became very \nlarge (and it became unfortunately common to drop a card deck or tear a paper tape). \nThese loaders and utility routines would become the beginnings of early OSs, which \nwere then often called  monitors. \n 1.5.2 What should an Operating System do (or what should \nit support)? \n From the early days of computing until today there has been a fierce debate\u2014\nranging from polite discussion to a political or almost religious argument\u2014about \nwhat an OS should do. The two extreme views of this debate could be called the \nmaximalist view and the minimalist view. The maximalist view argues that the OS \nshould include as much functionality as possible, whereas the minimalist view is that \nonly the most basic functionality should be part of the OS. From the early systems, \nthe question started: \u201cShould all the routines for input and output be included in my \nprogram? I don\u2019t even read from the card reader.\u201d Including too many routines\u2014any \nthat are not necessary\u2014makes the memory available for my program smaller, and \nit is too small to begin with. How can one get just what one needs? Mathematical \nroutines such as programs for performing floating-point arithmetic could be done \nonce in the OS rather than separately included in each user\u2019s program. But then \nevery program incurred the overhead of the extra memory occupied by these routines \nin the OS, even programs like accounting applications that did not use floating point \narithmetic. \n6 This type of loader is often known as a  bootstrap loader. \nBootstrap\nLoader\nApplication\nProgram\nLibrary\nRoutines\nI/O\nRoutines\nEND\nDelimiter\nFIGURE 1.6 \nAn application \nprogram with a \nloader and OS-like \nutilities.\nelm49810_ch01_001-018.indd   16\nelm49810_ch01_001-018.indd   16\n12/10/08   10:15:58 PM\n12/10/08   10:15:58 PM\n",
        "category": "Category"
    },
    {
        "id": "476",
        "title": "Title for Chunk 476",
        "content": "Confirming Pages\n \nChapter 1 Getting Started \n17\n In more recent times the debate concerning what to include in an OS continues. \nFor example, a user-friendly OS interface is now commonly considered to have \na pointing device\u2014such as a mouse, trackball, or pad\u2014and some type of screen \nwindowing with pull-down menus. Whether that interface should be a part of the \nOS\u2014thus giving all applications a similar \u201clook and feel,\u201d or part of the shell\u2014to \nallow each user to decide the particular look they want is one of the current issues of \nthe debate about what the OS should include. \n To be fair, like many hotly contested issues, both maximalist and minimal-\nist sides have a point. The historical trends are not clear. Newer OSs have been in \nsome cases smaller, simpler, and more configurable and in other cases exactly the \nopposite\u2014larger, more functional, and more constraining. This issue of what func-\ntionality should go where (in the OS kernel or not) has created different design \npossibilities for OSs, as we discuss further in Chapter 2. \n1.6  SUMMARY \n In this chapter, we first introduced some of the \nbasic functionality of operating systems. We gave \na few simple examples to illustrate why OSs are \nso important. Then we discussed the different \nviews of what an OS does by looking at the OS \nfrom two perspectives: the user\u2019s perspective and \nthe system\u2019s perspective. We then presented some \nbasic terminology and concepts, and provided some \nfigures to illustrate typical components of simple \nOSs. Next we began to look at a few architectures \nthat are commonly used to actually create OSs and \ndiscussed the very idea of abstraction that is so \nfundamental to the successful design of OSs. We \nconcluded with a brief historical perspective on the \norigins of OSs. \n The next chapter gives an overview of the major \ncomponents of an OS and discusses the architecture \nalternatives in more detail. \n REVIEW QUESTIONS \n \n1.1 Give a one-sentence definition of an OS. \n \n1.2 Since most of us are not going to be writing an OS, \nwhy do we need to know anything about them?  \n \n1.3 Give three reasons why a simple device such as a \nhandheld electronic game probably contains an OS. \n \n1.4 What is the primary difference between a user \nview of an OS and a system view? \n \n1.5 What are the four different classes of users that \nwere discussed, and what aspects of an OS are \nthey mostly interested in? \n \n1.6 The chapter discussed how the different users are \nsupported from the system view. Two examples \nwere presented, moving a mouse and file systems. \nConsider another aspect of an OS and discuss how \nthe system view works to support the three differ-\nent classes of users. \n \n1.7 Should OSs be proprietary so that the manufactur-\ners will be able to make enough profit to continue \ntheir development or should the internals and spec-\nifications of OSs be open for all users to know? *7  \n \n1.8 With respect to the study of OSs, how is a control-\nler best defined? \n \n1.9 What is the general principle of abstraction? \n 1.10 What are some of the reasons why we want \nabstraction in an OS? \n 1.11 Distinguish between an OS and a kernel. \n 1.12 Describe briefly the origins of OSs on the early \nlarge mainframe systems. \n 1.13 Should the characteristics of a windowing inter-\nface\u2014the factors that determine its look and \nfeel\u2014be a part of the OS kernel or part of the \ncommand shell?  \n* Note to instructors: Don\u2019t use this question as part of the class \nunless you have nothing else to talk about for the day.\nelm49810_ch01_001-018.indd   17\nelm49810_ch01_001-018.indd   17\n12/10/08   10:15:58 PM\n12/10/08   10:15:58 PM\n",
        "category": "Category"
    },
    {
        "id": "477",
        "title": "Title for Chunk 477",
        "content": "elm49810_ch01_001-018.indd   18\nelm49810_ch01_001-018.indd   18\n12/10/08   10:15:58 PM\n12/10/08   10:15:58 PM\n",
        "category": "Category"
    },
    {
        "id": "478",
        "title": "Title for Chunk 478",
        "content": "Confirming Pages\n151\n Chapter \n Chapter  8  8 \n Process Management: \nConcepts, Threads, \nand Scheduling \n In this chapter: \n \n8.1 Introduction to Processes 152\n \n8.2 Process Descriptor\u2013Process Control Block 152\n \n8.3 Process States and Transitions 154\n \n8.4 Process Scheduling 156\n \n8.5 One Good Process Deserves Another 164\n \n8.6 Threads  166\n \n8.7 Case Studies 173\n \n8.8 Summary  178\n  I\nn this chapter we talk about processes and threads. A fundamental function of an \nOS is the execution of a program and an executing program is known as a process. \nA program is a static thing. In most OSs a program is stored in a file on secondary \nstorage. Eventually an OS is instructed to run a program, usually by a user, but some-\ntimes by another process, perhaps one running on another system. The OS brings \nthat program into primary storage and begins to execute it. That running entity is \nknown as a  process. Note that we may run many copies of the same program at \nthe same time on one system. For example, it is possible to start several copies of a \nprogram development environment running at the same time. Each running copy of \nthe program would be a separate process. Other terms often used for a process are a \njob or a  task. \n In the first section we define a process and speak about the abstraction of a \nmachine that the process runs on. An OS must keep track of much information about \neach running process, especially when that process is not actually executing on a \nCPU. In  Section 8.2  we explain the main control structure that OSs use to store this \ndata for a process, a process control block. As a process executes it will be in vari-\nous states such as ready to run, running, waiting, and so on. Various events cause the \nelm49810_ch08_149-180.indd   151\nelm49810_ch08_149-180.indd   151\n12/18/08   11:25:14 AM\n12/18/08   11:25:14 AM\n",
        "category": "Category"
    },
    {
        "id": "479",
        "title": "Title for Chunk 479",
        "content": "Confirming Pages\n152 \nPart 3 CPU and Memory Management\nprocess to transition from one such state to another.  Section 8.3  discusses the various \nstates that a process can be in and the events that can cause the transitions between \nthe states. When systems are running multiple processes the OS must decide which \nprocess will run next.  Section 8.4  addresses the various algorithms for scheduling the \nexecution of processes. In order for a complex application to accomplish many things \nat once it is sometimes desirable for the process to start another process to do some \nof the work, so  Section 8.5 explains how one process can start another process. \n Switching between processes turns out to have substantial impact on the perfor-\nmance of an OS and the programs it is running. As a result, another mechanism was \ndeveloped that will allow a single process to accomplish more things at the same \ntime using the mechanism of threads.  Section 8.6  covers this topic. In  Section 8.7  \nwe discuss some real implementations of threads in some different OSs. Threads are \nalso available in some high-level languages and in a standard thread API available on \nmany OSs, so we discuss those in this section as well. In  Section 8.8  we close with a \nsummarization of the chapter. \n 8.1 INTRODUCTION TO PROCESSES \n As a process runs it will change its  state. Most obviously it will be changing the \nprogram counter (or instruction address register) as it runs and as it calls subroutines \nor functions or invokes methods, loops, and so on. It will also be changing the con-\ntents of the CPU registers, the system status register, and the stack pointer, at least \non most machines. These items (and more discussed later) are collectively known as \nthe process state. If we were only running one process on a system then there would \nbe nothing much more to say about the process state. But these days we are not nor-\nmally running only one process. We are rapidly switching between many processes \nin an effort to keep the hardware very busy and responsive to the user(s). \n While we want the system to be able to run many processes at the same time, we \nwant this switching among processes to be transparent to the processes themselves \n(i.e., a process does not need to know whether or when it will be suspended and \nanother process run). We are creating a \u201cvirtual CPU\u201d in the sense that every process \ncan act as if it were the only process running. Since we are doing all this switching \nbetween processes, when we stop one process to start another we will have to save \nthe state of the process we are stopping and restore the previous state of the process \nwe are starting. (This assumes that the process we are starting is not a new process.) \nWe will create a structure in memory where we will save the information describing \nthe state of the process we are stopping. We will call this structure a  process control \nblock ( PCB ). Some OSs call this structure a  process descriptor. \n 8.2 PROCESS DESCRIPTOR\u2014PROCESS CONTROL BLOCK \n As was just described, when a process is stopped by the OS for any reason, the state \nof the CPU at that time is saved in the PCB. There are many other pieces of infor-\nmation in the PCB as well. A typical PCB is shown in  Figure 8.1 . Different OSs \nelm49810_ch08_149-180.indd   152\nelm49810_ch08_149-180.indd   152\n12/18/08   11:25:18 AM\n12/18/08   11:25:18 AM\n",
        "category": "Category"
    },
    {
        "id": "480",
        "title": "Title for Chunk 480",
        "content": "Confirming Pages\n \nChapter 8  Process Management: Concepts, Threads, and Scheduling  \n153\nwill keep different information in the PCB, but here are some things that are fairly \ncommon:\n \ufffd Program name \n \ufffd Process ID, a number assigned by the OS to identify the process \n \ufffd Parent process ID or a pointer to the parent process PCB \n \ufffd Pointer to a list of child PCBs \n \ufffd Pointer to the \u201cnext\u201d PCB, probably in a queue \n \ufffd Accounting information \n \ufffd Pointer to a table of open files \n \ufffd CPU state information\n \ufffd Instruction counter \n \ufffd Stack pointer(s) \n \ufffd System status register \n \ufffd Other system registers \n \ufffd Event descriptor, valid if the process is waiting for something \n \ufffd Process state information (see next section) \n \ufffd Process owner (user) \n \ufffd Memory management information \n \ufffd Pointer to a message queue \n \ufffd Pointer to an event queue \n It is important to understand that while a process is actually running, the  CPU state \ninformation is not updated. It is saved only when the process is stopped for some \nreason. Note that the term \u201cstate\u201d is overloaded. We have been talking about the \n\u201cstate\u201d of the CPU and said that we saved that information in the part of the PCB \ncalled the \u201cCPU state information\u201d when we stopped a process. You may have \nnoticed that the PCB also has another entry called \u201cprocess state information.\u201d This \nis something different, and it is coming up next. \nprocess id\nnext PCB\nParent PCB\nChild PCB list\nOpen File Table\nCPU state\nProcess state\nMMU information\n. . .\nFIGURE 8.1 \nA process control \nblock.\nelm49810_ch08_149-180.indd   153\nelm49810_ch08_149-180.indd   153\n12/18/08   11:25:18 AM\n12/18/08   11:25:18 AM\n",
        "category": "Category"
    },
    {
        "id": "481",
        "title": "Title for Chunk 481",
        "content": "Confirming Pages\n154 \nPart 3 CPU and Memory Management\n 8.3 PROCESS STATES AND TRANSITIONS \n The designers of OSs have to document the external view of their systems so that \nprogrammers will know how to write programs for them and users will know how \nto run the programs. Some of the things that need to be discussed can be described \nin several ways. An example is the concept of \u201cstates\u201d that a process can be in. The \nmost obvious state for a process is that it is running. But only one process can be \nrunning at any time on each CPU, so what are the other processes doing? Some of \nthem are ready to run and some of them are waiting for something else to happen \nbefore they continue. \n Different designers (and authors) will use different models to explain the manag-\ning of processes by an OS. In Chapter 2 we introduced this five-state model with dif-\nferent state and transition labels, but it is also common to see a  three-state model that \neliminates the new and exit states. The five-state model is shown again in  Figure 8.2 . \nIt is convenient to describe these states with a state diagram. The states (or nodes) \nare indicated by the hexagons. The arrows (or transitions) are the events that cause \nthe transition from one state to another state. The five states are seen as New, Ready, \nRun, Wait, and Exit. These states often have different names in other references.  \n The  New state represents a process that the OS is currently preparing to run but \nthat is not yet ready. When the user tells the command processor module to run a \nprogram it goes through the transition marked \u201c0\u2013Program Loaded\u201d and is put in the \nNew state. First, the OS has to create a new PCB, assign a process id, and fill in all \n0\u2013Program\nLoaded\n4\u2013Got What\nIt Needed\n3\u2013Needs \nSomething\n6\u2013Finished \nor Aborted\n7\u2013Exits \nSystem\n5\u2013Interrupted\n2\u2013Gets\nCPU Time\n1\u2013Process \nInitialized\nNew\nReady\nRun\nExit\nWait\nFIGURE 8.2 \nA five-state process \nmodel.\nelm49810_ch08_149-180.indd   154\nelm49810_ch08_149-180.indd   154\n12/18/08   11:25:19 AM\n12/18/08   11:25:19 AM\n",
        "category": "Category"
    },
    {
        "id": "482",
        "title": "Title for Chunk 482",
        "content": "Confirming Pages\n \nChapter 8  Process Management: Concepts, Threads, and Scheduling  \n155\nthe other PCB parameters. Then it usually has to reserve memory, read the program \nin from secondary storage, and so forth. Especially on a multiple CPU system we \ndon\u2019t want an instance of the OS running on another CPU trying to dispatch this pro-\ncess, so until it is actually ready to run it is marked as being in the New state. \n When a process is ready to run it is put in the  Ready state. This is seen as \ntransition \u201c1\u2013Process Initialized.\u201d Eventually it will be selected by the OS as the \nnext process to run. Then it will be  dispatched (i.e., it will be put into the  Run \nstate). This transition is indicated by the arrow labeled \u201c2\u2013Gets CPU Time.\u201d As a \nprocess is running it may decide to wait for something else to happen before it con-\ntinues. A very common cause is that the process has requested a synchronous I/O \noperation (like a normal high-level language Read operation) and wants to wait until \nthe operation is complete and thus it is moved to the  Wait state, sometimes known \nas the  Suspended state. This transition is labeled \u201c3\u2013Needs Something.\u201d We will \nlater see that there are many different kinds of events that a process can wait for. \nWhen a process is in the Wait state, sooner or later the event that the process is wait-\ning for may occur. (Of course, that event might never occur, for example, a process \nthat is waiting for possible errors or for an incoming request for a service that is \nrarely used.) As an example of this transition, perhaps the I/O that a process had \nrequested has finished. This transition is labeled \u201c4\u2013Got What It Needed\u201d and the \nOS puts the process into the Ready state. The next transition in this model is labeled \n\u201c5\u2013I nterrupted.\u201d The OS may elect to interrupt a running process for several reasons, \nbut not all OSs do so. The first instance is a time-slicing system where each process \nin turn is given a short amount of time to execute. If it has not done something in that \ntime to cause it to go into wait state then the OS will take it out of Run state and put \nit into the Ready state and allow another process to run. A second instance would \nbe where a process with a high priority has been waiting for an event and the event \noccurs. If the process that is running has a lower priority than the process that was \nwaiting, then the OS may stop the lower priority process, put it back in the Ready \nstate, and put the higher priority process into Run state. But not all OSs use priority \nscheduling. \n The  Exit state is reserved for processes that are being ended by the OS. There \nmay be many reasons for a process to reach this state. This transition is labeled \n\u201c6\u2013Finished or Aborted.\u201d Finishing is obvious. Abort is fairly clear. Either the pro-\ncess or the OS has detected a problem and the process is being stopped before more \ndamage occurs. But there are also other reasons why a process might leave the run \nstate and go to the exit state. As one example: A parent process to this process may \ndecide that this child process is no longer needed and ask the OS to kill it. For most \npurposes we don\u2019t want to clutter up this model so we leave these more rare transi-\ntions out of the figure. \n The Exit state is rather peculiar in that processes don\u2019t stay in it very long, but \nthese processes are not running, ready, or waiting, so we could reasonably talk about \nthis state as being something distinct from those other states. The OS will need to \ndo some housekeeping for this process such as freeing up resources that the process \nmay have acquired and not yet returned, ensuring files are closed, and tearing down \nthe PCB for the process. Until the resources are fully recovered we don\u2019t want this \nprocess being selected to run, so we leave it in this state as we work. \nelm49810_ch08_149-180.indd   155\nelm49810_ch08_149-180.indd   155\n12/18/08   11:25:19 AM\n12/18/08   11:25:19 AM\n",
        "category": "Category"
    },
    {
        "id": "483",
        "title": "Title for Chunk 483",
        "content": "Confirming Pages\n156 \nPart 3 CPU and Memory Management\n Other OS documentation includes even more complex models. In at least one \ncase 1 the model used by the designers has nine states and many transitions. While \nthe designers of this system may have felt it was necessary to explain to application \nprogrammers some special facets of the system, this level of complexity is not seen \nin most documentation. \n Note that except for the Run state, there can normally be many processes in any \ngiven state. So, we should not be surprised to find that for most OSs there is an elab-\norate mechanism for tracking all the processes that are in any of the other states. The \nReady state will consist of at least one structure. Often we speak of it as the  Ready \nqueue, but technically we often use it in other ways than a strict queue would oper-\nate. In fact, it might be several linked lists. We discuss this more in the next section. \nThe Run state contains only one process unless we have a multiple CPU system. In \nthat case the processes running on the various CPUs might be linked on a separate \nlist, but it is probably sufficient that they merely be removed from the list(s) of the \nReady state. For the Wait state there may be many queues. In this case they some-\ntimes are operated in a FCFS manner so it is legitimate to call them queues. In other \ncases we will do more advanced scheduling of operations and the word \u201cqueue\u201d \nmight not actually apply. However, the term is well entrenched in OS literature, so \nwe will stick with it, realizing that it might not always be technically correct. \n 8.4 PROCESS SCHEDULING \n As was just discussed, a process may leave the Run state for several reasons. When \nit does, it may go immediately into the Ready state, for example, if it was interrupted \nfor reaching the limit of its time quantum. If a process is waiting on some event, per-\nhaps an I/O completion, and the event happens, then we will need to put the process \ninto the Ready state so it can get to the Run state and handle the event. When we put \na process into the Ready state, we need to decide when it should run in relation to the \nprocesses that are already in the Ready state. This decision is made by an OS module \ncalled the  short-term scheduler.  There are a number of ways the OS can make this \ndecision. We might want to design our OS so that we can plug in various short-term \nscheduler modules to suit the needs of the system users and administrators. First, we \ndescribe the algorithms and then we discuss some of the pluses and minuses of them \nin various situations. \n 8.4.1 FCFS scheduling \n The simplest method, and one historically used by many OSs, is simply to run a \nfirst-in, first-out schedule with an ordinary queue. This is called the  FCFS, or first \ncome, first served algorithm. It has several advantages. It is easy to implement. It is \nwell understood by designers, users, administrators, and even teachers. Finally, it is \nby definition the  fairest (i.e., it does not favor any one process over another in any \n 1 UNIX SVR4. See Bach, M. J., The Design of the UNIX Operating System. Englewood Cliffs, \nNJ: Prentice Hall, 1986. No. 1, January 1988.\nelm49810_ch08_149-180.indd   156\nelm49810_ch08_149-180.indd   156\n12/18/08   11:25:19 AM\n12/18/08   11:25:19 AM\n",
        "category": "Category"
    },
    {
        "id": "484",
        "title": "Title for Chunk 484",
        "content": "Confirming Pages\n \nChapter 8  Process Management: Concepts, Threads, and Scheduling  \n157\ncircumstance). FCFS is often enhanced by allowing a running process to make a \nsystem call that yields control to the next process in the Ready state. This is known \nas cooperative multitasking. It was typical of a generation of OSs that included the \npre-X Mac OS, Microsoft Windows, and many others. Of course, the running pro-\ncess might have a bug or might be trying to make itself have better user response by \nusing more CPU time that it ought, so it was not an ideal solution. \n 8.4.2 Priority scheduling \n There are some circumstances when we might not want to use a FCFS algorithm. For \none thing, we may have some processes that are much more important than others. In \na modern OS we want to process keystrokes and mouse operations promptly so that \nthe waiting time of the interactive user is minimized. We will want the process that is \nmanaging the window that has the focus of the OS to be fairly responsive\u2014perhaps we \nare browsing a website. We are less interested in the performance of other processes \nthat might be running but that don\u2019t currently have the focus\u2014perhaps our email reader \nis checking our mail servers to see if we have any mail. We are even less interested in \nthe performance of some other processes\u2014perhaps the SPOOLING system is printing \na document that we downloaded some time ago. In such cases we might use a  priority \nscheduling algorithm. In a priority algorithm we will associate a priority with each pro-\ncess. Our keystroke and mouse handler might be the highest priority, the window with \nthe focus the next higher priority, windows without the focus the next, and background \nprocesses like the SPOOLING system still lower. There normally is a process in most \nOSs called something like the  idle process that runs in a loop when no other process is \nready to run. (Note that the \u201chighest priority\u201d might be the lowest number, not the high-\nest number. The choice might depend on the instruction set of the computer or might \njust be an arbitrary decision on the part of the developer. As long as the scheduler is con-\nsistent it is perfectly normal to have the lowest number represent the highest priority.) \n Whenever we allow some jobs to have priority over other jobs there is a special \nproblem that we have to worry about. It is possible that higher-priority processes keep \npostponing a low-priority process to the point that the lower-priority process never \ngets to run. This problem is known as  starvation. There are several ways we can deal \nwith this potential problem. Collectively these are known as  aging. Generally we \nwill monitor those processes that are being postponed, and whenever we postpone \na process too many times we simply raise its priority temporarily. Eventually it will \nreach a high enough priority that it will run one time. Then we will let the priority \ndrop back to where it was originally. Eventually even fairly low-priority processes \nwill finish, but higher-priority jobs will still be given the majority of the time.  \n 8.4.3 Guaranteed scheduling \n FCFS scheduling gives each process a fair chance to run, but if a process does many \nblocking calls then it will not receive a fair amount of CPU time if other processes \nare running that do fewer blocking calls. It is possible to guarantee that if  n processes \nare running then each process will get 1/ n th of the CPU time. In  guaranteed sched-\nuling the OS needs to track the total amount of CPU time per process and the total \nelm49810_ch08_149-180.indd   157\nelm49810_ch08_149-180.indd   157\n12/18/08   11:25:20 AM\n12/18/08   11:25:20 AM\n",
        "category": "Category"
    },
    {
        "id": "485",
        "title": "Title for Chunk 485",
        "content": "Confirming Pages\n158 \nPart 3 CPU and Memory Management\nclock time. Then it calculates the ratio of the CPU time the process actually used to \nthe amount of time each the process is entitled to and runs the process with the low-\nest ratio. This is sometimes called  fair-share scheduling. In essence, this is a type \nof priority scheduling. \n 8.4.4 SRTF scheduling \n Even large batch-oriented mainframes can have priorities among the jobs. Typically \nprogrammers developing new jobs will want fast job turnaround so that they can get \ntheir work done. Other jobs can run overnight. Nevertheless, some jobs are more \nimportant than others. Everyone wants the payroll to be on time! When timesharing \nis also incorporated in the system, typically the interactive window-based jobs all run \nat a higher priority than the batch jobs. One way to make this happen is to use an algo-\nrithm called  shortest runtime first (sometimes called shortest remaining time first; \n SRTF ) or  shortest job next ( SJN ). This algorithm is fairly self describing. It merely \nselects the job to run next that will run for the shortest amount of time. Incidentally, \nthis algorithm will produce the shortest possible turnaround times for all jobs. \n Recall that when processes are running they will normally compute for a short \ntime and then do an I/O operation. The interactive time-sharing jobs typically run for \nshort amounts of time between I/O operations. Large batch jobs may run much lon-\nger before doing an I/O operation. So, one way we can give a higher priority to the \ninteractive jobs is to base the priority on the amount of time that the process will run \nin its next CPU burst before doing an I/O operation. However, most computers don\u2019t \ncome with the \u201cmind reader\u201d option installed, so we usually don\u2019t know how long \nthe next CPU burst of a process will be. However, we can track the past performance \nof each process and guess that it will behave in the next CPU burst much as it has in \nthe past few bursts. To make this guess we will use an exponentially decaying func-\ntion. We will use the following variables:\nTi will be the actual time taken by this processs in the i\u2019th time interval.\nEi will be the tim\ne we estimated in the i\u2019th time interval.\nThere is a parameter in this formula that will be used to tune the performance:  \ufffd . \nIt is the percentage of the guess that we want to be based on the last actual CPU time \ntaken by the process. Its value is therefore between 0 and 1. The rest of the guess will \nbe based on the last guess we made. The formula will be:\nE\nE\ni\ni\n1\ni\n1\n(\n)\n((1\n)\n)\n=\n\ufffd\n\ufffd\n\ufffd \ufffd\n*\n*\nT \ufffd\ufffd\n\ufffd\ufffd\n \ufffd is often initially set to .5, so that half of the guess for this time slot is based on \nthe last actual time and half (1\ufffd  \ufffd ) is based on the last guess. Each time we make \nanother guess, the effect of both the past guess and the time actually taken is reduced \nby half. This is why the function is described as  exponentially decaying. If we raise \nthe value of  \ufffd , then more of the next guess will be based on the actual CPU perfor-\nmance. This will make our estimate respond more quickly to changes in the CPU \nuse, but we will tend to overcorrect for small fluctuations. If we lower the value of  \ufffd \nelm49810_ch08_149-180.indd   158\nelm49810_ch08_149-180.indd   158\n12/18/08   11:25:20 AM\n12/18/08   11:25:20 AM\n",
        "category": "Category"
    },
    {
        "id": "486",
        "title": "Title for Chunk 486",
        "content": "Confirming Pages\n \nChapter 8  Process Management: Concepts, Threads, and Scheduling  \n159\nthen we will do the opposite\u2014we will respond to changes more slowly but will not \noverreact to short fluctuations. \n We will use this guess to select the processes to run next, choosing the pro-\ncess we guess will use the smallest amount of CPU time before it does an I/O \noperation. We will leave for later those processes that we think will take longer. \nIn this way the SRTF algorithm is a variation on the Priority algorithm. We are \nmerely setting the priority of the process based on our guess of the length of the \nnext CPU burst.  \n 8.4.5 Highest response ratio next \n Highest response ratio next (HRRN) scheduling is similar to Shortest job next, in \nwhich the priority of each job is dependent on its estimated runtime. But HRRN also \nincludes the amount of time the process has spent waiting. A process gets higher \npriority if it waits longer. This variation is used mainly because it lessens the likeli-\nhood of starvation.\nPriority\n(time waiting\nestimated runtime)\ne\n\ufffd\n\ufffd\n/\nsstimated runtime.\n 8.4.6 Preemption \n In each of these algorithms we have assumed that when a process has the CPU we \nwill let it run as long as it wants to\u2014typically it goes to Wait state for an I/O opera-\ntion. However, what if we were running the priority algorithm and currently had \na process running that was of fairly low priority? Assume another process with a \nhigher priority has been waiting on an I/O event that finishes. Since we know that \nthis process has higher priority than the one that is running we can stop the one that \nis running and start the higher-priority process. Taking a resource away from a pro-\ncess is called  preemption. In this particular case the resource we are preempting is \nthe CPU itself. \n We can apply this idea of preemption in each of the algorithms we have stud-\nied so far. In most cases we will give a new name to the algorithm when we are \nallowing preemption. If we allow preemption in the FCFS algorithm it becomes the \n round-robin algorithm. In this case the preemption is not based on priority but on \na time quantum. We allow each process a specific amount of time to run without \ndoing any I/O. If it exceeds that time then we preempt the CPU and put that process \nat the back of the run queue. \n If we apply preemption to the shortest runtime first algorithm then it becomes \nthe  shortest remaining time first algorithm. When we preempt a running process \nfor a higher-priority process we note in the PCB the amount of time remaining in our \nguess of the runtime of that process. When we restart it later we don\u2019t make a new \nguess\u2014we just use the time that was remaining when the process got preempted. \n In the priority algorithm we can apply preemption when a higher-priority pro-\ncess enters the Ready state. We don\u2019t give this modified algorithm a special name. It \nis simply referred to as  priority with preemption. \nelm49810_ch08_149-180.indd   159\nelm49810_ch08_149-180.indd   159\n12/18/08   11:25:20 AM\n12/18/08   11:25:20 AM\n",
        "category": "Category"
    },
    {
        "id": "487",
        "title": "Title for Chunk 487",
        "content": "Confirming Pages\n160 \nPart 3 CPU and Memory Management\n 8.4.7 Multilevel queues \n Modern OSs use a more complex scheduling algorithm called  multilevel queu-\ning. As the name implies, instead of a single queue we will use several queues. A \nnew job will be placed in one of the queues. The individual queues can all use the \nsame scheduling algorithm or they can use different algorithms. If the algorithms \nare all doing timeslicing then the queues may each have a different time quantum \nassigned. The queues will have different priorities, and the highest-priority queue \nis serviced first. A question that must be decided is the mechanism used to share \nthe CPU between the queues. There are basically two approaches. First, we could \nmake the mechanism a strict priority mechanism. That is to say that as long as there \nare processes in the higher-priority queues, those are run first. Of course, with this \nmechanism we would have to worry about starvation. An alternative approach is to \nshare the CPU among the queues. For example, we might dedicate 50% to the first \nqueue (as long as there were jobs in the queue to be run), 30% to the second, and \n20% to the third. Since the lower-priority queues are always getting some service \nthey will not starve. \n Most modern OSs add a  feedback mechanism to the multilevel queues. The \ninitial assumption is that a new process is interactive so it is put in a high-priority \nqueue. If the process runs for more than the allowed time quantum for this queue \nwithout doing any blocking OS call, then the OS assumes it is not really an interac-\ntive process, so it moves it to the next lower-priority queue. This queue may also \nhave a longer time quantum. Remember that context switches are not productive \nwork and they slow the execution of the processes down temporarily for hardware \nreasons that we will cover later. So if the process is not finishing its time quantum on \nthe fast queue, we may want to give it more time at the lower queue. Typically there \nare at least three such queues. So if a process running in the second queue still does \nnot do any blocking call in the time quantum for this queue it is moved to a lower \nqueue, perhaps with a still larger time quantum. \n Of course, all processes will have some intervals in which they are doing more \ncomputing than in others. So a process that is basically interactive may have short \nperiods where it is doing a lot of computing and sinks to a lower queue. Thus, we \nwill want to have some mechanism that will allow a process to rise back to a higher \nqueue. This might be as simple as elevating a process to a higher queue anytime it \ndoes a blocking call without finishing the time quantum at the current level. This \nmight be too reactive, however, and we might find it necessary to wait until a process \ndoes not finish its quantum several times in succession. \n 8.4.8 Selecting the best algorithm \n With so many algorithms, how do we compare them? There are a number of mea-\nsures of system performance that have been used to compare scheduling algorithms. \nA few of these include:\n \ufffd throughput\u2014jobs run per hour or per minute \n \ufffd average turnaround time\u2014time from start to end of the job \n \ufffd average response time\u2014time from submission to start of output \nelm49810_ch08_149-180.indd   160\nelm49810_ch08_149-180.indd   160\n12/18/08   11:25:21 AM\n12/18/08   11:25:21 AM\n",
        "category": "Category"
    },
    {
        "id": "488",
        "title": "Title for Chunk 488",
        "content": "Confirming Pages\n \nChapter 8  Process Management: Concepts, Threads, and Scheduling  \n161\n \ufffd CPU utilization\u2014the percent of time the CPU is running real jobs (not switching \nbetween processes or doing other overhead; of more interest in big systems)  \n \ufffd average wait time\u2014the time that processes spend in the ready queue \n The first three depend on the job mix, so they are difficult to compare fairly and \naccurately. CPU utilization is interesting and is easy to measure, but in personal \ncomputer systems we really don\u2019t care about it. These CPUs are reasonably cheap \nand we are more concerned with optimizing perceived user performance. The aver-\nage wait time is the measure that makes the most sense in most circumstances. We \nwant to make sure that the most computing is getting done with the least amount of \nwasted time. Average waiting time seems to reflect that most accurately. \n The easiest way to compare the average waiting time of the various algorithms is to \nuse a method known as  discrete modeling. We take a sample set of processes and their \nruntimes and we simulate by hand the execution of each process on that sample data. We \nthen calculate the waiting time of the nonrunning processes and compare the values. \n First, consider this set of processes:  \nProcess ID\nArrival Time\nRuntime\n1\n0\n20\n2\n2\n2\n3\n2\n2\nFor our purposes, it does not matter what the time units are, so let\u2019s just say they are \nmicroseconds. Also, note that we show P2 and P3 both arrived at time 2. With only \none CPU they can\u2019t really both arrive at time 2 since the computer can only do one \nthing at a time. But our clock isn\u2019t very fast, so for the purposes of this algorithm \nthey both arrive at time 2. For each set of data we produce a timeline showing the \nprocesses running on the CPU. For this set of data, using the FCFS algorithm, we \nwould see the following timeline:\n0\n|    P1\n|  P2  |  P3  |\n|_________________________________________|____|____|\n20\n22\n24\nNow let us compute the average waiting time. P1 arrives at T0, so it starts imme-\ndiately. P2 arrives at T2, but does not start running until T20 when P1 finishes, so it \nwaited for 18. P3 also arrived at T2 but did not start until P2 was over at T22, so it \nwaited for 20. So the average waiting time was (0  \ufffd 18  \ufffd 20) / 3  \ufffd 38/3  \ufffd 12.67. \n Now suppose that the same three processes arrived in a slightly different order:  \nProcess ID\nArrival Time\nRuntime\n1\n0\n2\n2\n2\n2\n3\n2\n20\nelm49810_ch08_149-180.indd   161\nelm49810_ch08_149-180.indd   161\n12/18/08   11:25:21 AM\n12/18/08   11:25:21 AM\n",
        "category": "Category"
    },
    {
        "id": "489",
        "title": "Title for Chunk 489",
        "content": "Confirming Pages\n162 \nPart 3 CPU and Memory Management\nThe timeline looks like this:\nP1\nP2\nP3\n0\n4\n24\n2\nThis time the short processes came first. P1 and P2 had no wait and P3 only \nwaited 2. Thus, the average waiting time was\n(\n) /\n/\n.\n.\n0\n0\n2\n3\n2\n3\n0 67\n\ufffd\n\ufffd\n\ufffd\n\ufffd\nThis small difference in arrival times illustrates a major problem with the FCFS \nalgorithm. It is called the  convoy effect or \u201c head of line blocking \u201d\u2014a short job \narriving just after a long job will have to wait a long time before it gets to run. This \nwill give a system running this algorithm a highly variable average wait time. \n Let\u2019s look at the first set of data again, but this time we assign priorities to the \narriving jobs \ufffd lowest number  \ufffd highest priority:  \nProcess ID\nArrival Time\nRuntime\nPriority\n1\n0\n20\n4\n2\n2\n2\n2\n3\n2\n2\n1\nNow our timeline will look like this:\n0\n24\n2\n4\n6\nP1\nP2\nP3\nP4\nNow P1 starts immediately, but at T2 it gets preempted by P3, which has the \nhighest priority, so P3 starts immediately. P2 has to wait for 2, then P1 starts again at \nT6 after waiting 4. So now the average waiting time is:\n(\n) /\n.\n4\n2\n0\n3\n2\n\ufffd\n\ufffd\n\ufffd\nThis is not quite as good as FCFS, when the processes happened to arrive in the \noptimum order, but it certainly is better than what happened when they arrived in \nthe wrong order. In this case the lower-priority job happened to be the longest job. \nWhen we are running SRTF, the process with the shortest estimated runtime gets the \nhighest priority. This is just what happens in SRTF, so this simulation applies to that \nspecific case of priority scheduling as well. \nelm49810_ch08_149-180.indd   162\nelm49810_ch08_149-180.indd   162\n12/18/08   11:25:21 AM\n12/18/08   11:25:21 AM\n",
        "category": "Category"
    },
    {
        "id": "490",
        "title": "Title for Chunk 490",
        "content": "Confirming Pages\n \nChapter 8  Process Management: Concepts, Threads, and Scheduling  \n163\n Next let us look at another example for SRTF. Suppose we had the following set \nof processes and that we were not allowing preemption:  \nProcess ID\nArrival Time\nRuntime\n1\n0\n12\n2\n2\n4\n3\n3\n1\n4\n4\n2\nThe timeline would look like this:\n0\n12\n13\n15\n19\nP1\nP3\nP4\nP2\nand our average waiting time would be:\n(\n) /\n.\n.\n0\n13\n9\n9\n4\n7 75\n\ufffd\n\ufffd\n\ufffd\n\ufffd\nNow suppose that we allow preemption. Our timeline would look like this:\n19\n0\n2\n9\nP1\nP1\n6\nP2\n4\nP4\n3\nP3\nP2\nNotice that the total execution time of the processes themselves was the same as \nwithout preemption. But now our average waiting time would be:\n(\n) /\n. .\n7\n3\n0\n0\n4\n2 5\n\ufffd\n\ufffd\n\ufffd\n\ufffd\nClearly, we would prefer this result\u2014but at what price? We know that every-\nthing has a price. Observe that in the case without preemption we only did three \ncontext switches and in the case with preemption we did five context switches. We \nshould recall that the time taken to do a context switch is not time that the system is \ndoing productive work. It is all overhead that we spend to make the average waiting \ntime smaller so many things appear to happen faster, especially the high-priority \nthings. Later we will see that context switches are even more expensive than just \nthe time it takes to save and restore the CPU state of the processes and the time \nwe spend running the chosen scheduling algorithm. Switching contexts also slows \ndown the hardware for a short time\u2014in some cases quite dramatically. As a result, \nwe want to do as few context switches as possible. We have to take a hard look at \nthe typical decrease in the average waiting time and balance that against the con-\ntext switch overhead (hardware system dependent) and the resulting slowdown of \nthe processes.  \nelm49810_ch08_149-180.indd   163\nelm49810_ch08_149-180.indd   163\n12/18/08   11:25:22 AM\n12/18/08   11:25:22 AM\n",
        "category": "Category"
    },
    {
        "id": "491",
        "title": "Title for Chunk 491",
        "content": "Confirming Pages\n164 \nPart 3 CPU and Memory Management\n 8.4.9 A long-term scheduler \n Some OSs also have another scheduler module called a  long-term scheduler. In a \nPC OS with a GUI there normally is not such a scheduler. When the user clicks on an \nicon, a process associated with that icon starts running. In large computer systems with \nbatch-oriented job streams (perhaps in addition to interactive processing) the system \ndoes not automatically start all the jobs that are submitted. Instead, they are put in a \nqueue for starting later. It is the job of the long-term scheduler to decide how many jobs \nto try to run at the same time and which jobs to run when. The first aspect of this deci-\nsion is that there will be some minimum number of jobs that we want to have running \nat the same time. We will start executing at least this minimum number of jobs, assum-\ning that there are more to run than we can run at one time. One aspect of this decision \nhas to do with the level of CPU utilization. If all of the jobs that are running are pri-\nmarily jobs heavily using I/O, the long-term scheduler will try to find some jobs that it \nthinks will raise the level of CPU utilization. To some extent this information may be \nconveyed by accounting information submitted with the job. In other cases the sched-\nuler will just pick one, probably on a FCFS basis. In Chapter 11 we discuss a problem \nthat this approach may cause when memory becomes too full. The long-term scheduler \ncan use most any of the short-term scheduling algorithms instead of FCFS. Since the \nlong-term scheduler runs only once for each process that is started, it does not need to \nbe extremely fast and can spend more resources selecting the next job carefully.  \n 8.4.10 Processor affinity \n We have mentioned several times that there is considerable overhead involved when a \nCPU switches from one process to another. Because of memory caching that the hard-\nware is doing, the execution of the new process will be slowed dramatically for some \nperiod of time until the cache buffers switch from the old process to the new process. \nWe may have some processes in a system that we consider to be much more important \nthan the other processes. Perhaps our system is being set up to be a dedicated database \nserver, for example. We might want that database program to have the very highest \npriority. As a result, in a multiprocessor system it is often possible for the OS to main-\ntain a  processor affinity for a given process. This affinity is value that the OS will use \nto indicate a preference for this process to run on some particular CPU whenever pos-\nsible. In some instances a system administrator may indicate that a particular process \nis to be closely coupled to a particular CPU. In other cases the OS will merely try to \nrun a process on the same CPU it ran on the last time it ran. In some OSs it is possible \nto dedicate a CPU to a process so that only that process will run on that CPU.  \n 8.5 ONE GOOD PROCESS DESERVES ANOTHER \n When a user signals to the Command Interpreter to start a new process, there has \nto be a way for that Command Interpreter process to start the user\u2019s process. The \nCommand Interpreter uses a normal supervisor call to start another process. This \nsupervisor call is known as a  fork. The process that makes the call is called a  parent \nelm49810_ch08_149-180.indd   164\nelm49810_ch08_149-180.indd   164\n12/18/08   11:25:22 AM\n12/18/08   11:25:22 AM\n",
        "category": "Category"
    },
    {
        "id": "492",
        "title": "Title for Chunk 492",
        "content": "Confirming Pages\n \nChapter 8  Process Management: Concepts, Threads, and Scheduling  \n165\nprocess and the process that is started as a result is called a  child process. The entire \nmechanism is referred to as \u201cforking a child,\u201d or sometimes as \u201cspawning a child.\u201d \nSo it is clear that the Command Interpreter needs to be able to start another process, \nbut why would a user application need to do so? The first reason is for performance. \nIf a process has many tasks to do that can be started at the same time, then it can \nstart additional processes to perform some of those tasks and the OS can keep all the \nprocesses running at the same time. This is especially true if the system has multiple \nCPUs. There are other reasons why an application might be broken into several pro-\ncesses. In the next chapter we discuss these at some length.  \n But there are several complications that arise when we let one process start \nanother. For one thing, if the parent process ends for any reason, do we let any child \nprocess continue running or do we end it as well? Most OSs will automatically end \nany child process if the parent process ends. Some do not. In most modern OSs we \ncan have our choice. A child process who\u2019s parent process has ended is known as an \n orphan process. \n Another question has to do with the ownership of resources. If a parent process \nhas a file open, can the child process access the file? Yet another question has to do \nwith the program that is running in the child process. In most cases of a fork call, the \nchild process is an exact copy of the parent process in another block of memory. Note \nthat both the parent process and the child process will next execute the instruction \nfollowing the fork call. An interesting question is, How does each of the processes \nknow which instance is the parent and which is the child? In general, the return code \nfrom the fork call is set to zero for the child process and a positive nonzero number \n(the child process ID) for the parent process. The following code is an example of a \ntypical fork system call: \nint main(void) {\n    pid_t pid = fork();\n    if (pid == 0) {/* If pid=0, we are in the child process.*/\n    do_something(from_the_child);\n    }\n    exit(0);\n    }\n    else if (pid > 0){/* If pid is positive we are in the\n        parent process and pid is the child process id.*/\n    do_something_else(from_the_parent);\n    }\n    exit(0);\n    }\n    Else {/* If pid is negative then there was an error;\n        E.g., the number of running processes reached\n        the maximum. */\n    fprintf(stderr, \u201cCan\u2019t fork, error %d\\n\u201d, errno);\n    exit(1);\n    }\n}\nelm49810_ch08_149-180.indd   165\nelm49810_ch08_149-180.indd   165\n12/18/08   11:25:22 AM\n12/18/08   11:25:22 AM\n",
        "category": "Category"
    },
    {
        "id": "493",
        "title": "Title for Chunk 493",
        "content": "Confirming Pages\n166 \nPart 3 CPU and Memory Management\n Usually having another instance of the parent process run is not what we really want. \nThis is obviously the case with the Command Interpreter. We don\u2019t want another \ncopy of the Command Interpreter. We want it to run some other program. Generally, \nwhat we really want is another program running in a child process. So after the fork \ncall, another call is made to load a new program into the memory space allocated for \nthe child process. This is usually an  exec system call. \n Of course, if what we really want is for another program to run, then the initial \nstep of copying the parent process into another block of memory is a waste of many \nresources. So some OSs provide a different call known as a  shell command. This \ncommand creates a new process but never copies the parent process to the child \nspace\u2014it loads the desired program immediately. Some OSs offer both a fork/exec \npair and a shell command and others only offer one or the other. In some systems a \nhigh-level language library will offer a shell command, but if the OS does not have \na corresponding function call then the library may have to use a fork/exec sequence \nto do the work. \n One last question has to do with the actions of the parent process while the \nchild process runs. In a manner analogous to I/O, which can be either synchronous \nor asynchronous, when a parent process forks a child process it can elect to continue \nexecution itself in parallel with the execution of the child process or it can elect to \nwait until the child process is finished. A parent process might initially elect to con-\ntinue but later need to wait until a child process has finished its work. In such a case \nthere is usually a separate  wait system call that a process can make to put itself into \na Wait state until the child process finishes. \n 8.6 THREADS \n 8.6.1 What is a thread? \n Suppose that we picture the logical address space of a process as the vertical axis on \na graph. As time goes by we keep moving to the right at intervals and making a mark \neverywhere the instruction counter has been in that interval. We might end up with \nsomething like  Figure 8.3 . We could instead imagine that we unwound a thread and \nplaced it on the graph instead of marking the space with a pencil. This is an analogy \nthat gave rise to the phrase \u201c thread of execution. \u201d \n Now suppose that we stopped this process, and saved all the data that represented \nthe CPU state in a table (we might call it a  thread control block, or  TCB ). Then further \nsuppose we started the process over from the beginning. Again we let it run for a time, \nthen stopped it and saved the CPU state in another TCB. We could now go back and \nrestore the saved CPU state of the first thread and resume its execution. How would this \nbe different from running multiple processes? There are several ways that using mul-\ntiple threads can be better than using multiple processes. For one thing, we only have \none copy of the program and data in memory, so we have more memory to use for other \nthings. For another thing, there is a much smaller overhead to switch between threads \nthan to switch between processes since we are only saving the CPU state. Generally \nthis means saving only a few registers (including the instruction pointer) and the pointer \nto the stack space. On some computers this can be done with a single instruction. We \nare not saving accounting data, OS scheduling information, execution statistics, etc. In \nelm49810_ch08_149-180.indd   166\nelm49810_ch08_149-180.indd   166\n12/18/08   11:25:23 AM\n12/18/08   11:25:23 AM\n",
        "category": "Category"
    },
    {
        "id": "494",
        "title": "Title for Chunk 494",
        "content": "Confirming Pages\n \nChapter 8  Process Management: Concepts, Threads, and Scheduling  \n167\naddition, as we have previously discussed, there are hardware performance problems \nwe will cause when we switch the CPU between one process and another. We want to \navoid the heavy overhead of a process context switch whenever we can.  \n Finally, when multiple processes are being used to implement a system, they \nhave a difficult time communicating. This is natural. The OS designers have gone \nto a great deal of trouble to isolate processes from one another so that one process \ncan\u2019t change the contents of memory in another process, intentionally or not. Many \ndifferent mechanisms have been invented to allow cooperating processes to commu-\nnicate. We look at several of them in the next chapter. However, threads don\u2019t have \nthis problem. By definition, all the threads created by a single process are running in \nthe same address space and share both the code and the data. Therefore interthread \ncommunication is trivial\u2014all threads simply access the same variables. The main \ndifficulty is keeping the individual threads from manipulating the same data at the \nsame time. This problem is discussed in depth in the next chapter. \n Actually, when we start a second thread we don\u2019t really start it at the beginning \nof the process. Recall that we just said that the various threads share a single copy of \nthe program code and the data that the process owns. Normally, one of the first things \na process does is to initialize data tables. Since the first thread has already done this \nsetup we don\u2019t want the second thread to redo it. More to the point, the startup of a \nsecond thread is not something that the OS does on its own. It is initiated by the run-\nning process in order to let the system do more work on behalf of the process with-\nout incurring that heavy overhead of a full process context switch. For this reason, \na thread is sometimes called a  lightweight process. As a process is running it will \nreach a point where there is some additional work that can be done in parallel with \nthe work the main thread is doing, so the process (parent thread) will start a child \nthread to do that extra work. In  Figure 8.4 , we see an example of two threads in a \nsingle process. The first thread is shown as a solid line. At some point it calls the OS \nto start a second thread, shown here as a dotted line. Eventually, the OS switches back \nLow Memory\nTime\nHigh Memory\nFIGURE 8.3 \nTracing the \ninstruction counter \nin a process.\nelm49810_ch08_149-180.indd   167\nelm49810_ch08_149-180.indd   167\n12/18/08   11:25:23 AM\n12/18/08   11:25:23 AM\n",
        "category": "Category"
    },
    {
        "id": "495",
        "title": "Title for Chunk 495",
        "content": "Confirming Pages\n168 \nPart 3 CPU and Memory Management\nto the first thread again. Both of these switches were done without the overhead of \na context switch between processes. And if the system has multiple CPUs or a CPU \nthat is capable of running multiple threads at the same time, then both of the threads \ncan literally run at the same time.  \n One example of how threads work can be seen in a word processing program. \nAs this is being written a check shows that the word processor has 18 threads run-\nning. Some are fairly obvious, but it is hard to come up with 18:\n \ufffd foreground keystroke handling \n \ufffd display updating \n \ufffd spelling checker \n \ufffd grammar checker \n \ufffd repagination \n \ufffd \u201csmart tag\u201d recognition \n \ufffd periodic file save \n Another example is commonly seen in server applications such as a Web server. \nOne thread will wait for incoming HTTP requests. For each incoming request a new \nthread is started. The thread will do (at least these) several steps:\n \ufffd Parse the incoming request \n \ufffd Look up the requested file \n \ufffd Read the page \n \ufffd Format it for output \n \ufffd Request the transmission of the page \n \ufffd Exit \nLow Memory\nFirst thread\nresumes\nSecond thread\ncreated here\nTime\nHigh Memory\nTCB 1\nTCB 2\nThread 1\nThread 2\nFIGURE 8.4 \nMultiple threads \nin a process sharing \nall code and data.\nelm49810_ch08_149-180.indd   168\nelm49810_ch08_149-180.indd   168\n12/18/08   11:25:23 AM\n12/18/08   11:25:23 AM\n",
        "category": "Category"
    },
    {
        "id": "496",
        "title": "Title for Chunk 496",
        "content": "Confirming Pages\n \nChapter 8  Process Management: Concepts, Threads, and Scheduling  \n169\n This sequence keeps the handling of each request in a separate thread of execution \nand makes the program logic much simpler than having a single process keep track \nof the state of hundreds or thousands of individual requests. \n 8.6.2 User-level threads versus kernel-level threads \n Historically, the use of multiple processes came before the idea of threads. When \nprogrammers realized that switching between processes used so many resources and \nslowed things down so much they begin to develop the concept of threads. However, \nthe OSs of the time did not have threads built in to them. So the original develop-\nment of threads was done as a set of library subroutines. Of course, this meant that \nthe entire thread package ran in user mode and the OS was unaware that an applica-\ntion was trying to keep multiple activities running in parallel. Accordingly, if any of \nthe threads in a process made a system call that would block for some reason, the \nentire application, including all the threads of that application, would be blocked at \nthe same time. Such a thread package is referred to as a  user-level thread package \nbecause it runs entirely in user mode. Designing programs that utilize such user \nthread libraries must therefore be done very carefully so that one thread does not put \nthe entire process to sleep. \n Eventually, however, OS designers decided that threads were such a good idea \nthat they would incorporate the thread functions into the kernel. Now the OS was \naware that the application was using threads. In many circumstances the OS did not \nneed to block an entire process if a single thread did a blocking call to the OS. Such \nthread packages are called  kernel-level threads. Also, since the OS is aware of the \nindividual threads, it is possible for the threads to execute on separate CPUs in a \nmulti-CPU system. This is a major advantage for kernel-level threads, especially in \nan era when a multicore CPU system will soon be the normal case for average work-\nstations rather than something found only in powerful servers. \n In general, kernel threads are much easier to use than user threads because the \nprogrammer does not have to avoid blocking calls. This makes the programming \nmodel much easier. For example, consider writing a Web server using threads. The \napplication sits in a loop, waiting for requests in HTTP commands to come in from \nthe network. When a request comes in to return a page, the main application thread \nstarts a separate thread to handle the request and goes back to waiting for more \nrequests. Now the child thread has a very simple task, as we outlined before. It parses \nthe HTTP request, looks up the page on the disk, reads the page in a series of reads, \nformats the page into HTTP messages, sends the answer back (assuming the page \nwas found), and exits. This makes each thread very straightforward since it does not \nhave to be designed to cope with multiple requests at the same time. The alternative \nwould be for the main application to issue asynchronous calls for each of the I/O \noperations. While this is certainly possible, it is a much more complex model and it \nis difficult to take advantage of a multiprocessor system. \n A later development is a user-level thread package that is designed to give \nsome of the advantages of the simplicity of programming one gets with kernel-level \nthreads without relying on kernel-level thread support. Such packages are called \nelm49810_ch08_149-180.indd   169\nelm49810_ch08_149-180.indd   169\n12/18/08   11:25:23 AM\n12/18/08   11:25:23 AM\n",
        "category": "Category"
    },
    {
        "id": "497",
        "title": "Title for Chunk 497",
        "content": "Confirming Pages\n170 \nPart 3 CPU and Memory Management\n green threads. Green thread libraries capture blocking system calls and turns them \ninto nonblocking calls. They then handle scheduling of the various user threads. This \nmodel allows a program to run unmodified in either mode by loading with the kernel-\nlevel thread library or with the green user thread library. However, there are some \ndisadvantages to this approach. First, if the system is a multi-CPU system, the indi-\nvidual threads will not take advantage of the multiple CPUs because the kernel is not \naware of them. As we have mentioned, the trend in processors is that most systems \nalready include multiple CPUs. Second, kernel-level threads can be scheduled pre-\nemptively, so a thread that takes too long to do its job cannot dominate the system. \nGreen threads do not offer this level of control.  \n 8.6.3 Thread support models \n When OSs began to offer kernel thread packages, the application programmers were \nnot anxious to rewrite their applications just to use kernel threads. So the OS design-\ners would take the existing user thread libraries and rewrite them so that they would \nuse the mechanisms provided by the kernel threads. There are three common meth-\nods for making the user library routines utilize kernel threads. The main question \nthat distinguishes them is the method of mapping the user threads to kernel threads. \nThe three methods are one-to-one, many-to-one, and many-to-many.  One-to-one \nmapping is fairly simple. When the application calls the library routine to create a \nnew thread, the library routine calls the kernel thread mechanism to create a new ker-\nnel thread.  Figure 8.5 shows a schematic diagram of the one-to-one thread mapping \nmodel. This model has the advantages of being fast and very simple to develop and \nfor the user to understand. Although other models appear to give the user more con-\ntrol, they are significantly more complex to use and therefore more prone to errors. \nMost OS vendors are moving away from the more complex models on the grounds \nthat the advantages of finer control are outweighed by the disadvantages. \n The second mapping model is called  many-to-one. Recall that the user library \nthat is being modified will block the entire process when any thread in the applica-\ntion makes a blocking call to the OS. In that case, this model will do exactly the same \nthing. Only one kernel thread is created and all the user threads will be mapped onto \nthat same kernel thread.  Figure 8.6  shows the many-to-one thread mapping model. \nKernel \nThread \n1\nKernel \nThread \n2\nKernel \nThread \n3\nUser \nThread \n1\nUser \nThread \n2\nUser \nThread \n3\nFIGURE 8.5 \nThe one-to-one \nthread mapping \nmodel.\nelm49810_ch08_149-180.indd   170\nelm49810_ch08_149-180.indd   170\n12/18/08   11:25:24 AM\n12/18/08   11:25:24 AM\n",
        "category": "Category"
    },
    {
        "id": "498",
        "title": "Title for Chunk 498",
        "content": "Confirming Pages\n \nChapter 8  Process Management: Concepts, Threads, and Scheduling  \n171\nThis model is less desirable than the one-to-one model because it does not offer \nthe advantages of kernel threads. It is used only when an operating system has no \nkernel thread support. The single \u201ckernel thread\u201d in this case is the running process \nitself.  \n The last model is called  many-to-many. In this model the programmer will tell \nthe system something about how many user threads and kernel threads will be needed \nand how they should be mapped. The basic idea is to have a group of kernel threads \navailable and dynamically assign user threads to them as they are needed. It may also \nbe possible to have multiple groups of user and kernel threads and to specify that some \nuser threads are bound to a single kernel thread.  Figure 8.7  illustrates the many-to-\nmany thread mapping model. As was mentioned before, this model theoretically gives \nthe user finer control over the behavior of the entire system, but it is more difficult to \nuse correctly and is losing favor since modern systems have such large memories and \nspeedy processing that the performance gain perceived by the user is very slight and \nnot worth the programming problems that come with using the more complex model. \n Although threads are easier to create and destroy than processes, there is still \nsome overhead involved in creating them. As a result, some thread packages will \ncreate a group of thread structures when the procedure first calls the thread package. \nThis group is called a  thread pool. When the parent thread calls for a new thread, \none structure is taken from the pool, initialized for the specific thread, and used. \nWhen that thread exits the structure is returned to the pool. \nKernel \nThread \n1\nUser \nThread \n2\nUser \nThread \n3\nUser \nThread \n1\nFIGURE 8.6 \nThe many-to-one \nthread mapping \nmodel.\nUser \nThread \n1\nUser \nThread \n2\nUser \nThread \n3\nKernel \nThread \n1\nKernel \nThread \n2\nKernel \nThread \n3\nFIGURE 8.7 \nThe many-to-many \nthread mapping \nmodel.\nelm49810_ch08_149-180.indd   171\nelm49810_ch08_149-180.indd   171\n12/18/08   11:25:24 AM\n12/18/08   11:25:24 AM\n",
        "category": "Category"
    },
    {
        "id": "499",
        "title": "Title for Chunk 499",
        "content": "Confirming Pages\n172 \nPart 3 CPU and Memory Management\n One problem with threads is that not all library subroutines are prepared to be \ncalled multiple times without completing one call before another call starts. (This is \ncalled \u201c reentrancy. \u201d) This is specifically a problem when a process is running on \na system with multiple CPUs. Suppose a library routine is called by a thread and it \nuses a static local variable during its work. Now another thread of the same process \nrunning on another CPU calls the same library routine and it tries to use the same \nstatic local variable. It is easy to see that there will be a problem here. The library \nroutine should be able to handle this situation by always allocating local variables \non the stack. Libraries that are coded in this way are called  thread-safe, and most \nmodern libraries are thread-safe. \n 8.6.4 Simultaneous multithreading \n In simultaneous multithreading (SMT), instructions from more than one process can \nbe executing in a single CPU at one time. The hardware essentially creates a second \n\u201clogical\u201d CPU. This CPU is not a completely distinct CPU since it shares many \nresources between two logical CPUs. The term \u201cmultithreading\u201d is somewhat mis-\nleading since the executing threads can be from distinct processes. The largest gains \ncome when one process tries to access data that is not in the cache. Without the SMT \nthe CPU would be idle until the data are ready. Other small gains can come when \nparts of the CPU are not being used by one process and can be used by the other. \n The main additions to the CPU are the ability to load instructions from more than \none thread (or process) during a cycle and a duplicate set of registers to hold data from \neach thread. A second addition concerns some memory management hardware that we \nhave not looked at yet. On most machines there is a memory addressing cache called \nthe translation lookaside buffer, or TLB. The problem here is that each TLB entry must \ncontain data that identifies which logical CPU each entry is for because the two logical \naddress spaces could not otherwise be distinguished by the hardware. The greatest gain \nfrom the SMT architecture will come when both of the CPUs are running threads from \na single process since they will be able to share the resources more effectively. Chip \ndesign complexity generally limits the number of logical CPUs to two. Measuring the \neffectiveness of SMT can be difficult. In some cases an increase of performance of \n30% or more can be seen, but in a few cases the performance actually decreases. The \nmost common implementation of SMT today is Intel\u2019s Hyper-Threading\u2122.  \n 8.6.5 Processes versus threads \n Threads and processes are both methods of adding parallelization to an application. \nProcesses are independent entities, each containing its own state information and \naddress space. They only interact with one other via interprocess communication \nmechanisms through the OS. Applications are typically divided into processes dur-\ning the design phase. A single controlling process invokes the other processes when \nit makes sense to logically separate significant application functionality. In other \nwords, processes are a design concept. \n By contrast, a thread is a coding technique that doesn\u2019t affect the architecture of \nan application. A single process often contains multiple threads. All the threads in a \nelm49810_ch08_149-180.indd   172\nelm49810_ch08_149-180.indd   172\n12/18/08   11:25:24 AM\n12/18/08   11:25:24 AM\n",
        "category": "Category"
    },
    {
        "id": "500",
        "title": "Title for Chunk 500",
        "content": "Confirming Pages\n \nChapter 8  Process Management: Concepts, Threads, and Scheduling  \n173\nprocess share the same state and same memory space and they implicitly communicate \nwith each other directly by manipulating the shared data. \n Threads typically are created for a short-term use that is usually thought of as \na serial task that does not have to be executed in sequence but rather can be run in \nparallel. They are then deconstructed when no longer required. The scope of a thread \nis within a specific code module so that we can introduce threading into a process \nwithout affecting the overall application design. \n 8.7 CASE STUDIES \n We have discussed processes and threads using an ideal model that is intended to \nexplain their various features. In the real OS world, no OS works exactly as we have \ndescribed. In addition, although the model may be very close to reality, the terminol-\nogy used by the OS documentation may differ from our model. In this section we \ncover a few modern systems and show how they differ from our idealized model and \ndiscuss their terminology a bit. \n 8.7.1 POSIX threads \n We have previously explained about the POSIX standards that attempt to bring some \nuniformity to the UNIX APIs that had proliferated so wildly. One of these standards \nhas to do with threads. This standard is so well known that it goes by the special \nname  Pthreads. Beyond UNIX, however, POSIX libraries are available on many \nOSs because of the large number of programs that have been implemented with these \nAPI system calls. You may recall that even the Windows NT family has a library \nthat supports some POSIX API system calls at the source level. Because of this \nwide availability POSIX threads have a real niche: They provide a very high level \nof portability for an application. The standard is so well known that there is even an \nimplementation of them in an IBM Fortran compiler!  2 It is important to remember, \nhowever, that POSIX is not a package, it is a standard. Each implementer is free to \nimplement the services in any way seen fit. \n Any implementation of POSIX threads can be written as purely a user thread \npackage. But if the OS supports kernel threads, then the POSIX thread package is \nusually implemented using either the one-to-one or many-to-many models. This \nshows the downside of the POSIX thread standard when developing an applica-\ntion to run with the POSIX API. If the system is to be run on a package where \nthe implementation will utilize user-level threads, then a single blocking call in any \nthread will block the entire process. But if the package will support kernel-level \nthreads, then the OS can run multiple threads for a single process at the same time. \nTherefore, if an application programmer really wants to take full advantage of mul-\ntithreading regardless of the particular package to be used, then the program must \nbe written with asynchronous I/O operations to avoid blocking the entire process. \nAs a result, if the program is running in an environment where the implementation \nis using kernel-level threads and will not block an entire process because one thread \n2 www-4.ibm.com/software/ad/fortran \nelm49810_ch08_149-180.indd   173\nelm49810_ch08_149-180.indd   173\n12/18/08   11:25:24 AM\n12/18/08   11:25:24 AM\n",
        "category": "Category"
    },
    {
        "id": "501",
        "title": "Title for Chunk 501",
        "content": "Confirming Pages\n174 \nPart 3 CPU and Memory Management\nissues a blocking call, the effort that was spent developing the program with the \nasynchronous calls has been wasted. This is the price that the developers had to pay \nto gain the portability of POSIX. \n There are over 60 functions available in the Pthreads standard. Only 22 of these \nhave to do with the basic functioning of the threads themselves. The other two-thirds \nare related to synchronization and interprocess communication. We address these \nadditional topics in the next chapter. \n 8.7.2 Windows NT \n None of the OSs that we are discussing implements threads and processes exactly \naccording to the way we have been describing them. Windows NT is the first such \nexample. NT does implement processes, but it does not schedule processes. Instead, \nit implements a thread for every process, even if the application never indicates that \nit wants to use threads. NT schedules the threads instead of the processes. In this \nway the kernel only has to worry about one sort of scheduled entity, a thread. Some \ninformation is kept in a process control block and some is kept in a thread control \nblock. If the application never calls a thread package to create any more threads, then \nonly the first thread is used. \n The scheduling mechanism in NT is a multilevel feedback queue. It uses 32 \nqueues. See  Figure 8.8 . The top 16 queues are considered to be \u201creal-time\u201d queues. \nNormal applications run in the bottom 16 queues. NT will always service all the \nthreads that are in the ready state at a higher-level queue before it will service a thread \nin a lower-level queue. In addition, NT is preemptive. If a thread has been waiting \nfor an event and the event happens, then if the thread that is currently running is of a \nlower priority than the thread that had just become ready, then the running thread will \nbe preempted and the thread that just became ready will be run. As threads run, if they \nfinish their time quantum without doing any blocking I/O operation, then they will be \n31\nReal-time\n(fixed)\nI\nD\nL\nE\nN \nO\nR\nM \n\u2013\nN \nO\nR\nM\nH \nI\nG \nH\n+ \nN \nO\nR\nM\nCritical\nNormal\n(Dynamic)\n30\n29\n28\n27\n26\n25\n24\n23\n22\n21\n20\n19\n18\n17\n16\n15\n14\n13\n12\n11\n10\n9\n8\n7\n6\n5\n4\n3\n2\n1\n0\nWorker\nThreads\nFIGURE 8.8 \nNT thread priority \nrelationships.\nelm49810_ch08_149-180.indd   174\nelm49810_ch08_149-180.indd   174\n12/18/08   11:25:24 AM\n12/18/08   11:25:24 AM\n",
        "category": "Category"
    },
    {
        "id": "502",
        "title": "Title for Chunk 502",
        "content": "Confirming Pages\n \nChapter 8  Process Management: Concepts, Threads, and Scheduling  \n175\ndemoted to the next lower level. The assumption is that the thread is acting more like \na background task than a foreground task\u2014it is computationally intensive\u2014so we \nwill run it less often. Similarly, threads that do not complete their time quantum will \neventually be promoted to a higher-level queue. When a thread is created it will have \nassociated with it a maximum priority level and a minimum priority level. The thread \nwill not be promoted or demoted past the associated priority limits.  \n Since the main intent of a personal computer with a GUI is to enable a user to \nget work done more efficiently, the threads associated with the GUI usually run at a \nhigher priority than threads that are running the processing aspects of an application. \nIn addition, one window will always be the window that has the focus. Any threads \nthat are associated with the window that has the focus will be temporarily promoted \nseveral queue levels and will have their time quantum multiplied by three. This pro-\nmotion will help to ensure that the user\u2019s actions are responded to quickly and that \nthe threads are able to complete their task without being preempted. \n The lowest priority is reserved for a job that is called the system idle task. This \nthread will run only when no other thread in the system is ready to run. In many cases \non a personal workstation this thread will often consume about 98% of the available \nCPU time. Our personal computers are often much faster in this respect than we need \nthem to be for many tasks that we do. This vast amount of available CPU cycles is \nbeginning to be tapped in such applications as SETI  3 and GIMPS.  4 These programs \nuse the idle CPU cycles on volunteer computers to processes batches of data for \nlarge-scale scientific experiments. The data are downloaded and updated over the \nInternet. These systems are similar to  grid computing, a technique that attempts to \ntap these unused CPU cycles in the desktop computers in a campus environment to \nrun some programs that are computationally intensive. This concept was discussed \nin Chapter 7 and is explained further in Chapter 17. \n Windows NT can also be used as a server. In general, the code is the same for \nthe server version of the software as it is for a personal workstation. The main differ-\nences are in the values assigned to the system tuning parameters. One example is that \nthe time quanta for the various queues are six times longer than the same queues in \nthe workstation version. You should recall that switching program contexts is consid-\nered overhead rather than useful work, so we want to avoid it when we don\u2019t need it. \nIn a workstation the entire focus is on the user and there are many idle CPU cycles \nanyway, so we will pay the extra penalty to make the OS more responsive to those \ninputs. In a server environment we are more concerned with overall throughput to \nmany service requests and we have less idle CPU time so we increase the time quan-\ntum and as a result we spend less time in the context switches. \n 8.7.3 Solaris \n The Solaris OS threading support has been a staple for OS discussions for some time \nbecause the architecture was quite complex and offered the programmer a choice \nof models to use to achieve the best possible balance between a user-level thread \n3 http://setiathome.berkely.edu/ \n4 http://www.mersenne.org/ \nelm49810_ch08_149-180.indd   175\nelm49810_ch08_149-180.indd   175\n12/18/08   11:25:25 AM\n12/18/08   11:25:25 AM\n",
        "category": "Category"
    },
    {
        "id": "503",
        "title": "Title for Chunk 503",
        "content": "Confirming Pages\n176 \nPart 3 CPU and Memory Management\nimplementation and a kernel-level thread implementation. The basic model used by \nSolaris has been a many-to-many model. Solaris created a structure called a \u201clight-\nweight process,\u201d or  LWP. A LWP was the unit that was set to run on a processor by \nthe operating system. User-level threads were bound to LWPs. An application pro-\ngrammer had considerable flexibility on how the threads were bound to the LWPs. \nThreads could be created in groups. On the one hand, the program could ask for a \nsingle thread to be bound to a single LWP. Thus, the programmer could approximate \nthe one-to-one model, although the library routines would be somewhat slower than \na library created for a pure one-to-one model because it also supported more com-\nplex mappings. For example, the program could ask for M threads and N LWPs to be \nin one group. In a group, if a particular thread made a blocking call, then the LWP \nthat was bound to that thread would be blocked. But other LWPs in that group would \nnot automatically be blocked, and user threads in that group could be dynamically \nassigned to the LWPs whenever one was ready to run. Additionally, for really high \nperformance applications, a \u201cprocessor affinity\u201d could be specified, as was men-\ntioned earlier in this chapter. This mechanism allowed only the LWPs bound to that \napplication to be run on that CPU (or CPUs). \n However, beginning with Solaris release 8 this elaborate mechanism was being \nphased out. The OS designers at Sun determined that all this mechanism is not worth \nthe trouble. Probably as a reflection of the continuing decrease in the cost of memory, \nthis complex model is being gradually withdrawn. A new alternative thread library \ncalled the T2 library has been created. It supports only the one-to-one model. The \nolder library was still supported in Solaris 8. However, as of Solaris release 9 the \nT2 model became the standard library and the older model is being phased out. Sun \nexpects the increased simplicity of the library to result in faster operation in most \ncases and in fewer bugs and support issues. The model should be simpler for the \nprogrammers and system administrators as well. \n 8.7.4 Linux \n The approach Linux takes to procedures and threads is also different from our basic \nmodel. Official Linux literature does not use either of those terms (though many \nwriters do). Instead, they speak of  tasks. A task is equivalent to what we have been \ncalling a procedure. Linux supports the  fork system call with the same effect as most \nUNIX systems, but it uses a memory management technique called copy-on-write \nto create the child task. This technique allows the child task to be created with very \nlittle overhead. Copy-on-write will be discussed further in Chapter 11. Differences \narise in Linux when a primary task starts another task with the  clone system call. \nHere is the syntax for the clone system call: \n#include <sched.h> \nint clone(int (*fn)(void *), void *child_stack, int flags, \nvoid *args);  \nThe first difference is that with a fork system call both the parent task and the child \ntask will continue execution with the next instruction after the call. In the clone sys-\ntem call, a function name ( *fn ) is passed as an argument to the system call. The par-\nent task returns and continues at the next instruction after the fork, but the child task \nelm49810_ch08_149-180.indd   176\nelm49810_ch08_149-180.indd   176\n12/18/08   11:25:25 AM\n12/18/08   11:25:25 AM\n",
        "category": "Category"
    },
    {
        "id": "504",
        "title": "Title for Chunk 504",
        "content": "Confirming Pages\n \nChapter 8  Process Management: Concepts, Threads, and Scheduling  \n177\nwill instead call the function that was passed as an argument. When that function \nexits the child task ends and the value of the function is returned to the parent task as \na return code. This is similar to the way that thread calls work in other OSs. \n The other major difference with the clone call has to do with the information \nshared between the parent and child tasks. Normally, all threads running in a single \ntask (or process) share the code segment, data segment, and other resources such as \nopen files, but each thread has its own thread control block to save the CPU state and \nits own stack (possibly two stacks, one for user mode and one for kernel mode). Under \nLinux, when a task clones a child task it provides a bit mask that specifies which ele-\nments the child task will share with the parent. Some of the flags available to the clone \ncall are:\n \ufffd CLONE_VM\u2014share the entire memory space \n \ufffd CLONE_FILES\u2014share file descriptors \n \ufffd CLONE_SIGHAND\u2014share signal handlers \n \ufffd CLONE_PID\u2014share PID (Process ID) \n \ufffd CLONE_FS\u2014share file system \n As an example of how these flags might make things different, if the child and par-\nent task do not share the same file system, then if the child task executes a chdir \ncall, changing the current working directory, the current directory for the parent task \nwill not change. If the two tasks share the same file system then both tasks will see \nthe change. The clone call can be used to create a new task such that the new task \nis equivalent to a new process in most OSs. This is done simply by sharing nothing \nbetween the parent task and the child task. Starting a task that is the equivalent to a \nthread in most OSs involves sharing everything except the process ID.  \nclone (CLONE_VM| CLONE_FS| CLONE_FILES| CLONE_SIGHAND, 0);\n Before executing the clone system call, the parent process will allocate the stack \nspace for the child task. It will pass to the clone call a pointer to the stack space that \nwas set up for the child ( * child_stack ). It will have to decide how much space is \nrequired for the operations the child process will perform. Typically this will be set \nthe same as for the parent process. The last parameter to the clone call is a pointer to \nthe arguments that will pass to the function that the child process will execute. \n 8.7.5 Java \n The Java programming language and runtime environment is an interesting example \nof threads because Java is a language rather than an OS. Java supports threads at \nthe language level rather than through subroutine calls, as is done with other pro-\ngramming languages. Java, of course, is implemented on many different OSs. Java \nthreads originally had the same problem as do POSIX threads\u2014there was no way of \nknowing whether the program would be executing with kernel-level threads or with \nuser-level threads. So Sun has implemented two thread libraries for Java, including \na \u201cgreen\u201d library that can be implemented without kernel-level thread support but \nstill provides the same nonblocking model as is provided with kernel-level threads. \nDepending on the OS these libraries might be based on kernel-level threads or might \nbe based on user-level threads. \nelm49810_ch08_149-180.indd   177\nelm49810_ch08_149-180.indd   177\n12/18/08   11:25:25 AM\n12/18/08   11:25:25 AM\n",
        "category": "Category"
    },
    {
        "id": "505",
        "title": "Title for Chunk 505",
        "content": "Confirming Pages\n178 \nPart 3 CPU and Memory Management\n 8.8 SUMMARY \n In this chapter, we defined the state of a process and \nhow that state is captured in the contents of a process \ncontrol block. We then defined various models for \nthe states of a process in the system and the events \nthat cause transitions from one state to another. We \nthen covered the various algorithms that are used \nto schedule processes in OSs and discussed how \nto evaluate them using deterministic modeling. We \nwrapped up the discussion of processes with a brief \ndiscussion of process forking. \n Next, we defined a thread and discussed the \ndifferences between processes and threads. Then \nwe explained the difference between user-level \nthreads and kernel-level threads. Next, we showed \nvarious ways that user-level threads could be \nmapped onto kernel-level threads. Finally, we cov-\nered the implementation of threads in modern OSs \nand discussed a couple of special cases of thread \nmechanisms. \n In the next chapter of the book we discuss how \nprocesses can communicate and cooperate and some \nof the problems involved in these areas. They are \nnot as simple as they might seem at first. \n BIBLIOGRAPHY \n Abbot, C., \u201cIntervention Schedules for Real-Time \nProgramming,\u201d  IEEE Transactions on Software \nEngineering, Vol. SE-10, No. 3, May 1984, \npp. 268\u2013274. \n Bach, M. J.,  The Design of the UNIX Operating System. \nEnglewood Cliffs, NJ: Prentice Hall, 1986. \n Brinch Hansen, P., \u201cThe Nucleus of a Multiprogramming \nSystem,\u201d  Communications of the ACM, Vol. 13, \nNo. 4, April 1970, pp. 238\u2013241. \n Henry, G. J., \u201cThe Fair Share Scheduler,\u201d  Bell Systems \nTechnical Journal, Vol. 63, No. 8, Part 2, October \n1984, pp. 1845\u20131857. \n Jensen, E. D., C. D. Locke, and H. Tokuda, \u201cA Time-\nDriven Scheduling Model for Real-Time Operating \nSystems,\u201d  Proceedings of the IEEE Real-Time \nSystems Symposium, December 3\u20136, 1985, \npp. 112\u2013122. \n Kay, J., and P. Lauder, \u201cA Fair Share Scheduler,\u201d \n Communications of the ACM, Vol. 31, \nNo. 1, January 1988, pp. 44\u201355. \n Liu, C. L., and J. W. Layland, \u201cScheduling Algorithms \nfor Multiprogramming in a Hard-Real-Time \nEnvironment,\u201d  Journal of the ACM, Vol. 20, \nNo. 1, January 1973, pp. 46\u201361. \n Woodside, C. M., \u201cControllability of Computer \nPerformance Tradeoffs Obtained Using Controlled-\nShare Queue Schedulers,\u201d  IEEE Transactions on \nSoftware Engineering, Vol. SE-12, No. 10, October \n1986, pp. 1041\u20131048. \n REVIEW QUESTIONS \n \n8.1 What is a PCB?\n a. A class of toxic chemical compounds \n b. A process control block \n c. A program counter boundary \n d. A partially completed buffer \n e. None of the above \n WEB RESOURCES \n http://web.cs.mun.ca/~paul/cs3725/material/web/notes/\nnode19.html (Allocation of processes to a processor)\n http://www-4.ibm.com/software/ad/fortran (IBM Fortran \ncompilers)\nelm49810_ch08_149-180.indd   178\nelm49810_ch08_149-180.indd   178\n12/18/08   11:25:25 AM\n12/18/08   11:25:25 AM\n",
        "category": "Category"
    },
    {
        "id": "506",
        "title": "Title for Chunk 506",
        "content": "Confirming Pages\n \nChapter 8  Process Management: Concepts, Threads, and Scheduling  \n179\n \n8.2 In the context of processes, the word \u201cstate\u201d is \noverloaded. Distinguish between the two mean-\nings of this word with respect to processes. \n \n8.3 How many unique OS states can a process be in? \n \n8.4 How many queues are there in the ready state? \n \n8.5 How many queues are there in the wait state? \n \n8.6 Why do we care if a process scheduler is fair? \n \n8.7 The SRTF process scheduling algorithm is opti-\nmum, so why do we not use it as it was described \ninitially? \n \n8.8 Since FCFS process scheduling is so fair, what is \nthe problem with it? \n \n8.9 Why do systems with GUIs generally not have a \nlong-term scheduler? \n 8.10 What is the purpose of processor affinity? \n 8.11 What does a process do to start another process? \n 8.12 Distinguish between a process and a thread. \n 8.13 Why do we usually say that kernel-level threads \nare better than user-level threads? \n 8.14 User-level thread packages were developed before \nkernel-level thread packages. When kernel-level \nthreads were made available, users did not want \nto throw out or rewrite their multithreaded appli-\ncations. So the user-level thread packages were \nrecoded to work with kernel-level threads. What \nwere the three models we spoke of that were used \nto map user-level threads to kernel-level threads? \n 8.15 What do we mean when we say that a library is \n\u201cthread safe\u201d? \n 8.16 True or false? Simultaneous multithreading refers \nto having multiple processes create threads at the \nsame time. \n 8.17 POSIX threads would appear to be ideal in the \nsense that they are ubiquitous. What is the major \ndrawback to POSIX threads? \n 8.18 What is unique about Windows NT process \nscheduling? \n 8.19 What is unique about Linux process scheduling? \n 8.20 Solaris provided an elaborate mechanism for \nmapping user-level threads to \u201clightweight\u201d pro-\ncesses. Why was this done? \n 8.21 What is unusual about Java threads?  \nelm49810_ch08_149-180.indd   179\nelm49810_ch08_149-180.indd   179\n12/18/08   11:25:26 AM\n12/18/08   11:25:26 AM\n",
        "category": "Category"
    },
    {
        "id": "507",
        "title": "Title for Chunk 507",
        "content": "elm49810_ch08_149-180.indd   180\nelm49810_ch08_149-180.indd   180\n12/18/08   11:25:26 AM\n12/18/08   11:25:26 AM\n",
        "category": "Category"
    }
]